{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score,log_loss, mean_absolute_error,median_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "def makefile(what,filename):\n",
    "    with open(filename,\"wb\") as f3:\n",
    "        pickle.dump(what,f3)\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename,\"rb\") as f4:\n",
    "        ans=pickle.load(f4)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[\"Lenna.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2=Image.open(\"Lenna.png\").resize([32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FA134429310>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.rotate(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.4964 - val_loss: 47.0583\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 44.6931 - val_loss: 41.3572\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 40.9610 - val_loss: 40.0628\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 38.7518 - val_loss: 39.1128\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 38.5250 - val_loss: 40.3225\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 37.4665 - val_loss: 37.4738\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 36.0504 - val_loss: 36.4793\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 35.8873 - val_loss: 36.9803\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 36.2102 - val_loss: 38.3420\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 35.1760 - val_loss: 37.2378\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 34.2547 - val_loss: 34.1353\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 33.0232 - val_loss: 33.8830\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 698us/step - loss: 32.8391 - val_loss: 33.0595\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 32.9338 - val_loss: 33.7201\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 688us/step - loss: 32.7600 - val_loss: 32.6872\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 32.5611 - val_loss: 33.1211\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 880us/step - loss: 32.0713 - val_loss: 32.3502\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 855us/step - loss: 32.3321 - val_loss: 33.6408\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 861us/step - loss: 31.7122 - val_loss: 34.0086\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 821us/step - loss: 30.9144 - val_loss: 31.3822\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 889us/step - loss: 31.0055 - val_loss: 33.1410\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 807us/step - loss: 30.9776 - val_loss: 32.0235\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 696us/step - loss: 30.2194 - val_loss: 30.9467\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 31.3732 - val_loss: 35.0643\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 31.7510 - val_loss: 34.4132\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 689us/step - loss: 30.8459 - val_loss: 30.6568\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 29.5609 - val_loss: 30.2374\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 688us/step - loss: 29.7999 - val_loss: 31.9044\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 735us/step - loss: 29.0088 - val_loss: 29.6275\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 691us/step - loss: 29.4997 - val_loss: 30.1673\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 28.5137 - val_loss: 29.4629\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 696us/step - loss: 29.8225 - val_loss: 30.7133\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 715us/step - loss: 28.7843 - val_loss: 29.1483\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 28.9395 - val_loss: 30.1406\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 689us/step - loss: 29.0285 - val_loss: 29.1852\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 837us/step - loss: 27.6144 - val_loss: 29.7619\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 806us/step - loss: 27.2526 - val_loss: 28.9049\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 858us/step - loss: 27.0690 - val_loss: 28.0363\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 816us/step - loss: 27.0131 - val_loss: 30.4824\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 847us/step - loss: 28.2743 - val_loss: 28.5435\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 703us/step - loss: 26.7763 - val_loss: 28.2342\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 847us/step - loss: 27.8038 - val_loss: 31.3165\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 804us/step - loss: 27.7575 - val_loss: 28.5945\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 80.4974 - val_loss: 56.2680\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 51.2839 - val_loss: 49.1657\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 700us/step - loss: 46.6245 - val_loss: 48.8910\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 696us/step - loss: 44.3435 - val_loss: 45.2570\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 700us/step - loss: 41.2682 - val_loss: 43.9525\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 42.0336 - val_loss: 44.7798\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 40.2934 - val_loss: 41.8674\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 698us/step - loss: 43.9217 - val_loss: 44.2759\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 736us/step - loss: 40.5907 - val_loss: 42.4919\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 38.9535 - val_loss: 39.7928\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 38.1859 - val_loss: 40.0303\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.6638 - val_loss: 39.3963\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.0082 - val_loss: 39.1390\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.4806 - val_loss: 39.3022\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.7728 - val_loss: 37.1699\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.3468 - val_loss: 36.4507\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 35.1640 - val_loss: 37.0587\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.5893 - val_loss: 40.2317\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.8301 - val_loss: 38.2421\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.2913 - val_loss: 35.4409\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.4427 - val_loss: 35.3986\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 34.0088 - val_loss: 36.5073\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.4763 - val_loss: 34.8235\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.2859 - val_loss: 36.2406\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 34.1215 - val_loss: 36.3386\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.2477 - val_loss: 37.8290\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.4603 - val_loss: 33.3270\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.4745 - val_loss: 35.3548\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.7206 - val_loss: 32.1284\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.7021 - val_loss: 32.1478\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.1536 - val_loss: 30.9235\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.6231 - val_loss: 30.3341\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 28.7401 - val_loss: 28.7374\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.1580 - val_loss: 29.5359\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.0815 - val_loss: 28.2919\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 26.5089 - val_loss: 27.2328\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.9141 - val_loss: 26.6978\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.4923 - val_loss: 26.1850\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.1246 - val_loss: 26.2107\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.1047 - val_loss: 25.7327\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.7107 - val_loss: 25.4528\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 24.7443 - val_loss: 25.3791\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.4533 - val_loss: 25.1308\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.2125 - val_loss: 25.1285\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.0688 - val_loss: 24.8137\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.0289 - val_loss: 24.7030\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.6971 - val_loss: 24.6087\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.5039 - val_loss: 24.5038\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.5161 - val_loss: 24.7960\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.3596 - val_loss: 24.2850\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.1900 - val_loss: 24.1149\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.1004 - val_loss: 24.1049\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.8532 - val_loss: 23.9497\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.6968 - val_loss: 23.8704\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.6187 - val_loss: 23.8097\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.4866 - val_loss: 23.7193\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.5156 - val_loss: 23.5323\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.8749 - val_loss: 23.6219\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.2905 - val_loss: 23.4374\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.0963 - val_loss: 23.3241\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0525 - val_loss: 23.3438\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.3863 - val_loss: 23.4676\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8918 - val_loss: 23.2117\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.7469 - val_loss: 23.4674\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.7078 - val_loss: 23.9234\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.1227 - val_loss: 23.3192\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6405 - val_loss: 23.0939\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.4037 - val_loss: 23.0460\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5811 - val_loss: 23.0762\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.3658 - val_loss: 22.9049\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.1606 - val_loss: 22.9115\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.1567 - val_loss: 22.8444\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.1287 - val_loss: 22.8887\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.1560 - val_loss: 23.0705\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.1311 - val_loss: 23.1751\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.9059 - val_loss: 22.8205\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.8236 - val_loss: 22.6792\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.8713 - val_loss: 22.8195\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.9741 - val_loss: 22.8993\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.7267 - val_loss: 22.9149\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.7539 - val_loss: 22.8839\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.7438 - val_loss: 23.5927\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.5249 - val_loss: 50.2993\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 45.6667 - val_loss: 45.3558\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 42.1128 - val_loss: 40.8135\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.0434 - val_loss: 39.4927\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 42.7076 - val_loss: 43.4802\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.2654 - val_loss: 42.3051\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 40.1422 - val_loss: 39.6469\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.0534 - val_loss: 38.5554\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.8455 - val_loss: 40.2654\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.3786 - val_loss: 37.1873\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.5452 - val_loss: 36.4174\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 38.0802 - val_loss: 37.7806\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.0881 - val_loss: 39.9767\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.3085 - val_loss: 37.8361\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.9504 - val_loss: 37.1041\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.7009 - val_loss: 35.6711\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.1738 - val_loss: 34.8808\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.0922 - val_loss: 35.6489\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.0189 - val_loss: 38.1388\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.1738 - val_loss: 35.7581\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.1740 - val_loss: 34.3223\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 34.0055 - val_loss: 33.7616\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.8245 - val_loss: 33.5026\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.1614 - val_loss: 36.2647\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.1251 - val_loss: 34.5117\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.8481 - val_loss: 33.2774\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.2602 - val_loss: 33.9151\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.8413 - val_loss: 34.0285\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 612us/step - loss: 31.6931 - val_loss: 32.8612\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.4439 - val_loss: 37.4472\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.7877 - val_loss: 32.7057\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.7591 - val_loss: 31.9938\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 31.5457 - val_loss: 34.0077\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.0232 - val_loss: 32.6654\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.4961 - val_loss: 33.4356\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.0155 - val_loss: 31.3530\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.0596 - val_loss: 34.5069\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.8205 - val_loss: 32.3880\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.8160 - val_loss: 32.6252\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.5771 - val_loss: 31.5438\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.9327 - val_loss: 31.3754\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 85.4285 - val_loss: 53.6011\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 49.3801 - val_loss: 46.1638\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 43.9368 - val_loss: 41.7414\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 44.3406 - val_loss: 40.7167\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 42.1191 - val_loss: 41.9138\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 40.6261 - val_loss: 38.7694\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.9044 - val_loss: 39.8399\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 40.0416 - val_loss: 41.4823\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 42.2705 - val_loss: 39.6305\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.7713 - val_loss: 37.8137\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.7764 - val_loss: 37.2248\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 37.4745 - val_loss: 36.7608\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.5988 - val_loss: 36.2785\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.9683 - val_loss: 37.1108\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.6318 - val_loss: 36.7240\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.9139 - val_loss: 36.4471\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.9207 - val_loss: 35.3423\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 35.8840 - val_loss: 36.1611\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.1260 - val_loss: 35.5773\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 36.8186 - val_loss: 36.0998\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.3188 - val_loss: 34.0157\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.9968 - val_loss: 34.2899\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.6905 - val_loss: 34.4207\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.7232 - val_loss: 33.5338\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.7543 - val_loss: 34.1444\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.0020 - val_loss: 34.0872\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 35.0343 - val_loss: 34.7645\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.0720 - val_loss: 34.0735\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.1858 - val_loss: 34.9345\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.9346 - val_loss: 52.5484\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 48.2153 - val_loss: 49.0648\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 45.3957 - val_loss: 44.1800\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 43.2472 - val_loss: 43.8358\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.9328 - val_loss: 45.1074\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 42.2885 - val_loss: 42.0761\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 42.4230 - val_loss: 41.2779\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 45.7551 - val_loss: 44.3070\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 40.6679 - val_loss: 40.8210\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.4191 - val_loss: 40.2891\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.6325 - val_loss: 38.9641\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.4836 - val_loss: 41.5691\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 38.2487 - val_loss: 38.6583\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.5053 - val_loss: 37.7662\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.6506 - val_loss: 37.2794\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.8262 - val_loss: 38.7848\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.4392 - val_loss: 37.8122\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 36.6502 - val_loss: 38.8442\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.7826 - val_loss: 36.4972\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.9802 - val_loss: 36.6483\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.1447 - val_loss: 36.5055\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.8064 - val_loss: 34.9016\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.4606 - val_loss: 35.7511\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.9676 - val_loss: 37.2897\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.2572 - val_loss: 34.4817\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.1992 - val_loss: 34.7352\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.2608 - val_loss: 33.3878\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.0865 - val_loss: 33.2643\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.0737 - val_loss: 35.7228\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.7131 - val_loss: 32.5186\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.4303 - val_loss: 38.1053\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.8615 - val_loss: 34.1644\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.0942 - val_loss: 33.2170\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.4340 - val_loss: 31.5677\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.2731 - val_loss: 31.1168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 29.3452 - val_loss: 30.6085\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 841us/step - loss: 29.4067 - val_loss: 29.7635\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 690us/step - loss: 29.0684 - val_loss: 30.1343\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.5543 - val_loss: 28.5292\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 26.9494 - val_loss: 27.5371\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 26.2985 - val_loss: 26.7771\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 25.6516 - val_loss: 26.3348\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 25.2598 - val_loss: 25.5102\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 24.6733 - val_loss: 25.2794\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.3128 - val_loss: 24.7987\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.0335 - val_loss: 24.4662\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 23.6642 - val_loss: 24.4692\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.9317 - val_loss: 24.0748\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.4441 - val_loss: 23.9225\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.1534 - val_loss: 23.8543\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 23.0301 - val_loss: 23.5032\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.9478 - val_loss: 23.6902\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.7728 - val_loss: 23.2715\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.6761 - val_loss: 23.2111\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.5513 - val_loss: 23.1480\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.4293 - val_loss: 23.2376\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.3731 - val_loss: 23.0575\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.4239 - val_loss: 22.8402\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.3106 - val_loss: 22.9681\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.1080 - val_loss: 22.7968\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.9843 - val_loss: 22.6490\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.9167 - val_loss: 22.7657\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.2029 - val_loss: 23.0233\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.9094 - val_loss: 22.5651\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.8390 - val_loss: 22.5755\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.9836 - val_loss: 22.7029\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.6990 - val_loss: 22.4172\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.7246 - val_loss: 22.7712\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.6065 - val_loss: 22.3171\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.4470 - val_loss: 22.2579\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4050 - val_loss: 22.2868\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.4193 - val_loss: 22.5579\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.4481 - val_loss: 22.2076\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.2896 - val_loss: 22.1974\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.3327 - val_loss: 22.8974\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.2682 - val_loss: 22.1836\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.2354 - val_loss: 22.3970\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.1997 - val_loss: 22.2988\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.1002 - val_loss: 22.1761\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.0761 - val_loss: 22.4069\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.1626 - val_loss: 22.0332\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.0628 - val_loss: 22.2281\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9815 - val_loss: 21.9460\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.0870 - val_loss: 22.2831\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1287 - val_loss: 21.9307\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.9233 - val_loss: 21.8585\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.9273 - val_loss: 21.8880\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.9630 - val_loss: 22.1374\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.9553 - val_loss: 22.2648\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.8930 - val_loss: 22.1248\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.8097 - val_loss: 21.8633\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.4685 - val_loss: 49.0763\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 43.9760 - val_loss: 40.0337\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 39.9961 - val_loss: 38.1963\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.8219 - val_loss: 37.5031\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.6486 - val_loss: 37.2904\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.0295 - val_loss: 36.7954\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.9872 - val_loss: 49.2345\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 41.3438 - val_loss: 36.1543\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.4376 - val_loss: 39.8924\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.9494 - val_loss: 38.9698\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.0651 - val_loss: 36.1153\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.7943 - val_loss: 36.8797\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.6576 - val_loss: 33.6576\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.3982 - val_loss: 38.4124\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.3532 - val_loss: 36.1842\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 36.6794 - val_loss: 34.7720\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.0857 - val_loss: 33.7887\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.4163 - val_loss: 33.7202\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.1845 - val_loss: 49.3959\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 46.0097 - val_loss: 43.7188\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 43.1452 - val_loss: 42.0987\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.8709 - val_loss: 39.1693\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.8794 - val_loss: 38.6348\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 38.6897 - val_loss: 38.6924\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.9295 - val_loss: 37.3816\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.9339 - val_loss: 37.0594\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 36.9354 - val_loss: 36.2164\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.4695 - val_loss: 35.6033\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.1306 - val_loss: 36.9276\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.9072 - val_loss: 34.5981\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.9914 - val_loss: 34.5141\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.0932 - val_loss: 35.0111\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.7384 - val_loss: 36.5803\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.2175 - val_loss: 34.1322\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.2231 - val_loss: 35.5781\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 33.8552 - val_loss: 38.0364\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 33.9199 - val_loss: 33.5015\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.4494 - val_loss: 33.7393\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 33.2080 - val_loss: 33.4636\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.6056 - val_loss: 32.5897\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 30.9505 - val_loss: 32.0884\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.9309 - val_loss: 31.5549\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 30.8582 - val_loss: 31.8808\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 30.5190 - val_loss: 34.2421\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 32.1360 - val_loss: 31.6100\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.4776 - val_loss: 31.7247\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 31.1719 - val_loss: 31.2813\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 710us/step - loss: 31.0225 - val_loss: 31.6054\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 759us/step - loss: 30.5136 - val_loss: 32.6475\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 31.4382 - val_loss: 32.3148\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 30.9770 - val_loss: 32.6655\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 29.9841 - val_loss: 31.3762\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 60.4172 - val_loss: 45.1601\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 47.6254 - val_loss: 51.2727\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 45.2157 - val_loss: 42.1157\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 42.6543 - val_loss: 39.8154\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.9833 - val_loss: 39.9945\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.7142 - val_loss: 42.1799\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.8563 - val_loss: 37.7419\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.7541 - val_loss: 36.3592\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.8178 - val_loss: 36.4482\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.6625 - val_loss: 37.5779\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.3343 - val_loss: 35.2851\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.7892 - val_loss: 34.9411\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.4484 - val_loss: 35.9018\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.7300 - val_loss: 37.2480\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.4899 - val_loss: 34.5053\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.8647 - val_loss: 35.4454\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.6520 - val_loss: 40.1642\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.5845 - val_loss: 34.3391\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.6332 - val_loss: 33.9407\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.1737 - val_loss: 36.9530\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.9361 - val_loss: 34.6964\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.7755 - val_loss: 32.6394\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.0561 - val_loss: 31.6465\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.3507 - val_loss: 33.2882\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.3585 - val_loss: 32.2959\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.9120 - val_loss: 32.1603\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.8214 - val_loss: 33.7310\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.0277 - val_loss: 31.2968\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.4874 - val_loss: 31.4139\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.2503 - val_loss: 31.1125\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.2187 - val_loss: 31.9374\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.7570 - val_loss: 31.1486\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.7954 - val_loss: 30.9643\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 32.4989 - val_loss: 32.0297\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.1287 - val_loss: 32.7553\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.1683 - val_loss: 33.7467\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.3917 - val_loss: 30.2799\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.3291 - val_loss: 35.2211\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.4783 - val_loss: 29.5034\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.5824 - val_loss: 29.6246\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.3834 - val_loss: 29.6125\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.9308 - val_loss: 29.8489\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 784us/step - loss: 30.8435 - val_loss: 29.3737\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.2871 - val_loss: 38.5853\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.1061 - val_loss: 30.8328\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 648us/step - loss: 32.0600 - val_loss: 32.8453\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.6856 - val_loss: 35.1565\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.6936 - val_loss: 30.4813\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.6107 - val_loss: 65.7512\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 51.5229 - val_loss: 45.2118\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 43.5921 - val_loss: 41.6998\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 41.3667 - val_loss: 40.2260\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 41.0481 - val_loss: 39.9661\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.3389 - val_loss: 38.7257\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.3335 - val_loss: 39.6635\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.5472 - val_loss: 39.6834\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.4968 - val_loss: 37.7362\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.3590 - val_loss: 38.9561\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.8268 - val_loss: 36.8339\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.2877 - val_loss: 37.3027\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.2610 - val_loss: 36.4276\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.8421 - val_loss: 36.7598\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.9540 - val_loss: 37.7665\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 36.9132 - val_loss: 35.8355\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.8262 - val_loss: 35.9707\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.5261 - val_loss: 36.9486\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.3733 - val_loss: 34.9110\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.6014 - val_loss: 36.9825\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.6850 - val_loss: 35.2894\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.3611 - val_loss: 34.9375\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.0931 - val_loss: 34.9062\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.2867 - val_loss: 34.8570\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.7441 - val_loss: 33.7057\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.5188 - val_loss: 33.0728\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.1348 - val_loss: 35.0157\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.0921 - val_loss: 33.3154\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.8767 - val_loss: 34.7894\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.2437 - val_loss: 32.7969\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.0802 - val_loss: 32.7892\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.9713 - val_loss: 31.5814\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.3274 - val_loss: 34.8939\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.3927 - val_loss: 33.0852\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.4956 - val_loss: 33.0693\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.5445 - val_loss: 31.5212\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.8557 - val_loss: 31.9894\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.9938 - val_loss: 31.7776\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.1909 - val_loss: 32.0834\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.8936 - val_loss: 32.0180\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.7255 - val_loss: 33.9290\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.0063 - val_loss: 49.1112\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 45.8618 - val_loss: 45.0276\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 43.4587 - val_loss: 43.1793\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 41.2903 - val_loss: 40.6869\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.2837 - val_loss: 40.4175\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 39.9005 - val_loss: 39.6724\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 40.0990 - val_loss: 39.6924\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.5659 - val_loss: 41.0147\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.2021 - val_loss: 37.8480\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.2915 - val_loss: 36.9955\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.8148 - val_loss: 38.0346\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.2724 - val_loss: 39.6373\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.6123 - val_loss: 36.7846\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.1451 - val_loss: 38.6711\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.6507 - val_loss: 35.9566\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.1313 - val_loss: 37.7577\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.5079 - val_loss: 35.1513\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.2834 - val_loss: 36.5332\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 34.7983 - val_loss: 35.2043\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.3982 - val_loss: 35.8425\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.9069 - val_loss: 39.9599\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 36.0275 - val_loss: 35.3969\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.3251 - val_loss: 52.3804\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 49.1089 - val_loss: 45.0163\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 44.9893 - val_loss: 41.5301\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.7620 - val_loss: 40.1667\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.3184 - val_loss: 38.3602\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.2830 - val_loss: 37.3896\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.6438 - val_loss: 37.5039\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.9344 - val_loss: 36.4060\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 37.9700 - val_loss: 40.5250\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.6638 - val_loss: 36.6489\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 37.4999 - val_loss: 35.6762\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.6046 - val_loss: 34.9335\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.8840 - val_loss: 34.6509\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.9492 - val_loss: 35.5335\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.9648 - val_loss: 36.1467\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.1458 - val_loss: 34.1290\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.1358 - val_loss: 43.3404\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.4402 - val_loss: 35.2856\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.8809 - val_loss: 38.6410\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.6431 - val_loss: 34.2649\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.8284 - val_loss: 34.7603\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.2397 - val_loss: 49.6365\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 46.0031 - val_loss: 46.0232\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 42.9564 - val_loss: 40.6672\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.9766 - val_loss: 39.1558\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.7862 - val_loss: 39.8433\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.4233 - val_loss: 37.6381\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.4973 - val_loss: 36.7646\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.3345 - val_loss: 35.6148\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.9831 - val_loss: 36.9897\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.3292 - val_loss: 34.7613\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.1153 - val_loss: 34.0714\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.8333 - val_loss: 37.1306\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.6901 - val_loss: 34.0202\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.2979 - val_loss: 35.4489\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.8881 - val_loss: 34.6515\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.5846 - val_loss: 33.2875\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.5968 - val_loss: 33.9729\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.8108 - val_loss: 33.0297\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.1122 - val_loss: 34.5314\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.4278 - val_loss: 32.7732\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.2436 - val_loss: 32.1195\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.2464 - val_loss: 34.7904\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.0193 - val_loss: 32.7504\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.2224 - val_loss: 32.6171\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.6720 - val_loss: 31.8692\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.4330 - val_loss: 31.9198\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 30.9558 - val_loss: 31.8974\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.2391 - val_loss: 35.5225\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.5568 - val_loss: 31.9278\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.4324 - val_loss: 30.5331\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.3658 - val_loss: 30.4749\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.3412 - val_loss: 31.7245\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.5459 - val_loss: 31.1722\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.4690 - val_loss: 30.1759\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.9811 - val_loss: 29.6567\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 29.2062 - val_loss: 29.8657\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.6555 - val_loss: 31.7536\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.8987 - val_loss: 29.1700\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.6857 - val_loss: 29.0255\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.4533 - val_loss: 29.9626\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.2442 - val_loss: 29.2973\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 27.9279 - val_loss: 27.9720\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.8809 - val_loss: 30.1938\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 27.9818 - val_loss: 28.6808\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 27.5381 - val_loss: 27.6998\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.7408 - val_loss: 27.6252\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.5866 - val_loss: 27.0070\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 26.8633 - val_loss: 27.9978\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.1364 - val_loss: 26.8240\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 26.2153 - val_loss: 26.6511\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.5861 - val_loss: 26.1058\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 25.5150 - val_loss: 26.7706\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.6284 - val_loss: 26.1023\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 24.5829 - val_loss: 25.6941\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 24.7611 - val_loss: 25.2384\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 24.2630 - val_loss: 24.8748\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 24.1265 - val_loss: 24.7443\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.7789 - val_loss: 24.7354\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.8393 - val_loss: 25.6948\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.7956 - val_loss: 24.4091\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 23.4277 - val_loss: 25.4412\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 23.3509 - val_loss: 24.4520\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 23.1891 - val_loss: 24.1303\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.1453 - val_loss: 23.9023\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.9279 - val_loss: 24.3059\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.7932 - val_loss: 23.7963\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 617us/step - loss: 22.7466 - val_loss: 23.9557\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.5191 - val_loss: 23.6681\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.4951 - val_loss: 23.6671\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.5351 - val_loss: 23.7925\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.3032 - val_loss: 23.6627\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.5855 - val_loss: 23.5643\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.3035 - val_loss: 23.6979\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1446 - val_loss: 23.3417\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.0877 - val_loss: 23.5339\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.0286 - val_loss: 23.4367\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.0462 - val_loss: 23.3155\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8674 - val_loss: 23.2911\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3673 - val_loss: 23.3355\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.3025 - val_loss: 23.5140\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.8083 - val_loss: 23.1949\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.8513 - val_loss: 23.1370\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.9845 - val_loss: 23.6369\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6067 - val_loss: 23.5217\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6394 - val_loss: 23.0487\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.4556 - val_loss: 23.1332\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.3448 - val_loss: 22.9864\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.2546 - val_loss: 22.9957\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.2114 - val_loss: 23.0881\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3429 - val_loss: 23.0136\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2396 - val_loss: 23.1612\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.2013 - val_loss: 23.0868\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.0242 - val_loss: 47.6035\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 44.6068 - val_loss: 45.8113\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 893us/step - loss: 43.5194 - val_loss: 42.8472\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 759us/step - loss: 40.6914 - val_loss: 39.5569\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 38.6725 - val_loss: 38.2503\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.5664 - val_loss: 37.8112\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.5090 - val_loss: 36.1734\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 36.5297 - val_loss: 39.4437\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.5191 - val_loss: 34.7161\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 35.3841 - val_loss: 38.6056\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.6802 - val_loss: 34.2413\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 747us/step - loss: 34.0394 - val_loss: 34.2590\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 34.3858 - val_loss: 33.3584\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.7372 - val_loss: 33.6664\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.0128 - val_loss: 32.9156\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 33.2450 - val_loss: 32.9514\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 33.1203 - val_loss: 34.4530\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.3003 - val_loss: 33.8326\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.6764 - val_loss: 33.2678\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.8071 - val_loss: 32.8087\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.6274 - val_loss: 33.0443\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.8945 - val_loss: 32.2354\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.0384 - val_loss: 31.7645\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.2130 - val_loss: 31.3668\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.7800 - val_loss: 31.0987\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.2858 - val_loss: 31.0802\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.0733 - val_loss: 30.9999\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.7948 - val_loss: 33.1892\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.6716 - val_loss: 32.1251\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 30.7879 - val_loss: 30.3318\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.2278 - val_loss: 30.2791\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.6693 - val_loss: 30.6565\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 30.0515 - val_loss: 30.3393\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.1065 - val_loss: 31.0520\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.6835 - val_loss: 30.1243\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 29.8069 - val_loss: 30.0079\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 29.3987 - val_loss: 29.5451\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.0911 - val_loss: 29.2798\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 28.8854 - val_loss: 29.8029\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 29.0217 - val_loss: 32.1033\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 30.1541 - val_loss: 31.0449\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 28.8100 - val_loss: 29.4033\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.9239 - val_loss: 28.6922\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 28.2534 - val_loss: 28.7433\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.4297 - val_loss: 28.9228\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 27.4828 - val_loss: 28.0590\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.3881 - val_loss: 27.9877\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 26.4753 - val_loss: 27.1320\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 26.1808 - val_loss: 27.7046\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 25.3803 - val_loss: 25.9760\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 25.5846 - val_loss: 26.1384\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 641us/step - loss: 26.7288 - val_loss: 26.0659\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 25.7195 - val_loss: 26.4030\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.2053 - val_loss: 25.1886\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.4021 - val_loss: 25.1571\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 24.7746 - val_loss: 26.0884\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.2633 - val_loss: 24.4004\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.4586 - val_loss: 24.3129\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.4042 - val_loss: 23.8708\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.1003 - val_loss: 23.7315\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.9199 - val_loss: 23.6239\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.0687 - val_loss: 23.5179\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 22.7821 - val_loss: 23.5996\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 22.6783 - val_loss: 23.8148\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.8424 - val_loss: 23.3703\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.5194 - val_loss: 23.5279\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4945 - val_loss: 23.1233\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.2083 - val_loss: 23.1759\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.6300 - val_loss: 23.3058\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 22.2172 - val_loss: 23.1641\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 22.0917 - val_loss: 22.9519\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.3455 - val_loss: 23.1040\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.8809 - val_loss: 22.7598\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.7117 - val_loss: 22.7612\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.6629 - val_loss: 22.6481\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.6086 - val_loss: 22.8553\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.8573 - val_loss: 23.2865\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.1329 - val_loss: 23.5200\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.1000 - val_loss: 22.7517\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.8893 - val_loss: 23.7113\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 82.2736 - val_loss: 48.4557\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 46.8315 - val_loss: 44.3497\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 41.9489 - val_loss: 41.3474\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.7919 - val_loss: 40.5434\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.9686 - val_loss: 39.3503\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.2162 - val_loss: 38.9999\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.9366 - val_loss: 37.7118\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.5022 - val_loss: 38.5932\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.5393 - val_loss: 37.6017\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.6799 - val_loss: 37.8953\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.5393 - val_loss: 36.5598\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.6096 - val_loss: 36.4506\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.6630 - val_loss: 37.5560\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.6521 - val_loss: 38.7800\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.2887 - val_loss: 35.3677\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.5252 - val_loss: 36.1568\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.7799 - val_loss: 34.8263\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.8279 - val_loss: 34.2174\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.1379 - val_loss: 33.5378\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.6575 - val_loss: 33.3847\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.5519 - val_loss: 33.1892\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.0308 - val_loss: 35.4263\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.5392 - val_loss: 33.7610\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.5822 - val_loss: 33.0891\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.4590 - val_loss: 32.8333\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.3502 - val_loss: 32.5162\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 29.8295 - val_loss: 32.0958\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.7280 - val_loss: 31.3703\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.7817 - val_loss: 30.9607\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.2768 - val_loss: 30.8840\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.6769 - val_loss: 30.9359\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.6547 - val_loss: 30.4816\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.9963 - val_loss: 32.1285\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.3849 - val_loss: 30.1354\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.4524 - val_loss: 29.8115\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.6156 - val_loss: 30.0016\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.6316 - val_loss: 33.8592\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.5273 - val_loss: 29.6380\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.8420 - val_loss: 29.1874\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.6929 - val_loss: 28.5992\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.4656 - val_loss: 29.3709\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.4927 - val_loss: 28.1479\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.6521 - val_loss: 27.0841\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.0750 - val_loss: 27.3559\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.0266 - val_loss: 26.4301\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.0388 - val_loss: 26.4017\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.4635 - val_loss: 26.9848\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.0275 - val_loss: 25.5198\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 624us/step - loss: 23.7043 - val_loss: 25.2759\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.6330 - val_loss: 25.1779\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.2687 - val_loss: 25.0074\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.1486 - val_loss: 24.9341\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.0791 - val_loss: 25.9903\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 22.8929 - val_loss: 24.6708\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7377 - val_loss: 24.8574\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.7651 - val_loss: 24.9209\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.7349 - val_loss: 24.5563\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.6223 - val_loss: 24.3164\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.6184 - val_loss: 24.3477\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3706 - val_loss: 24.6726\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.4520 - val_loss: 24.2077\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.1962 - val_loss: 23.9985\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.9434 - val_loss: 24.0409\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.9538 - val_loss: 23.9668\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.0744 - val_loss: 24.7602\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.9348 - val_loss: 23.9661\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.7195 - val_loss: 23.7491\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.6578 - val_loss: 24.4038\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.6544 - val_loss: 23.9200\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.4699 - val_loss: 23.6854\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6712 - val_loss: 24.3748\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.8472 - val_loss: 24.4603\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.8796 - val_loss: 23.7243\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.3566 - val_loss: 23.6049\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.1880 - val_loss: 23.6652\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.2655 - val_loss: 23.7246\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1081 - val_loss: 23.7532\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1067 - val_loss: 23.7726\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.0912 - val_loss: 23.6686\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 85.0716 - val_loss: 54.0242\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 48.7270 - val_loss: 44.2193\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 44.0410 - val_loss: 43.3640\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 42.3942 - val_loss: 40.1622\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.1026 - val_loss: 39.5784\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.8382 - val_loss: 38.2474\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.0094 - val_loss: 40.3405\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.5573 - val_loss: 37.5022\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.7173 - val_loss: 36.5209\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.4456 - val_loss: 36.3742\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.8852 - val_loss: 39.2131\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.6591 - val_loss: 35.3351\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.8902 - val_loss: 34.5063\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.0148 - val_loss: 34.6546\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.8475 - val_loss: 33.8326\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.5946 - val_loss: 33.4793\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.0775 - val_loss: 32.8654\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.1287 - val_loss: 34.1744\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.4902 - val_loss: 36.8819\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.0927 - val_loss: 33.3149\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.3464 - val_loss: 33.3754\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.3510 - val_loss: 34.7520\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.4729 - val_loss: 48.2018\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 44.8625 - val_loss: 41.4292\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 43.1368 - val_loss: 43.5021\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.9373 - val_loss: 38.5278\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.9524 - val_loss: 38.3550\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.5964 - val_loss: 37.2544\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.8445 - val_loss: 36.1901\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.4540 - val_loss: 36.4258\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.2823 - val_loss: 36.9407\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.4039 - val_loss: 35.5322\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.3479 - val_loss: 36.9560\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.8448 - val_loss: 35.1162\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.3005 - val_loss: 34.1024\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.8207 - val_loss: 33.8042\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.5304 - val_loss: 38.4254\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.1806 - val_loss: 36.5142\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 35.2183 - val_loss: 35.1415\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.5598 - val_loss: 33.8460\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.5668 - val_loss: 32.6773\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.0788 - val_loss: 34.2195\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.3477 - val_loss: 32.7685\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.5320 - val_loss: 31.9278\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.3187 - val_loss: 31.5426\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.4754 - val_loss: 32.3447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.1904 - val_loss: 31.4017\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.6239 - val_loss: 35.5273\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.4570 - val_loss: 32.1617\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.3651 - val_loss: 30.8920\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.5450 - val_loss: 30.7253\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.8701 - val_loss: 32.3346\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.6666 - val_loss: 30.4634\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.1908 - val_loss: 30.1579\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.5343 - val_loss: 30.4059\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.3183 - val_loss: 31.6511\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.2502 - val_loss: 30.0542\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.8881 - val_loss: 31.5928\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.4815 - val_loss: 29.9623\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 29.6204 - val_loss: 29.3326\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.3995 - val_loss: 29.7823\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.0205 - val_loss: 28.8219\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.3445 - val_loss: 37.5422\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.9668 - val_loss: 28.9124\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.0194 - val_loss: 29.2719\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.4359 - val_loss: 29.9258\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.0709 - val_loss: 28.4401\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.1067 - val_loss: 28.8098\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.6854 - val_loss: 29.0961\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.3184 - val_loss: 28.6525\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.9830 - val_loss: 27.9027\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.6266 - val_loss: 29.7969\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.4082 - val_loss: 27.7394\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.4976 - val_loss: 28.8963\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.1551 - val_loss: 27.7915\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.3973 - val_loss: 27.6700\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.8871 - val_loss: 27.8206\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.9443 - val_loss: 27.5135\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.8491 - val_loss: 26.2427\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.7291 - val_loss: 25.9178\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.6486 - val_loss: 26.2066\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.1283 - val_loss: 26.6199\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 24.5644 - val_loss: 24.9645\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 24.2333 - val_loss: 25.3366\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.2332 - val_loss: 25.0680\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.9352 - val_loss: 24.1995\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.3976 - val_loss: 23.9704\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.2047 - val_loss: 23.9351\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.2099 - val_loss: 23.8533\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.0207 - val_loss: 23.7591\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.9296 - val_loss: 23.7354\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.6220 - val_loss: 23.0980\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.3980 - val_loss: 23.1238\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.2322 - val_loss: 22.9608\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.1021 - val_loss: 22.9731\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.1947 - val_loss: 23.3522\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.1275 - val_loss: 22.8200\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.9286 - val_loss: 22.6976\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.8646 - val_loss: 22.6036\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.7556 - val_loss: 23.0844\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8472 - val_loss: 22.5370\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7121 - val_loss: 22.5664\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6444 - val_loss: 22.5432\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.8853 - val_loss: 22.5649\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.6008 - val_loss: 22.3615\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.5437 - val_loss: 22.6250\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4781 - val_loss: 22.4162\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.3797 - val_loss: 22.5676\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.3173 - val_loss: 22.2242\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 21.2232 - val_loss: 22.5019\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.1604 - val_loss: 22.1668\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3006 - val_loss: 22.2742\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.2299 - val_loss: 22.2290\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.0689 - val_loss: 22.3552\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2041 - val_loss: 22.1831\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.9679 - val_loss: 22.0981\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0745 - val_loss: 22.5051\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.1618 - val_loss: 22.2814\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.9124 - val_loss: 22.0332\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.8170 - val_loss: 22.5188\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.8457 - val_loss: 22.1228\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.6838 - val_loss: 22.1579\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.6747 - val_loss: 45.5734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 46.4149 - val_loss: 44.1118\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 41.9401 - val_loss: 40.3110\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 39.8417 - val_loss: 38.9438\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.8590 - val_loss: 38.0213\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 38.8076 - val_loss: 38.1299\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 38.4330 - val_loss: 38.3592\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.1825 - val_loss: 37.2919\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.0264 - val_loss: 36.4307\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 36.0538 - val_loss: 35.6370\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.2872 - val_loss: 35.8292\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 35.0474 - val_loss: 37.2464\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 35.6749 - val_loss: 38.5143\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.9197 - val_loss: 43.9476\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.4841 - val_loss: 38.1037\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.1994 - val_loss: 47.3343\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 43.5410 - val_loss: 40.0124\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 38.5628 - val_loss: 36.8224\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 37.6335 - val_loss: 36.8959\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 35.7030 - val_loss: 34.3360\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.8613 - val_loss: 35.0643\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.9035 - val_loss: 34.0628\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.1007 - val_loss: 33.2587\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.0499 - val_loss: 32.7273\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.1121 - val_loss: 33.1968\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.8101 - val_loss: 32.2361\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.7944 - val_loss: 31.9519\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.4648 - val_loss: 32.4657\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.2575 - val_loss: 31.5675\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.0286 - val_loss: 30.8673\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.2169 - val_loss: 32.5985\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.8271 - val_loss: 31.9735\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.4969 - val_loss: 31.9014\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.7417 - val_loss: 30.8858\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.8459 - val_loss: 30.3291\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.2962 - val_loss: 31.4724\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.6430 - val_loss: 30.3250\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.9497 - val_loss: 30.1421\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.9409 - val_loss: 30.9536\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.6295 - val_loss: 30.1046\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.6962 - val_loss: 30.9013\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 29.6726 - val_loss: 29.8492\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.9515 - val_loss: 29.6317\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.5661 - val_loss: 29.3541\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.1489 - val_loss: 30.0587\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.6842 - val_loss: 29.2797\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.1221 - val_loss: 29.1660\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.4819 - val_loss: 28.9987\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.7811 - val_loss: 28.6732\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.8034 - val_loss: 29.5370\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.2558 - val_loss: 29.2399\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.2648 - val_loss: 29.3819\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.4179 - val_loss: 28.6197\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.6962 - val_loss: 30.1710\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.5244 - val_loss: 29.3833\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.0315 - val_loss: 29.5462\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.2168 - val_loss: 28.3211\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.2101 - val_loss: 27.9423\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.6082 - val_loss: 28.3885\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.6933 - val_loss: 27.7445\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.4186 - val_loss: 29.0704\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.3902 - val_loss: 28.2572\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.8855 - val_loss: 28.2621\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 27.8932 - val_loss: 28.1372\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.6905 - val_loss: 28.6908\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.5849 - val_loss: 50.7785\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 46.9989 - val_loss: 45.5834\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 44.1905 - val_loss: 46.3906\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 42.1474 - val_loss: 41.7862\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.6604 - val_loss: 41.4301\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.7958 - val_loss: 41.4476\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.4775 - val_loss: 42.8140\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.4090 - val_loss: 40.5043\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 38.7244 - val_loss: 39.6643\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.8615 - val_loss: 39.7542\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.1441 - val_loss: 38.8368\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.2478 - val_loss: 39.3140\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 37.1363 - val_loss: 38.8871\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.6749 - val_loss: 37.8366\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.6895 - val_loss: 38.9827\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.9548 - val_loss: 38.3333\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.1921 - val_loss: 37.2048\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.2872 - val_loss: 36.8538\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.7522 - val_loss: 39.3986\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.4052 - val_loss: 37.4187\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.1167 - val_loss: 36.5492\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.8778 - val_loss: 39.2331\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.1278 - val_loss: 37.8275\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.7625 - val_loss: 35.9483\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.6895 - val_loss: 35.2025\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.9945 - val_loss: 36.4168\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.2780 - val_loss: 36.6552\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.9870 - val_loss: 35.3736\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.7020 - val_loss: 34.5957\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.7406 - val_loss: 34.5260\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.1889 - val_loss: 34.1896\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.2677 - val_loss: 33.8564\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.4354 - val_loss: 34.0990\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.0832 - val_loss: 33.8626\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.5914 - val_loss: 32.7584\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7685 - val_loss: 36.4147\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.0925 - val_loss: 38.0068\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.3431 - val_loss: 32.2972\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.4436 - val_loss: 32.1932\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.1679 - val_loss: 31.4463\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.2350 - val_loss: 31.4154\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.9358 - val_loss: 30.8184\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.8534 - val_loss: 29.5104\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.9277 - val_loss: 28.2370\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.5262 - val_loss: 28.3353\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 27.2448 - val_loss: 26.7023\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 25.7586 - val_loss: 26.7754\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.3067 - val_loss: 25.7122\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.7661 - val_loss: 25.3642\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 758us/step - loss: 24.4163 - val_loss: 25.1082\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 820us/step - loss: 24.1943 - val_loss: 24.7585\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.0679 - val_loss: 24.5902\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.8824 - val_loss: 24.5229\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.6053 - val_loss: 24.6960\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.5591 - val_loss: 24.2586\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.4166 - val_loss: 24.1407\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.2585 - val_loss: 24.6805\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.1452 - val_loss: 24.0470\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0265 - val_loss: 23.7664\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 712us/step - loss: 22.9939 - val_loss: 23.7182\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.8417 - val_loss: 23.8115\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.9365 - val_loss: 23.5419\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7931 - val_loss: 23.5845\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.5190 - val_loss: 23.4964\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 22.5023 - val_loss: 23.4555\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3918 - val_loss: 23.4058\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 22.3076 - val_loss: 23.1987\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 807us/step - loss: 22.2259 - val_loss: 23.2519\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 796us/step - loss: 22.1763 - val_loss: 23.6464\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 765us/step - loss: 22.1162 - val_loss: 23.4588\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 758us/step - loss: 22.1066 - val_loss: 23.3978\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.9778 - val_loss: 23.3800\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 60.7350 - val_loss: 47.6215\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 44.8083 - val_loss: 46.3950\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 42.6759 - val_loss: 43.8996\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 41.2191 - val_loss: 42.1655\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 39.3508 - val_loss: 41.1572\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 38.7174 - val_loss: 39.6217\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.3365 - val_loss: 39.0122\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 38.2578 - val_loss: 38.9739\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 37.6471 - val_loss: 38.9442\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 37.4348 - val_loss: 37.2210\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 35.5148 - val_loss: 37.5597\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 35.3735 - val_loss: 35.9691\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 36.1808 - val_loss: 38.9743\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 37.4140 - val_loss: 37.4911\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 34.5141 - val_loss: 35.9266\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 33.8926 - val_loss: 35.6649\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.6398 - val_loss: 34.3520\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 660us/step - loss: 33.3184 - val_loss: 36.0222\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 34.0937 - val_loss: 34.1067\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 32.5241 - val_loss: 33.6381\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 32.4208 - val_loss: 36.2373\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.5048 - val_loss: 37.5385\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 33.1990 - val_loss: 33.9313\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 31.9544 - val_loss: 33.1522\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 31.5981 - val_loss: 33.4325\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 31.4149 - val_loss: 32.6867\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 30.8639 - val_loss: 35.0080\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 31.6380 - val_loss: 34.8540\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.3092 - val_loss: 32.3322\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 30.4933 - val_loss: 32.4668\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.5187 - val_loss: 34.2200\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 30.2364 - val_loss: 31.4187\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 32.0163 - val_loss: 34.1166\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.6952 - val_loss: 33.3087\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 30.0720 - val_loss: 30.8474\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 28.8975 - val_loss: 31.0924\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.6075 - val_loss: 30.1255\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 29.4691 - val_loss: 30.8186\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 30.0885 - val_loss: 31.1151\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 28.8193 - val_loss: 32.4682\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.4363 - val_loss: 29.5763\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 27.8663 - val_loss: 29.7885\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 27.5321 - val_loss: 29.0292\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 27.3162 - val_loss: 28.9103\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 28.1979 - val_loss: 30.3370\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 27.6005 - val_loss: 28.7351\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 26.3988 - val_loss: 27.3613\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 25.8581 - val_loss: 27.1675\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 26.2579 - val_loss: 28.1626\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.0476 - val_loss: 26.2765\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 24.9144 - val_loss: 26.0807\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 24.6904 - val_loss: 26.1259\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 896us/step - loss: 24.2292 - val_loss: 24.9137\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 23.9643 - val_loss: 24.9628\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 826us/step - loss: 23.5463 - val_loss: 24.3121\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 884us/step - loss: 23.3473 - val_loss: 24.2050\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 820us/step - loss: 23.1205 - val_loss: 24.4909\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.0834 - val_loss: 23.9039\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.8254 - val_loss: 23.8508\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.6395 - val_loss: 24.0584\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.6123 - val_loss: 24.1806\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.5170 - val_loss: 23.5395\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.3897 - val_loss: 24.2596\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.6749 - val_loss: 23.3153\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.2159 - val_loss: 23.2261\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2126 - val_loss: 23.1625\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.0401 - val_loss: 23.3127\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.8920 - val_loss: 23.1389\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.7475 - val_loss: 23.3535\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7472 - val_loss: 23.0304\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6223 - val_loss: 22.9614\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.6376 - val_loss: 23.8109\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7798 - val_loss: 23.0179\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.5107 - val_loss: 22.8771\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.3840 - val_loss: 22.7743\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.3083 - val_loss: 22.7344\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.2552 - val_loss: 22.8557\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2220 - val_loss: 23.0514\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.1951 - val_loss: 22.7084\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2740 - val_loss: 23.7485\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.2866 - val_loss: 22.8483\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9754 - val_loss: 22.7067\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.8958 - val_loss: 22.6735\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 20.9543 - val_loss: 23.2518\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.2249 - val_loss: 23.0759\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8666 - val_loss: 22.7830\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.7933 - val_loss: 22.7748\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.6723 - val_loss: 22.7054\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 60.6101 - val_loss: 44.7034\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 43.5707 - val_loss: 41.5114\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 40.7315 - val_loss: 38.9314\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 788us/step - loss: 38.2583 - val_loss: 37.9867\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.1905 - val_loss: 36.7672\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.1030 - val_loss: 36.0323\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 634us/step - loss: 35.4600 - val_loss: 35.0793\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 35.5735 - val_loss: 36.3682\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.7106 - val_loss: 34.4919\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.1349 - val_loss: 35.7540\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.2023 - val_loss: 34.2228\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.7789 - val_loss: 33.2972\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.1599 - val_loss: 33.7896\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.6364 - val_loss: 32.3586\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.7735 - val_loss: 31.7543\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.8819 - val_loss: 35.3648\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.9738 - val_loss: 32.9080\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.6063 - val_loss: 30.9849\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.3058 - val_loss: 31.3659\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.6728 - val_loss: 32.8215\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.3356 - val_loss: 30.6212\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.8514 - val_loss: 33.1013\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.9079 - val_loss: 33.5487\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.9456 - val_loss: 30.1321\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.3612 - val_loss: 31.0766\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.9184 - val_loss: 29.4359\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.7700 - val_loss: 28.9232\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.5413 - val_loss: 30.4118\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.5496 - val_loss: 29.2114\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.0507 - val_loss: 28.6987\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.2760 - val_loss: 29.0569\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 27.4940 - val_loss: 28.7286\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 27.2850 - val_loss: 28.1454\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.9289 - val_loss: 28.0301\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 26.9855 - val_loss: 28.0237\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.0562 - val_loss: 28.9012\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.4910 - val_loss: 28.3431\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.8223 - val_loss: 27.9438\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 27.2476 - val_loss: 29.0676\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.5813 - val_loss: 28.0368\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.0510 - val_loss: 28.9226\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 26.6033 - val_loss: 32.0396\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.6372 - val_loss: 28.2702\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.9606 - val_loss: 53.9547\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 47.7982 - val_loss: 47.3403\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 44.3029 - val_loss: 45.8415\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 43.0874 - val_loss: 46.2452\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 42.8872 - val_loss: 43.4668\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 40.1627 - val_loss: 41.3692\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.5935 - val_loss: 42.1241\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.2345 - val_loss: 40.0537\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 39.2226 - val_loss: 42.0381\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.4903 - val_loss: 41.5246\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.4282 - val_loss: 39.3811\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.7074 - val_loss: 39.5174\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.2996 - val_loss: 39.2513\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.1303 - val_loss: 38.0849\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.8713 - val_loss: 37.0756\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 34.9909 - val_loss: 36.2255\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.0382 - val_loss: 38.1235\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.9127 - val_loss: 36.2886\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.3443 - val_loss: 43.4095\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.9613 - val_loss: 36.4956\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.3035 - val_loss: 36.1933\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.2081 - val_loss: 34.2117\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.1048 - val_loss: 35.7339\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.7618 - val_loss: 35.2352\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.5580 - val_loss: 32.9255\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.8128 - val_loss: 32.7693\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.1449 - val_loss: 33.5565\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.6734 - val_loss: 30.8970\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 29.4325 - val_loss: 32.1072\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 29.6043 - val_loss: 33.4314\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.9725 - val_loss: 28.9419\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.6111 - val_loss: 28.6945\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 27.8684 - val_loss: 27.9672\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.9248 - val_loss: 27.1882\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.5514 - val_loss: 29.5572\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 26.9935 - val_loss: 26.6226\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.9008 - val_loss: 26.2905\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.6454 - val_loss: 26.2136\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.3095 - val_loss: 26.5370\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.0483 - val_loss: 25.4203\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 24.9280 - val_loss: 25.4662\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.7258 - val_loss: 25.1225\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.4882 - val_loss: 25.0685\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.3815 - val_loss: 24.8953\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.9226 - val_loss: 24.6170\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.8046 - val_loss: 24.6769\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.7235 - val_loss: 24.3474\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.4766 - val_loss: 24.4311\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.3999 - val_loss: 24.2121\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.4413 - val_loss: 24.2365\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.0713 - val_loss: 23.8490\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.9070 - val_loss: 23.9648\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.9704 - val_loss: 23.9693\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.0753 - val_loss: 23.7686\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.7451 - val_loss: 23.5165\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6895 - val_loss: 23.4274\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.4633 - val_loss: 23.4361\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.1966 - val_loss: 23.3053\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.1147 - val_loss: 23.2030\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.0815 - val_loss: 23.1649\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0304 - val_loss: 23.0930\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.9172 - val_loss: 23.0322\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7794 - val_loss: 22.9278\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.7338 - val_loss: 23.0163\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.8095 - val_loss: 23.2842\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7875 - val_loss: 22.9916\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.5326 - val_loss: 22.8045\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.4325 - val_loss: 22.7392\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3483 - val_loss: 22.8693\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.7700 - val_loss: 23.3239\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.5881 - val_loss: 22.7947\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.3277 - val_loss: 22.6604\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3481 - val_loss: 22.8605\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.1179 - val_loss: 22.7058\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9698 - val_loss: 22.5356\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.8964 - val_loss: 22.5989\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 760us/step - loss: 20.9778 - val_loss: 22.6468\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.8514 - val_loss: 22.6801\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.0451 - val_loss: 22.4725\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.9224 - val_loss: 22.5155\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0029 - val_loss: 23.0500\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 20.8690 - val_loss: 22.4340\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.6635 - val_loss: 22.4549\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.5634 - val_loss: 22.5549\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.5626 - val_loss: 22.6310\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.7161 - val_loss: 22.4018\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.3436 - val_loss: 22.4101\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.2762 - val_loss: 22.3365\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.2157 - val_loss: 22.3628\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.0772 - val_loss: 22.3224\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.0519 - val_loss: 22.4070\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.0936 - val_loss: 22.2821\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.0804 - val_loss: 22.3743\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 19.9314 - val_loss: 22.4373\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.0222 - val_loss: 22.2913\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 19.9778 - val_loss: 23.0542\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.1105 - val_loss: 23.0916\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.9099 - val_loss: 48.0714\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 45.3055 - val_loss: 43.0514\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 42.1743 - val_loss: 43.6802\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 41.5316 - val_loss: 39.7030\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 42.1405 - val_loss: 39.1599\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.7898 - val_loss: 38.5869\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 39.1256 - val_loss: 40.5508\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.9437 - val_loss: 40.8675\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.3146 - val_loss: 36.9548\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.7884 - val_loss: 36.4716\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.6888 - val_loss: 37.2815\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.9391 - val_loss: 35.1727\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.7518 - val_loss: 35.1053\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.4657 - val_loss: 36.9559\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.7131 - val_loss: 35.0955\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.8019 - val_loss: 35.0836\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.8138 - val_loss: 35.4118\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.7449 - val_loss: 35.7293\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 36.0088 - val_loss: 35.5630\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.2590 - val_loss: 34.1169\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 615us/step - loss: 34.7411 - val_loss: 35.9502\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.4496 - val_loss: 37.8024\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.8233 - val_loss: 33.3719\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.8395 - val_loss: 33.2316\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.2776 - val_loss: 37.5736\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.5203 - val_loss: 36.1505\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.4190 - val_loss: 32.6516\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.9848 - val_loss: 33.2438\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.0834 - val_loss: 32.9529\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.9036 - val_loss: 32.8990\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.5511 - val_loss: 31.8469\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.1374 - val_loss: 31.6571\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.8745 - val_loss: 31.9785\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.4039 - val_loss: 31.7050\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.7067 - val_loss: 31.8715\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.6602 - val_loss: 31.3650\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.1399 - val_loss: 32.9976\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.7522 - val_loss: 30.8519\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.6787 - val_loss: 30.4557\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.7655 - val_loss: 30.5130\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.7505 - val_loss: 31.7101\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.6417 - val_loss: 30.6111\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.5102 - val_loss: 32.9667\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.5878 - val_loss: 30.8977\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.7788 - val_loss: 52.6211\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 47.9106 - val_loss: 44.3243\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 759us/step - loss: 43.7025 - val_loss: 42.3995\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 41.8142 - val_loss: 41.4820\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.3925 - val_loss: 38.9011\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.3763 - val_loss: 38.4984\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.8673 - val_loss: 40.5729\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.0565 - val_loss: 38.1812\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.5218 - val_loss: 37.0952\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.3208 - val_loss: 37.8577\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.7569 - val_loss: 36.7229\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.7155 - val_loss: 38.9343\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.3485 - val_loss: 35.9955\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.2213 - val_loss: 36.9796\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.4373 - val_loss: 36.6638\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.8955 - val_loss: 35.3665\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.2162 - val_loss: 35.4088\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.4708 - val_loss: 34.2227\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 35.9576 - val_loss: 37.6869\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.1609 - val_loss: 35.8030\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.2183 - val_loss: 34.5579\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.2650 - val_loss: 34.0505\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.9739 - val_loss: 36.7573\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.2435 - val_loss: 35.2599\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.7967 - val_loss: 37.6636\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.0859 - val_loss: 33.8753\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.7371 - val_loss: 32.9934\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.3274 - val_loss: 33.8683\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.2654 - val_loss: 32.6403\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.9055 - val_loss: 37.4621\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.1079 - val_loss: 31.9348\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.8752 - val_loss: 33.6789\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.8870 - val_loss: 31.3519\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.4062 - val_loss: 31.2081\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.2808 - val_loss: 30.7898\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.9684 - val_loss: 30.5837\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.8318 - val_loss: 31.3784\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.2932 - val_loss: 30.1186\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.7014 - val_loss: 29.5641\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.6763 - val_loss: 29.3069\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.5935 - val_loss: 29.7497\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.6018 - val_loss: 28.0634\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.8105 - val_loss: 26.8401\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 25.9829 - val_loss: 27.4505\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.5882 - val_loss: 26.6916\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.4442 - val_loss: 25.2234\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.8291 - val_loss: 25.1176\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.4015 - val_loss: 24.6818\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.8757 - val_loss: 25.0063\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.8579 - val_loss: 24.2749\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.3826 - val_loss: 23.9680\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.2000 - val_loss: 23.9641\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.2484 - val_loss: 23.7754\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 619us/step - loss: 23.0596 - val_loss: 23.6156\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.8116 - val_loss: 23.7521\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.7666 - val_loss: 23.4267\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.5288 - val_loss: 23.3996\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.3881 - val_loss: 23.2597\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.3448 - val_loss: 23.3406\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.4241 - val_loss: 23.2326\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.2055 - val_loss: 23.1362\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.1792 - val_loss: 23.2133\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.0370 - val_loss: 23.0400\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.9241 - val_loss: 23.0393\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.0485 - val_loss: 22.9968\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.9085 - val_loss: 23.0414\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.8209 - val_loss: 23.0897\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.6720 - val_loss: 22.8815\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.5929 - val_loss: 22.8575\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.5028 - val_loss: 22.8822\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.5697 - val_loss: 22.9067\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5190 - val_loss: 22.7916\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.4850 - val_loss: 22.7054\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.4296 - val_loss: 22.7694\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.2655 - val_loss: 23.4775\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.3140 - val_loss: 22.6644\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.2235 - val_loss: 23.2448\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.2452 - val_loss: 23.0907\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.0909 - val_loss: 22.6592\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.9264 - val_loss: 22.7270\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.8470 - val_loss: 22.7018\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.8159 - val_loss: 22.5554\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.8852 - val_loss: 22.6825\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.7974 - val_loss: 22.7303\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.9433 - val_loss: 22.7730\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 20.8264 - val_loss: 22.6516\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 20.6236 - val_loss: 22.6974\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.0331 - val_loss: 55.7241\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 49.3718 - val_loss: 46.8398\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 707us/step - loss: 44.8132 - val_loss: 49.7722\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 799us/step - loss: 44.7592 - val_loss: 43.3202\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 842us/step - loss: 42.3200 - val_loss: 43.4559\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 41.2431 - val_loss: 42.2007\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.9703 - val_loss: 41.8315\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 40.6542 - val_loss: 41.0459\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.8327 - val_loss: 39.6677\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.6406 - val_loss: 41.3029\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.2223 - val_loss: 41.4889\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.7232 - val_loss: 42.5182\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 41.0117 - val_loss: 40.2337\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 689us/step - loss: 37.6976 - val_loss: 42.3306\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.0592 - val_loss: 43.1759\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 43.4004 - val_loss: 45.1506\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.4762 - val_loss: 40.4015\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.6382 - val_loss: 38.8169\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.4267 - val_loss: 37.4341\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.3350 - val_loss: 36.8601\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.5637 - val_loss: 36.7572\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.8525 - val_loss: 37.1055\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.4041 - val_loss: 35.9702\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.9582 - val_loss: 36.0334\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.9576 - val_loss: 34.5598\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.8725 - val_loss: 35.7485\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.6697 - val_loss: 36.3541\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.4974 - val_loss: 34.5227\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.0225 - val_loss: 34.5225\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.9514 - val_loss: 34.3066\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.1901 - val_loss: 33.3169\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.5955 - val_loss: 35.7662\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.5699 - val_loss: 34.7602\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.1860 - val_loss: 32.2900\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.0335 - val_loss: 32.0704\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.4007 - val_loss: 33.9071\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.3942 - val_loss: 34.0445\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.3239 - val_loss: 32.9991\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.6541 - val_loss: 32.0062\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.3568 - val_loss: 31.7022\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.0873 - val_loss: 34.9161\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.4534 - val_loss: 31.1884\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.2109 - val_loss: 31.6076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.9015 - val_loss: 32.7320\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 30.8294 - val_loss: 31.1792\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.8147 - val_loss: 31.0309\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 30.1727 - val_loss: 32.6849\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.8076 - val_loss: 31.9435\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 29.6814 - val_loss: 29.6551\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.5883 - val_loss: 30.2273\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.8870 - val_loss: 31.7773\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 30.9522 - val_loss: 32.5836\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.9166 - val_loss: 29.5903\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.7168 - val_loss: 30.7060\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 28.7368 - val_loss: 28.7167\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 28.1437 - val_loss: 30.6930\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.3534 - val_loss: 31.0844\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 28.9470 - val_loss: 27.9459\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.8715 - val_loss: 28.9515\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.7816 - val_loss: 27.0404\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.8278 - val_loss: 27.3004\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 26.8131 - val_loss: 28.6303\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.1848 - val_loss: 25.2771\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 24.3559 - val_loss: 26.1262\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 24.0877 - val_loss: 24.4958\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.6659 - val_loss: 24.3441\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.8727 - val_loss: 24.1568\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.3617 - val_loss: 23.8543\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.0669 - val_loss: 24.2961\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.4110 - val_loss: 23.7253\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.3018 - val_loss: 23.5968\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.6838 - val_loss: 23.4110\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.5162 - val_loss: 23.5982\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.5131 - val_loss: 23.1716\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.6227 - val_loss: 23.4603\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.5191 - val_loss: 23.0558\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.1562 - val_loss: 22.9565\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4695 - val_loss: 23.4196\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.1863 - val_loss: 22.8979\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.0204 - val_loss: 23.3416\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2405 - val_loss: 22.8371\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0653 - val_loss: 23.3785\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.9108 - val_loss: 22.6774\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.6680 - val_loss: 22.6306\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.5689 - val_loss: 22.6801\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.5094 - val_loss: 22.6272\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.5332 - val_loss: 22.5345\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9570 - val_loss: 23.1483\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.6062 - val_loss: 22.6405\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.3365 - val_loss: 22.6833\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2547 - val_loss: 22.7099\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.3958 - val_loss: 22.5493\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.1871 - val_loss: 51.7836\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 46.1046 - val_loss: 43.6777\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 41.4805 - val_loss: 39.7447\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.9681 - val_loss: 39.4689\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.8189 - val_loss: 38.7794\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.1201 - val_loss: 38.2708\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.9649 - val_loss: 37.0771\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.7333 - val_loss: 36.1219\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.7424 - val_loss: 38.9707\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.2383 - val_loss: 37.5269\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.2147 - val_loss: 35.6438\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.9043 - val_loss: 35.2393\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 34.1269 - val_loss: 34.8379\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.6140 - val_loss: 34.2123\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.6707 - val_loss: 35.1538\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.2073 - val_loss: 34.1908\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.7660 - val_loss: 36.1196\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.9103 - val_loss: 38.6071\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.4954 - val_loss: 38.4772\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.9382 - val_loss: 33.0059\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.7146 - val_loss: 33.4210\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.3902 - val_loss: 32.3773\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.1131 - val_loss: 34.2206\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.5694 - val_loss: 32.5394\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.8021 - val_loss: 32.8361\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.7750 - val_loss: 34.8673\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.9505 - val_loss: 33.9371\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.9304 - val_loss: 45.1651\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 42.7536 - val_loss: 42.0453\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 42.7764 - val_loss: 42.6417\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.5646 - val_loss: 39.2208\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.0804 - val_loss: 37.5556\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.9213 - val_loss: 36.8211\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.8622 - val_loss: 42.6498\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.1082 - val_loss: 35.9275\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.1231 - val_loss: 38.0557\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.9983 - val_loss: 35.8402\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.8404 - val_loss: 39.4055\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.0599 - val_loss: 39.7349\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.4523 - val_loss: 37.8876\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.5883 - val_loss: 39.7372\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 41.3861 - val_loss: 36.5078\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 85.2856 - val_loss: 49.7073\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 48.0040 - val_loss: 43.4453\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 43.8357 - val_loss: 41.1301\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.9071 - val_loss: 40.3636\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 40.2451 - val_loss: 39.0183\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.8202 - val_loss: 42.2178\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.6028 - val_loss: 38.7743\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.0153 - val_loss: 38.2311\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.0752 - val_loss: 37.6728\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.7456 - val_loss: 36.9929\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.9942 - val_loss: 37.0979\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.1658 - val_loss: 37.7071\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.1812 - val_loss: 35.7297\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.2377 - val_loss: 36.6484\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.4132 - val_loss: 35.3964\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.8400 - val_loss: 34.6707\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.0363 - val_loss: 36.9211\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.8243 - val_loss: 33.7631\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.2885 - val_loss: 33.9860\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.4347 - val_loss: 33.9866\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.2478 - val_loss: 33.4272\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.3948 - val_loss: 32.8457\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.5353 - val_loss: 33.7600\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.2751 - val_loss: 31.6560\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.1337 - val_loss: 31.0020\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7459 - val_loss: 36.8093\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.4652 - val_loss: 29.9173\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 29.2773 - val_loss: 29.0408\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.3725 - val_loss: 28.6447\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 27.5813 - val_loss: 27.4990\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.8866 - val_loss: 27.4906\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.1316 - val_loss: 26.2443\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.3741 - val_loss: 26.0134\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.5432 - val_loss: 26.0709\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.1140 - val_loss: 25.2657\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.6209 - val_loss: 25.0689\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.4561 - val_loss: 24.8148\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.8853 - val_loss: 24.5564\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.5498 - val_loss: 24.2941\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.3374 - val_loss: 24.0656\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.0816 - val_loss: 23.9125\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.0544 - val_loss: 24.5244\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.2360 - val_loss: 24.1247\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.7042 - val_loss: 23.5911\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.5679 - val_loss: 23.5100\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.4064 - val_loss: 23.4131\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.2807 - val_loss: 23.3310\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.1577 - val_loss: 23.2983\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.1169 - val_loss: 23.2579\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.0050 - val_loss: 23.2047\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.0950 - val_loss: 23.1185\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.8995 - val_loss: 23.0255\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.0981 - val_loss: 22.9968\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.7204 - val_loss: 22.9897\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.5568 - val_loss: 22.9557\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4069 - val_loss: 22.8955\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3970 - val_loss: 22.9050\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.2101 - val_loss: 22.7727\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.1905 - val_loss: 22.9362\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.3283 - val_loss: 22.7353\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.0279 - val_loss: 22.9205\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.1130 - val_loss: 22.8195\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 617us/step - loss: 21.0852 - val_loss: 22.8421\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 20.8119 - val_loss: 22.6981\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.6505 - val_loss: 22.6759\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.6244 - val_loss: 22.7693\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 20.6539 - val_loss: 22.9405\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.7911 - val_loss: 22.6482\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.4597 - val_loss: 22.7227\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 20.3910 - val_loss: 22.5392\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.3333 - val_loss: 22.6632\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.4528 - val_loss: 22.6863\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.2718 - val_loss: 22.5695\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.0866 - val_loss: 22.5687\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.3031 - val_loss: 22.5889\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.7576 - val_loss: 50.2951\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 48.0751 - val_loss: 47.2545\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 44.7217 - val_loss: 43.1647\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 42.3922 - val_loss: 43.2221\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 42.2041 - val_loss: 43.8087\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.6844 - val_loss: 41.0298\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.7353 - val_loss: 39.2953\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.4962 - val_loss: 42.1784\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 39.4762 - val_loss: 43.1941\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 40.9808 - val_loss: 39.1788\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.3727 - val_loss: 38.1699\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.1181 - val_loss: 40.6254\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.3354 - val_loss: 36.8966\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.4735 - val_loss: 36.1690\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.9953 - val_loss: 35.9112\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.9363 - val_loss: 39.9696\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.4934 - val_loss: 37.3396\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.4999 - val_loss: 35.3302\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.5748 - val_loss: 34.9333\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.5240 - val_loss: 34.5147\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.0211 - val_loss: 35.2739\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.7327 - val_loss: 37.3112\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.3756 - val_loss: 34.4519\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.6959 - val_loss: 34.0662\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.2668 - val_loss: 33.8953\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.5849 - val_loss: 33.1447\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.8525 - val_loss: 33.1856\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.1610 - val_loss: 32.1539\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.2200 - val_loss: 32.5487\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.6045 - val_loss: 36.1858\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.4803 - val_loss: 31.9290\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 30.8911 - val_loss: 32.4019\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.5814 - val_loss: 32.7115\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.0066 - val_loss: 31.6069\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.0963 - val_loss: 31.3321\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.7114 - val_loss: 30.7911\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.7887 - val_loss: 30.5897\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.8477 - val_loss: 30.4810\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.3555 - val_loss: 29.9263\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.6439 - val_loss: 33.4313\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.4403 - val_loss: 30.4955\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.3951 - val_loss: 30.2657\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.9563 - val_loss: 29.2278\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.0942 - val_loss: 28.6783\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.7421 - val_loss: 28.9894\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.9182 - val_loss: 27.3125\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 26.4815 - val_loss: 28.6720\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 26.7080 - val_loss: 26.6093\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.2309 - val_loss: 26.6216\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.6363 - val_loss: 25.7170\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.4500 - val_loss: 26.1553\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.9528 - val_loss: 25.8961\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.7694 - val_loss: 25.6203\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 23.8862 - val_loss: 24.8392\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.4574 - val_loss: 24.4106\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.2096 - val_loss: 24.1112\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.9689 - val_loss: 25.2806\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.1230 - val_loss: 23.8899\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.5911 - val_loss: 23.6121\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2933 - val_loss: 23.4692\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.3026 - val_loss: 23.5268\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.2449 - val_loss: 23.2794\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.2196 - val_loss: 23.5055\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.5427 - val_loss: 24.3171\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 636us/step - loss: 22.2769 - val_loss: 23.1793\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.7112 - val_loss: 23.1163\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.6226 - val_loss: 23.0448\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.5298 - val_loss: 22.9273\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.4754 - val_loss: 22.9422\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4268 - val_loss: 22.7981\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.2226 - val_loss: 23.1177\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.2095 - val_loss: 22.7425\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.3775 - val_loss: 23.0187\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2547 - val_loss: 22.9060\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.0215 - val_loss: 22.5700\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.8868 - val_loss: 22.8796\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.9267 - val_loss: 22.4199\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 20.7552 - val_loss: 22.5812\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.8575 - val_loss: 22.6059\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.2718 - val_loss: 23.0619\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.9039 - val_loss: 22.3601\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.5034 - val_loss: 22.2461\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.5904 - val_loss: 22.5244\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.4920 - val_loss: 22.2742\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.2618 - val_loss: 22.2159\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.1633 - val_loss: 22.1668\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.1089 - val_loss: 22.2771\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.1280 - val_loss: 22.2062\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.0776 - val_loss: 22.4827\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.1610 - val_loss: 22.6615\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.0629 - val_loss: 22.1427\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 19.9790 - val_loss: 22.1458\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 19.8629 - val_loss: 22.2617\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 19.8224 - val_loss: 22.3022\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 19.7785 - val_loss: 22.4093\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 19.9558 - val_loss: 22.7545\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 99.0697 - val_loss: 85.9217\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 57.5107 - val_loss: 42.9154\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 44.1003 - val_loss: 41.2426\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.8577 - val_loss: 43.2415\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 39.9483 - val_loss: 38.0702\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 38.9073 - val_loss: 37.0306\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 37.7428 - val_loss: 36.2535\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 41.1008 - val_loss: 38.2801\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.6377 - val_loss: 39.7387\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.4005 - val_loss: 36.9578\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.1093 - val_loss: 38.1297\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.0959 - val_loss: 34.8518\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.5868 - val_loss: 37.0350\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.1853 - val_loss: 34.5464\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.6739 - val_loss: 35.7835\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.5674 - val_loss: 34.2483\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.1894 - val_loss: 38.1536\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.2709 - val_loss: 32.9176\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.9494 - val_loss: 35.3614\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.1980 - val_loss: 32.2905\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.5931 - val_loss: 34.8652\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.4483 - val_loss: 32.3918\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.7742 - val_loss: 31.7917\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.1446 - val_loss: 31.3712\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.6470 - val_loss: 34.7924\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.2122 - val_loss: 31.9309\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.4817 - val_loss: 31.6143\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.9217 - val_loss: 32.0432\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.8966 - val_loss: 31.7868\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.0478 - val_loss: 48.4756\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 48.6350 - val_loss: 45.5317\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 43.7221 - val_loss: 43.3650\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.1500 - val_loss: 42.9468\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.7520 - val_loss: 39.7251\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 39.6235 - val_loss: 38.1521\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 38.9866 - val_loss: 39.9799\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 39.9034 - val_loss: 45.3870\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 38.1166 - val_loss: 36.5248\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 37.0323 - val_loss: 37.1555\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 36.6354 - val_loss: 35.9771\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 38.0634 - val_loss: 37.1224\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 36.5998 - val_loss: 37.8763\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 35.7533 - val_loss: 34.5737\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.6902 - val_loss: 35.1340\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.3720 - val_loss: 34.2578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.6076 - val_loss: 33.6373\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.2566 - val_loss: 33.3913\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.0247 - val_loss: 33.3442\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.1474 - val_loss: 32.9559\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.3459 - val_loss: 35.4614\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.3351 - val_loss: 32.8291\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 32.5531 - val_loss: 34.8133\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.4073 - val_loss: 32.5085\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 31.4996 - val_loss: 31.7689\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 31.9214 - val_loss: 31.5862\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 32.3984 - val_loss: 35.7699\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.7100 - val_loss: 31.7746\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 31.4082 - val_loss: 32.0575\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.7574 - val_loss: 30.4777\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.1329 - val_loss: 30.6898\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.6444 - val_loss: 31.2577\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 30.3480 - val_loss: 30.9771\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 729us/step - loss: 31.4802 - val_loss: 31.1124\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 749us/step - loss: 30.8564 - val_loss: 35.7144\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.5628 - val_loss: 48.6323\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 766us/step - loss: 44.9766 - val_loss: 41.0503\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 985us/step - loss: 40.2468 - val_loss: 38.1654\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 909us/step - loss: 39.0143 - val_loss: 38.6906\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 874us/step - loss: 38.0213 - val_loss: 37.7610\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 900us/step - loss: 37.2791 - val_loss: 36.0892\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 37.2620 - val_loss: 37.5067\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 37.2021 - val_loss: 40.7262\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.1113 - val_loss: 36.0837\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.1495 - val_loss: 35.0208\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.5522 - val_loss: 35.3364\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.2758 - val_loss: 34.1338\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.7249 - val_loss: 33.7059\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.0505 - val_loss: 33.8212\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.1818 - val_loss: 33.5194\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.6337 - val_loss: 33.4733\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 33.0837 - val_loss: 32.5766\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.5073 - val_loss: 36.3961\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.5007 - val_loss: 33.5429\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.4408 - val_loss: 34.8582\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.8972 - val_loss: 33.6449\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.8923 - val_loss: 32.2218\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.1909 - val_loss: 32.3019\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.8660 - val_loss: 31.6344\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.6846 - val_loss: 32.3245\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.3656 - val_loss: 32.6548\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.2213 - val_loss: 31.4197\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.3767 - val_loss: 32.0442\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.1277 - val_loss: 30.6290\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.8723 - val_loss: 30.6661\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.0487 - val_loss: 32.2150\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.1278 - val_loss: 31.1519\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.1450 - val_loss: 30.5294\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.6143 - val_loss: 35.0967\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.6164 - val_loss: 32.8617\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.7545 - val_loss: 30.0236\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.5757 - val_loss: 31.5111\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.1355 - val_loss: 30.1022\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.7558 - val_loss: 29.7035\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.7163 - val_loss: 29.3587\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.6482 - val_loss: 32.0144\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.2073 - val_loss: 30.1603\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.3856 - val_loss: 28.8916\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.3467 - val_loss: 28.1446\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 27.1038 - val_loss: 27.9358\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.4014 - val_loss: 29.4949\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.1179 - val_loss: 27.0609\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.3733 - val_loss: 26.8341\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.9062 - val_loss: 26.3946\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.1371 - val_loss: 25.9143\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.5531 - val_loss: 25.6257\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.5516 - val_loss: 26.1077\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.1996 - val_loss: 24.9392\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 23.8818 - val_loss: 24.5585\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.5678 - val_loss: 24.5597\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.6009 - val_loss: 24.7882\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.4103 - val_loss: 24.2871\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.0920 - val_loss: 24.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.9411 - val_loss: 23.9343\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.8163 - val_loss: 24.3213\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7030 - val_loss: 23.8025\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.7586 - val_loss: 23.8219\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.6701 - val_loss: 23.8158\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 22.5951 - val_loss: 23.8229\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 22.4844 - val_loss: 23.5571\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.2938 - val_loss: 23.4724\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.1518 - val_loss: 23.4854\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.0855 - val_loss: 23.3135\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 22.0417 - val_loss: 23.4469\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 769us/step - loss: 21.9794 - val_loss: 23.1862\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.8517 - val_loss: 23.1639\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7887 - val_loss: 23.0666\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.9342 - val_loss: 23.0697\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.8039 - val_loss: 23.1327\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6322 - val_loss: 22.9897\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.6446 - val_loss: 23.5273\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.6269 - val_loss: 22.8542\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5014 - val_loss: 22.9705\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3496 - val_loss: 23.3403\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7793 - val_loss: 22.9718\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.3054 - val_loss: 22.8893\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.3206 - val_loss: 23.4501\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.6029 - val_loss: 48.0924\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 44.6434 - val_loss: 44.4785\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 40.8413 - val_loss: 41.1563\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.5158 - val_loss: 39.4418\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 40.0103 - val_loss: 42.9083\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 38.8266 - val_loss: 40.5814\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.0658 - val_loss: 38.4471\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 36.7917 - val_loss: 37.7619\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.1635 - val_loss: 36.7004\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.0821 - val_loss: 35.9707\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 747us/step - loss: 34.9823 - val_loss: 36.8446\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 34.8377 - val_loss: 39.2328\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.8724 - val_loss: 36.8429\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.4086 - val_loss: 34.7535\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.0205 - val_loss: 36.0764\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 790us/step - loss: 33.4068 - val_loss: 35.0600\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.4903 - val_loss: 33.5228\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.9401 - val_loss: 33.1121\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.9589 - val_loss: 34.3301\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.8569 - val_loss: 32.6932\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.0875 - val_loss: 33.4986\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.3558 - val_loss: 32.3546\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.2750 - val_loss: 32.7690\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.6277 - val_loss: 32.6041\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.5501 - val_loss: 31.9908\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.9658 - val_loss: 31.5632\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.8605 - val_loss: 31.5062\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 31.4112 - val_loss: 35.2613\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.7079 - val_loss: 35.4654\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.1192 - val_loss: 32.7630\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.8845 - val_loss: 31.0752\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.4218 - val_loss: 30.7456\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.3951 - val_loss: 33.3557\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.9062 - val_loss: 31.5422\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.5248 - val_loss: 31.1269\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.9767 - val_loss: 29.3905\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.6891 - val_loss: 30.2518\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.8142 - val_loss: 29.0513\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 27.6116 - val_loss: 29.1073\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 27.0219 - val_loss: 28.5149\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.7783 - val_loss: 27.9581\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.0034 - val_loss: 28.9241\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.9705 - val_loss: 26.8899\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.5157 - val_loss: 27.2243\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 24.8974 - val_loss: 25.8468\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 24.6068 - val_loss: 26.2651\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 24.4350 - val_loss: 25.9339\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.0413 - val_loss: 25.0440\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.6636 - val_loss: 24.6704\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 23.3614 - val_loss: 24.6946\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.8526 - val_loss: 24.5104\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.2042 - val_loss: 24.4108\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 23.1952 - val_loss: 24.7753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.9835 - val_loss: 23.9748\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.7558 - val_loss: 24.4964\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7617 - val_loss: 23.8705\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.4966 - val_loss: 23.6407\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.4126 - val_loss: 23.6467\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.2778 - val_loss: 23.5800\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.2224 - val_loss: 23.6394\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2778 - val_loss: 24.7691\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.3780 - val_loss: 23.5369\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.9388 - val_loss: 23.3616\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.8377 - val_loss: 23.2514\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8977 - val_loss: 23.3489\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8505 - val_loss: 23.2722\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.7747 - val_loss: 23.2681\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.6192 - val_loss: 23.1047\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.5651 - val_loss: 23.0508\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.3536 - val_loss: 23.3451\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3052 - val_loss: 22.9803\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.2552 - val_loss: 22.8914\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1728 - val_loss: 22.9089\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.1907 - val_loss: 23.5023\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.1001 - val_loss: 22.8124\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.0160 - val_loss: 22.7702\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.0107 - val_loss: 22.7982\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.0440 - val_loss: 22.8682\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.8455 - val_loss: 22.7465\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.9078 - val_loss: 22.7777\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.8257 - val_loss: 23.3078\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0567 - val_loss: 23.0326\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.9433 - val_loss: 22.7503\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.5885 - val_loss: 22.6768\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.5323 - val_loss: 22.6413\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.5657 - val_loss: 22.7895\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.4092 - val_loss: 22.6280\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.2789 - val_loss: 22.5408\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.3210 - val_loss: 23.2439\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.4289 - val_loss: 22.5343\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.2478 - val_loss: 23.0797\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.2343 - val_loss: 22.7195\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.1381 - val_loss: 23.1228\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.2240 - val_loss: 22.5296\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.0884 - val_loss: 22.6028\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.0137 - val_loss: 23.1580\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.1314 - val_loss: 22.7498\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 19.9927 - val_loss: 22.6976\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 19.8269 - val_loss: 22.7851\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.0000 - val_loss: 55.6930\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 563us/step - loss: 49.5409 - val_loss: 44.8870\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 43.1705 - val_loss: 41.7182\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.7739 - val_loss: 42.4156\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.9671 - val_loss: 40.1517\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 40.0692 - val_loss: 39.0543\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.6107 - val_loss: 37.7802\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 38.7818 - val_loss: 37.1320\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.7583 - val_loss: 43.2726\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 43.3228 - val_loss: 39.9920\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 40.4089 - val_loss: 38.8423\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.6511 - val_loss: 38.2381\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.0992 - val_loss: 36.2110\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.4780 - val_loss: 37.1002\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.9925 - val_loss: 35.3919\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.4053 - val_loss: 34.9951\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.1346 - val_loss: 35.1493\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.6816 - val_loss: 36.0600\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.2718 - val_loss: 33.9818\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.8684 - val_loss: 34.5409\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.3495 - val_loss: 37.5185\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.8618 - val_loss: 35.3518\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.3982 - val_loss: 36.7667\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.8073 - val_loss: 36.4238\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.9782 - val_loss: 44.9443\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 44.5349 - val_loss: 41.3059\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.4592 - val_loss: 40.6291\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.8087 - val_loss: 38.0529\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.4696 - val_loss: 39.1268\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 38.2300 - val_loss: 36.5221\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.9791 - val_loss: 36.5642\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 36.6619 - val_loss: 38.0454\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.5081 - val_loss: 36.4913\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 36.5991 - val_loss: 42.2765\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 37.8740 - val_loss: 35.0211\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.2958 - val_loss: 35.2975\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.5604 - val_loss: 34.9474\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.2353 - val_loss: 33.8459\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.8959 - val_loss: 33.4051\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.3491 - val_loss: 33.3727\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 34.2153 - val_loss: 33.5064\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.0542 - val_loss: 33.3630\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.3083 - val_loss: 35.1092\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 33.7894 - val_loss: 32.2514\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 32.8725 - val_loss: 36.7395\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.2007 - val_loss: 35.1748\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.4838 - val_loss: 33.5438\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.1808 - val_loss: 37.5267\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.6253 - val_loss: 37.8309\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.6981 - val_loss: 48.5923\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 46.2736 - val_loss: 44.7877\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 41.3436 - val_loss: 39.2681\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 40.6568 - val_loss: 45.8069\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.0820 - val_loss: 40.0859\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 39.6371 - val_loss: 38.8650\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.7496 - val_loss: 37.7211\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.7273 - val_loss: 39.8942\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.8691 - val_loss: 36.7012\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 37.2988 - val_loss: 38.1137\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.9204 - val_loss: 35.9538\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.1412 - val_loss: 36.5232\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.4312 - val_loss: 35.8452\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.6763 - val_loss: 36.8470\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.0348 - val_loss: 34.3970\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.8227 - val_loss: 34.5764\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.6305 - val_loss: 36.4627\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.3246 - val_loss: 34.3495\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.6598 - val_loss: 34.8257\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.1960 - val_loss: 35.5501\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 34.6314 - val_loss: 34.1939\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.3754 - val_loss: 33.1879\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.7998 - val_loss: 32.9291\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.1921 - val_loss: 33.4477\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 32.2294 - val_loss: 32.1995\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 32.9467 - val_loss: 37.0045\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8427 - val_loss: 32.7162\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.0532 - val_loss: 33.0371\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.3524 - val_loss: 34.6192\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.3294 - val_loss: 32.3256\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.1422 - val_loss: 50.5684\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 44.0099 - val_loss: 39.7735\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.9952 - val_loss: 38.3330\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.8442 - val_loss: 36.1659\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 35.6295 - val_loss: 36.3451\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.7453 - val_loss: 33.8701\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 34.3570 - val_loss: 34.2040\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.8529 - val_loss: 33.0687\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.3591 - val_loss: 33.6471\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.6040 - val_loss: 33.3148\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.3399 - val_loss: 32.7613\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.9228 - val_loss: 31.5949\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.0977 - val_loss: 31.7319\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.8507 - val_loss: 31.2853\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.2984 - val_loss: 32.0176\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.7205 - val_loss: 32.7701\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 30.5226 - val_loss: 30.2688\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 29.8985 - val_loss: 30.8237\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.3364 - val_loss: 33.9959\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 30.8092 - val_loss: 33.0179\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.2955 - val_loss: 31.7237\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 30.6351 - val_loss: 30.3763\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.1756 - val_loss: 46.3311\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 44.2966 - val_loss: 43.3080\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 42.5672 - val_loss: 45.3986\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 40.6648 - val_loss: 42.7846\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.6330 - val_loss: 41.1490\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 614us/step - loss: 39.7006 - val_loss: 43.9528\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 39.5046 - val_loss: 40.9756\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.3006 - val_loss: 39.8456\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.2855 - val_loss: 38.6188\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.2454 - val_loss: 38.8038\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 37.9974 - val_loss: 38.3411\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 37.4749 - val_loss: 39.9695\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 37.6706 - val_loss: 60.2921\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.4392 - val_loss: 38.9657\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 37.7391 - val_loss: 38.8600\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 36.3158 - val_loss: 38.6030\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.6331 - val_loss: 49.3941\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 43.3935 - val_loss: 42.1123\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 40.2523 - val_loss: 41.9927\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.7987 - val_loss: 43.2941\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.2357 - val_loss: 44.6371\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.8490 - val_loss: 39.2829\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 37.7122 - val_loss: 39.0590\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 36.5777 - val_loss: 38.5528\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 37.6506 - val_loss: 39.8510\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.9608 - val_loss: 37.8486\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.9459 - val_loss: 36.8138\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.7206 - val_loss: 36.7755\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.5344 - val_loss: 36.0879\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.1361 - val_loss: 36.7701\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.6901 - val_loss: 35.6524\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.2371 - val_loss: 35.9470\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.4251 - val_loss: 35.4828\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.9587 - val_loss: 35.1171\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.4277 - val_loss: 34.8277\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.4395 - val_loss: 36.3137\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 33.3774 - val_loss: 34.2242\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.2545 - val_loss: 36.5154\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.1191 - val_loss: 36.0693\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.9897 - val_loss: 36.4723\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.7167 - val_loss: 33.8002\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.2849 - val_loss: 34.3488\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.5548 - val_loss: 33.7922\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.1886 - val_loss: 32.8179\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.6482 - val_loss: 33.5493\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.3065 - val_loss: 34.2258\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.2205 - val_loss: 32.6026\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.8667 - val_loss: 32.2693\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.0873 - val_loss: 33.4165\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.4383 - val_loss: 31.8574\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.8669 - val_loss: 31.9341\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.9136 - val_loss: 31.7145\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.5368 - val_loss: 31.1084\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.9850 - val_loss: 30.9628\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.8291 - val_loss: 32.7412\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.7729 - val_loss: 33.3220\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.5384 - val_loss: 30.6813\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 28.8315 - val_loss: 31.9037\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 821us/step - loss: 28.9335 - val_loss: 30.1605\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 825us/step - loss: 28.0456 - val_loss: 30.0231\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.1265 - val_loss: 32.5057\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.3522 - val_loss: 30.1034\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.1089 - val_loss: 29.2759\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 26.8400 - val_loss: 29.1303\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 27.5144 - val_loss: 28.7399\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 27.1419 - val_loss: 33.3408\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 27.4186 - val_loss: 30.1789\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.8515 - val_loss: 29.7905\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 686us/step - loss: 26.0426 - val_loss: 27.4061\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.0988 - val_loss: 26.2130\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 25.6542 - val_loss: 25.9431\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 24.6668 - val_loss: 26.3562\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 24.4544 - val_loss: 25.1264\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.7855 - val_loss: 25.0011\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.8882 - val_loss: 25.3608\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.7406 - val_loss: 24.5245\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.3680 - val_loss: 24.7728\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 23.1773 - val_loss: 24.2422\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.9507 - val_loss: 23.9346\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.7432 - val_loss: 23.7685\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 22.6044 - val_loss: 23.6279\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.5193 - val_loss: 23.5839\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 604us/step - loss: 22.3402 - val_loss: 23.4307\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 22.3050 - val_loss: 23.4954\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 22.6091 - val_loss: 23.3540\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.2282 - val_loss: 23.3171\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.0339 - val_loss: 23.1220\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.9700 - val_loss: 23.1373\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.9111 - val_loss: 23.0716\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.8757 - val_loss: 23.2073\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 21.8600 - val_loss: 23.0399\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.8060 - val_loss: 23.2704\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 539us/step - loss: 21.7661 - val_loss: 22.9027\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.7862 - val_loss: 22.8709\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 21.6896 - val_loss: 22.9146\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.5863 - val_loss: 22.7858\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5286 - val_loss: 22.8327\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3982 - val_loss: 23.1110\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.3361 - val_loss: 22.7114\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 21.2749 - val_loss: 22.8141\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.2929 - val_loss: 22.7384\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3176 - val_loss: 22.6730\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.2921 - val_loss: 22.6537\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.0787 - val_loss: 22.6061\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.0188 - val_loss: 22.7577\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 21.0069 - val_loss: 22.6224\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.0249 - val_loss: 22.6055\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.9948 - val_loss: 23.0824\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.0973 - val_loss: 22.5629\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 20.8328 - val_loss: 22.4955\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0067 - val_loss: 23.0860\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.9451 - val_loss: 22.7991\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.7917 - val_loss: 22.5850\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.6432 - val_loss: 22.7100\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.5797 - val_loss: 22.7103\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.2719 - val_loss: 48.5726\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 46.1968 - val_loss: 45.3389\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 43.6203 - val_loss: 42.1985\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.8831 - val_loss: 39.7500\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.5082 - val_loss: 41.4668\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.1172 - val_loss: 37.3815\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 37.9440 - val_loss: 38.2782\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.2058 - val_loss: 38.8862\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.9913 - val_loss: 35.2986\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.7331 - val_loss: 35.8240\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.7794 - val_loss: 34.4041\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.0095 - val_loss: 34.9799\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.9189 - val_loss: 34.1224\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.6108 - val_loss: 39.0131\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.8936 - val_loss: 35.0470\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.8487 - val_loss: 39.3477\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.4425 - val_loss: 33.5539\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.5579 - val_loss: 32.7206\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.4071 - val_loss: 32.7049\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.6057 - val_loss: 31.9430\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.4559 - val_loss: 32.4228\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.8545 - val_loss: 33.8772\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.3463 - val_loss: 34.4672\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.7961 - val_loss: 31.1808\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.9077 - val_loss: 30.7542\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.8933 - val_loss: 32.6028\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.5738 - val_loss: 30.5595\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 29.6182 - val_loss: 30.0249\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.8993 - val_loss: 32.7186\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.1646 - val_loss: 29.7396\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.9473 - val_loss: 29.5328\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.5548 - val_loss: 29.5680\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.4566 - val_loss: 31.6295\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 28.7362 - val_loss: 29.3420\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.9574 - val_loss: 30.7700\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.7700 - val_loss: 29.3455\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.7533 - val_loss: 30.1204\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.3297 - val_loss: 28.6342\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.9601 - val_loss: 29.4886\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 27.5195 - val_loss: 28.8404\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.0680 - val_loss: 27.7837\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.8378 - val_loss: 28.2484\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.9036 - val_loss: 27.5532\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.6034 - val_loss: 28.3298\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 27.0146 - val_loss: 27.6623\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 26.4794 - val_loss: 28.6015\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.7982 - val_loss: 29.5140\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.9700 - val_loss: 27.9561\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.8439 - val_loss: 58.8220\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 812us/step - loss: 50.3939 - val_loss: 51.5348\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 45.5165 - val_loss: 47.5471\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 44.2887 - val_loss: 44.2818\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 41.3085 - val_loss: 42.4528\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.9235 - val_loss: 41.2625\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.6432 - val_loss: 42.2989\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 38.3212 - val_loss: 40.7264\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.3934 - val_loss: 39.6683\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.6441 - val_loss: 39.6315\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.4003 - val_loss: 42.1538\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 38.3004 - val_loss: 38.8626\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.2608 - val_loss: 39.2520\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.3940 - val_loss: 38.2266\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.9116 - val_loss: 37.7722\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.3309 - val_loss: 38.9340\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.3285 - val_loss: 36.5523\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 36.6295 - val_loss: 37.8052\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.4134 - val_loss: 36.8435\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.3136 - val_loss: 36.3953\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.0650 - val_loss: 37.5133\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.4103 - val_loss: 35.5679\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.2855 - val_loss: 36.5778\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.1670 - val_loss: 34.9695\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.4640 - val_loss: 35.3417\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.2152 - val_loss: 34.7741\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.8507 - val_loss: 33.9179\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.0048 - val_loss: 33.7021\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.1892 - val_loss: 33.9994\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.9164 - val_loss: 32.2510\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.7565 - val_loss: 31.9855\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.1805 - val_loss: 33.6571\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.1756 - val_loss: 30.5924\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.6803 - val_loss: 30.5370\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.9792 - val_loss: 29.3865\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 28.3547 - val_loss: 28.8413\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.2576 - val_loss: 28.0158\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.1127 - val_loss: 27.6024\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.1787 - val_loss: 26.9873\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 25.8021 - val_loss: 26.6414\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 25.3721 - val_loss: 26.4873\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.7876 - val_loss: 26.1190\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.3539 - val_loss: 25.6914\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.3156 - val_loss: 26.2820\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 24.7364 - val_loss: 25.3891\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.6063 - val_loss: 25.9934\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 25.0068 - val_loss: 25.0477\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.9866 - val_loss: 24.8510\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.6885 - val_loss: 24.6041\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.5276 - val_loss: 24.4888\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.5189 - val_loss: 24.2541\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.3138 - val_loss: 24.1221\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.1217 - val_loss: 24.0399\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 23.0300 - val_loss: 24.0234\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.9838 - val_loss: 23.9143\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.9037 - val_loss: 23.7645\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.7902 - val_loss: 23.8788\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 22.7956 - val_loss: 23.7161\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.7165 - val_loss: 23.5068\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.6572 - val_loss: 23.6033\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.3907 - val_loss: 23.3836\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.4398 - val_loss: 23.8393\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.5225 - val_loss: 23.2881\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.1110 - val_loss: 23.1639\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.9648 - val_loss: 23.0758\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.9144 - val_loss: 23.0124\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.0100 - val_loss: 23.0219\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.8134 - val_loss: 23.0174\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.8248 - val_loss: 22.9120\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.8466 - val_loss: 23.0401\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.9146 - val_loss: 23.0997\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.5797 - val_loss: 22.7935\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.5436 - val_loss: 22.8032\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 649us/step - loss: 21.4748 - val_loss: 22.6848\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3060 - val_loss: 22.6385\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.4434 - val_loss: 22.5770\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1799 - val_loss: 22.7249\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2367 - val_loss: 22.5795\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1416 - val_loss: 22.4768\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.0829 - val_loss: 22.5811\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.1898 - val_loss: 22.4554\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9133 - val_loss: 22.3945\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.8075 - val_loss: 22.4416\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.7449 - val_loss: 22.3814\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.8026 - val_loss: 22.5017\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.7298 - val_loss: 22.3878\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.6955 - val_loss: 22.2939\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.7286 - val_loss: 22.2707\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.5760 - val_loss: 22.3546\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.5926 - val_loss: 23.0455\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.8028 - val_loss: 22.4807\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.3936 - val_loss: 22.2729\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.3643 - val_loss: 22.1830\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.7069 - val_loss: 22.5275\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.4150 - val_loss: 22.3557\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.2382 - val_loss: 22.1790\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.1630 - val_loss: 22.0774\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.1680 - val_loss: 22.1180\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.0558 - val_loss: 22.0926\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.0689 - val_loss: 22.3052\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 105.0884 - val_loss: 74.3125\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 52.5424 - val_loss: 43.7456\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 42.5224 - val_loss: 41.2380\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 40.7961 - val_loss: 39.4336\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.9879 - val_loss: 38.8797\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.4034 - val_loss: 39.6462\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.2502 - val_loss: 37.7930\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.2787 - val_loss: 37.4986\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.5739 - val_loss: 36.9786\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 36.8291 - val_loss: 36.7271\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.0788 - val_loss: 36.2048\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.1055 - val_loss: 36.3730\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 34.7238 - val_loss: 34.7031\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.4068 - val_loss: 34.3670\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 34.6295 - val_loss: 35.1652\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.9325 - val_loss: 34.3473\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.7410 - val_loss: 34.6827\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.4420 - val_loss: 33.6108\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.5504 - val_loss: 35.9868\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.2340 - val_loss: 33.7082\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.8925 - val_loss: 34.5556\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.5334 - val_loss: 33.4493\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.3141 - val_loss: 32.7495\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.1760 - val_loss: 32.0722\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.8159 - val_loss: 33.6017\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.5707 - val_loss: 31.7001\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 31.0550 - val_loss: 31.2718\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.4263 - val_loss: 31.1253\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.2500 - val_loss: 31.6466\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.2452 - val_loss: 30.6692\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.9707 - val_loss: 31.3215\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.9446 - val_loss: 29.9550\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.8666 - val_loss: 32.8313\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.1684 - val_loss: 29.7711\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.9786 - val_loss: 31.6719\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.9174 - val_loss: 28.2465\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.3524 - val_loss: 27.8196\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.6145 - val_loss: 27.0923\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.8191 - val_loss: 26.7688\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.7895 - val_loss: 27.9335\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.6018 - val_loss: 26.4811\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.6525 - val_loss: 25.4563\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.3459 - val_loss: 25.2284\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.9764 - val_loss: 25.2489\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.1609 - val_loss: 25.2447\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.6425 - val_loss: 24.5648\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.3639 - val_loss: 24.5150\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.1762 - val_loss: 24.1326\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 23.2256 - val_loss: 24.0698\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.0098 - val_loss: 24.3043\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 606us/step - loss: 22.9585 - val_loss: 23.7991\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 22.6925 - val_loss: 23.8608\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.5617 - val_loss: 23.8076\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.4212 - val_loss: 23.6495\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.5854 - val_loss: 23.5928\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.4411 - val_loss: 23.5716\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.2452 - val_loss: 23.4481\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.2666 - val_loss: 23.6737\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.0919 - val_loss: 23.5017\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.9951 - val_loss: 23.3066\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.8879 - val_loss: 23.2997\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.9210 - val_loss: 23.5986\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.4930 - val_loss: 23.9631\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.2325 - val_loss: 23.2567\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.6742 - val_loss: 23.0877\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.5631 - val_loss: 23.4495\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.7809 - val_loss: 23.3487\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5516 - val_loss: 22.9763\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.5212 - val_loss: 23.2298\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.4067 - val_loss: 23.0711\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.4962 - val_loss: 22.9181\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.3319 - val_loss: 23.1120\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.2751 - val_loss: 22.8310\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.1568 - val_loss: 22.8990\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3379 - val_loss: 22.8402\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.9069 - val_loss: 23.8608\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3502 - val_loss: 22.7626\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 21.0587 - val_loss: 23.0951\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9349 - val_loss: 22.7569\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9350 - val_loss: 22.9163\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.9261 - val_loss: 22.7534\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.8712 - val_loss: 22.9103\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.9943 - val_loss: 22.8102\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 20.9441 - val_loss: 22.9382\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.8477 - val_loss: 22.6601\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.6547 - val_loss: 22.7068\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.7483 - val_loss: 22.9025\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.5806 - val_loss: 22.7347\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.6098 - val_loss: 22.6242\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.6315 - val_loss: 22.8557\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.7531 - val_loss: 22.8849\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.5575 - val_loss: 22.6828\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.4020 - val_loss: 22.7619\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.5347 - val_loss: 23.2959\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.6666 - val_loss: 52.5446\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 47.1226 - val_loss: 47.4232\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 43.0399 - val_loss: 41.3547\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.1024 - val_loss: 43.3585\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 42.0559 - val_loss: 40.1857\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.2405 - val_loss: 41.0941\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 40.9660 - val_loss: 39.5372\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 39.2510 - val_loss: 38.7497\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 38.5256 - val_loss: 37.8532\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.0387 - val_loss: 37.7318\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.3036 - val_loss: 37.3805\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 37.5101 - val_loss: 36.8389\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.4484 - val_loss: 39.5215\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 38.3451 - val_loss: 36.6333\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.3898 - val_loss: 35.8843\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.9960 - val_loss: 36.7147\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.3086 - val_loss: 37.4144\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.6461 - val_loss: 35.1780\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.2184 - val_loss: 35.3084\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.5910 - val_loss: 36.1357\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.5283 - val_loss: 35.0610\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.1723 - val_loss: 34.9595\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.3869 - val_loss: 34.5299\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.5182 - val_loss: 35.4993\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.8332 - val_loss: 35.1901\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.7409 - val_loss: 34.4936\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 33.3340 - val_loss: 33.1224\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.2096 - val_loss: 34.5365\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.9709 - val_loss: 33.5789\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.0147 - val_loss: 39.0706\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.0392 - val_loss: 32.3515\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.7806 - val_loss: 31.9051\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.2559 - val_loss: 31.5256\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 627us/step - loss: 31.1793 - val_loss: 31.5118\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.5313 - val_loss: 31.6981\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.8721 - val_loss: 31.1437\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.2722 - val_loss: 30.3915\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.0821 - val_loss: 30.7361\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.8638 - val_loss: 30.7328\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.6621 - val_loss: 29.8610\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.2517 - val_loss: 31.0473\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.5626 - val_loss: 31.0146\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.8146 - val_loss: 28.1930\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 27.1707 - val_loss: 27.2987\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 26.8003 - val_loss: 26.8992\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 26.2316 - val_loss: 27.0116\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 25.6607 - val_loss: 26.4607\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 25.2463 - val_loss: 25.3842\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 24.6735 - val_loss: 24.9245\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 24.2074 - val_loss: 24.8039\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 23.9981 - val_loss: 24.4327\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 24.3333 - val_loss: 24.3696\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 24.0591 - val_loss: 24.7369\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 23.5935 - val_loss: 24.0060\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 23.5058 - val_loss: 23.8388\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 23.1991 - val_loss: 23.7777\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.9399 - val_loss: 23.5665\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.9205 - val_loss: 23.4499\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 22.8004 - val_loss: 23.3738\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.7727 - val_loss: 23.2510\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.5933 - val_loss: 23.5704\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 22.7850 - val_loss: 23.6799\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 22.6107 - val_loss: 23.1010\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 22.3212 - val_loss: 23.0897\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 22.2006 - val_loss: 23.0338\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 22.1494 - val_loss: 22.9176\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.3638 - val_loss: 22.9252\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 22.0841 - val_loss: 23.0471\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 21.9615 - val_loss: 22.8374\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 22.0589 - val_loss: 22.8199\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 22.0981 - val_loss: 22.7323\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.7657 - val_loss: 22.6649\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 21.7432 - val_loss: 22.6781\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.6367 - val_loss: 22.5841\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 21.7977 - val_loss: 22.8255\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.6212 - val_loss: 22.7430\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.5599 - val_loss: 22.5659\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.6111 - val_loss: 22.9663\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 21.6833 - val_loss: 22.6472\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 21.3889 - val_loss: 22.4654\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.2935 - val_loss: 22.4914\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 21.3889 - val_loss: 22.8289\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 21.3008 - val_loss: 22.4905\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 21.4008 - val_loss: 23.3267\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.4748 - val_loss: 22.4625\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 21.3043 - val_loss: 22.5338\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.1892 - val_loss: 22.4782\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.0644 - val_loss: 22.3354\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 20.9495 - val_loss: 22.3289\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 20.8815 - val_loss: 22.6452\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 21.0180 - val_loss: 22.6305\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 21.0789 - val_loss: 22.5925\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 20.9997 - val_loss: 22.3810\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 21.1569 - val_loss: 22.2951\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 20.8628 - val_loss: 22.4279\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 20.6536 - val_loss: 22.3096\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 690us/step - loss: 20.6524 - val_loss: 22.3669\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 20.6312 - val_loss: 22.2500\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 20.6789 - val_loss: 22.4818\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 20.5889 - val_loss: 22.2427\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.0275 - val_loss: 53.6937\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 48.3701 - val_loss: 55.3505\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 48.5728 - val_loss: 45.5842\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 44.1223 - val_loss: 44.7451\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 45.5994 - val_loss: 46.1968\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 45.0879 - val_loss: 43.4657\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.2689 - val_loss: 43.1286\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 42.0831 - val_loss: 42.7683\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.6009 - val_loss: 40.9031\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 39.5607 - val_loss: 40.5730\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 590us/step - loss: 38.7781 - val_loss: 40.2687\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.7758 - val_loss: 40.2637\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 39.6158 - val_loss: 40.9291\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 482us/step - loss: 38.4725 - val_loss: 41.0777\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 39.1768 - val_loss: 41.0031\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 975us/step - loss: 37.9452 - val_loss: 38.6610\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 914us/step - loss: 37.2040 - val_loss: 37.4686\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 885us/step - loss: 37.4798 - val_loss: 39.0035\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 897us/step - loss: 40.0817 - val_loss: 38.0278\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 874us/step - loss: 37.1676 - val_loss: 39.6220\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 942us/step - loss: 35.5065 - val_loss: 35.8767\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 967us/step - loss: 35.4039 - val_loss: 36.8702\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 920us/step - loss: 34.8529 - val_loss: 36.8641\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 878us/step - loss: 34.2884 - val_loss: 34.7494\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 908us/step - loss: 35.4491 - val_loss: 36.0508\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 957us/step - loss: 35.2824 - val_loss: 37.8626\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 878us/step - loss: 34.4705 - val_loss: 34.9287\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 880us/step - loss: 34.6393 - val_loss: 36.3488\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 877us/step - loss: 33.3325 - val_loss: 35.7143\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.0193 - val_loss: 46.5919\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 46.7057 - val_loss: 42.6368\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 45.0123 - val_loss: 43.9500\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.3113 - val_loss: 39.7701\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.2711 - val_loss: 37.9399\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.6275 - val_loss: 39.2944\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.5391 - val_loss: 39.5973\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.3727 - val_loss: 39.2057\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.1201 - val_loss: 39.7395\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.1281 - val_loss: 36.3841\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.0764 - val_loss: 35.9948\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.3378 - val_loss: 34.9142\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.3673 - val_loss: 36.1448\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.3611 - val_loss: 34.6666\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.8249 - val_loss: 34.5655\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.4249 - val_loss: 33.5143\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.5962 - val_loss: 34.5599\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 34.3902 - val_loss: 33.2082\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.4051 - val_loss: 33.4388\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.4315 - val_loss: 33.1172\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.7275 - val_loss: 33.5227\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.6004 - val_loss: 32.6699\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.5054 - val_loss: 32.9689\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.9606 - val_loss: 31.8199\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.6088 - val_loss: 32.4144\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.4541 - val_loss: 31.4140\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.8727 - val_loss: 32.2697\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 31.4753 - val_loss: 30.8117\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.6759 - val_loss: 30.7395\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.4887 - val_loss: 30.5882\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.3942 - val_loss: 31.2426\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.8910 - val_loss: 30.6884\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.0575 - val_loss: 31.8634\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.0445 - val_loss: 33.2546\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.5860 - val_loss: 31.7972\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 90.7082 - val_loss: 54.2636\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 48.2137 - val_loss: 43.1962\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 42.4332 - val_loss: 40.6688\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 41.1428 - val_loss: 40.0781\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.3480 - val_loss: 38.0582\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.6646 - val_loss: 38.6384\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.2710 - val_loss: 36.7709\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.0762 - val_loss: 37.1767\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.2861 - val_loss: 37.8938\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.1630 - val_loss: 35.3482\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.6010 - val_loss: 35.6415\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.8773 - val_loss: 35.2691\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.9316 - val_loss: 35.4956\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.5853 - val_loss: 34.6115\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.2422 - val_loss: 34.8172\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.2480 - val_loss: 33.3865\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.5553 - val_loss: 33.8264\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.3600 - val_loss: 33.3503\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.8301 - val_loss: 32.7359\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.0216 - val_loss: 31.9333\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.0151 - val_loss: 31.9601\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.5482 - val_loss: 31.5571\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 30.7800 - val_loss: 33.4911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.1465 - val_loss: 33.6069\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.6044 - val_loss: 31.5492\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 30.6926 - val_loss: 30.8958\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.4464 - val_loss: 31.2550\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.7712 - val_loss: 30.8022\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.3537 - val_loss: 30.4227\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.1229 - val_loss: 30.0136\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.8620 - val_loss: 29.4784\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.9994 - val_loss: 29.3073\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.2592 - val_loss: 30.2361\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.9816 - val_loss: 29.3589\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.7350 - val_loss: 28.7332\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 27.4444 - val_loss: 28.8345\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 26.9428 - val_loss: 28.0253\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 27.4046 - val_loss: 28.6849\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 27.8794 - val_loss: 28.5225\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 27.0382 - val_loss: 27.4576\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.0434 - val_loss: 27.4040\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.6462 - val_loss: 27.4819\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.8015 - val_loss: 28.2597\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.3091 - val_loss: 26.6730\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 25.4255 - val_loss: 26.0916\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 24.9376 - val_loss: 25.8517\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 24.7153 - val_loss: 25.9206\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 24.5777 - val_loss: 25.1811\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.0523 - val_loss: 25.1334\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.9333 - val_loss: 24.6591\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.7016 - val_loss: 24.4204\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.4811 - val_loss: 24.3588\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.5809 - val_loss: 24.2148\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0636 - val_loss: 23.9981\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.8157 - val_loss: 23.8148\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.8640 - val_loss: 23.8940\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.0087 - val_loss: 24.7833\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.1385 - val_loss: 23.7498\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.5876 - val_loss: 23.6274\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.3615 - val_loss: 23.6539\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.2623 - val_loss: 23.4188\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.1882 - val_loss: 23.3520\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.1075 - val_loss: 23.2358\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.0740 - val_loss: 23.2567\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.0375 - val_loss: 23.5031\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.4376 - val_loss: 23.4508\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.4359 - val_loss: 23.3601\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.1805 - val_loss: 23.1023\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 21.7882 - val_loss: 23.3600\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.6853 - val_loss: 22.9882\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6085 - val_loss: 22.9574\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5909 - val_loss: 22.9374\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.5470 - val_loss: 23.0022\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.5481 - val_loss: 22.8246\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.3552 - val_loss: 23.0281\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.5236 - val_loss: 22.8554\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3625 - val_loss: 22.7862\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.2711 - val_loss: 22.7597\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.1672 - val_loss: 22.8311\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.0949 - val_loss: 22.7323\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.0336 - val_loss: 22.7339\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.1176 - val_loss: 22.8191\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.9337 - val_loss: 22.6713\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9629 - val_loss: 22.6869\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.8940 - val_loss: 22.6122\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.8720 - val_loss: 22.7850\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.9390 - val_loss: 22.6490\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.8402 - val_loss: 22.6454\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.7572 - val_loss: 22.9406\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.8779 - val_loss: 22.6846\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.8787 - val_loss: 47.3800\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 46.0223 - val_loss: 41.4460\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 44.7663 - val_loss: 42.0891\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.6903 - val_loss: 39.3245\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.1329 - val_loss: 38.4852\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.4890 - val_loss: 38.9251\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.3854 - val_loss: 39.2732\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.8126 - val_loss: 37.3615\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.9633 - val_loss: 36.7541\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.3117 - val_loss: 38.8959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.5756 - val_loss: 35.9430\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.5191 - val_loss: 48.4896\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.4831 - val_loss: 35.5919\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 37.5356 - val_loss: 34.6220\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.7331 - val_loss: 44.3449\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.0255 - val_loss: 34.4511\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.2000 - val_loss: 37.5116\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 37.3641 - val_loss: 35.0639\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.9982 - val_loss: 38.0010\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.8484 - val_loss: 35.9122\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.6615 - val_loss: 33.6220\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.4864 - val_loss: 33.5532\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.3160 - val_loss: 33.1375\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.6947 - val_loss: 34.5304\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.2214 - val_loss: 36.4150\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.7129 - val_loss: 34.0297\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.4198 - val_loss: 34.0415\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.8925 - val_loss: 32.4541\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.7582 - val_loss: 32.0655\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.2999 - val_loss: 31.9054\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.8800 - val_loss: 31.8391\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.2928 - val_loss: 31.3617\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.8897 - val_loss: 34.1579\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.5825 - val_loss: 30.7281\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.0231 - val_loss: 31.3354\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.7068 - val_loss: 35.6584\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.4520 - val_loss: 30.8918\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.5388 - val_loss: 30.5916\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.0252 - val_loss: 30.1615\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.1091 - val_loss: 30.6953\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.5730 - val_loss: 31.4359\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.4983 - val_loss: 30.2639\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.0496 - val_loss: 29.9183\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.3538 - val_loss: 31.9215\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.6705 - val_loss: 36.3943\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.4444 - val_loss: 30.7183\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.3708 - val_loss: 33.5272\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.4504 - val_loss: 29.7081\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.2004 - val_loss: 28.8433\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.8860 - val_loss: 29.5788\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.9267 - val_loss: 28.4518\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.3423 - val_loss: 28.4810\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.6553 - val_loss: 29.6971\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.8710 - val_loss: 28.2639\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.4877 - val_loss: 28.6525\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 27.7698 - val_loss: 27.0696\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.3217 - val_loss: 26.9014\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.6192 - val_loss: 26.5994\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.1388 - val_loss: 27.2711\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.9027 - val_loss: 26.9317\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 25.7916 - val_loss: 25.8365\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.2450 - val_loss: 25.0781\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.5435 - val_loss: 24.5401\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 24.3243 - val_loss: 25.0186\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.5615 - val_loss: 23.9858\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.4597 - val_loss: 24.2100\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.3705 - val_loss: 23.4439\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.8471 - val_loss: 23.2517\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.6181 - val_loss: 23.2680\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.5265 - val_loss: 23.0817\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.2434 - val_loss: 22.9069\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.1663 - val_loss: 23.6265\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.1105 - val_loss: 22.6763\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.9200 - val_loss: 22.8764\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.7326 - val_loss: 22.4673\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5606 - val_loss: 22.3847\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5473 - val_loss: 22.4100\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4080 - val_loss: 22.2966\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.3594 - val_loss: 22.2510\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.1454 - val_loss: 22.1579\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2513 - val_loss: 22.1996\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.1086 - val_loss: 22.3706\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.9780 - val_loss: 22.0811\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.8597 - val_loss: 22.0338\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.8056 - val_loss: 21.9573\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.8051 - val_loss: 22.5215\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.6484 - val_loss: 21.9534\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.6513 - val_loss: 22.0315\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.7655 - val_loss: 22.7298\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.5871 - val_loss: 21.9392\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.5815 - val_loss: 22.5547\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.5785 - val_loss: 21.9341\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.2596 - val_loss: 22.0384\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.2001 - val_loss: 21.9656\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.0877 - val_loss: 21.7335\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.0197 - val_loss: 21.7543\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.0339 - val_loss: 21.8986\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 19.8804 - val_loss: 21.6992\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 19.8717 - val_loss: 22.1322\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 19.8002 - val_loss: 21.6149\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.9351 - val_loss: 50.9879\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 48.3967 - val_loss: 48.1068\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 44.4296 - val_loss: 42.7610\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 42.1189 - val_loss: 41.1987\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.5382 - val_loss: 42.8577\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 41.2337 - val_loss: 39.7436\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.6568 - val_loss: 41.0716\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 40.5921 - val_loss: 40.7500\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 41.3748 - val_loss: 39.7368\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 39.4907 - val_loss: 38.8835\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 39.3775 - val_loss: 38.6518\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 38.3088 - val_loss: 37.4438\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 37.7060 - val_loss: 39.1220\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 37.0351 - val_loss: 37.1260\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 37.8818 - val_loss: 36.4011\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.8146 - val_loss: 36.0787\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.6537 - val_loss: 36.3048\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.6064 - val_loss: 39.4072\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.0605 - val_loss: 38.9887\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.6287 - val_loss: 34.3451\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.0010 - val_loss: 34.4156\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.7741 - val_loss: 36.8281\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.7582 - val_loss: 33.6154\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 32.9901 - val_loss: 33.2796\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.2580 - val_loss: 33.5842\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.4305 - val_loss: 33.5991\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.1749 - val_loss: 31.8728\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.3850 - val_loss: 31.8299\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.6385 - val_loss: 30.4383\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.5019 - val_loss: 33.2779\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 32.5091 - val_loss: 30.6184\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 29.4960 - val_loss: 29.8089\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.7417 - val_loss: 28.7456\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 28.8060 - val_loss: 28.8770\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.4024 - val_loss: 27.9036\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.0687 - val_loss: 26.8327\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.0811 - val_loss: 26.0170\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.5292 - val_loss: 26.0987\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.3304 - val_loss: 24.9935\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.7565 - val_loss: 24.7790\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.5334 - val_loss: 24.5452\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.9775 - val_loss: 24.1460\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.8441 - val_loss: 24.0554\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.4678 - val_loss: 23.8294\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.3003 - val_loss: 23.6893\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.1162 - val_loss: 23.8067\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.2019 - val_loss: 23.5158\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.8327 - val_loss: 23.8771\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.4201 - val_loss: 23.2793\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.8791 - val_loss: 23.2431\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.5829 - val_loss: 23.0709\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.3752 - val_loss: 22.9778\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.3614 - val_loss: 23.1038\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.1932 - val_loss: 22.8875\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.1433 - val_loss: 22.8314\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.0805 - val_loss: 22.9267\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.8642 - val_loss: 22.6042\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7973 - val_loss: 23.0154\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0105 - val_loss: 22.6454\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.6853 - val_loss: 22.4390\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6342 - val_loss: 22.3523\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.5481 - val_loss: 22.3294\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5358 - val_loss: 22.2831\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.4358 - val_loss: 22.2583\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 631us/step - loss: 21.4070 - val_loss: 22.2257\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2931 - val_loss: 22.2195\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.2579 - val_loss: 22.2541\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3212 - val_loss: 22.3490\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4185 - val_loss: 22.2829\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.0693 - val_loss: 22.1479\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.0165 - val_loss: 22.1087\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.0232 - val_loss: 22.1841\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.0858 - val_loss: 22.0748\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.8368 - val_loss: 22.1707\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.9303 - val_loss: 22.0935\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8707 - val_loss: 21.9279\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.7421 - val_loss: 22.0016\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.9522 - val_loss: 22.3475\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.6343 - val_loss: 21.8269\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 20.3938 - val_loss: 21.8859\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.3754 - val_loss: 21.8240\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.3916 - val_loss: 22.0849\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.3719 - val_loss: 21.8408\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.2173 - val_loss: 22.0925\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 20.5675 - val_loss: 22.3405\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.3182 - val_loss: 21.7829\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.0586 - val_loss: 21.7478\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.0530 - val_loss: 21.7573\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 19.9791 - val_loss: 22.0059\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 19.9245 - val_loss: 21.8534\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 19.9315 - val_loss: 21.7482\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.0582 - val_loss: 22.5362\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.6312 - val_loss: 48.4670\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 45.4458 - val_loss: 43.2814\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 44.8214 - val_loss: 43.3072\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 42.4514 - val_loss: 43.1426\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 41.6193 - val_loss: 45.9246\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.9942 - val_loss: 39.8787\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 39.1721 - val_loss: 39.3064\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.1706 - val_loss: 38.1495\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.6275 - val_loss: 40.6601\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.1053 - val_loss: 38.4571\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.1387 - val_loss: 42.1353\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.6021 - val_loss: 38.0389\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.9540 - val_loss: 37.4706\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.6927 - val_loss: 38.5784\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.3195 - val_loss: 36.5800\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.4886 - val_loss: 35.2609\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.7071 - val_loss: 35.3455\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.3090 - val_loss: 37.9742\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 36.7519 - val_loss: 39.4048\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.0366 - val_loss: 34.8613\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.4441 - val_loss: 37.1278\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.2644 - val_loss: 33.8540\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.2194 - val_loss: 35.0464\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.6233 - val_loss: 33.5955\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.2128 - val_loss: 33.1458\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.3241 - val_loss: 34.0610\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.2231 - val_loss: 35.2474\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.6020 - val_loss: 33.5012\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.6127 - val_loss: 32.1097\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.7867 - val_loss: 35.0037\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.2618 - val_loss: 32.6770\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.7069 - val_loss: 32.8889\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.8680 - val_loss: 31.4012\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.3574 - val_loss: 31.9422\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.9303 - val_loss: 35.6172\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 33.2793 - val_loss: 33.4640\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.4478 - val_loss: 32.5606\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.3015 - val_loss: 31.8810\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.7743 - val_loss: 49.9015\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 47.0858 - val_loss: 48.3082\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 46.5302 - val_loss: 45.6182\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 43.8193 - val_loss: 40.7939\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.8087 - val_loss: 41.1758\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.7202 - val_loss: 40.1728\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 40.2410 - val_loss: 39.8868\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.5408 - val_loss: 41.1929\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.5804 - val_loss: 40.2289\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.0645 - val_loss: 36.6259\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.1596 - val_loss: 36.9118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 37.2204 - val_loss: 35.5053\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 709us/step - loss: 36.8718 - val_loss: 36.1271\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 821us/step - loss: 36.9216 - val_loss: 35.8989\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 35.8612 - val_loss: 34.5140\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.6043 - val_loss: 34.6777\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.1622 - val_loss: 35.4083\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.0957 - val_loss: 35.2545\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.0556 - val_loss: 33.7858\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.7950 - val_loss: 35.3802\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.5692 - val_loss: 36.6204\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.8134 - val_loss: 35.7484\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.8675 - val_loss: 33.6661\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 32.9790 - val_loss: 33.2378\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.5449 - val_loss: 32.5474\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.8381 - val_loss: 32.2611\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.1212 - val_loss: 32.2371\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 31.8166 - val_loss: 32.0779\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.2100 - val_loss: 34.4222\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.9371 - val_loss: 32.7302\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.6853 - val_loss: 32.0523\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.3310 - val_loss: 31.4794\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.6092 - val_loss: 35.3236\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.3830 - val_loss: 34.8718\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.5582 - val_loss: 31.7588\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.7321 - val_loss: 30.9691\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.1041 - val_loss: 35.3314\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.0664 - val_loss: 31.6411\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.1320 - val_loss: 30.9247\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.4680 - val_loss: 30.9629\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.1056 - val_loss: 30.6419\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 29.8562 - val_loss: 30.0932\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.2152 - val_loss: 34.4288\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 30.5385 - val_loss: 31.1565\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.5923 - val_loss: 31.2707\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.7826 - val_loss: 30.3235\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.0855 - val_loss: 29.9285\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.7018 - val_loss: 30.2168\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.4523 - val_loss: 31.0366\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.8495 - val_loss: 29.7979\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.5496 - val_loss: 29.3247\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.3738 - val_loss: 28.8610\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.0583 - val_loss: 28.8961\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.6589 - val_loss: 28.2512\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 28.2112 - val_loss: 29.1738\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.4504 - val_loss: 28.8703\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.1671 - val_loss: 30.9452\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.0854 - val_loss: 28.3349\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 26.9161 - val_loss: 28.1413\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 27.6068 - val_loss: 28.4127\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 27.9315 - val_loss: 28.6351\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.1149 - val_loss: 27.1959\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 26.6043 - val_loss: 26.8674\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.8848 - val_loss: 26.9612\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.9458 - val_loss: 26.5188\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.7060 - val_loss: 28.3193\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.5160 - val_loss: 26.1713\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.0528 - val_loss: 26.2469\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 24.9408 - val_loss: 26.8891\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 24.6005 - val_loss: 25.7470\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 24.1097 - val_loss: 24.9098\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.5282 - val_loss: 25.2075\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.4220 - val_loss: 24.3707\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.0946 - val_loss: 24.5884\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.8014 - val_loss: 24.2836\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6900 - val_loss: 24.2798\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.4355 - val_loss: 23.8713\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 22.4021 - val_loss: 23.4477\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.6529 - val_loss: 23.5124\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.6121 - val_loss: 24.0035\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.3451 - val_loss: 23.3917\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.4094 - val_loss: 23.0680\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2694 - val_loss: 23.2469\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.9275 - val_loss: 23.0243\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7626 - val_loss: 23.2411\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.4260 - val_loss: 22.8040\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.3064 - val_loss: 22.9526\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.2404 - val_loss: 22.9688\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1488 - val_loss: 23.0725\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.4458 - val_loss: 22.5887\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1125 - val_loss: 22.5644\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.9196 - val_loss: 22.5232\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.8231 - val_loss: 22.3904\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.7577 - val_loss: 22.6097\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.6149 - val_loss: 22.5964\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.7566 - val_loss: 22.3844\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.7445 - val_loss: 22.3756\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 20.6664 - val_loss: 22.4400\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.5333 - val_loss: 22.6605\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.4530 - val_loss: 22.3411\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.2831 - val_loss: 47.0906\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 45.1359 - val_loss: 41.9222\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 41.8664 - val_loss: 40.0831\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 41.2476 - val_loss: 42.6137\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.3774 - val_loss: 40.9934\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 42.0646 - val_loss: 39.4055\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 39.4901 - val_loss: 40.4051\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.1980 - val_loss: 39.4918\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 39.3383 - val_loss: 40.3299\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.2928 - val_loss: 40.1895\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.2732 - val_loss: 36.8060\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.6900 - val_loss: 37.8176\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.9000 - val_loss: 35.8336\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.5315 - val_loss: 35.3434\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.9857 - val_loss: 34.6597\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.5782 - val_loss: 36.3855\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.0275 - val_loss: 34.9336\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.6193 - val_loss: 35.1559\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.8357 - val_loss: 34.4297\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.5020 - val_loss: 33.6150\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.6807 - val_loss: 33.8578\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.4999 - val_loss: 32.8623\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.2183 - val_loss: 33.8375\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.3762 - val_loss: 32.3413\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.9338 - val_loss: 33.2126\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.5507 - val_loss: 32.9811\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.2778 - val_loss: 33.7332\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.3437 - val_loss: 32.3583\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.0544 - val_loss: 32.8488\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.7119 - val_loss: 49.3428\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 48.9644 - val_loss: 44.9645\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 43.7149 - val_loss: 40.8832\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 42.4678 - val_loss: 43.0035\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 41.4083 - val_loss: 39.1717\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.4744 - val_loss: 38.2391\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.0006 - val_loss: 37.2941\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 39.8998 - val_loss: 38.8823\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 39.2769 - val_loss: 37.1287\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.4900 - val_loss: 36.6529\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.0820 - val_loss: 38.5442\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.1848 - val_loss: 36.1838\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.0503 - val_loss: 35.6014\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.2904 - val_loss: 36.5309\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 35.6075 - val_loss: 34.5478\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.2964 - val_loss: 35.1764\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.8704 - val_loss: 33.7774\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.6339 - val_loss: 33.4347\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.2047 - val_loss: 34.3237\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.6469 - val_loss: 33.1582\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.2886 - val_loss: 33.7618\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.2727 - val_loss: 32.9019\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.7454 - val_loss: 37.5745\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.1527 - val_loss: 34.9035\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.7103 - val_loss: 31.8444\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.9175 - val_loss: 32.1168\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.5120 - val_loss: 31.4631\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.9368 - val_loss: 31.5213\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.6533 - val_loss: 31.5166\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.4458 - val_loss: 30.9541\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.2500 - val_loss: 32.5539\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.3672 - val_loss: 33.1968\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.9161 - val_loss: 30.5480\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.6443 - val_loss: 30.3567\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.9167 - val_loss: 31.7827\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 596us/step - loss: 31.6343 - val_loss: 31.8802\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.3289 - val_loss: 30.4976\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.8827 - val_loss: 31.7317\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.4499 - val_loss: 31.3561\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 98.4120 - val_loss: 83.1658\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 53.6589 - val_loss: 46.7296\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 43.2559 - val_loss: 41.9194\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.1707 - val_loss: 41.0368\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 40.8254 - val_loss: 41.9922\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.9622 - val_loss: 39.0828\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.6358 - val_loss: 40.2078\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.5797 - val_loss: 39.0447\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.2403 - val_loss: 37.9058\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.1469 - val_loss: 37.7928\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.3588 - val_loss: 38.1625\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.5733 - val_loss: 36.7593\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.1151 - val_loss: 38.0028\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.2985 - val_loss: 37.6304\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.3307 - val_loss: 35.6066\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.7652 - val_loss: 35.8409\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.9564 - val_loss: 36.3753\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.9163 - val_loss: 37.0444\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.8153 - val_loss: 37.7888\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.4349 - val_loss: 33.9076\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.0523 - val_loss: 34.4337\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.2126 - val_loss: 33.4179\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.3409 - val_loss: 33.1314\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.5351 - val_loss: 33.2068\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.4350 - val_loss: 33.9790\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9957 - val_loss: 34.2670\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.6531 - val_loss: 32.2456\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 29.7588 - val_loss: 31.0503\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 29.7252 - val_loss: 30.6138\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.7075 - val_loss: 36.0183\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.7852 - val_loss: 30.6836\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.6504 - val_loss: 29.2878\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.9896 - val_loss: 28.8614\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.3837 - val_loss: 28.7086\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.1172 - val_loss: 31.0834\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 26.8453 - val_loss: 27.2444\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.6487 - val_loss: 26.3887\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.1713 - val_loss: 26.1402\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.7840 - val_loss: 25.6426\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.2165 - val_loss: 25.5999\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 24.5531 - val_loss: 25.2302\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.1543 - val_loss: 25.0974\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.9494 - val_loss: 24.8737\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.8284 - val_loss: 24.7583\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.5696 - val_loss: 24.5623\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 23.3643 - val_loss: 24.5123\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.4768 - val_loss: 24.6010\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.2518 - val_loss: 24.2958\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.0908 - val_loss: 24.4298\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.9763 - val_loss: 24.0214\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.8328 - val_loss: 23.9730\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.9736 - val_loss: 23.9609\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.2767 - val_loss: 23.9468\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.6223 - val_loss: 23.6560\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.5765 - val_loss: 23.5957\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.4409 - val_loss: 23.5164\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.2833 - val_loss: 23.4851\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.1252 - val_loss: 23.4739\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.0789 - val_loss: 23.3296\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.9546 - val_loss: 23.3184\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.8523 - val_loss: 23.2341\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.0115 - val_loss: 23.5658\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.8279 - val_loss: 23.4032\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.7357 - val_loss: 23.3802\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.7109 - val_loss: 23.0618\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.5341 - val_loss: 23.2113\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.5837 - val_loss: 23.3669\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.7292 - val_loss: 23.4392\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.5142 - val_loss: 22.9227\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3072 - val_loss: 22.9709\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.3531 - val_loss: 23.1708\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.3356 - val_loss: 22.9029\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.1271 - val_loss: 22.8484\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 639us/step - loss: 21.0552 - val_loss: 22.9828\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.4131 - val_loss: 22.9066\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1446 - val_loss: 22.7918\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.2544 - val_loss: 23.9865\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.4227 - val_loss: 23.5201\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.1011 - val_loss: 22.8066\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 20.8763 - val_loss: 22.7551\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.8967 - val_loss: 22.7484\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.8535 - val_loss: 22.9723\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8924 - val_loss: 22.7826\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.6151 - val_loss: 23.0037\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 769us/step - loss: 20.5854 - val_loss: 22.8346\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.4970 - val_loss: 22.8582\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.0181 - val_loss: 58.2216\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 46.0587 - val_loss: 41.6650\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 558us/step - loss: 41.4925 - val_loss: 39.9567\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.1274 - val_loss: 40.2460\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 40.0983 - val_loss: 38.3667\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.2592 - val_loss: 38.3049\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.1263 - val_loss: 38.9294\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.2890 - val_loss: 36.6640\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.7909 - val_loss: 40.2812\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.4334 - val_loss: 35.5444\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.3451 - val_loss: 35.9444\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.7961 - val_loss: 38.9882\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 36.1221 - val_loss: 34.7784\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.4702 - val_loss: 34.4692\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.2028 - val_loss: 34.0955\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.4463 - val_loss: 35.1949\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.1352 - val_loss: 34.2890\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 34.4743 - val_loss: 36.6623\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.5373 - val_loss: 33.6041\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 33.4318 - val_loss: 34.0893\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 33.5270 - val_loss: 32.9804\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.8228 - val_loss: 32.5870\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 33.0784 - val_loss: 34.3306\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.5438 - val_loss: 32.5151\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.7438 - val_loss: 32.9908\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 31.8903 - val_loss: 33.6147\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 31.6644 - val_loss: 31.4282\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 31.4979 - val_loss: 32.6203\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.3380 - val_loss: 31.4617\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.8070 - val_loss: 31.4153\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 31.5492 - val_loss: 32.4286\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 30.6259 - val_loss: 31.6586\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 30.5348 - val_loss: 31.3479\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 31.9892 - val_loss: 31.7565\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.7034 - val_loss: 32.2496\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 29.6870 - val_loss: 30.3313\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 29.1171 - val_loss: 31.1796\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 30.1899 - val_loss: 29.9335\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 30.3321 - val_loss: 30.2211\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 29.6762 - val_loss: 30.5508\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 28.7309 - val_loss: 30.0483\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 28.6881 - val_loss: 29.7286\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.3359 - val_loss: 30.2572\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 27.9926 - val_loss: 28.5998\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.8472 - val_loss: 28.8580\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 27.7061 - val_loss: 28.5426\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 27.5754 - val_loss: 28.9157\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 27.4464 - val_loss: 27.8584\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 27.3698 - val_loss: 29.4983\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 27.0172 - val_loss: 27.2792\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 26.3430 - val_loss: 27.5879\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 26.4723 - val_loss: 26.8809\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 25.7620 - val_loss: 26.7218\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 26.1737 - val_loss: 26.3299\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 24.9839 - val_loss: 26.0191\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.5070 - val_loss: 25.5624\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.4616 - val_loss: 25.2455\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 24.9482 - val_loss: 25.4611\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 23.9751 - val_loss: 24.9757\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 24.2790 - val_loss: 24.4113\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 23.5363 - val_loss: 24.4162\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 23.3058 - val_loss: 24.7978\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 23.0502 - val_loss: 23.9810\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.8594 - val_loss: 23.8714\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 647us/step - loss: 22.7506 - val_loss: 23.7603\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.5160 - val_loss: 23.7817\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.4838 - val_loss: 23.8749\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.4699 - val_loss: 23.5278\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.2467 - val_loss: 23.4402\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.0979 - val_loss: 23.5349\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.0416 - val_loss: 23.2798\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.8669 - val_loss: 23.2136\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.9672 - val_loss: 23.6788\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.9992 - val_loss: 23.2138\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.7723 - val_loss: 23.1091\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.8287 - val_loss: 23.3281\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6124 - val_loss: 23.0473\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.8235 - val_loss: 23.1075\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.6846 - val_loss: 22.9592\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3164 - val_loss: 23.1020\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 698us/step - loss: 21.2619 - val_loss: 22.9383\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 855us/step - loss: 21.2052 - val_loss: 23.1754\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 21.1076 - val_loss: 23.0009\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 848us/step - loss: 21.0145 - val_loss: 23.0012\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 994us/step - loss: 21.0299 - val_loss: 22.8971\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 809us/step - loss: 20.9427 - val_loss: 23.0032\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1393 - val_loss: 23.5755\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.0007 - val_loss: 22.7727\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.9159 - val_loss: 23.0522\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2922 - val_loss: 23.3814\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.8474 - val_loss: 22.9171\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.6838 - val_loss: 22.7519\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 20.5470 - val_loss: 22.7413\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.4839 - val_loss: 22.7620\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 565us/step - loss: 20.5083 - val_loss: 22.7802\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.3816 - val_loss: 22.7709\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.3514 - val_loss: 22.8483\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.2869 - val_loss: 22.7539\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 97.0345 - val_loss: 87.8068\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 86.0509 - val_loss: 65.2260\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 46.3714 - val_loss: 42.2915\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 41.8994 - val_loss: 39.8531\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.4497 - val_loss: 38.9459\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 41.2661 - val_loss: 42.7414\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 42.9033 - val_loss: 38.0979\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 38.5720 - val_loss: 41.3117\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.5512 - val_loss: 35.6593\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 39.6414 - val_loss: 38.4464\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.4706 - val_loss: 44.3394\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 36.7049 - val_loss: 35.0167\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.2694 - val_loss: 33.8626\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.0358 - val_loss: 34.0558\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.0384 - val_loss: 33.7869\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.9939 - val_loss: 33.1899\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.1557 - val_loss: 34.0375\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.7797 - val_loss: 33.8459\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.6765 - val_loss: 33.4209\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.5552 - val_loss: 31.9417\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 32.1714 - val_loss: 31.5339\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 32.1479 - val_loss: 31.3173\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 31.9222 - val_loss: 31.3354\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 738us/step - loss: 32.4578 - val_loss: 33.5357\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.2699 - val_loss: 31.6025\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.2263 - val_loss: 30.5540\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 32.0758 - val_loss: 32.0369\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.3131 - val_loss: 30.8610\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.7152 - val_loss: 30.3419\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.3256 - val_loss: 29.9418\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.4211 - val_loss: 29.8097\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.9754 - val_loss: 31.0362\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.8604 - val_loss: 29.2420\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.1436 - val_loss: 29.2157\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.9161 - val_loss: 29.6923\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.5846 - val_loss: 29.2215\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.8926 - val_loss: 29.2673\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 29.2647 - val_loss: 28.2855\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.0223 - val_loss: 27.7660\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.7478 - val_loss: 27.5026\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 27.2249 - val_loss: 27.0100\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.5066 - val_loss: 29.3427\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.3966 - val_loss: 29.4418\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 627us/step - loss: 26.9776 - val_loss: 27.5123\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.8790 - val_loss: 25.6391\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.1419 - val_loss: 25.4411\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.6708 - val_loss: 24.8228\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 24.0938 - val_loss: 25.0009\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.0796 - val_loss: 24.2797\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.5994 - val_loss: 24.1794\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.5304 - val_loss: 23.8049\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.2702 - val_loss: 24.6983\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.2288 - val_loss: 23.8285\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 23.1049 - val_loss: 23.5206\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 555us/step - loss: 22.9521 - val_loss: 23.3988\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.8764 - val_loss: 23.6435\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.6134 - val_loss: 23.2745\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.4988 - val_loss: 23.1651\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 22.4510 - val_loss: 23.1627\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 22.3507 - val_loss: 23.1957\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.2093 - val_loss: 23.0417\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 22.1960 - val_loss: 23.1687\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.1528 - val_loss: 23.2972\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.2420 - val_loss: 22.9639\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.9795 - val_loss: 22.8972\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8430 - val_loss: 22.9822\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.8039 - val_loss: 22.8516\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.7511 - val_loss: 22.9003\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.7122 - val_loss: 22.8663\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.6776 - val_loss: 23.6100\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.9534 - val_loss: 23.2730\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.6935 - val_loss: 22.8690\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.4871 - val_loss: 45.6069\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 44.8720 - val_loss: 41.8441\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 41.8991 - val_loss: 40.0662\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 41.3735 - val_loss: 40.3773\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.9092 - val_loss: 38.6846\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.4522 - val_loss: 39.0299\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.1282 - val_loss: 38.4518\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 38.0346 - val_loss: 37.2704\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.0675 - val_loss: 36.0892\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.0880 - val_loss: 35.0912\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.3835 - val_loss: 36.6846\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 35.8954 - val_loss: 36.6806\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.4844 - val_loss: 34.3265\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 34.3229 - val_loss: 35.7920\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.3723 - val_loss: 34.4799\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.1345 - val_loss: 33.3503\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.4652 - val_loss: 33.0211\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 34.0544 - val_loss: 35.1800\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 34.7417 - val_loss: 33.2358\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.7489 - val_loss: 34.3169\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.7768 - val_loss: 33.7254\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.5213 - val_loss: 33.5649\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 86.8468 - val_loss: 51.0406\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 47.1942 - val_loss: 45.6509\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 43.0424 - val_loss: 41.9467\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 42.4127 - val_loss: 43.7783\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.9026 - val_loss: 40.9070\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.2467 - val_loss: 37.8766\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.9109 - val_loss: 36.4571\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.5249 - val_loss: 40.0825\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.1674 - val_loss: 37.0007\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.6094 - val_loss: 34.5245\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.3475 - val_loss: 35.0373\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.5957 - val_loss: 34.5720\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.5441 - val_loss: 33.8011\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.2512 - val_loss: 33.4373\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.1218 - val_loss: 33.9755\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.5039 - val_loss: 32.5193\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.3825 - val_loss: 32.6046\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.2075 - val_loss: 31.6990\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.8774 - val_loss: 33.3875\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.2292 - val_loss: 32.9762\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.2590 - val_loss: 31.0659\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.2266 - val_loss: 32.8560\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.3699 - val_loss: 31.6410\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.4318 - val_loss: 32.2172\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.0163 - val_loss: 31.9355\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 30.6064 - val_loss: 32.3429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.5519 - val_loss: 52.3122\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 49.0183 - val_loss: 50.9850\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 45.1942 - val_loss: 44.5369\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 42.8346 - val_loss: 46.7101\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 41.6294 - val_loss: 42.0251\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.9931 - val_loss: 43.5227\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 40.2440 - val_loss: 43.0143\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 40.0719 - val_loss: 40.3981\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.8984 - val_loss: 41.4081\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 40.1186 - val_loss: 41.1141\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 38.9295 - val_loss: 40.9084\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.5857 - val_loss: 44.8924\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 38.9347 - val_loss: 39.9198\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 37.4299 - val_loss: 38.8968\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.2981 - val_loss: 38.8439\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.7601 - val_loss: 39.0414\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.6592 - val_loss: 40.6078\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 36.8872 - val_loss: 41.2601\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.2697 - val_loss: 40.3673\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.1209 - val_loss: 38.9417\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.3415 - val_loss: 47.7701\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 46.3428 - val_loss: 45.6984\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 42.4177 - val_loss: 42.0764\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 42.3275 - val_loss: 40.8764\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 40.7038 - val_loss: 40.1220\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 38.6817 - val_loss: 39.0966\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.6789 - val_loss: 37.7505\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 37.5006 - val_loss: 37.6249\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.6738 - val_loss: 37.1396\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 37.0154 - val_loss: 39.3786\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 39.0620 - val_loss: 37.5475\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 36.5805 - val_loss: 37.2372\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.7633 - val_loss: 37.6866\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.8771 - val_loss: 35.7648\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.0795 - val_loss: 37.2119\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 34.7153 - val_loss: 35.0522\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 33.9486 - val_loss: 34.9717\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 33.6742 - val_loss: 35.4335\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.3635 - val_loss: 34.6999\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 35.2278 - val_loss: 36.6399\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.8370 - val_loss: 34.0964\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.4933 - val_loss: 34.5268\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.3042 - val_loss: 34.5738\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.0795 - val_loss: 33.7297\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.8976 - val_loss: 33.0714\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8890 - val_loss: 35.8391\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.3804 - val_loss: 32.6383\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.1043 - val_loss: 32.1816\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.0333 - val_loss: 33.0701\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.0609 - val_loss: 35.4635\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 30.7389 - val_loss: 32.5401\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.0363 - val_loss: 31.3284\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.9779 - val_loss: 31.3448\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.6320 - val_loss: 31.0881\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.2809 - val_loss: 30.9241\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.1285 - val_loss: 32.8749\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.1158 - val_loss: 33.9556\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 30.2637 - val_loss: 30.4049\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.6299 - val_loss: 30.8610\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.9957 - val_loss: 29.2160\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.0159 - val_loss: 28.5506\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 28.1516 - val_loss: 28.4276\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.9705 - val_loss: 30.5061\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.6876 - val_loss: 27.8374\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.0313 - val_loss: 27.2690\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 25.5623 - val_loss: 26.7674\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.0932 - val_loss: 25.8069\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.6684 - val_loss: 25.5334\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.2419 - val_loss: 25.0025\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.9034 - val_loss: 24.9074\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.6432 - val_loss: 24.5384\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.4952 - val_loss: 24.3450\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.4785 - val_loss: 24.3692\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.1764 - val_loss: 24.0745\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.0060 - val_loss: 24.0287\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.8707 - val_loss: 23.8515\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.7933 - val_loss: 23.8023\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.7861 - val_loss: 23.9563\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.5808 - val_loss: 23.7003\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.4694 - val_loss: 23.6386\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.2353 - val_loss: 23.5327\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 22.3747 - val_loss: 23.6940\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.1543 - val_loss: 23.4340\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.0303 - val_loss: 23.3870\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.8801 - val_loss: 23.3712\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.9836 - val_loss: 23.6387\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.9038 - val_loss: 23.2543\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7047 - val_loss: 23.3023\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 21.6223 - val_loss: 23.2691\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.5588 - val_loss: 23.5755\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6201 - val_loss: 23.1808\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 21.5724 - val_loss: 23.2010\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.3706 - val_loss: 23.2180\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.2948 - val_loss: 23.1221\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.2726 - val_loss: 23.4706\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 21.2768 - val_loss: 23.1979\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 21.1247 - val_loss: 23.1170\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.0127 - val_loss: 23.1344\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.0104 - val_loss: 23.0895\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 20.9845 - val_loss: 23.2364\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.1781 - val_loss: 23.1405\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 21.0263 - val_loss: 23.1520\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.9154 - val_loss: 23.1428\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.8253 - val_loss: 23.1932\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 79.4253 - val_loss: 50.0545\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 46.6371 - val_loss: 47.0061\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 42.3502 - val_loss: 42.5090\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 39.3984 - val_loss: 39.2938\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.4309 - val_loss: 38.6254\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.1059 - val_loss: 37.2236\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.2279 - val_loss: 35.9175\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.6655 - val_loss: 35.7981\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.5665 - val_loss: 34.6758\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 34.5372 - val_loss: 34.3718\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.1404 - val_loss: 34.8600\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.6005 - val_loss: 33.6245\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.7992 - val_loss: 32.8248\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.2767 - val_loss: 33.3480\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.0254 - val_loss: 33.0301\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.6511 - val_loss: 36.5190\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.9789 - val_loss: 32.0643\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.5305 - val_loss: 32.1388\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.5231 - val_loss: 31.4885\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.1440 - val_loss: 31.7845\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.1029 - val_loss: 31.9739\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 30.6284 - val_loss: 30.9022\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 30.6041 - val_loss: 32.8483\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.0779 - val_loss: 30.0848\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.4615 - val_loss: 29.6823\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.0893 - val_loss: 29.7015\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 28.8515 - val_loss: 30.2850\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.8037 - val_loss: 28.8036\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.9994 - val_loss: 30.4010\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.5486 - val_loss: 31.4290\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.0246 - val_loss: 29.6527\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 28.1572 - val_loss: 28.7381\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 28.0506 - val_loss: 29.9567\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.5727 - val_loss: 28.6911\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 27.9884 - val_loss: 29.8860\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 27.1126 - val_loss: 27.9383\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.7009 - val_loss: 34.4974\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.7119 - val_loss: 29.7245\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 27.7764 - val_loss: 28.3038\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 27.3502 - val_loss: 28.6518\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.4832 - val_loss: 27.2738\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.6599 - val_loss: 30.7682\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.4160 - val_loss: 27.4836\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.5465 - val_loss: 29.4354\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.1026 - val_loss: 27.8216\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.2618 - val_loss: 27.1945\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.8120 - val_loss: 26.9959\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.7400 - val_loss: 26.8926\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.9778 - val_loss: 28.2603\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 617us/step - loss: 26.2186 - val_loss: 26.7381\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 25.3111 - val_loss: 28.7762\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 25.7342 - val_loss: 27.2660\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 24.8864 - val_loss: 26.3922\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.1235 - val_loss: 26.6353\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 25.1757 - val_loss: 27.0163\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.8934 - val_loss: 26.5891\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.2643 - val_loss: 27.0425\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 25.7629 - val_loss: 28.2640\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.6664 - val_loss: 55.6257\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 554us/step - loss: 52.0747 - val_loss: 54.8345\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 47.2645 - val_loss: 47.2864\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 44.0720 - val_loss: 47.7578\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 43.4092 - val_loss: 44.1869\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 42.1655 - val_loss: 43.1641\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.1981 - val_loss: 42.2542\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 40.2306 - val_loss: 42.0479\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.8985 - val_loss: 40.6411\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.3044 - val_loss: 40.1470\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 37.9045 - val_loss: 40.3922\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 38.1602 - val_loss: 43.1176\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.4313 - val_loss: 40.5756\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.6030 - val_loss: 38.4958\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.4864 - val_loss: 38.7830\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.8911 - val_loss: 38.0767\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.4259 - val_loss: 39.8934\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.1615 - val_loss: 36.9092\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.0474 - val_loss: 37.3050\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.2861 - val_loss: 36.5306\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 33.7827 - val_loss: 35.7806\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.1272 - val_loss: 37.6558\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 33.2313 - val_loss: 37.5629\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.1920 - val_loss: 34.9665\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.8043 - val_loss: 35.8508\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 32.4088 - val_loss: 35.9811\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 31.8619 - val_loss: 34.1724\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.4638 - val_loss: 36.7541\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.8369 - val_loss: 34.7554\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.9811 - val_loss: 33.5701\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.9874 - val_loss: 32.2807\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.5127 - val_loss: 33.2793\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.0142 - val_loss: 32.1517\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 30.3079 - val_loss: 30.9264\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.7145 - val_loss: 30.4007\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 28.3314 - val_loss: 29.9748\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.0915 - val_loss: 29.4863\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.3502 - val_loss: 27.9805\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.7204 - val_loss: 27.6958\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 26.1501 - val_loss: 27.1541\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.1777 - val_loss: 26.9405\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 26.1956 - val_loss: 26.4127\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 25.2075 - val_loss: 25.9361\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.7427 - val_loss: 25.8569\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 24.3634 - val_loss: 25.3462\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.2674 - val_loss: 26.0483\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 24.3619 - val_loss: 24.8768\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.8329 - val_loss: 24.6461\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.6114 - val_loss: 24.4680\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.5246 - val_loss: 24.7410\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.3016 - val_loss: 24.1764\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.1813 - val_loss: 23.9781\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 22.9020 - val_loss: 23.8710\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 22.7623 - val_loss: 23.7182\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.7438 - val_loss: 23.6815\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.5133 - val_loss: 23.4875\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.3799 - val_loss: 23.4723\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.6098 - val_loss: 24.1636\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.4979 - val_loss: 23.2764\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 22.1225 - val_loss: 23.3095\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.9897 - val_loss: 23.2958\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.9969 - val_loss: 23.0877\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.8199 - val_loss: 22.9342\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.6629 - val_loss: 22.9101\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6718 - val_loss: 23.4731\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.8022 - val_loss: 22.8368\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.4336 - val_loss: 22.6544\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3954 - val_loss: 22.7483\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 21.5391 - val_loss: 22.7585\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 21.2790 - val_loss: 22.5920\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.2929 - val_loss: 22.9880\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.1626 - val_loss: 22.4767\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.0747 - val_loss: 22.4574\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.0165 - val_loss: 22.5143\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 21.0661 - val_loss: 22.5979\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9008 - val_loss: 22.4559\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.9271 - val_loss: 22.5593\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.7169 - val_loss: 22.2672\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.7976 - val_loss: 23.2792\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.9059 - val_loss: 22.2999\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.5700 - val_loss: 22.3230\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 20.5782 - val_loss: 22.4473\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.4840 - val_loss: 22.1700\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 20.7477 - val_loss: 22.6247\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 20.8939 - val_loss: 22.4780\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.6289 - val_loss: 22.5745\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.3262 - val_loss: 22.0760\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 20.1899 - val_loss: 22.1569\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.1494 - val_loss: 22.0444\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.0703 - val_loss: 22.0890\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.0558 - val_loss: 21.9802\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 20.0157 - val_loss: 22.2862\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 19.9918 - val_loss: 22.1362\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 19.8894 - val_loss: 22.3971\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.1478 - val_loss: 22.5779\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 19.9141 - val_loss: 21.9368\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 19.8743 - val_loss: 22.1389\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 19.7435 - val_loss: 21.9946\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 19.5832 - val_loss: 22.0503\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 19.5694 - val_loss: 22.1185\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 83.4738 - val_loss: 50.3662\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 45.5591 - val_loss: 42.0059\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 42.8990 - val_loss: 44.4700\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.8487 - val_loss: 39.6468\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.5187 - val_loss: 39.0328\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.9912 - val_loss: 38.4866\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 38.4934 - val_loss: 41.9303\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.5949 - val_loss: 38.0482\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.0582 - val_loss: 39.7947\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 37.0134 - val_loss: 37.6177\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.6652 - val_loss: 37.6789\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.8500 - val_loss: 35.6473\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.6448 - val_loss: 37.0620\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.6822 - val_loss: 36.8122\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.6632 - val_loss: 37.7648\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.6394 - val_loss: 36.0544\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.8882 - val_loss: 35.8213\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.9423 - val_loss: 46.8256\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 45.1241 - val_loss: 43.1522\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.6322 - val_loss: 42.3210\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 42.4266 - val_loss: 41.8353\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.6390 - val_loss: 42.9661\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 41.3736 - val_loss: 42.2370\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 40.3290 - val_loss: 38.9428\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.5846 - val_loss: 40.1805\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.4204 - val_loss: 41.3551\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.5351 - val_loss: 40.2275\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.2366 - val_loss: 38.7400\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.6335 - val_loss: 37.8933\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.5215 - val_loss: 38.8104\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.8303 - val_loss: 43.0665\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.9512 - val_loss: 37.6564\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.0404 - val_loss: 37.6552\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.6264 - val_loss: 36.7006\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 38.3006 - val_loss: 36.2641\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 37.1712 - val_loss: 36.2553\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.2323 - val_loss: 34.7042\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.0899 - val_loss: 37.5339\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.0453 - val_loss: 35.6323\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.2994 - val_loss: 35.2216\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.9229 - val_loss: 34.2383\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.7147 - val_loss: 34.3335\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 710us/step - loss: 33.1038 - val_loss: 35.7223\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 776us/step - loss: 32.8295 - val_loss: 33.1520\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 730us/step - loss: 32.2791 - val_loss: 35.2097\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.7108 - val_loss: 35.5783\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.0128 - val_loss: 34.0981\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.2945 - val_loss: 32.4586\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.2271 - val_loss: 31.7762\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.3657 - val_loss: 31.4504\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.9122 - val_loss: 33.3309\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.1562 - val_loss: 31.5611\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.9583 - val_loss: 30.2412\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 29.6317 - val_loss: 29.9966\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 29.1067 - val_loss: 30.5844\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.0280 - val_loss: 29.1325\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 28.4555 - val_loss: 28.7871\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 27.9331 - val_loss: 27.1386\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 26.9141 - val_loss: 26.7342\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.9069 - val_loss: 26.2177\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.2909 - val_loss: 25.9996\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 24.9352 - val_loss: 25.8534\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 24.8079 - val_loss: 24.9871\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.5281 - val_loss: 24.8084\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.1324 - val_loss: 24.4974\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 23.8142 - val_loss: 24.3330\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.6320 - val_loss: 24.3509\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.5675 - val_loss: 24.0825\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.3294 - val_loss: 23.9527\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.1212 - val_loss: 23.8073\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.0387 - val_loss: 23.7243\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.9423 - val_loss: 23.8045\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.8504 - val_loss: 23.4940\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.7214 - val_loss: 23.5038\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.7061 - val_loss: 23.4681\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6801 - val_loss: 23.3433\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4357 - val_loss: 23.3017\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.3479 - val_loss: 23.4917\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.3608 - val_loss: 23.2434\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7651 - val_loss: 23.8083\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.1801 - val_loss: 23.0734\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.0231 - val_loss: 23.1481\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0084 - val_loss: 22.9871\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.9378 - val_loss: 22.9890\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.9110 - val_loss: 23.2810\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.8157 - val_loss: 22.8780\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.8222 - val_loss: 23.1077\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.6506 - val_loss: 23.0859\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.7398 - val_loss: 22.9827\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.6593 - val_loss: 22.8213\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7892 - val_loss: 22.7595\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5886 - val_loss: 23.0544\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.5082 - val_loss: 22.6858\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.3431 - val_loss: 22.6823\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.3258 - val_loss: 22.6088\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3140 - val_loss: 23.0304\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3342 - val_loss: 22.7127\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.1446 - val_loss: 22.7178\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.0692 - val_loss: 22.8572\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0325 - val_loss: 22.7272\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.2994 - val_loss: 49.7184\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 48.8850 - val_loss: 47.7408\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 45.0681 - val_loss: 44.2447\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.6039 - val_loss: 42.2418\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.6017 - val_loss: 41.3563\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.4916 - val_loss: 40.3133\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.3695 - val_loss: 41.1937\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.6310 - val_loss: 40.2052\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.9578 - val_loss: 47.2247\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.1564 - val_loss: 39.3975\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.7086 - val_loss: 44.8082\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 42.1565 - val_loss: 39.5643\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.3823 - val_loss: 38.2480\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.3415 - val_loss: 38.2732\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.1756 - val_loss: 37.8920\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.8087 - val_loss: 39.8526\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.1872 - val_loss: 36.8677\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.5290 - val_loss: 37.0947\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.1775 - val_loss: 37.5933\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.2711 - val_loss: 35.2252\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.8380 - val_loss: 37.5618\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 620us/step - loss: 33.8166 - val_loss: 35.4927\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.6643 - val_loss: 35.1168\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.0076 - val_loss: 36.5359\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.4226 - val_loss: 34.5524\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.0038 - val_loss: 34.0227\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.8756 - val_loss: 34.0561\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.2744 - val_loss: 33.3635\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 33.1736 - val_loss: 33.7478\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.1500 - val_loss: 33.4092\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.3300 - val_loss: 35.8088\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.0723 - val_loss: 32.8247\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.8007 - val_loss: 32.6362\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 31.0938 - val_loss: 32.3761\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.7497 - val_loss: 31.5912\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 29.7276 - val_loss: 30.8870\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.4446 - val_loss: 30.4514\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 28.8446 - val_loss: 29.4753\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.8026 - val_loss: 29.1861\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.6385 - val_loss: 27.9180\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 26.8610 - val_loss: 27.1371\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.0808 - val_loss: 26.8986\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.5668 - val_loss: 25.9245\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.8989 - val_loss: 25.3252\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.6130 - val_loss: 25.2732\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.3363 - val_loss: 24.6795\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.9718 - val_loss: 24.9101\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.9173 - val_loss: 24.1306\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.5237 - val_loss: 24.1542\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.3242 - val_loss: 23.7992\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.1808 - val_loss: 24.0506\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 23.0398 - val_loss: 23.6836\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.8882 - val_loss: 23.5079\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.6925 - val_loss: 23.4000\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.6215 - val_loss: 23.7215\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.5287 - val_loss: 23.1442\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.3810 - val_loss: 23.0745\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.4209 - val_loss: 23.5445\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.3450 - val_loss: 23.0273\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.1947 - val_loss: 23.0146\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.1373 - val_loss: 22.9550\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.2368 - val_loss: 22.9928\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.9314 - val_loss: 22.9027\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 713us/step - loss: 21.8188 - val_loss: 23.2321\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 827us/step - loss: 21.9804 - val_loss: 22.8368\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.9076 - val_loss: 22.6387\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.6887 - val_loss: 22.6603\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.6438 - val_loss: 22.6853\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.6380 - val_loss: 22.9800\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5524 - val_loss: 22.4444\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3794 - val_loss: 22.4548\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.3296 - val_loss: 22.4357\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.3802 - val_loss: 22.3220\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.2447 - val_loss: 22.4368\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2073 - val_loss: 22.4908\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.2393 - val_loss: 22.8970\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5687 - val_loss: 22.4105\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.1566 - val_loss: 22.2786\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.9856 - val_loss: 22.2437\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9860 - val_loss: 22.4503\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.9127 - val_loss: 22.2666\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.9137 - val_loss: 22.3440\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.7536 - val_loss: 22.2376\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.7732 - val_loss: 22.1980\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.8869 - val_loss: 22.2173\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.2628 - val_loss: 22.2168\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.0642 - val_loss: 22.3317\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.5810 - val_loss: 22.1830\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 765us/step - loss: 20.5249 - val_loss: 22.0519\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.4949 - val_loss: 22.0799\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.6449 - val_loss: 22.7529\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.5417 - val_loss: 22.0999\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.3441 - val_loss: 22.1149\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.3346 - val_loss: 22.0358\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.3082 - val_loss: 22.0964\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.3646 - val_loss: 22.5397\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.4451 - val_loss: 22.2555\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.3866 - val_loss: 22.1375\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.3304 - val_loss: 22.1299\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.8338 - val_loss: 51.1552\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 47.1425 - val_loss: 41.2567\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 42.5626 - val_loss: 43.7100\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.1533 - val_loss: 39.9293\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.4930 - val_loss: 37.8395\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.6042 - val_loss: 38.2595\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.5477 - val_loss: 37.5868\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.2267 - val_loss: 36.0417\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.7385 - val_loss: 35.3321\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.4273 - val_loss: 34.7832\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 704us/step - loss: 35.4244 - val_loss: 36.1560\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.3011 - val_loss: 34.1125\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.2432 - val_loss: 39.2813\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 36.6132 - val_loss: 34.7449\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.4879 - val_loss: 33.8919\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.6619 - val_loss: 33.0708\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.1171 - val_loss: 33.6462\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.4285 - val_loss: 33.2183\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.1929 - val_loss: 37.2594\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.8085 - val_loss: 32.5959\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.6243 - val_loss: 34.2922\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.2669 - val_loss: 32.8120\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.3541 - val_loss: 31.6379\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.9722 - val_loss: 31.7741\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.9254 - val_loss: 32.4688\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 730us/step - loss: 31.7697 - val_loss: 31.8358\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.1703 - val_loss: 31.4640\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.4594 - val_loss: 36.4740\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.2826 - val_loss: 30.8210\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.7997 - val_loss: 32.5315\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.1414 - val_loss: 32.8877\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.6956 - val_loss: 30.2847\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.1674 - val_loss: 31.7363\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.9734 - val_loss: 30.9678\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.7045 - val_loss: 29.7921\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.9099 - val_loss: 30.4748\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 29.8172 - val_loss: 29.6419\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.2573 - val_loss: 29.1778\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.6326 - val_loss: 29.5233\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.7545 - val_loss: 29.2719\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.9782 - val_loss: 29.1804\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.4004 - val_loss: 30.2218\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.8371 - val_loss: 28.9242\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.5917 - val_loss: 28.3757\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 27.5986 - val_loss: 27.7926\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.6297 - val_loss: 31.1564\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.2405 - val_loss: 27.6778\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.5776 - val_loss: 29.4932\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 27.0737 - val_loss: 26.8251\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.6492 - val_loss: 26.6503\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.4029 - val_loss: 26.2024\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.8502 - val_loss: 24.7391\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.6096 - val_loss: 26.9964\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.2066 - val_loss: 24.1251\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.6555 - val_loss: 23.8357\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.5530 - val_loss: 24.7444\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.5668 - val_loss: 23.4805\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.9468 - val_loss: 23.3972\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.8490 - val_loss: 23.2176\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.7424 - val_loss: 23.1748\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.8071 - val_loss: 23.4587\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.4645 - val_loss: 22.9084\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.2799 - val_loss: 22.7632\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.2718 - val_loss: 22.9017\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.2572 - val_loss: 22.9474\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.1074 - val_loss: 22.6949\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.0661 - val_loss: 22.6482\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.0777 - val_loss: 22.5913\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.9106 - val_loss: 22.5683\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.8369 - val_loss: 22.4983\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.7017 - val_loss: 22.4074\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.5960 - val_loss: 22.4293\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7301 - val_loss: 22.4529\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.6721 - val_loss: 23.3164\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.6088 - val_loss: 22.4675\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.4843 - val_loss: 22.4423\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 1s 2ms/step - loss: 74.6996 - val_loss: 53.4265\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 47.0662 - val_loss: 42.9564\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 42.5786 - val_loss: 40.7382\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 40.0833 - val_loss: 38.8870\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 39.3122 - val_loss: 39.7706\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 38.2229 - val_loss: 37.6093\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 700us/step - loss: 36.9146 - val_loss: 37.3524\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 37.4584 - val_loss: 38.2492\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 37.5660 - val_loss: 37.2676\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 36.4815 - val_loss: 35.5807\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.0822 - val_loss: 35.2567\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.9777 - val_loss: 34.9894\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 34.4065 - val_loss: 34.8584\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 34.6777 - val_loss: 34.3075\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 34.3502 - val_loss: 34.7033\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.2589 - val_loss: 35.6879\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.0657 - val_loss: 35.8170\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.9360 - val_loss: 34.3515\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.8920 - val_loss: 35.2004\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.4243 - val_loss: 48.1730\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 44.7571 - val_loss: 41.1357\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.8890 - val_loss: 39.5615\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 40.3198 - val_loss: 41.6183\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 39.8883 - val_loss: 38.0988\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.5270 - val_loss: 38.4945\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.0328 - val_loss: 39.5943\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.6955 - val_loss: 36.7372\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.7845 - val_loss: 38.4633\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.8395 - val_loss: 38.9563\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.8956 - val_loss: 35.7837\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.8644 - val_loss: 35.1451\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.4248 - val_loss: 37.2526\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 37.4200 - val_loss: 34.7678\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.7066 - val_loss: 35.5339\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.0533 - val_loss: 36.3420\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.5588 - val_loss: 33.5923\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 34.6645 - val_loss: 33.0750\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.5059 - val_loss: 33.2408\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 35.4019 - val_loss: 32.8571\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.5841 - val_loss: 32.6052\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.1078 - val_loss: 34.1957\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.5272 - val_loss: 36.3080\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.8170 - val_loss: 34.1134\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.5754 - val_loss: 32.2488\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.0343 - val_loss: 31.3380\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.0323 - val_loss: 35.7402\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 33.1874 - val_loss: 31.3358\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.9382 - val_loss: 34.5787\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.0943 - val_loss: 33.1288\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 32.4252 - val_loss: 32.3867\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.0059 - val_loss: 31.2828\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.6085 - val_loss: 30.4476\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 31.3709 - val_loss: 32.5598\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.4719 - val_loss: 31.1781\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.1241 - val_loss: 30.2539\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.8354 - val_loss: 29.9429\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.8627 - val_loss: 30.7773\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.3757 - val_loss: 29.1747\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.7723 - val_loss: 33.2373\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.6119 - val_loss: 29.7909\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.1145 - val_loss: 29.2862\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.6722 - val_loss: 28.5223\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.8530 - val_loss: 33.3264\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 30.6499 - val_loss: 30.0818\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.4284 - val_loss: 29.5899\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.8400 - val_loss: 33.6099\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.7191 - val_loss: 28.5382\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.0830 - val_loss: 51.5186\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 47.3805 - val_loss: 44.5288\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 43.7878 - val_loss: 42.3600\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 44.4349 - val_loss: 43.0245\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 44.1421 - val_loss: 45.9705\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 41.4222 - val_loss: 40.6246\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.4540 - val_loss: 38.9782\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 39.6572 - val_loss: 38.8537\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 39.8495 - val_loss: 38.2655\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.8163 - val_loss: 37.1485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.5266 - val_loss: 39.7147\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.8361 - val_loss: 37.6156\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.8481 - val_loss: 36.7794\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.1349 - val_loss: 39.2138\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.3484 - val_loss: 35.3528\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.7889 - val_loss: 34.8997\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.3887 - val_loss: 36.8150\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.6095 - val_loss: 34.2317\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.0228 - val_loss: 37.6293\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.4891 - val_loss: 33.3175\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.6569 - val_loss: 34.7832\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.6811 - val_loss: 32.8933\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 32.2439 - val_loss: 32.9359\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.1303 - val_loss: 34.1949\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 33.5074 - val_loss: 33.1730\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.9425 - val_loss: 31.8043\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.6935 - val_loss: 32.7291\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.1894 - val_loss: 31.8946\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.6771 - val_loss: 31.7194\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 31.1867 - val_loss: 32.6717\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.0691 - val_loss: 30.9367\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.6384 - val_loss: 30.5510\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.2342 - val_loss: 31.2567\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.5184 - val_loss: 30.9427\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.5490 - val_loss: 31.2086\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.6503 - val_loss: 31.5875\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.6466 - val_loss: 29.4546\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.5023 - val_loss: 29.0581\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.5062 - val_loss: 27.7656\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.9067 - val_loss: 27.8068\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 26.0399 - val_loss: 26.7566\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.6446 - val_loss: 26.2012\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 25.4762 - val_loss: 25.4088\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.9339 - val_loss: 25.0524\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 24.0921 - val_loss: 24.5898\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 23.8433 - val_loss: 24.3096\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.6049 - val_loss: 24.4408\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.5762 - val_loss: 23.8682\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.7615 - val_loss: 24.4109\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 23.3046 - val_loss: 23.8880\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.9406 - val_loss: 23.8823\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.7133 - val_loss: 23.3946\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.7109 - val_loss: 23.7847\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.6577 - val_loss: 23.9065\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.9465 - val_loss: 23.5058\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.6479 - val_loss: 23.5079\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.2424 - val_loss: 23.0632\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.1130 - val_loss: 22.9742\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.0676 - val_loss: 22.9661\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.9043 - val_loss: 22.8205\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.9674 - val_loss: 23.1061\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.1542 - val_loss: 23.8649\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.9335 - val_loss: 22.8380\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 21.5777 - val_loss: 22.6846\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6144 - val_loss: 22.8931\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.4307 - val_loss: 22.5514\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.3517 - val_loss: 22.5680\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.2606 - val_loss: 22.4549\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.1616 - val_loss: 22.4282\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.1487 - val_loss: 22.6884\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.1688 - val_loss: 22.4042\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.0190 - val_loss: 22.3726\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.9795 - val_loss: 22.7614\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.1671 - val_loss: 22.4523\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9801 - val_loss: 22.3686\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.0972 - val_loss: 23.1447\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.9749 - val_loss: 22.2201\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.6444 - val_loss: 22.2098\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.5668 - val_loss: 22.3013\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.7383 - val_loss: 22.1889\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.5616 - val_loss: 22.2509\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.4395 - val_loss: 22.1450\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.2899 - val_loss: 22.1287\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.8041 - val_loss: 22.5779\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.7798 - val_loss: 22.0864\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.4573 - val_loss: 22.1189\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.1635 - val_loss: 22.0048\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.0528 - val_loss: 22.0058\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 19.9660 - val_loss: 21.9816\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 19.9865 - val_loss: 22.1485\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.3587 - val_loss: 22.1441\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.0018 - val_loss: 22.0956\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.0081 - val_loss: 22.5369\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 19.8785 - val_loss: 22.0522\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.9845 - val_loss: 51.3512\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 48.1891 - val_loss: 47.0972\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 44.5297 - val_loss: 45.8630\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 43.3023 - val_loss: 41.4725\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 41.2564 - val_loss: 44.1429\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 41.1583 - val_loss: 40.3769\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.6228 - val_loss: 40.5791\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.7776 - val_loss: 38.5646\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 38.4060 - val_loss: 38.1545\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.5084 - val_loss: 38.9239\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.7417 - val_loss: 36.9033\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.6528 - val_loss: 36.5947\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 36.4768 - val_loss: 38.4702\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.9625 - val_loss: 36.0915\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.2714 - val_loss: 36.2108\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.8067 - val_loss: 37.0992\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.6467 - val_loss: 36.2991\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.3166 - val_loss: 35.2092\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 35.4482 - val_loss: 36.1309\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.5039 - val_loss: 35.7183\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.7938 - val_loss: 35.9977\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.8651 - val_loss: 34.3582\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.5061 - val_loss: 34.4795\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.9290 - val_loss: 36.9365\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 34.2620 - val_loss: 38.2325\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.6620 - val_loss: 35.0224\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.2158 - val_loss: 38.6322\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 92.7726 - val_loss: 63.5374\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 49.9501 - val_loss: 44.5649\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 44.1238 - val_loss: 44.7966\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 41.6559 - val_loss: 39.8869\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.1177 - val_loss: 39.5479\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 40.0670 - val_loss: 40.3793\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 40.3647 - val_loss: 41.4266\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.1005 - val_loss: 37.1284\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.5356 - val_loss: 39.9431\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.4061 - val_loss: 36.6841\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.6486 - val_loss: 35.2400\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.5900 - val_loss: 36.3714\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.6250 - val_loss: 34.9652\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.3537 - val_loss: 39.7385\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.1805 - val_loss: 34.8079\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.8439 - val_loss: 34.2906\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.5401 - val_loss: 33.9520\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.2979 - val_loss: 36.3490\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.7900 - val_loss: 33.2398\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.4936 - val_loss: 32.7206\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.2173 - val_loss: 38.1941\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.3826 - val_loss: 32.7794\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.7949 - val_loss: 34.7081\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.3667 - val_loss: 32.0878\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.3168 - val_loss: 35.7345\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.3756 - val_loss: 34.8631\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.7665 - val_loss: 35.9568\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.5988 - val_loss: 34.3612\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.7238 - val_loss: 33.3719\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.9044 - val_loss: 45.9572\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 44.4252 - val_loss: 40.6197\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 43.7532 - val_loss: 42.2827\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 40.6569 - val_loss: 43.3355\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.8087 - val_loss: 39.1025\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.4026 - val_loss: 37.8957\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.6906 - val_loss: 43.5088\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 38.7419 - val_loss: 39.1984\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 37.4873 - val_loss: 38.7741\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.0407 - val_loss: 40.2441\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 36.7785 - val_loss: 35.8034\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.4310 - val_loss: 35.2613\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.4818 - val_loss: 34.5759\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 629us/step - loss: 34.7105 - val_loss: 33.4848\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.8437 - val_loss: 33.6678\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.8329 - val_loss: 35.6567\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.1278 - val_loss: 32.5454\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.8552 - val_loss: 34.0788\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.8135 - val_loss: 33.0221\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.8729 - val_loss: 34.9740\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.9714 - val_loss: 31.9693\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.8838 - val_loss: 32.1708\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.8546 - val_loss: 31.4470\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.1915 - val_loss: 31.4618\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.1535 - val_loss: 30.9834\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.8307 - val_loss: 31.2987\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.9441 - val_loss: 30.7236\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.4278 - val_loss: 31.0525\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.1399 - val_loss: 31.1013\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.3748 - val_loss: 30.3506\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.7038 - val_loss: 31.1856\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.4801 - val_loss: 30.4389\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.8160 - val_loss: 31.6058\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.8907 - val_loss: 30.0469\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.7688 - val_loss: 31.9372\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.5582 - val_loss: 29.9733\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.3408 - val_loss: 31.4265\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.1072 - val_loss: 28.9693\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.6800 - val_loss: 30.9193\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 29.1478 - val_loss: 30.5895\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.3558 - val_loss: 33.6003\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.1745 - val_loss: 29.1194\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 732us/step - loss: 28.3918 - val_loss: 28.8477\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 689us/step - loss: 27.5442 - val_loss: 28.2466\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.2640 - val_loss: 28.4038\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.0899 - val_loss: 27.9148\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 27.0649 - val_loss: 27.5211\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.8945 - val_loss: 27.5856\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.6493 - val_loss: 28.4046\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.2852 - val_loss: 29.6839\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 27.7882 - val_loss: 27.2737\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.2185 - val_loss: 27.2839\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 25.6326 - val_loss: 26.4312\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 26.3126 - val_loss: 26.4319\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.0316 - val_loss: 26.3752\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.1738 - val_loss: 26.4944\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.5919 - val_loss: 26.0404\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.7204 - val_loss: 25.4261\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 24.2350 - val_loss: 26.3507\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.2584 - val_loss: 27.7384\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 24.3957 - val_loss: 25.1071\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.5738 - val_loss: 24.4962\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.0725 - val_loss: 25.5743\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 24.1163 - val_loss: 25.7249\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.6865 - val_loss: 24.3166\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.2767 - val_loss: 23.9930\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 22.8512 - val_loss: 23.9175\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.7807 - val_loss: 24.2388\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.9188 - val_loss: 23.7103\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.5242 - val_loss: 23.6361\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.6854 - val_loss: 23.6228\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.3932 - val_loss: 23.5412\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 22.3332 - val_loss: 23.4275\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.2347 - val_loss: 23.2772\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.5328 - val_loss: 24.0318\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.2407 - val_loss: 23.2433\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.1533 - val_loss: 23.6850\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 21.8799 - val_loss: 23.0591\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 21.8758 - val_loss: 23.8356\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.2554 - val_loss: 23.1417\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 21.8961 - val_loss: 23.1892\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 21.8301 - val_loss: 23.6810\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.0984 - val_loss: 23.2235\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.7926 - val_loss: 48.5127\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 48.2559 - val_loss: 43.5778\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 43.6125 - val_loss: 40.9320\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 40.9865 - val_loss: 39.1638\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 40.1289 - val_loss: 38.1165\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 38.7697 - val_loss: 37.9977\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 39.7154 - val_loss: 38.5112\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 651us/step - loss: 38.4617 - val_loss: 38.2937\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 37.2857 - val_loss: 39.3554\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.2318 - val_loss: 35.8284\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.7278 - val_loss: 36.3882\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.8329 - val_loss: 34.7791\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.7791 - val_loss: 34.3757\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.4712 - val_loss: 34.6880\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.1218 - val_loss: 36.6335\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.6076 - val_loss: 34.0293\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.9729 - val_loss: 36.8417\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 34.6605 - val_loss: 34.5929\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.7726 - val_loss: 34.9106\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.1151 - val_loss: 34.6350\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.0295 - val_loss: 32.7014\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.7882 - val_loss: 33.4137\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.2102 - val_loss: 34.2284\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.4128 - val_loss: 33.6254\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.2996 - val_loss: 31.9040\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.8098 - val_loss: 31.9674\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.0905 - val_loss: 32.2263\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.8447 - val_loss: 31.3606\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.8225 - val_loss: 32.2720\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.9086 - val_loss: 31.3792\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.4401 - val_loss: 31.1893\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.9115 - val_loss: 32.2122\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 32.1618 - val_loss: 30.8609\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.3777 - val_loss: 30.4394\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.4998 - val_loss: 30.7484\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.1921 - val_loss: 30.8232\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.5129 - val_loss: 30.0391\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.0672 - val_loss: 30.2066\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.4108 - val_loss: 32.4939\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.5276 - val_loss: 30.2941\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.2803 - val_loss: 30.0852\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.0427 - val_loss: 30.3314\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.6681 - val_loss: 49.5545\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 47.9476 - val_loss: 45.1219\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 42.9277 - val_loss: 43.8596\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.6295 - val_loss: 40.4855\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.9663 - val_loss: 42.3219\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.8499 - val_loss: 38.9687\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.8064 - val_loss: 38.9177\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.2343 - val_loss: 38.0113\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.6600 - val_loss: 36.9851\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.6464 - val_loss: 36.4911\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.1432 - val_loss: 37.6262\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.4217 - val_loss: 38.9358\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 34.7540 - val_loss: 35.5941\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.7834 - val_loss: 37.3359\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.0582 - val_loss: 35.9720\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.7729 - val_loss: 34.7066\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.4561 - val_loss: 34.2825\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.0757 - val_loss: 34.6357\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.5411 - val_loss: 34.0137\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.9472 - val_loss: 34.3738\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.2372 - val_loss: 36.2034\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.8362 - val_loss: 36.5212\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.5234 - val_loss: 34.4791\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.5114 - val_loss: 32.9783\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.2186 - val_loss: 32.9811\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.4145 - val_loss: 32.5898\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.8366 - val_loss: 34.1970\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.1161 - val_loss: 32.6988\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.0010 - val_loss: 31.6642\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.6250 - val_loss: 33.2358\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.1814 - val_loss: 32.2304\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.0877 - val_loss: 32.6116\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.7830 - val_loss: 31.2327\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.3863 - val_loss: 32.6063\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.9751 - val_loss: 30.5658\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.4856 - val_loss: 30.0112\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 27.8488 - val_loss: 32.3336\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.3921 - val_loss: 30.0649\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.3813 - val_loss: 33.0057\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.2423 - val_loss: 29.3231\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.1613 - val_loss: 29.7341\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.8900 - val_loss: 28.4830\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 616us/step - loss: 26.4969 - val_loss: 28.2692\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 26.0347 - val_loss: 27.4748\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 25.2850 - val_loss: 27.2181\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.4049 - val_loss: 26.6442\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.9068 - val_loss: 26.0810\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 24.9645 - val_loss: 25.7785\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.6098 - val_loss: 26.5498\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.3229 - val_loss: 25.3838\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.6052 - val_loss: 25.2291\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.5637 - val_loss: 24.9975\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.3815 - val_loss: 24.9129\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 23.7618 - val_loss: 25.7100\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 23.0109 - val_loss: 24.3834\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.6679 - val_loss: 24.1908\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 22.5369 - val_loss: 24.0674\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.4078 - val_loss: 24.2145\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.4050 - val_loss: 23.7221\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.0296 - val_loss: 23.6149\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.0929 - val_loss: 24.0996\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.0641 - val_loss: 23.4912\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.7975 - val_loss: 23.3716\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.7056 - val_loss: 23.4232\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.6110 - val_loss: 23.2664\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5345 - val_loss: 23.6684\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.6435 - val_loss: 23.1968\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4486 - val_loss: 23.1399\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.4399 - val_loss: 23.3764\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3353 - val_loss: 23.0428\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.2069 - val_loss: 23.8919\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 21.2283 - val_loss: 23.0966\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.1710 - val_loss: 23.2899\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2366 - val_loss: 23.1819\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.8757 - val_loss: 23.2269\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.6052 - val_loss: 58.8516\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 49.7289 - val_loss: 45.0419\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 44.9179 - val_loss: 43.5422\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 43.5280 - val_loss: 45.6589\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 42.6454 - val_loss: 40.6700\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.9699 - val_loss: 40.5990\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.1071 - val_loss: 38.6129\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.6352 - val_loss: 38.3235\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.8873 - val_loss: 37.9830\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.1210 - val_loss: 38.3197\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.4577 - val_loss: 37.3972\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.0727 - val_loss: 36.9525\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.8091 - val_loss: 37.9844\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.6718 - val_loss: 39.0519\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 35.7594 - val_loss: 35.2607\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.9182 - val_loss: 37.5608\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.0517 - val_loss: 34.8313\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.3645 - val_loss: 35.3855\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.2092 - val_loss: 34.4357\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.5349 - val_loss: 34.1974\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.7232 - val_loss: 34.4000\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.5609 - val_loss: 33.4916\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.9275 - val_loss: 33.2339\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.6396 - val_loss: 33.1506\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.4117 - val_loss: 36.1574\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.9200 - val_loss: 33.7919\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.1920 - val_loss: 34.2068\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.0520 - val_loss: 33.8938\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.3998 - val_loss: 33.6427\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.8103 - val_loss: 50.6309\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 46.4430 - val_loss: 41.8153\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.8749 - val_loss: 40.1097\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 40.0298 - val_loss: 38.6585\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.5742 - val_loss: 38.8732\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.4384 - val_loss: 37.7295\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.3319 - val_loss: 37.8278\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.7113 - val_loss: 36.1507\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 36.1479 - val_loss: 35.3516\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.2199 - val_loss: 35.7939\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.8694 - val_loss: 35.4358\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.2961 - val_loss: 35.4009\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.1002 - val_loss: 34.3023\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.3668 - val_loss: 34.5518\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.3838 - val_loss: 33.9603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.7700 - val_loss: 33.2990\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 33.4775 - val_loss: 33.4781\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.8578 - val_loss: 34.9744\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.2800 - val_loss: 32.5731\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.2447 - val_loss: 34.2756\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 33.1681 - val_loss: 32.6906\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.8301 - val_loss: 32.7538\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.4438 - val_loss: 33.1443\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.4958 - val_loss: 32.3001\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.9837 - val_loss: 32.2127\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.2266 - val_loss: 33.4949\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.3425 - val_loss: 33.3038\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.6883 - val_loss: 35.1103\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.7275 - val_loss: 31.9834\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.8801 - val_loss: 31.4339\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.3136 - val_loss: 30.7141\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.6591 - val_loss: 31.2845\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 30.6645 - val_loss: 30.0382\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.0780 - val_loss: 30.6609\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.8606 - val_loss: 32.7294\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.6525 - val_loss: 30.7210\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.4045 - val_loss: 29.9927\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.8322 - val_loss: 30.9574\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 31.4969 - val_loss: 30.3078\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 29.0497 - val_loss: 30.5971\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 29.8700 - val_loss: 28.8150\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.3779 - val_loss: 28.9078\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.0374 - val_loss: 31.1744\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.6467 - val_loss: 29.4471\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.7675 - val_loss: 28.2632\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.0129 - val_loss: 27.5855\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.5585 - val_loss: 27.1394\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.0900 - val_loss: 26.8508\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.5403 - val_loss: 26.6235\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 26.1595 - val_loss: 27.9112\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.5624 - val_loss: 27.9654\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.5257 - val_loss: 25.9419\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.5222 - val_loss: 25.4815\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.3059 - val_loss: 25.2370\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.9763 - val_loss: 25.1429\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.6680 - val_loss: 24.6129\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.5444 - val_loss: 24.6433\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.3271 - val_loss: 24.3079\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.1616 - val_loss: 25.4876\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.4139 - val_loss: 24.0211\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.0080 - val_loss: 24.1606\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.7954 - val_loss: 24.0072\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.9397 - val_loss: 23.7845\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.7866 - val_loss: 24.4698\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.7922 - val_loss: 23.9598\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.4458 - val_loss: 23.4559\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.2265 - val_loss: 23.3863\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.2206 - val_loss: 23.6377\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.0991 - val_loss: 23.5161\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 22.1894 - val_loss: 23.2104\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.9875 - val_loss: 23.3629\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.8085 - val_loss: 23.0759\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8321 - val_loss: 23.0929\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.6347 - val_loss: 23.0761\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6915 - val_loss: 23.0577\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5560 - val_loss: 22.8813\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.3737 - val_loss: 22.8898\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4345 - val_loss: 22.9222\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.3940 - val_loss: 22.9238\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.2313 - val_loss: 22.8511\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.1343 - val_loss: 22.7027\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 21.0515 - val_loss: 22.8525\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.0512 - val_loss: 22.6613\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0549 - val_loss: 22.8270\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.9487 - val_loss: 22.9239\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.9920 - val_loss: 22.8158\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9089 - val_loss: 22.6871\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.7127 - val_loss: 22.7441\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.7760 - val_loss: 48.0910\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 47.2628 - val_loss: 42.9460\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 42.9399 - val_loss: 43.5903\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 42.6142 - val_loss: 40.5963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 41.5919 - val_loss: 39.8853\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.2640 - val_loss: 38.4064\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 38.0629 - val_loss: 38.7613\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.7624 - val_loss: 38.4096\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.1688 - val_loss: 38.3357\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.5183 - val_loss: 36.1732\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.5067 - val_loss: 36.7131\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.2000 - val_loss: 35.8892\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.7366 - val_loss: 38.6759\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.2096 - val_loss: 45.7027\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.2847 - val_loss: 35.9619\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.8231 - val_loss: 37.1683\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.8597 - val_loss: 34.0828\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.0515 - val_loss: 33.7386\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.0533 - val_loss: 34.8466\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.9960 - val_loss: 34.1590\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.3718 - val_loss: 33.4957\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.3181 - val_loss: 37.7054\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.6760 - val_loss: 35.3285\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.8424 - val_loss: 34.7300\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.1581 - val_loss: 32.3117\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.7385 - val_loss: 32.8845\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.6275 - val_loss: 33.7459\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.9144 - val_loss: 31.9576\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.9196 - val_loss: 31.9146\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.0090 - val_loss: 31.7102\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 31.3804 - val_loss: 36.8243\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.5123 - val_loss: 31.2175\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.5475 - val_loss: 31.5002\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.5991 - val_loss: 32.0400\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.5246 - val_loss: 32.2102\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.7424 - val_loss: 33.3151\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.8788 - val_loss: 31.4353\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.5842 - val_loss: 46.4082\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 45.0043 - val_loss: 42.1009\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 41.4784 - val_loss: 41.1633\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.0666 - val_loss: 38.2174\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.8112 - val_loss: 37.2999\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 37.4735 - val_loss: 36.8410\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.1755 - val_loss: 35.3669\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.5059 - val_loss: 34.5745\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.3135 - val_loss: 34.0040\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.8631 - val_loss: 33.7218\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.3006 - val_loss: 33.5365\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.6100 - val_loss: 34.1434\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.9487 - val_loss: 34.9392\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.6240 - val_loss: 32.2790\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.8843 - val_loss: 35.8744\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.1407 - val_loss: 33.2464\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 31.6198 - val_loss: 31.9110\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.3937 - val_loss: 31.1664\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.9766 - val_loss: 32.8419\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.0049 - val_loss: 31.2649\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.7183 - val_loss: 31.0921\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.1350 - val_loss: 30.3101\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.8955 - val_loss: 32.2379\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.3294 - val_loss: 31.4238\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.6331 - val_loss: 29.4706\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.5502 - val_loss: 29.8013\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 28.9946 - val_loss: 30.3737\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 28.3047 - val_loss: 28.7055\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.8919 - val_loss: 29.8821\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.0758 - val_loss: 28.4978\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.5761 - val_loss: 29.4425\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.7514 - val_loss: 30.0313\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.2728 - val_loss: 28.3679\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.4094 - val_loss: 27.2652\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 26.9379 - val_loss: 27.3059\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 26.3418 - val_loss: 26.8298\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.8234 - val_loss: 28.1700\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.6547 - val_loss: 26.6266\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.8671 - val_loss: 26.6229\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 26.0250 - val_loss: 25.7925\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.9344 - val_loss: 25.3862\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.4651 - val_loss: 25.0573\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.0106 - val_loss: 24.7810\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.0836 - val_loss: 24.9580\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 633us/step - loss: 23.5898 - val_loss: 24.3084\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.2570 - val_loss: 24.5823\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2233 - val_loss: 23.8216\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.1871 - val_loss: 24.8802\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.2115 - val_loss: 24.2086\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.7178 - val_loss: 23.6209\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.4461 - val_loss: 23.6137\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3398 - val_loss: 23.3336\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.2580 - val_loss: 23.1617\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.2972 - val_loss: 23.1481\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.1036 - val_loss: 23.2076\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.2094 - val_loss: 23.0110\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.0175 - val_loss: 22.8276\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.8541 - val_loss: 22.7335\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7679 - val_loss: 22.8465\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8308 - val_loss: 22.9166\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.7221 - val_loss: 22.8054\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6752 - val_loss: 23.8854\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6578 - val_loss: 22.9578\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.6439 - val_loss: 47.8187\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 45.7931 - val_loss: 43.8305\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 43.3115 - val_loss: 43.1909\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 40.9968 - val_loss: 45.2153\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 41.3916 - val_loss: 41.2712\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.2597 - val_loss: 41.1774\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.0978 - val_loss: 42.2551\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.5674 - val_loss: 42.3352\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.3345 - val_loss: 40.3014\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.9564 - val_loss: 39.2359\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.9340 - val_loss: 42.3801\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.2201 - val_loss: 39.3202\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.3339 - val_loss: 41.8133\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.5257 - val_loss: 38.3724\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.0306 - val_loss: 39.7273\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.7924 - val_loss: 39.0588\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.7231 - val_loss: 38.4343\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.5353 - val_loss: 40.0351\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.9769 - val_loss: 39.2344\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 79.7206 - val_loss: 51.6067\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 47.6960 - val_loss: 45.1138\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 42.6776 - val_loss: 42.6009\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.6602 - val_loss: 43.3842\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.0335 - val_loss: 40.8811\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.5381 - val_loss: 48.5672\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.8277 - val_loss: 40.5570\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.2094 - val_loss: 38.9426\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.4029 - val_loss: 41.5550\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.8929 - val_loss: 38.8363\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 37.0421 - val_loss: 38.0827\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.6909 - val_loss: 39.6210\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 37.7377 - val_loss: 38.3217\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 35.9626 - val_loss: 38.3027\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 35.3037 - val_loss: 39.3207\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 36.0196 - val_loss: 36.7910\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 34.8624 - val_loss: 36.0554\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 34.3978 - val_loss: 36.0694\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 33.7320 - val_loss: 36.0046\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 33.2457 - val_loss: 37.6383\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 32.7597 - val_loss: 34.3372\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.1076 - val_loss: 36.9907\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.4370 - val_loss: 36.0558\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 33.3626 - val_loss: 34.3810\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 33.7845 - val_loss: 34.2835\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 33.0727 - val_loss: 35.9677\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 32.9646 - val_loss: 33.6286\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 32.1850 - val_loss: 37.1496\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 32.4978 - val_loss: 33.0166\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 31.7071 - val_loss: 34.5966\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 31.4304 - val_loss: 32.5632\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 30.3967 - val_loss: 33.0162\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 30.8519 - val_loss: 32.0234\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.4741 - val_loss: 32.3698\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 30.2651 - val_loss: 32.8548\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 30.3312 - val_loss: 31.8986\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 29.9819 - val_loss: 32.4562\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 30.4169 - val_loss: 33.8978\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 29.7190 - val_loss: 32.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 29.4882 - val_loss: 31.6103\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 29.1875 - val_loss: 30.6852\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.8025 - val_loss: 30.6344\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 28.3682 - val_loss: 31.7441\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.8575 - val_loss: 30.3630\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 29.8363 - val_loss: 35.8918\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.2129 - val_loss: 30.7395\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 28.4285 - val_loss: 29.9953\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 27.8018 - val_loss: 29.4055\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 28.2444 - val_loss: 29.3509\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 27.6132 - val_loss: 31.7558\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 28.3145 - val_loss: 29.0341\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 28.1135 - val_loss: 30.0985\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 27.0296 - val_loss: 28.3831\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 26.6672 - val_loss: 27.8981\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 26.2909 - val_loss: 27.7440\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 26.2047 - val_loss: 28.8796\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 27.3457 - val_loss: 28.7969\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 25.4824 - val_loss: 26.5654\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 24.8597 - val_loss: 25.9114\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 24.3659 - val_loss: 25.6237\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 23.8857 - val_loss: 25.6236\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 23.8187 - val_loss: 24.9330\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 23.5695 - val_loss: 24.5216\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 23.4722 - val_loss: 24.2217\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.9494 - val_loss: 23.9975\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 23.2644 - val_loss: 23.9951\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.9786 - val_loss: 23.7883\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 22.5442 - val_loss: 23.7664\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.6584 - val_loss: 24.1157\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.3654 - val_loss: 23.5901\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.1681 - val_loss: 23.3444\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.1087 - val_loss: 23.6739\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 869us/step - loss: 22.0243 - val_loss: 23.1578\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 21.8937 - val_loss: 23.1888\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 854us/step - loss: 22.1542 - val_loss: 23.1304\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 728us/step - loss: 21.8022 - val_loss: 23.2195\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 846us/step - loss: 21.6542 - val_loss: 22.9458\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6013 - val_loss: 23.2460\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.7981 - val_loss: 22.9142\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.4205 - val_loss: 22.8805\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.3769 - val_loss: 23.5459\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.7157 - val_loss: 23.1003\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.2185 - val_loss: 22.7401\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.2999 - val_loss: 22.8073\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.1023 - val_loss: 22.6551\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0039 - val_loss: 22.6056\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.9608 - val_loss: 22.9824\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2306 - val_loss: 22.5808\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0487 - val_loss: 22.5738\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.9057 - val_loss: 22.8150\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.7257 - val_loss: 22.9223\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.9019 - val_loss: 22.9542\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.0073 - val_loss: 22.5266\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.5979 - val_loss: 22.4149\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.6614 - val_loss: 22.6333\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.6484 - val_loss: 22.3832\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.5337 - val_loss: 22.4204\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.5109 - val_loss: 22.5730\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.4616 - val_loss: 22.4579\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.4061 - val_loss: 22.4230\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.0393 - val_loss: 47.7757\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 43.6300 - val_loss: 42.9933\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.2118 - val_loss: 39.2123\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 37.3907 - val_loss: 36.6980\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.8785 - val_loss: 35.3203\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.0599 - val_loss: 35.9964\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.4220 - val_loss: 35.5169\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.9292 - val_loss: 34.4970\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.7671 - val_loss: 35.7300\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.9735 - val_loss: 36.1607\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.7507 - val_loss: 33.6128\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.5205 - val_loss: 33.7928\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 32.3595 - val_loss: 32.7725\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 33.1163 - val_loss: 33.2500\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.8554 - val_loss: 32.7606\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.7557 - val_loss: 32.8966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.4116 - val_loss: 33.1210\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.0258 - val_loss: 31.0517\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.1532 - val_loss: 31.7670\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.5817 - val_loss: 31.3326\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.9699 - val_loss: 30.4808\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.3456 - val_loss: 32.9430\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.5314 - val_loss: 30.7423\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.5177 - val_loss: 30.3740\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.9570 - val_loss: 31.1484\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9806 - val_loss: 31.0687\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.9955 - val_loss: 30.6225\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.3931 - val_loss: 31.8789\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.0305 - val_loss: 30.6625\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 84.8756 - val_loss: 54.2695\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 51.9100 - val_loss: 50.0355\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 45.3710 - val_loss: 44.0477\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 42.2466 - val_loss: 42.3444\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.1675 - val_loss: 42.0267\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.8409 - val_loss: 40.4205\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.3199 - val_loss: 41.3142\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.2036 - val_loss: 43.8212\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.6973 - val_loss: 39.7763\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.3610 - val_loss: 41.6709\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.3372 - val_loss: 40.0506\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.4399 - val_loss: 39.0572\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.5607 - val_loss: 37.8452\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 36.5270 - val_loss: 37.8179\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.9999 - val_loss: 36.6438\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.9758 - val_loss: 37.4151\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.6538 - val_loss: 38.3688\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.3661 - val_loss: 36.0220\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.7652 - val_loss: 36.2763\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.7213 - val_loss: 38.4359\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.6227 - val_loss: 36.5219\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.2972 - val_loss: 34.8956\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.1652 - val_loss: 34.1352\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.6358 - val_loss: 35.5492\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.6894 - val_loss: 34.2916\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.1138 - val_loss: 35.8496\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.2755 - val_loss: 34.5349\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.4619 - val_loss: 33.2568\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 31.3344 - val_loss: 33.5276\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.5059 - val_loss: 32.2107\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.7323 - val_loss: 32.9418\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.4434 - val_loss: 31.9536\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.0106 - val_loss: 29.9899\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.1317 - val_loss: 31.9749\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.8925 - val_loss: 31.3709\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.9028 - val_loss: 30.6585\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.7375 - val_loss: 29.3597\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.1610 - val_loss: 26.8579\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.5175 - val_loss: 26.4809\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.6516 - val_loss: 26.9025\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.4878 - val_loss: 27.5500\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.9784 - val_loss: 26.6830\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.2217 - val_loss: 25.6099\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.4365 - val_loss: 25.2727\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 24.0994 - val_loss: 25.1499\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.9354 - val_loss: 25.3811\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.8587 - val_loss: 24.9980\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.5956 - val_loss: 24.5369\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 23.6773 - val_loss: 24.7729\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.4480 - val_loss: 24.3628\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.1194 - val_loss: 24.1809\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.0442 - val_loss: 24.3169\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.9530 - val_loss: 24.0527\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.7636 - val_loss: 23.9585\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.7395 - val_loss: 23.8234\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.6046 - val_loss: 23.7753\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 22.5313 - val_loss: 23.8643\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4148 - val_loss: 23.5809\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.2220 - val_loss: 23.4842\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.1023 - val_loss: 23.4384\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.0098 - val_loss: 23.4672\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.0255 - val_loss: 23.3492\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.8673 - val_loss: 23.3195\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.0372 - val_loss: 23.2756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7330 - val_loss: 23.2618\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.7359 - val_loss: 23.4268\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.7168 - val_loss: 23.2719\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.6302 - val_loss: 23.1687\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.3692 - val_loss: 23.0059\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.3292 - val_loss: 23.2978\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.3820 - val_loss: 23.0678\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3680 - val_loss: 23.0718\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.2793 - val_loss: 22.9327\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1287 - val_loss: 23.0120\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.5437 - val_loss: 22.9837\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3302 - val_loss: 22.9138\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1005 - val_loss: 22.7694\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.9057 - val_loss: 22.6960\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.8894 - val_loss: 22.7877\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.7972 - val_loss: 22.9370\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.7736 - val_loss: 22.7809\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.6412 - val_loss: 22.7966\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.6078 - val_loss: 22.6768\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.6938 - val_loss: 22.8957\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.6410 - val_loss: 22.9123\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.5202 - val_loss: 22.6549\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.3918 - val_loss: 22.9292\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.3685 - val_loss: 22.6992\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.2472 - val_loss: 22.6772\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.2643 - val_loss: 23.4185\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.3948 - val_loss: 22.8266\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 79.3539 - val_loss: 53.4805\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 46.0841 - val_loss: 43.2956\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 41.8284 - val_loss: 41.7464\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 41.3136 - val_loss: 40.8789\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.4670 - val_loss: 39.4548\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.9106 - val_loss: 39.3627\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 38.9234 - val_loss: 39.5218\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.2883 - val_loss: 37.6417\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 37.9149 - val_loss: 41.8085\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.9068 - val_loss: 42.7044\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.0204 - val_loss: 36.3809\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.3490 - val_loss: 36.2621\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.6325 - val_loss: 36.9709\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.0340 - val_loss: 35.4145\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.2115 - val_loss: 37.0933\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.3137 - val_loss: 34.9837\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.3057 - val_loss: 34.5824\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.6631 - val_loss: 34.3439\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.1422 - val_loss: 35.1402\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.8140 - val_loss: 35.4102\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.7160 - val_loss: 33.5602\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.2875 - val_loss: 33.5750\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.2919 - val_loss: 35.5289\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.9370 - val_loss: 33.8491\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.9751 - val_loss: 34.2186\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.3590 - val_loss: 32.4426\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.3401 - val_loss: 34.3485\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.5747 - val_loss: 33.1018\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.8416 - val_loss: 33.7983\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.7643 - val_loss: 33.7556\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.5963 - val_loss: 33.0656\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.8573 - val_loss: 49.5062\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 46.8343 - val_loss: 43.6354\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 43.2527 - val_loss: 43.6134\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.2373 - val_loss: 40.7215\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 40.7547 - val_loss: 40.3035\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 41.6145 - val_loss: 40.9105\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.9812 - val_loss: 40.0879\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.2048 - val_loss: 40.6783\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.1955 - val_loss: 39.5845\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 38.5511 - val_loss: 38.7244\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 38.8574 - val_loss: 43.8129\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.2573 - val_loss: 43.9345\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.9282 - val_loss: 39.3482\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.6603 - val_loss: 36.6809\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.7300 - val_loss: 37.6246\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.7172 - val_loss: 36.3821\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.2169 - val_loss: 36.0234\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.6405 - val_loss: 36.7226\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.8865 - val_loss: 38.6267\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.2138 - val_loss: 35.7724\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.8610 - val_loss: 34.9620\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.3844 - val_loss: 34.4090\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.9051 - val_loss: 34.6301\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.0812 - val_loss: 34.1147\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.7566 - val_loss: 34.1355\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.7688 - val_loss: 33.3455\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.1100 - val_loss: 33.2430\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 32.9598 - val_loss: 32.9186\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 32.4449 - val_loss: 32.6546\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.8073 - val_loss: 35.6026\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.8207 - val_loss: 33.1051\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.9487 - val_loss: 32.8463\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.6031 - val_loss: 32.4061\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.3187 - val_loss: 32.0678\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 31.9631 - val_loss: 32.9469\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 31.8318 - val_loss: 31.9327\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 31.2357 - val_loss: 31.7211\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.8075 - val_loss: 36.4848\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.2476 - val_loss: 33.6421\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.8943 - val_loss: 31.4551\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.5432 - val_loss: 34.2650\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.3709 - val_loss: 31.7712\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.3930 - val_loss: 30.9420\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.2281 - val_loss: 30.8902\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.4384 - val_loss: 31.1606\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 29.8693 - val_loss: 30.1689\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.0074 - val_loss: 30.3426\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.6542 - val_loss: 30.1851\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.3059 - val_loss: 28.8432\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 27.2210 - val_loss: 28.6519\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.0880 - val_loss: 28.0135\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.2983 - val_loss: 30.1866\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 27.8803 - val_loss: 26.9055\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.8572 - val_loss: 26.3262\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.2116 - val_loss: 25.7861\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.5796 - val_loss: 25.0125\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 24.1709 - val_loss: 25.0821\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.7563 - val_loss: 24.9537\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.6470 - val_loss: 24.5908\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.2367 - val_loss: 24.1067\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.9818 - val_loss: 23.9114\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.8876 - val_loss: 24.2737\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.9238 - val_loss: 23.4504\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7077 - val_loss: 23.6640\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.5360 - val_loss: 23.3533\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.3884 - val_loss: 23.1992\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2349 - val_loss: 23.2665\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.2168 - val_loss: 23.1791\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0437 - val_loss: 23.1960\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.9615 - val_loss: 22.9624\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.9260 - val_loss: 22.9031\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.7712 - val_loss: 22.9581\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.7150 - val_loss: 22.8293\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7810 - val_loss: 23.3621\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6540 - val_loss: 22.7158\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.5214 - val_loss: 22.8950\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 21.4550 - val_loss: 22.5525\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.4311 - val_loss: 22.8300\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3944 - val_loss: 22.8626\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.3598 - val_loss: 22.5859\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.4698 - val_loss: 22.4804\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.4446 - val_loss: 22.6924\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5553 - val_loss: 22.4941\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.1447 - val_loss: 22.4222\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.0338 - val_loss: 22.4617\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.0094 - val_loss: 22.3715\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.9364 - val_loss: 22.4429\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.9857 - val_loss: 22.5766\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.0563 - val_loss: 22.3260\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.8083 - val_loss: 22.2688\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.8693 - val_loss: 22.4326\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7706 - val_loss: 22.2988\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.6614 - val_loss: 22.3745\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.7502 - val_loss: 22.7037\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6727 - val_loss: 22.1999\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 623us/step - loss: 20.6127 - val_loss: 22.2312\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 20.5047 - val_loss: 22.1068\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.5395 - val_loss: 22.1076\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.4098 - val_loss: 22.2569\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.5547 - val_loss: 22.0907\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.4751 - val_loss: 49.6802\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 49.9074 - val_loss: 46.6121\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 45.5969 - val_loss: 42.3979\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 43.0964 - val_loss: 41.2269\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 42.8300 - val_loss: 44.8495\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 43.3186 - val_loss: 39.9293\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.3523 - val_loss: 41.8899\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 43.2794 - val_loss: 48.9176\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 41.7245 - val_loss: 38.6545\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.9126 - val_loss: 38.8396\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 41.3045 - val_loss: 46.4975\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 41.9982 - val_loss: 42.1006\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 39.6843 - val_loss: 38.9132\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 39.0742 - val_loss: 36.3595\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 37.6403 - val_loss: 36.4255\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.5516 - val_loss: 36.3890\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 37.2448 - val_loss: 36.3212\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.4433 - val_loss: 34.3016\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.4821 - val_loss: 34.2585\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 37.6342 - val_loss: 35.0145\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.3971 - val_loss: 40.0508\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 36.6574 - val_loss: 34.5800\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 35.1119 - val_loss: 34.2810\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.9045 - val_loss: 33.4264\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 34.4143 - val_loss: 32.4330\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.3940 - val_loss: 34.9602\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.1959 - val_loss: 33.5984\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 33.8817 - val_loss: 32.8267\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 33.3524 - val_loss: 31.8827\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 33.7254 - val_loss: 31.1041\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.7621 - val_loss: 33.7658\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 690us/step - loss: 31.6801 - val_loss: 31.3352\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.2709 - val_loss: 29.8852\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.1778 - val_loss: 31.4747\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.5909 - val_loss: 29.1897\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.8236 - val_loss: 27.8811\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.4415 - val_loss: 27.0884\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.6509 - val_loss: 26.1616\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.7876 - val_loss: 26.4532\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.1862 - val_loss: 25.1550\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.5921 - val_loss: 24.7718\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 24.2091 - val_loss: 24.5630\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 24.1192 - val_loss: 24.2590\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.6722 - val_loss: 24.1460\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.5306 - val_loss: 24.0314\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.3878 - val_loss: 24.2728\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.2926 - val_loss: 23.5629\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.0897 - val_loss: 23.4837\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.9049 - val_loss: 23.5280\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.8875 - val_loss: 23.2909\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 23.0269 - val_loss: 23.6086\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.8394 - val_loss: 23.1685\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.4726 - val_loss: 23.2273\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.4811 - val_loss: 23.1137\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.3392 - val_loss: 22.9819\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.2161 - val_loss: 23.2208\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.1322 - val_loss: 22.8988\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.0394 - val_loss: 22.9084\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.2076 - val_loss: 23.1271\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1725 - val_loss: 22.8358\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.9340 - val_loss: 22.7079\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.8581 - val_loss: 22.7112\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.7940 - val_loss: 22.8035\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7643 - val_loss: 23.1402\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7794 - val_loss: 22.6630\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.7429 - val_loss: 22.7491\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.6995 - val_loss: 22.6033\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.5198 - val_loss: 22.4766\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.4208 - val_loss: 22.4982\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.4979 - val_loss: 22.5316\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4654 - val_loss: 22.6101\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.7695 - val_loss: 22.5962\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 646us/step - loss: 21.4437 - val_loss: 22.3938\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.3014 - val_loss: 22.3508\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.1578 - val_loss: 22.3441\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.0735 - val_loss: 22.3209\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0465 - val_loss: 22.3272\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.0349 - val_loss: 22.2645\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.0254 - val_loss: 22.2957\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.0316 - val_loss: 22.2614\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 21.0072 - val_loss: 22.2408\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.9678 - val_loss: 22.4276\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.8201 - val_loss: 22.2507\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.6803 - val_loss: 22.2656\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.6595 - val_loss: 22.3158\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.6376 - val_loss: 22.1510\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.5776 - val_loss: 22.2093\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.5856 - val_loss: 22.2571\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.5001 - val_loss: 22.4838\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8211 - val_loss: 23.1358\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.8278 - val_loss: 22.5112\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.1137 - val_loss: 46.0301\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 43.8684 - val_loss: 41.7267\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 40.9861 - val_loss: 44.3371\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.3451 - val_loss: 38.9307\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.2221 - val_loss: 38.5613\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.6764 - val_loss: 38.4837\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 37.8963 - val_loss: 40.3161\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.9451 - val_loss: 36.2269\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 37.7418 - val_loss: 39.6014\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.0458 - val_loss: 35.8946\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.4733 - val_loss: 35.6376\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.9915 - val_loss: 35.6638\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.4770 - val_loss: 35.6401\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.8863 - val_loss: 35.4500\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.5066 - val_loss: 38.3822\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.3724 - val_loss: 36.5770\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.7325 - val_loss: 34.1967\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.0033 - val_loss: 35.1893\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.5627 - val_loss: 33.6683\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.2083 - val_loss: 35.4023\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8046 - val_loss: 34.5382\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 33.1636 - val_loss: 33.4477\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.5012 - val_loss: 32.9089\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.2602 - val_loss: 32.5148\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.4810 - val_loss: 32.1963\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.7676 - val_loss: 32.1312\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.8289 - val_loss: 32.7720\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.1264 - val_loss: 32.1186\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.1741 - val_loss: 31.8935\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.7140 - val_loss: 32.2300\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.0733 - val_loss: 31.2420\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.4624 - val_loss: 31.2233\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.2937 - val_loss: 31.3981\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 29.6957 - val_loss: 32.5232\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.9327 - val_loss: 32.5011\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.7918 - val_loss: 32.7926\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.4609 - val_loss: 33.0145\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.2007 - val_loss: 47.6789\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 775us/step - loss: 45.0360 - val_loss: 42.6168\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 751us/step - loss: 41.7403 - val_loss: 39.8555\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 765us/step - loss: 40.4973 - val_loss: 38.7831\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 793us/step - loss: 39.6349 - val_loss: 38.1975\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 761us/step - loss: 38.8382 - val_loss: 37.1487\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 786us/step - loss: 38.3202 - val_loss: 38.1318\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 775us/step - loss: 37.7713 - val_loss: 37.5465\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 702us/step - loss: 36.6547 - val_loss: 35.3257\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.8660 - val_loss: 34.9963\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.9344 - val_loss: 36.3036\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 744us/step - loss: 35.2894 - val_loss: 34.4459\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 35.3388 - val_loss: 34.4552\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.2408 - val_loss: 35.2752\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.5621 - val_loss: 34.2666\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.6956 - val_loss: 32.4733\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.5975 - val_loss: 32.6737\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.3659 - val_loss: 33.6436\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.1449 - val_loss: 36.4660\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.6065 - val_loss: 33.2106\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.4481 - val_loss: 31.4084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.1597 - val_loss: 32.9423\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.1066 - val_loss: 34.9424\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.7564 - val_loss: 34.3042\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.4178 - val_loss: 30.6778\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.1283 - val_loss: 30.3334\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.2155 - val_loss: 31.1751\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.7160 - val_loss: 34.3241\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.2474 - val_loss: 36.6875\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.1191 - val_loss: 30.6409\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.4306 - val_loss: 30.1665\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.2559 - val_loss: 33.5408\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.8340 - val_loss: 29.8802\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.2800 - val_loss: 30.5861\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.7114 - val_loss: 30.3305\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.6578 - val_loss: 30.7063\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.9077 - val_loss: 29.1241\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.6391 - val_loss: 29.4225\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.4027 - val_loss: 29.2165\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.1083 - val_loss: 31.0477\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.8482 - val_loss: 29.1908\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.5955 - val_loss: 28.5730\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 29.1726 - val_loss: 28.9709\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.5580 - val_loss: 29.2605\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 28.2400 - val_loss: 28.6598\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.1862 - val_loss: 28.5555\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.1085 - val_loss: 28.1709\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.3543 - val_loss: 28.7627\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.0868 - val_loss: 28.3041\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.6241 - val_loss: 28.1550\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.7900 - val_loss: 28.8428\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.1294 - val_loss: 30.5926\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.8373 - val_loss: 29.0691\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.7427 - val_loss: 27.8704\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 27.6969 - val_loss: 27.8510\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.3378 - val_loss: 27.8396\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.0790 - val_loss: 27.5836\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 27.0186 - val_loss: 29.1312\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.5514 - val_loss: 28.3911\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 26.8225 - val_loss: 26.8563\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.0409 - val_loss: 26.5149\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 25.8513 - val_loss: 26.8911\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.9218 - val_loss: 26.3565\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.9253 - val_loss: 26.3937\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 25.5856 - val_loss: 26.0948\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.2676 - val_loss: 25.9057\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.9900 - val_loss: 25.6952\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.8247 - val_loss: 25.9065\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 25.0080 - val_loss: 25.9335\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.1007 - val_loss: 25.3238\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.0739 - val_loss: 25.2879\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.0520 - val_loss: 24.6683\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.6223 - val_loss: 24.5272\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.6794 - val_loss: 25.8644\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.9884 - val_loss: 25.7063\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.3488 - val_loss: 24.3184\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.3853 - val_loss: 24.6528\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.0042 - val_loss: 24.0656\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.8701 - val_loss: 24.2904\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.7313 - val_loss: 23.7915\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.7360 - val_loss: 23.6508\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3716 - val_loss: 23.3525\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.1381 - val_loss: 23.2792\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.0080 - val_loss: 23.2748\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.0041 - val_loss: 23.4269\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.1675 - val_loss: 23.0735\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.8389 - val_loss: 23.2406\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.0749 - val_loss: 24.2805\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.2216 - val_loss: 23.6356\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.6975 - val_loss: 22.8979\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.8009 - val_loss: 22.8691\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.4897 - val_loss: 22.8601\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.4028 - val_loss: 22.7314\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.3875 - val_loss: 22.7168\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.2501 - val_loss: 22.7546\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.1154 - val_loss: 23.4752\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.2652 - val_loss: 22.9739\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.1116 - val_loss: 22.6054\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9857 - val_loss: 22.7639\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.9724 - val_loss: 22.7161\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.1782 - val_loss: 48.9117\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 44.5522 - val_loss: 40.9526\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.5847 - val_loss: 39.6317\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 40.1712 - val_loss: 40.4833\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 38.6866 - val_loss: 38.6489\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.3074 - val_loss: 37.6622\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.0624 - val_loss: 44.2337\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 40.8407 - val_loss: 42.8814\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 40.6372 - val_loss: 39.7156\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 38.5455 - val_loss: 39.1582\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.7649 - val_loss: 41.7939\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.6773 - val_loss: 44.7031\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 44.0118 - val_loss: 57.0283\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 44.8534 - val_loss: 40.9851\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.0389 - val_loss: 45.5288\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.6438 - val_loss: 39.4932\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 40.2193 - val_loss: 39.3617\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.1548 - val_loss: 40.4623\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.9325 - val_loss: 38.8279\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.7027 - val_loss: 38.3768\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.8929 - val_loss: 38.7261\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.0835 - val_loss: 37.3425\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.0587 - val_loss: 37.0573\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 38.3743 - val_loss: 40.6979\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.4167 - val_loss: 38.5406\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.2475 - val_loss: 38.0638\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.5612 - val_loss: 37.2207\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.0428 - val_loss: 39.2417\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 96.7194 - val_loss: 52.6813\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 47.7285 - val_loss: 47.5825\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 42.5366 - val_loss: 43.6302\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.7302 - val_loss: 41.4060\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.4990 - val_loss: 40.5501\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.0144 - val_loss: 46.1488\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.1732 - val_loss: 39.9566\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.3775 - val_loss: 39.9668\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.1232 - val_loss: 39.5534\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 713us/step - loss: 39.5942 - val_loss: 41.0979\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 37.0900 - val_loss: 37.3433\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 733us/step - loss: 37.7722 - val_loss: 38.3330\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 704us/step - loss: 36.2461 - val_loss: 36.9464\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.4907 - val_loss: 36.4139\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.0189 - val_loss: 37.6309\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.4846 - val_loss: 36.0976\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.6570 - val_loss: 36.0879\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.1020 - val_loss: 35.0440\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.8079 - val_loss: 34.5303\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.3890 - val_loss: 35.8249\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.5444 - val_loss: 35.0855\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 33.6147 - val_loss: 35.2955\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.0359 - val_loss: 34.1311\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.7788 - val_loss: 33.2366\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.9083 - val_loss: 34.3940\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 31.3580 - val_loss: 33.7808\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.3461 - val_loss: 33.0053\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.7861 - val_loss: 32.5695\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.0275 - val_loss: 32.6834\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.2112 - val_loss: 32.4032\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.2948 - val_loss: 32.8323\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.7525 - val_loss: 32.0337\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.6936 - val_loss: 31.7291\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.9258 - val_loss: 31.1778\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.9081 - val_loss: 31.9658\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.9337 - val_loss: 31.8950\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.4384 - val_loss: 30.3335\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.5061 - val_loss: 30.7181\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.8678 - val_loss: 29.9305\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 29.2119 - val_loss: 31.1544\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.0593 - val_loss: 30.6016\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.6937 - val_loss: 28.8866\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.2712 - val_loss: 28.5338\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.3164 - val_loss: 28.1578\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.9636 - val_loss: 27.9875\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.8156 - val_loss: 27.1860\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 632us/step - loss: 25.4312 - val_loss: 26.8794\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.2417 - val_loss: 26.6896\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 24.3894 - val_loss: 26.0108\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.7866 - val_loss: 25.6014\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.5434 - val_loss: 25.3062\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.3410 - val_loss: 25.0349\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.2996 - val_loss: 25.1809\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.9900 - val_loss: 25.2851\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.2111 - val_loss: 25.1345\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.9824 - val_loss: 24.7620\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.7454 - val_loss: 24.5516\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.8243 - val_loss: 24.9443\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.4489 - val_loss: 24.3837\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2798 - val_loss: 24.3438\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0659 - val_loss: 24.2444\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.9135 - val_loss: 24.0765\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0941 - val_loss: 24.0352\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.9932 - val_loss: 24.9333\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.7471 - val_loss: 24.0889\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7504 - val_loss: 23.9287\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.5816 - val_loss: 23.8580\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.4534 - val_loss: 23.7628\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.2500 - val_loss: 23.7778\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2754 - val_loss: 23.8513\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6671 - val_loss: 23.7092\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.2617 - val_loss: 23.6646\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.1161 - val_loss: 23.5913\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.0361 - val_loss: 23.3892\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.1056 - val_loss: 24.7007\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2510 - val_loss: 23.5777\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.0431 - val_loss: 23.8057\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.9208 - val_loss: 23.3062\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.8310 - val_loss: 23.6235\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.7805 - val_loss: 23.2927\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.7171 - val_loss: 23.4105\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.4206 - val_loss: 23.2749\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.5632 - val_loss: 23.2740\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.4642 - val_loss: 23.1724\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.4250 - val_loss: 23.4704\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.3654 - val_loss: 23.1569\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.6664 - val_loss: 23.2960\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.2667 - val_loss: 23.1315\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.1009 - val_loss: 23.4841\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.2646 - val_loss: 23.2802\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.2820 - val_loss: 23.2900\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.0913 - val_loss: 23.2940\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 19.9829 - val_loss: 23.1516\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 88.0111 - val_loss: 49.7470\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 49.9215 - val_loss: 47.4061\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 44.7383 - val_loss: 42.3022\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 41.9741 - val_loss: 40.2985\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.1140 - val_loss: 39.3654\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.3400 - val_loss: 38.9345\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.0042 - val_loss: 38.0718\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.4346 - val_loss: 37.7332\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.7879 - val_loss: 39.2991\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.2653 - val_loss: 37.5168\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.1808 - val_loss: 39.0330\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.1033 - val_loss: 36.8061\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 35.5049 - val_loss: 35.3427\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.1611 - val_loss: 34.3400\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 36.3160 - val_loss: 33.4950\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.8955 - val_loss: 33.0270\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.6894 - val_loss: 33.6178\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.5267 - val_loss: 39.1743\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 35.2952 - val_loss: 35.1410\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.0312 - val_loss: 35.1401\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.3316 - val_loss: 31.9052\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.2738 - val_loss: 31.9248\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.3209 - val_loss: 31.7514\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.6246 - val_loss: 32.3003\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.5522 - val_loss: 31.7219\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.4436 - val_loss: 31.4109\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.9546 - val_loss: 32.0930\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.1976 - val_loss: 30.6927\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.3655 - val_loss: 30.9287\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.9385 - val_loss: 31.9820\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 613us/step - loss: 30.8206 - val_loss: 30.3725\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.2502 - val_loss: 31.2102\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.3222 - val_loss: 29.9427\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.5363 - val_loss: 29.4108\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.2162 - val_loss: 31.2898\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.8961 - val_loss: 29.1022\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.4990 - val_loss: 29.9716\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.8027 - val_loss: 28.4636\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.6019 - val_loss: 28.7769\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.8441 - val_loss: 28.4293\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.1343 - val_loss: 27.9413\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 27.3604 - val_loss: 27.4553\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 298us/step - loss: 25.9576 - val_loss: 26.8009\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.6902 - val_loss: 27.8515\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 25.3546 - val_loss: 26.7576\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 24.8212 - val_loss: 25.5768\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 24.9011 - val_loss: 26.9406\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.2296 - val_loss: 25.2697\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.8417 - val_loss: 25.8999\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.5391 - val_loss: 24.5205\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.1316 - val_loss: 24.4553\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.2656 - val_loss: 24.5021\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.9481 - val_loss: 23.9961\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.6724 - val_loss: 23.8865\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 22.7171 - val_loss: 25.0281\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.4420 - val_loss: 23.6307\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 22.1799 - val_loss: 23.5498\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 22.1104 - val_loss: 23.4694\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.1578 - val_loss: 23.5047\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.9083 - val_loss: 23.2649\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 21.7294 - val_loss: 23.7282\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.6319 - val_loss: 23.1397\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.5475 - val_loss: 23.1737\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 21.4031 - val_loss: 23.1516\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.3253 - val_loss: 22.9705\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 21.3079 - val_loss: 22.9052\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.2909 - val_loss: 22.9867\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.2410 - val_loss: 22.7812\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 20.9943 - val_loss: 22.7499\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 20.8749 - val_loss: 22.7276\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 20.8297 - val_loss: 22.6152\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 20.9261 - val_loss: 22.5853\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.8586 - val_loss: 22.7887\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 20.6637 - val_loss: 22.7366\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.8297 - val_loss: 23.3200\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.5508 - val_loss: 22.5650\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.5733 - val_loss: 22.9113\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.5440 - val_loss: 22.5459\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.4845 - val_loss: 22.3893\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.9098 - val_loss: 22.8060\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 20.6724 - val_loss: 22.6158\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 20.2909 - val_loss: 22.2568\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.0334 - val_loss: 22.1549\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 19.9761 - val_loss: 22.2673\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.0111 - val_loss: 22.4854\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.0526 - val_loss: 22.1079\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 19.9525 - val_loss: 23.4104\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 19.9774 - val_loss: 22.2294\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 19.8620 - val_loss: 22.0304\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 19.9097 - val_loss: 22.0619\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 19.8970 - val_loss: 21.9985\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 19.6475 - val_loss: 21.9148\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 19.5997 - val_loss: 22.0484\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 19.4890 - val_loss: 21.9111\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 19.4046 - val_loss: 21.8625\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 19.4790 - val_loss: 22.0562\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 19.7480 - val_loss: 22.0438\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 19.4420 - val_loss: 21.8427\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 19.4061 - val_loss: 21.9889\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 19.2423 - val_loss: 21.8318\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.9815 - val_loss: 48.0841\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 46.8818 - val_loss: 44.7753\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 43.5979 - val_loss: 42.6576\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 42.3686 - val_loss: 39.5386\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.1382 - val_loss: 38.6323\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 38.8440 - val_loss: 38.1534\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 38.6605 - val_loss: 36.5945\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 602us/step - loss: 38.1563 - val_loss: 37.7759\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 37.0365 - val_loss: 36.2332\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 550us/step - loss: 36.6012 - val_loss: 40.1232\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.4954 - val_loss: 35.1142\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 35.9683 - val_loss: 35.5423\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.1117 - val_loss: 34.8415\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.8128 - val_loss: 34.8570\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.9446 - val_loss: 34.7070\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.5962 - val_loss: 35.8195\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 34.1350 - val_loss: 32.9720\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.5895 - val_loss: 33.5081\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.9960 - val_loss: 37.0046\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.3310 - val_loss: 34.1377\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 553us/step - loss: 34.8749 - val_loss: 32.9923\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.5925 - val_loss: 31.7437\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.8258 - val_loss: 31.7709\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 32.2231 - val_loss: 32.2220\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.7096 - val_loss: 31.7503\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 31.6700 - val_loss: 31.0386\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 31.7291 - val_loss: 30.7772\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.7739 - val_loss: 30.1091\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.7594 - val_loss: 33.0550\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.2083 - val_loss: 30.3985\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.9215 - val_loss: 29.5535\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 29.5821 - val_loss: 29.9008\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 29.1059 - val_loss: 29.7631\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.5913 - val_loss: 28.7440\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.2820 - val_loss: 28.5392\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.8406 - val_loss: 30.6618\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.9017 - val_loss: 28.7650\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.3113 - val_loss: 28.4194\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.6313 - val_loss: 27.4988\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 564us/step - loss: 26.5093 - val_loss: 28.7678\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.1394 - val_loss: 27.2640\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 25.7770 - val_loss: 26.1338\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 25.1456 - val_loss: 25.8240\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.7516 - val_loss: 25.4955\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.4520 - val_loss: 25.2453\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 24.3881 - val_loss: 25.5415\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 24.1584 - val_loss: 24.9480\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 24.1508 - val_loss: 25.1280\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.9952 - val_loss: 24.7394\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.5218 - val_loss: 24.5845\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.6454 - val_loss: 24.6030\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 766us/step - loss: 23.3760 - val_loss: 24.3843\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.1121 - val_loss: 24.3931\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.0189 - val_loss: 24.2708\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.8906 - val_loss: 24.1429\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.9436 - val_loss: 23.9969\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.7960 - val_loss: 24.0640\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.7391 - val_loss: 24.0148\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.8478 - val_loss: 25.0962\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.8311 - val_loss: 23.9845\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.4750 - val_loss: 23.9692\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3698 - val_loss: 23.7784\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.2366 - val_loss: 23.8622\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.3357 - val_loss: 24.2503\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.1687 - val_loss: 23.7865\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.1649 - val_loss: 23.8548\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.0205 - val_loss: 23.6349\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9896 - val_loss: 24.5349\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.3292 - val_loss: 23.6738\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.9199 - val_loss: 23.4750\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.7808 - val_loss: 23.6097\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.1506 - val_loss: 23.5645\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.6852 - val_loss: 23.4736\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.5468 - val_loss: 23.4597\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.4585 - val_loss: 23.8872\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5995 - val_loss: 23.4098\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3669 - val_loss: 23.4529\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.2538 - val_loss: 23.5742\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.4372 - val_loss: 23.4391\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.5538 - val_loss: 23.4617\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4622 - val_loss: 23.6656\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.9953 - val_loss: 46.9611\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 48.5132 - val_loss: 44.9261\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.9893 - val_loss: 41.8087\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 39.9406 - val_loss: 42.4129\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.0764 - val_loss: 38.9627\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.1307 - val_loss: 37.5355\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.1995 - val_loss: 37.4322\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.7588 - val_loss: 35.8444\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.6569 - val_loss: 35.7450\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.2007 - val_loss: 34.6886\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.5476 - val_loss: 34.8618\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.0488 - val_loss: 35.2597\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.9115 - val_loss: 36.1196\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.3750 - val_loss: 34.0393\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.3457 - val_loss: 34.8000\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.0307 - val_loss: 34.8212\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.5289 - val_loss: 33.0550\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.6178 - val_loss: 32.8703\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.6637 - val_loss: 33.2228\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.2435 - val_loss: 31.8704\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 32.4352 - val_loss: 32.8596\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.8879 - val_loss: 32.3396\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.7899 - val_loss: 34.5720\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.8956 - val_loss: 32.9925\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.8642 - val_loss: 31.1254\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.5515 - val_loss: 30.6462\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.7317 - val_loss: 31.2641\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.3863 - val_loss: 32.3188\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.5140 - val_loss: 32.3032\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.6334 - val_loss: 30.6251\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.8122 - val_loss: 32.4190\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.6135 - val_loss: 30.5244\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.1828 - val_loss: 30.4362\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.3648 - val_loss: 32.1623\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.6410 - val_loss: 30.2262\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.1709 - val_loss: 29.5298\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.9320 - val_loss: 29.3966\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.1175 - val_loss: 29.0862\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.0826 - val_loss: 28.9296\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.6029 - val_loss: 28.5178\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.9734 - val_loss: 29.3979\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.9640 - val_loss: 30.2178\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.2729 - val_loss: 28.7575\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 27.7787 - val_loss: 27.2797\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.6403 - val_loss: 27.1059\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.1116 - val_loss: 29.5502\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 27.4551 - val_loss: 30.5872\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.0121 - val_loss: 26.3378\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 25.3260 - val_loss: 25.5191\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.1442 - val_loss: 25.0208\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.0037 - val_loss: 25.5501\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.7964 - val_loss: 24.5797\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.3575 - val_loss: 24.0965\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.6711 - val_loss: 24.0711\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 23.3852 - val_loss: 24.0141\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.5186 - val_loss: 23.8732\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.1669 - val_loss: 23.3761\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.8541 - val_loss: 23.2666\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.7940 - val_loss: 23.7863\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.7121 - val_loss: 23.5563\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.6437 - val_loss: 22.9379\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3847 - val_loss: 22.8640\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 22.2361 - val_loss: 22.8005\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.3137 - val_loss: 22.7193\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.2124 - val_loss: 22.6297\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.4555 - val_loss: 23.0576\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.1697 - val_loss: 22.5034\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.8888 - val_loss: 22.4813\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.8749 - val_loss: 22.5199\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.8362 - val_loss: 22.4445\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.7351 - val_loss: 22.4476\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.7516 - val_loss: 22.3013\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.5369 - val_loss: 22.2644\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.5645 - val_loss: 22.2311\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5231 - val_loss: 22.3114\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3607 - val_loss: 22.1457\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.3208 - val_loss: 22.1348\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.3611 - val_loss: 22.2111\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.5613 - val_loss: 22.0774\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.3326 - val_loss: 22.1250\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2638 - val_loss: 22.1990\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.4874 - val_loss: 22.4336\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.2074 - val_loss: 22.0439\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.1329 - val_loss: 22.2580\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.0713 - val_loss: 21.9982\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9749 - val_loss: 22.0007\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9758 - val_loss: 22.0269\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.9840 - val_loss: 22.5501\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.1730 - val_loss: 21.9606\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.8885 - val_loss: 21.8479\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.4068 - val_loss: 22.4676\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0235 - val_loss: 22.1202\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.8520 - val_loss: 21.8759\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.7431 - val_loss: 21.8050\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.6780 - val_loss: 21.8143\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.6452 - val_loss: 22.0589\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.6705 - val_loss: 22.0979\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.6170 - val_loss: 21.8238\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.5542 - val_loss: 21.7821\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.5721 - val_loss: 21.7794\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 96.6716 - val_loss: 86.7710\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 85.5640 - val_loss: 78.1572\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 51.4267 - val_loss: 42.5440\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.4303 - val_loss: 40.8652\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.7214 - val_loss: 38.4790\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.7709 - val_loss: 39.2625\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.0630 - val_loss: 37.4837\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.3672 - val_loss: 36.8868\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.5549 - val_loss: 36.6458\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.9976 - val_loss: 35.6836\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.1653 - val_loss: 34.6195\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.8998 - val_loss: 35.1113\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.8179 - val_loss: 34.5441\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.5398 - val_loss: 33.7104\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.9584 - val_loss: 32.9682\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.8071 - val_loss: 32.6019\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.6885 - val_loss: 33.1286\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.0742 - val_loss: 32.6259\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.2249 - val_loss: 32.6872\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.5040 - val_loss: 31.6666\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.2395 - val_loss: 32.8648\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.6520 - val_loss: 31.7102\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.4207 - val_loss: 32.1031\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.8681 - val_loss: 33.4021\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.4457 - val_loss: 32.7163\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.9552 - val_loss: 51.5037\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 48.0560 - val_loss: 46.6772\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 43.4410 - val_loss: 41.3379\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.8155 - val_loss: 41.2382\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.8038 - val_loss: 40.2970\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.9669 - val_loss: 39.9916\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.1509 - val_loss: 41.1942\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.2079 - val_loss: 38.0907\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.6737 - val_loss: 39.7291\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.2175 - val_loss: 40.5835\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.7385 - val_loss: 37.7749\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.1278 - val_loss: 41.5079\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.4911 - val_loss: 39.4700\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.0654 - val_loss: 36.2893\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.2948 - val_loss: 36.6099\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.0075 - val_loss: 35.5127\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.9619 - val_loss: 35.5433\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.9488 - val_loss: 36.2757\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.8878 - val_loss: 34.5613\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.8767 - val_loss: 33.9827\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.7453 - val_loss: 36.3450\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.5373 - val_loss: 35.4521\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.8633 - val_loss: 36.7123\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.7192 - val_loss: 36.7244\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 748us/step - loss: 34.2048 - val_loss: 33.4177\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 833us/step - loss: 33.8962 - val_loss: 33.7268\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 781us/step - loss: 32.7923 - val_loss: 33.3446\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 32.5656 - val_loss: 34.2483\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.3005 - val_loss: 33.3712\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.1360 - val_loss: 32.5219\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.9196 - val_loss: 33.0089\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 622us/step - loss: 31.5647 - val_loss: 33.9047\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.2962 - val_loss: 32.5048\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.7584 - val_loss: 32.8158\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.4959 - val_loss: 34.4640\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 712us/step - loss: 31.8438 - val_loss: 31.9478\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.8204 - val_loss: 32.1903\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.3187 - val_loss: 33.4700\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 30.4331 - val_loss: 31.2606\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.6790 - val_loss: 32.4668\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.2917 - val_loss: 30.7943\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.6194 - val_loss: 31.3094\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.1781 - val_loss: 31.9043\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.5224 - val_loss: 34.0306\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.5731 - val_loss: 30.7338\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.8308 - val_loss: 31.3886\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.6199 - val_loss: 34.4299\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.8406 - val_loss: 30.0251\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.9599 - val_loss: 29.8403\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.6418 - val_loss: 30.7829\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.7862 - val_loss: 30.0476\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 27.9053 - val_loss: 30.5685\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.9016 - val_loss: 29.4309\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.4457 - val_loss: 29.8586\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.0412 - val_loss: 28.8285\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.5996 - val_loss: 29.6668\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.7680 - val_loss: 28.1252\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 27.1114 - val_loss: 28.0720\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 26.8072 - val_loss: 27.8601\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.7905 - val_loss: 27.1947\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.8857 - val_loss: 28.7087\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.7231 - val_loss: 27.0401\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.1537 - val_loss: 26.0453\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.8982 - val_loss: 25.9787\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.4728 - val_loss: 24.9523\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.8985 - val_loss: 24.4494\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.5814 - val_loss: 24.3601\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.5592 - val_loss: 24.0536\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.1240 - val_loss: 23.9245\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.0145 - val_loss: 23.6632\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.8208 - val_loss: 23.4996\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.5930 - val_loss: 23.7949\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.4676 - val_loss: 23.5574\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.8418 - val_loss: 25.6610\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.8579 - val_loss: 23.2337\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.5233 - val_loss: 23.5051\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.2928 - val_loss: 22.9948\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.0659 - val_loss: 23.3458\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.9198 - val_loss: 22.7635\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.7463 - val_loss: 22.7876\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.6634 - val_loss: 22.6218\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.5375 - val_loss: 22.5500\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.5381 - val_loss: 22.7188\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.7324 - val_loss: 22.8465\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5840 - val_loss: 22.5810\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.2806 - val_loss: 22.4721\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.2189 - val_loss: 22.6156\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.2155 - val_loss: 22.3451\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.0941 - val_loss: 22.5122\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.0314 - val_loss: 22.4138\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.9511 - val_loss: 22.3511\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.8663 - val_loss: 22.3847\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.7684 - val_loss: 22.2777\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.7611 - val_loss: 22.2025\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.6367 - val_loss: 22.2322\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.6097 - val_loss: 22.2120\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.4550 - val_loss: 22.1895\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.4469 - val_loss: 22.1790\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.3987 - val_loss: 22.3027\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.3492 - val_loss: 22.4543\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 91.6504 - val_loss: 50.4894\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 46.5797 - val_loss: 43.2961\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 42.2175 - val_loss: 41.7093\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 40.6573 - val_loss: 41.1919\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.9083 - val_loss: 39.1052\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 38.4393 - val_loss: 37.8936\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 37.9559 - val_loss: 38.9017\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 38.2094 - val_loss: 39.0861\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 649us/step - loss: 36.7835 - val_loss: 35.9904\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.9517 - val_loss: 37.7038\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.8354 - val_loss: 35.7942\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.7781 - val_loss: 34.7096\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.3129 - val_loss: 35.1773\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.0638 - val_loss: 34.5072\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.1809 - val_loss: 39.2944\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.1689 - val_loss: 33.6750\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.3840 - val_loss: 34.7857\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.9067 - val_loss: 32.6964\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.2647 - val_loss: 32.7887\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.1000 - val_loss: 33.2509\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.8652 - val_loss: 32.9709\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 31.3560 - val_loss: 32.4872\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.1242 - val_loss: 32.6985\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.5532 - val_loss: 32.6537\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.8579 - val_loss: 31.2315\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.6717 - val_loss: 31.7313\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.9840 - val_loss: 30.6527\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.6106 - val_loss: 31.9669\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.7359 - val_loss: 30.8321\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.9860 - val_loss: 31.4524\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.4770 - val_loss: 29.7164\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.7951 - val_loss: 29.1844\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.4061 - val_loss: 29.4984\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.5616 - val_loss: 28.9300\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.8164 - val_loss: 28.4243\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 27.9161 - val_loss: 29.1972\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 27.2152 - val_loss: 27.8290\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.7414 - val_loss: 27.1579\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.8276 - val_loss: 26.4925\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.5613 - val_loss: 26.0797\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 25.1739 - val_loss: 25.5082\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 25.0994 - val_loss: 25.3457\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 24.3196 - val_loss: 26.2843\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.3477 - val_loss: 24.5331\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 745us/step - loss: 23.6564 - val_loss: 24.7685\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 23.3946 - val_loss: 25.5674\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 23.6523 - val_loss: 24.2570\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.4780 - val_loss: 23.8895\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.0992 - val_loss: 23.7790\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 754us/step - loss: 22.8313 - val_loss: 23.6535\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.7459 - val_loss: 23.6005\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 22.7062 - val_loss: 24.3572\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.8841 - val_loss: 23.4463\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.6103 - val_loss: 23.4271\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.4752 - val_loss: 23.9177\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.4924 - val_loss: 23.3423\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.2004 - val_loss: 23.1674\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.1861 - val_loss: 23.1413\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.0631 - val_loss: 23.1194\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1295 - val_loss: 24.1078\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.1182 - val_loss: 22.9870\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.0085 - val_loss: 23.8625\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.9497 - val_loss: 22.8861\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7744 - val_loss: 23.2383\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.8603 - val_loss: 22.8527\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7032 - val_loss: 23.1888\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8858 - val_loss: 22.9302\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.6681 - val_loss: 23.0056\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6156 - val_loss: 22.7728\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.5147 - val_loss: 22.7889\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.3752 - val_loss: 22.6862\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.3672 - val_loss: 22.6964\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.2948 - val_loss: 22.8122\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.2440 - val_loss: 22.5980\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2891 - val_loss: 22.6649\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.1582 - val_loss: 22.6376\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1732 - val_loss: 22.7711\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.1877 - val_loss: 22.6008\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.0450 - val_loss: 22.5691\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.1459 - val_loss: 22.5489\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0487 - val_loss: 22.6507\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.0477 - val_loss: 22.5221\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.0300 - val_loss: 22.6156\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.8758 - val_loss: 22.5227\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.8410 - val_loss: 22.5932\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.8405 - val_loss: 22.8076\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.0905 - val_loss: 23.4016\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 59.9020 - val_loss: 45.3571\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 44.0066 - val_loss: 43.5855\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 42.7145 - val_loss: 41.1081\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 39.3041 - val_loss: 39.7098\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 38.1824 - val_loss: 39.8634\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.6118 - val_loss: 38.9579\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.4152 - val_loss: 37.8245\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.7283 - val_loss: 37.5763\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.6996 - val_loss: 37.4288\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 36.9247 - val_loss: 37.3574\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.6143 - val_loss: 45.1896\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.7629 - val_loss: 37.9820\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.3737 - val_loss: 37.7305\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.9304 - val_loss: 37.3114\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.3172 - val_loss: 35.6131\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.3942 - val_loss: 42.9670\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.6488 - val_loss: 35.3167\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.4139 - val_loss: 38.7619\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.6450 - val_loss: 34.4867\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.1926 - val_loss: 34.2695\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.8232 - val_loss: 34.5673\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.6169 - val_loss: 35.4448\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.3837 - val_loss: 33.4725\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.2447 - val_loss: 34.0542\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.2807 - val_loss: 35.9776\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.3777 - val_loss: 32.8922\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.1059 - val_loss: 32.8454\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.7672 - val_loss: 32.1501\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.1524 - val_loss: 32.9625\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.2634 - val_loss: 33.8935\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.7548 - val_loss: 32.2141\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.0956 - val_loss: 32.9160\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 560us/step - loss: 29.6022 - val_loss: 31.8684\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 29.7931 - val_loss: 32.2018\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.7857 - val_loss: 31.9282\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.3692 - val_loss: 31.8048\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.5940 - val_loss: 31.6076\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.0629 - val_loss: 34.8933\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.3579 - val_loss: 33.7563\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.3057 - val_loss: 33.1364\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.0284 - val_loss: 30.7759\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.4259 - val_loss: 31.1293\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.6175 - val_loss: 33.3684\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.2242 - val_loss: 30.4193\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 27.9785 - val_loss: 31.4556\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.3471 - val_loss: 30.4701\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.1516 - val_loss: 31.1718\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 29.2852 - val_loss: 32.7448\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.8093 - val_loss: 30.7984\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.8145 - val_loss: 45.4082\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 43.2952 - val_loss: 40.9700\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 40.9263 - val_loss: 37.4343\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.9922 - val_loss: 35.4471\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.4364 - val_loss: 34.5483\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.3514 - val_loss: 33.6500\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.9896 - val_loss: 34.6187\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.2505 - val_loss: 32.4420\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.5056 - val_loss: 32.7029\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.2565 - val_loss: 31.4559\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.4065 - val_loss: 34.7492\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.3178 - val_loss: 31.7502\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.9534 - val_loss: 31.5453\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.1217 - val_loss: 30.8531\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.4689 - val_loss: 30.9472\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.7350 - val_loss: 32.8889\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.0383 - val_loss: 30.5401\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.5336 - val_loss: 30.4042\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.8289 - val_loss: 31.0221\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.4229 - val_loss: 29.6508\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.4719 - val_loss: 29.2907\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.0339 - val_loss: 29.2586\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.2304 - val_loss: 33.8923\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.4985 - val_loss: 29.0521\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.7574 - val_loss: 28.9287\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.3408 - val_loss: 28.8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.0009 - val_loss: 28.6380\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.5130 - val_loss: 29.5335\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.7995 - val_loss: 28.6913\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 29.4948 - val_loss: 29.0964\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.6292 - val_loss: 29.9313\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.9123 - val_loss: 28.5525\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 28.5330 - val_loss: 28.2450\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 28.2014 - val_loss: 28.1664\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.2711 - val_loss: 27.9221\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 28.4994 - val_loss: 28.2128\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.2678 - val_loss: 30.0466\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.8593 - val_loss: 27.9064\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 27.8042 - val_loss: 27.1906\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.4982 - val_loss: 27.9956\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 28.3918 - val_loss: 27.1141\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.6594 - val_loss: 27.4580\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 27.0122 - val_loss: 26.7566\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.6061 - val_loss: 26.8782\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 26.4317 - val_loss: 26.7385\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.0960 - val_loss: 26.4835\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.0441 - val_loss: 26.3687\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.9935 - val_loss: 27.6243\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.0647 - val_loss: 26.3330\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 26.1125 - val_loss: 25.6677\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.0125 - val_loss: 25.2855\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.2022 - val_loss: 25.3530\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 24.8030 - val_loss: 25.2138\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.6439 - val_loss: 25.1176\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.1087 - val_loss: 24.5447\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.4769 - val_loss: 24.8975\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.6344 - val_loss: 23.9252\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.4682 - val_loss: 23.7782\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.1134 - val_loss: 23.6806\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.0723 - val_loss: 23.4017\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.0179 - val_loss: 24.7499\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.8099 - val_loss: 23.3821\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 23.2971 - val_loss: 24.2606\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.6798 - val_loss: 22.9612\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.6082 - val_loss: 22.9802\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.5596 - val_loss: 22.7668\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.2463 - val_loss: 23.5675\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.6080 - val_loss: 22.7800\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2094 - val_loss: 22.5360\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.8185 - val_loss: 22.5540\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.8415 - val_loss: 22.6121\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.9499 - val_loss: 22.3370\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.5479 - val_loss: 22.3149\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.5289 - val_loss: 22.3412\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3963 - val_loss: 22.2686\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3276 - val_loss: 22.1727\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3648 - val_loss: 22.5142\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3971 - val_loss: 22.2528\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1663 - val_loss: 22.2295\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.0806 - val_loss: 22.1583\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.1599 - val_loss: 22.2502\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.1435 - val_loss: 21.9641\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9804 - val_loss: 22.0973\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.0427 - val_loss: 21.9967\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.8210 - val_loss: 21.9207\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.7376 - val_loss: 21.8731\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.7976 - val_loss: 21.8082\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.7210 - val_loss: 22.0717\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.7837 - val_loss: 21.8037\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.7254 - val_loss: 22.0793\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.7555 - val_loss: 21.9136\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.5800 - val_loss: 21.8235\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.4232 - val_loss: 21.7544\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.6073 - val_loss: 21.6756\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.3312 - val_loss: 22.1330\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.4044 - val_loss: 21.6559\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.3602 - val_loss: 21.7308\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.4729 - val_loss: 21.8535\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.6439 - val_loss: 21.7351\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.2063 - val_loss: 21.5133\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.1668 - val_loss: 47.9984\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 44.6530 - val_loss: 44.3836\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 41.4881 - val_loss: 42.0913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 41.5254 - val_loss: 42.0338\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 42.2259 - val_loss: 43.0992\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.8137 - val_loss: 40.0729\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 38.4177 - val_loss: 39.2738\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 39.7387 - val_loss: 45.2185\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.3367 - val_loss: 42.2697\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.2850 - val_loss: 38.8787\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.9711 - val_loss: 40.2609\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.6036 - val_loss: 38.2368\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 37.3668 - val_loss: 38.2644\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.2564 - val_loss: 37.2394\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.0441 - val_loss: 36.5154\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.8442 - val_loss: 37.1202\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.1389 - val_loss: 37.0435\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.9895 - val_loss: 37.2270\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 35.3049 - val_loss: 36.0723\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.3322 - val_loss: 37.6400\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.8771 - val_loss: 35.2470\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.7992 - val_loss: 34.7038\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.9035 - val_loss: 36.7816\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.4370 - val_loss: 37.2315\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.4880 - val_loss: 34.4476\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.4102 - val_loss: 34.9323\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.5963 - val_loss: 36.0815\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.8024 - val_loss: 34.7054\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.9881 - val_loss: 33.6898\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.2436 - val_loss: 33.9080\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.5254 - val_loss: 33.8152\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 32.4665 - val_loss: 34.3839\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.9787 - val_loss: 34.0611\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.3328 - val_loss: 33.1249\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.5734 - val_loss: 33.4742\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.7570 - val_loss: 32.9831\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.5678 - val_loss: 32.4320\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.1567 - val_loss: 32.4099\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.8122 - val_loss: 37.4244\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.4405 - val_loss: 32.4107\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.5873 - val_loss: 33.8963\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.1411 - val_loss: 31.8401\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.4113 - val_loss: 31.4244\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.4144 - val_loss: 32.1163\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.3158 - val_loss: 31.4021\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.9541 - val_loss: 32.6742\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.9993 - val_loss: 34.4998\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.6257 - val_loss: 30.4822\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.8706 - val_loss: 29.8386\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.6992 - val_loss: 29.6349\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.6500 - val_loss: 29.3436\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.4126 - val_loss: 28.2544\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 26.7130 - val_loss: 29.2973\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.2499 - val_loss: 26.5047\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.5832 - val_loss: 25.6721\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.2523 - val_loss: 25.1161\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.7898 - val_loss: 26.0557\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.3498 - val_loss: 24.6373\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.0062 - val_loss: 24.3830\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.4983 - val_loss: 24.2918\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.3417 - val_loss: 23.9065\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.1310 - val_loss: 23.6512\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.2069 - val_loss: 24.0830\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.9294 - val_loss: 23.3755\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.9113 - val_loss: 23.3161\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.6896 - val_loss: 23.2102\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.5215 - val_loss: 23.4177\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.4160 - val_loss: 23.2566\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.8691 - val_loss: 24.3393\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.4627 - val_loss: 22.9650\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.1658 - val_loss: 22.8855\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.0773 - val_loss: 22.8828\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.0195 - val_loss: 22.8284\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.9816 - val_loss: 22.9322\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.8884 - val_loss: 22.7435\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.8102 - val_loss: 22.6852\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.7597 - val_loss: 22.7027\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.8052 - val_loss: 22.6310\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.6284 - val_loss: 22.6806\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.5739 - val_loss: 22.5350\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.5816 - val_loss: 22.5073\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.4658 - val_loss: 22.5338\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4852 - val_loss: 22.4729\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4504 - val_loss: 22.5542\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.3765 - val_loss: 22.5331\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.3336 - val_loss: 22.4378\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1871 - val_loss: 22.3625\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3375 - val_loss: 22.4469\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2136 - val_loss: 22.4370\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.1466 - val_loss: 22.9096\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.2449 - val_loss: 22.3880\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0490 - val_loss: 22.3892\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.3851 - val_loss: 46.0287\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 44.7416 - val_loss: 40.9448\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 41.1298 - val_loss: 41.4286\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.6460 - val_loss: 38.4884\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.4465 - val_loss: 37.4189\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.7429 - val_loss: 38.6875\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.1082 - val_loss: 37.8663\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.3095 - val_loss: 36.8875\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.3616 - val_loss: 35.1964\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.6037 - val_loss: 35.9762\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.2354 - val_loss: 35.0867\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.6292 - val_loss: 35.9552\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.3663 - val_loss: 33.8714\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.5845 - val_loss: 33.6653\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.4261 - val_loss: 34.1910\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.8253 - val_loss: 33.7352\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.8770 - val_loss: 35.0050\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 725us/step - loss: 33.9649 - val_loss: 33.7821\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 689us/step - loss: 33.1128 - val_loss: 35.9971\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.3635 - val_loss: 45.5399\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 45.5846 - val_loss: 42.0373\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.0001 - val_loss: 39.6669\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 38.6537 - val_loss: 39.3017\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 36.7774 - val_loss: 36.5453\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.2974 - val_loss: 38.4675\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.2020 - val_loss: 36.4994\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.6474 - val_loss: 35.5119\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.3123 - val_loss: 35.1633\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.1092 - val_loss: 33.7136\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.5664 - val_loss: 35.2470\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.5753 - val_loss: 34.1021\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.0787 - val_loss: 32.6897\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.7476 - val_loss: 33.0469\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.6503 - val_loss: 33.1245\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.7847 - val_loss: 34.1054\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.5495 - val_loss: 32.7962\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.7685 - val_loss: 33.2183\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 87.1159 - val_loss: 52.4289\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 51.2478 - val_loss: 47.7603\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 46.2438 - val_loss: 44.7459\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 43.1146 - val_loss: 44.5012\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 44.2253 - val_loss: 43.6622\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.7680 - val_loss: 41.4559\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.5406 - val_loss: 39.9747\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 39.4161 - val_loss: 39.3947\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.2309 - val_loss: 39.2302\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.9490 - val_loss: 43.7554\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 37.2841 - val_loss: 39.2103\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.7120 - val_loss: 39.7980\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.7407 - val_loss: 38.1986\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.9644 - val_loss: 38.5149\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 408us/step - loss: 35.8443 - val_loss: 37.0292\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 461us/step - loss: 35.7847 - val_loss: 37.7303\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.0982 - val_loss: 37.0413\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.6165 - val_loss: 37.9493\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.3857 - val_loss: 37.0648\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.9784 - val_loss: 35.2271\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.1793 - val_loss: 37.3091\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 33.2352 - val_loss: 36.2938\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.4323 - val_loss: 32.5224\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.2551 - val_loss: 32.0636\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.8704 - val_loss: 32.3688\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.0268 - val_loss: 30.5104\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 28.8691 - val_loss: 29.3448\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 651us/step - loss: 28.2164 - val_loss: 28.9470\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.6865 - val_loss: 28.0071\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.2149 - val_loss: 27.6586\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 26.5562 - val_loss: 27.1735\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 26.2330 - val_loss: 26.9076\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 25.9604 - val_loss: 26.5268\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.7470 - val_loss: 26.2125\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 25.1675 - val_loss: 25.7988\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 24.8898 - val_loss: 25.5695\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.5558 - val_loss: 25.1710\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.2194 - val_loss: 24.9647\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 23.9663 - val_loss: 24.7776\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 23.6359 - val_loss: 24.5138\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.4204 - val_loss: 24.4388\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 23.4986 - val_loss: 24.3213\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.2525 - val_loss: 24.0045\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.0341 - val_loss: 24.4180\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.8730 - val_loss: 23.8920\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.6800 - val_loss: 23.8753\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.6976 - val_loss: 23.7014\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.3907 - val_loss: 23.5521\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.2065 - val_loss: 23.6628\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.0689 - val_loss: 23.4382\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.0389 - val_loss: 23.3676\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.8630 - val_loss: 23.4551\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.8418 - val_loss: 23.3435\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.7370 - val_loss: 23.3383\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.7199 - val_loss: 23.3022\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.5240 - val_loss: 23.1252\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.4903 - val_loss: 23.2373\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.3661 - val_loss: 23.4325\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.4710 - val_loss: 23.1295\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.2571 - val_loss: 23.1964\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.1795 - val_loss: 23.1300\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.7907 - val_loss: 50.5996\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 557us/step - loss: 48.4522 - val_loss: 44.7423\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 43.5729 - val_loss: 42.5502\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 42.9523 - val_loss: 40.9499\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 40.7005 - val_loss: 39.7906\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 39.0745 - val_loss: 40.4638\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.6617 - val_loss: 37.9931\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.7974 - val_loss: 38.3748\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 38.2804 - val_loss: 37.5426\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.1438 - val_loss: 39.6597\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.6562 - val_loss: 37.5596\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.9767 - val_loss: 36.3165\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 36.7806 - val_loss: 37.7566\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.9231 - val_loss: 37.8286\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.5385 - val_loss: 37.7071\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.9327 - val_loss: 39.5046\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.2393 - val_loss: 35.2312\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.5172 - val_loss: 35.1136\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.1643 - val_loss: 35.0568\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.3848 - val_loss: 36.9325\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.3996 - val_loss: 34.5374\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.7498 - val_loss: 33.7840\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 32.5878 - val_loss: 34.5964\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 32.2616 - val_loss: 34.2100\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.8872 - val_loss: 35.0652\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.1911 - val_loss: 32.8159\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.2933 - val_loss: 33.0347\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.2903 - val_loss: 34.2517\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.0560 - val_loss: 32.7836\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 31.0664 - val_loss: 32.1548\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.3560 - val_loss: 32.1137\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.5200 - val_loss: 31.8495\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 31.4352 - val_loss: 32.7019\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.4889 - val_loss: 31.6364\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.4799 - val_loss: 34.6698\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.7821 - val_loss: 32.9426\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 29.8970 - val_loss: 31.1064\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 29.4117 - val_loss: 30.6911\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.7591 - val_loss: 33.0804\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.6806 - val_loss: 30.0627\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.2255 - val_loss: 29.7115\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.4953 - val_loss: 30.4176\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.2832 - val_loss: 29.3393\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 598us/step - loss: 28.6608 - val_loss: 30.0255\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 549us/step - loss: 27.6269 - val_loss: 29.2145\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 27.6949 - val_loss: 29.2978\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.4220 - val_loss: 28.3172\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 27.1026 - val_loss: 30.2872\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 26.8307 - val_loss: 27.2353\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 25.4396 - val_loss: 26.2359\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 553us/step - loss: 25.1054 - val_loss: 25.7967\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 24.7409 - val_loss: 26.4314\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.4348 - val_loss: 26.3015\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 25.1473 - val_loss: 25.6726\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 24.0217 - val_loss: 24.9090\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 23.8025 - val_loss: 24.6733\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 23.7451 - val_loss: 24.5300\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 23.6631 - val_loss: 24.3106\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.5001 - val_loss: 24.4488\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.3570 - val_loss: 24.0967\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 23.1725 - val_loss: 24.0430\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.9753 - val_loss: 23.9501\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 23.1157 - val_loss: 24.0674\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 23.0758 - val_loss: 23.7831\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 22.8420 - val_loss: 23.8249\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.7209 - val_loss: 23.6166\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 762us/step - loss: 22.6300 - val_loss: 23.5707\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.5162 - val_loss: 23.7572\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.4712 - val_loss: 23.4362\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.3710 - val_loss: 23.3402\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.3133 - val_loss: 23.3036\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.2245 - val_loss: 23.2656\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.1691 - val_loss: 23.2530\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.3034 - val_loss: 23.2285\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.1700 - val_loss: 23.1991\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.0322 - val_loss: 23.1463\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.9157 - val_loss: 23.0428\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8115 - val_loss: 23.0091\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.9037 - val_loss: 23.1071\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.8072 - val_loss: 23.0121\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.9075 - val_loss: 23.3994\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8865 - val_loss: 22.9934\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.6252 - val_loss: 22.8934\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.6006 - val_loss: 23.1081\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.5694 - val_loss: 23.1120\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.5914 - val_loss: 22.8470\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.5405 - val_loss: 23.9855\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.9992 - val_loss: 23.3761\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.6311 - val_loss: 22.8100\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.4686 - val_loss: 22.9859\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.3761 - val_loss: 22.7928\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.2284 - val_loss: 22.6461\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.2444 - val_loss: 22.7291\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.2570 - val_loss: 22.6671\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.3253 - val_loss: 22.6396\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1479 - val_loss: 22.7269\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.2069 - val_loss: 22.6623\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0544 - val_loss: 22.6196\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.0043 - val_loss: 22.8656\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0061 - val_loss: 22.5708\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.6009 - val_loss: 50.6231\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 47.1703 - val_loss: 43.0507\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 43.9914 - val_loss: 42.2070\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.4986 - val_loss: 40.2397\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 41.6544 - val_loss: 43.9291\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.8946 - val_loss: 39.8702\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 40.3707 - val_loss: 39.4654\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.6441 - val_loss: 39.6935\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 38.8748 - val_loss: 40.4642\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.8791 - val_loss: 39.1417\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.2962 - val_loss: 37.3867\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.0486 - val_loss: 36.6803\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.2707 - val_loss: 40.9976\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.0934 - val_loss: 37.1386\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.2776 - val_loss: 38.6386\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.1682 - val_loss: 39.0358\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.4859 - val_loss: 40.1922\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.1599 - val_loss: 49.8399\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 51.2867 - val_loss: 45.0015\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 46.8742 - val_loss: 46.0189\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 565us/step - loss: 44.6102 - val_loss: 42.0669\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.6479 - val_loss: 40.3560\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 42.2587 - val_loss: 41.1348\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 42.7223 - val_loss: 40.0716\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 42.1605 - val_loss: 42.5020\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.4521 - val_loss: 40.5348\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.6041 - val_loss: 38.5697\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 40.0373 - val_loss: 39.9688\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.0765 - val_loss: 36.8263\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.9329 - val_loss: 36.4727\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.8679 - val_loss: 45.3998\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 41.5410 - val_loss: 40.0991\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.2320 - val_loss: 41.2712\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 40.1829 - val_loss: 38.1919\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.7168 - val_loss: 35.7392\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.0827 - val_loss: 35.3898\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.0942 - val_loss: 37.6441\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.0214 - val_loss: 34.7021\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.7494 - val_loss: 35.9355\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.8064 - val_loss: 36.5723\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.3021 - val_loss: 33.4996\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.9133 - val_loss: 37.2341\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.9583 - val_loss: 33.6323\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.3923 - val_loss: 33.0405\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.5862 - val_loss: 33.6068\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.5549 - val_loss: 32.4016\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.7200 - val_loss: 34.6057\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.2346 - val_loss: 36.1708\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.1842 - val_loss: 35.6085\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.9029 - val_loss: 34.0734\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.5674 - val_loss: 31.3724\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.2802 - val_loss: 30.5835\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.8839 - val_loss: 35.9447\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 31.9716 - val_loss: 30.0609\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.5647 - val_loss: 29.8131\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.4957 - val_loss: 29.1197\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.2991 - val_loss: 29.9570\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.0365 - val_loss: 27.9790\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.5055 - val_loss: 27.3009\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 26.4534 - val_loss: 26.0465\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.0897 - val_loss: 26.4339\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.1544 - val_loss: 25.5249\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.7874 - val_loss: 24.7427\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.2743 - val_loss: 24.6178\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.8990 - val_loss: 24.3686\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.7208 - val_loss: 24.2119\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.5259 - val_loss: 23.8645\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.3907 - val_loss: 24.2695\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.0644 - val_loss: 23.5136\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.7812 - val_loss: 23.6646\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.6805 - val_loss: 23.3340\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 22.5931 - val_loss: 23.1289\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.4790 - val_loss: 23.0914\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.4413 - val_loss: 23.0552\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.2818 - val_loss: 23.1895\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.2603 - val_loss: 22.8068\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.1376 - val_loss: 22.7533\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.0500 - val_loss: 22.6344\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.8346 - val_loss: 22.7202\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.7473 - val_loss: 22.7773\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7451 - val_loss: 22.5817\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.6658 - val_loss: 22.3608\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.5797 - val_loss: 22.3373\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.4766 - val_loss: 22.4859\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.5460 - val_loss: 23.1999\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.7483 - val_loss: 22.5798\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4737 - val_loss: 22.7635\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.2718 - val_loss: 22.1932\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1960 - val_loss: 22.2510\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1790 - val_loss: 22.1552\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0902 - val_loss: 22.0456\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1933 - val_loss: 22.1064\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.9972 - val_loss: 22.3650\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.9750 - val_loss: 22.2485\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.2013 - val_loss: 22.0255\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.9449 - val_loss: 22.1634\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 601us/step - loss: 20.8948 - val_loss: 21.9928\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 20.8705 - val_loss: 22.0992\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.7361 - val_loss: 22.0598\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 20.8604 - val_loss: 21.8021\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 20.5782 - val_loss: 21.8086\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.6069 - val_loss: 21.8337\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.5881 - val_loss: 21.8989\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.4724 - val_loss: 21.9578\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.4598 - val_loss: 21.9266\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.0203 - val_loss: 45.4664\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 45.2100 - val_loss: 41.8262\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.3188 - val_loss: 39.2987\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.6644 - val_loss: 38.2705\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.1540 - val_loss: 38.3427\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.3164 - val_loss: 38.2010\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.6923 - val_loss: 39.8054\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.8044 - val_loss: 37.0207\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 37.6072 - val_loss: 39.6648\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.1073 - val_loss: 46.1236\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 37.3238 - val_loss: 37.0909\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.9149 - val_loss: 35.5894\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 36.4140 - val_loss: 38.0114\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.7001 - val_loss: 35.1621\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.4066 - val_loss: 34.3874\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.7247 - val_loss: 34.5985\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.7592 - val_loss: 34.8039\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.7402 - val_loss: 35.2145\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.4602 - val_loss: 34.8195\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.7639 - val_loss: 33.5629\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.4559 - val_loss: 33.4580\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.5551 - val_loss: 34.6059\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.1554 - val_loss: 33.6760\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.5185 - val_loss: 33.3230\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.6844 - val_loss: 32.5570\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.7788 - val_loss: 32.8498\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.2485 - val_loss: 32.5831\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.0246 - val_loss: 32.7947\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.3174 - val_loss: 33.0383\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.0436 - val_loss: 31.8373\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.6366 - val_loss: 35.0987\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.7463 - val_loss: 31.9329\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.9876 - val_loss: 34.0334\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.2549 - val_loss: 33.7697\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 32.8393 - val_loss: 33.2442\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 60.7615 - val_loss: 49.9015\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 46.5045 - val_loss: 42.3049\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 42.5974 - val_loss: 41.0228\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.2807 - val_loss: 41.0477\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.6468 - val_loss: 40.1981\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.5258 - val_loss: 42.9951\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.7630 - val_loss: 37.9405\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.1632 - val_loss: 37.2275\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.0780 - val_loss: 36.5209\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.0948 - val_loss: 37.8343\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.6697 - val_loss: 37.5107\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.9029 - val_loss: 36.4272\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.9899 - val_loss: 38.1277\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.6705 - val_loss: 39.6787\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.8967 - val_loss: 34.6667\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.6753 - val_loss: 37.9063\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.7165 - val_loss: 37.6098\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.4175 - val_loss: 34.7656\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.5993 - val_loss: 32.9883\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 33.3988 - val_loss: 33.9719\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.1509 - val_loss: 33.2208\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.5630 - val_loss: 33.0702\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.2692 - val_loss: 36.2718\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.0898 - val_loss: 33.3807\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 84.4257 - val_loss: 49.8140\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 48.6061 - val_loss: 44.9187\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 42.9088 - val_loss: 41.4462\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 41.8246 - val_loss: 40.8913\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 691us/step - loss: 40.2061 - val_loss: 40.3674\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 743us/step - loss: 39.9607 - val_loss: 39.0989\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 40.5683 - val_loss: 37.9113\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 39.0173 - val_loss: 38.2691\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 37.5223 - val_loss: 38.5344\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 37.7284 - val_loss: 37.1391\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 37.5412 - val_loss: 36.7872\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 36.4194 - val_loss: 38.6939\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 38.1551 - val_loss: 38.9933\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 36.8867 - val_loss: 36.9633\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 35.9980 - val_loss: 35.4897\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 37.6917 - val_loss: 37.1478\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.2658 - val_loss: 37.1948\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.9543 - val_loss: 36.1058\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 34.3359 - val_loss: 33.9720\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 34.0358 - val_loss: 34.5458\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.8993 - val_loss: 33.8841\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.2949 - val_loss: 33.6502\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 34.1729 - val_loss: 38.5106\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.8694 - val_loss: 34.0928\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.8782 - val_loss: 32.9039\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 32.5705 - val_loss: 32.2860\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.8172 - val_loss: 33.7797\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 32.6372 - val_loss: 35.9455\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 32.8870 - val_loss: 38.2456\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.3215 - val_loss: 34.6387\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.3315 - val_loss: 34.7454\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.1228 - val_loss: 46.4035\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 45.4879 - val_loss: 43.8621\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 42.8650 - val_loss: 41.3031\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 40.7499 - val_loss: 40.4702\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 40.4163 - val_loss: 39.2920\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 42.0349 - val_loss: 44.3052\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 40.0253 - val_loss: 40.0354\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 40.4432 - val_loss: 39.2930\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.5730 - val_loss: 38.6091\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.5632 - val_loss: 38.3351\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.4961 - val_loss: 37.8603\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.6730 - val_loss: 38.2488\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.7424 - val_loss: 37.1774\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.6862 - val_loss: 39.2905\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.9752 - val_loss: 35.9215\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.0612 - val_loss: 35.6223\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.0523 - val_loss: 39.4821\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.9995 - val_loss: 34.9525\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.3773 - val_loss: 34.9368\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.9710 - val_loss: 36.1236\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.5764 - val_loss: 35.2798\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.3015 - val_loss: 34.5758\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.5451 - val_loss: 43.0331\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.3207 - val_loss: 35.5208\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.7525 - val_loss: 34.0913\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.8193 - val_loss: 32.8493\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.1717 - val_loss: 35.2180\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.4799 - val_loss: 35.8888\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.5020 - val_loss: 32.4508\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.8731 - val_loss: 31.5810\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.3471 - val_loss: 33.7931\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 32.4876 - val_loss: 31.4210\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.8562 - val_loss: 31.9801\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.0716 - val_loss: 30.7042\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.5069 - val_loss: 31.1808\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.0347 - val_loss: 29.8739\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.0759 - val_loss: 33.6178\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 29.8852 - val_loss: 32.1993\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.0176 - val_loss: 28.8923\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.2086 - val_loss: 27.6867\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.1106 - val_loss: 27.7242\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 26.7511 - val_loss: 27.1695\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.5082 - val_loss: 25.8991\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.2050 - val_loss: 25.5804\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.7732 - val_loss: 25.1741\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.3596 - val_loss: 25.4306\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.4155 - val_loss: 24.4396\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.8530 - val_loss: 24.4063\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.7548 - val_loss: 23.9901\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.9729 - val_loss: 23.9023\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.3029 - val_loss: 23.7895\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.2673 - val_loss: 23.6709\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.0874 - val_loss: 23.4849\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.8659 - val_loss: 23.5318\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 605us/step - loss: 22.7422 - val_loss: 23.3512\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.6241 - val_loss: 23.2844\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.6233 - val_loss: 23.3816\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4930 - val_loss: 23.1507\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.3520 - val_loss: 23.0867\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.2119 - val_loss: 23.4762\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.1963 - val_loss: 23.1398\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.0896 - val_loss: 22.9831\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.9905 - val_loss: 22.8701\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.8492 - val_loss: 22.8296\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.8320 - val_loss: 22.9800\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7288 - val_loss: 22.8497\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.8259 - val_loss: 22.6855\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.5782 - val_loss: 22.7664\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.5606 - val_loss: 22.7814\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.4209 - val_loss: 22.8982\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3772 - val_loss: 23.1521\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.4405 - val_loss: 22.4994\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.2911 - val_loss: 22.6561\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.2376 - val_loss: 22.6066\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.1284 - val_loss: 22.4775\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.9430 - val_loss: 22.4209\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.0651 - val_loss: 22.5423\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.8101 - val_loss: 22.4069\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.8324 - val_loss: 22.6163\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.7545 - val_loss: 23.0387\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.7114 - val_loss: 22.3258\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6745 - val_loss: 23.1672\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6818 - val_loss: 22.3538\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.4194 - val_loss: 22.3173\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.4352 - val_loss: 22.4553\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.4367 - val_loss: 22.3759\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.1938 - val_loss: 22.2455\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.1446 - val_loss: 22.3570\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.2211 - val_loss: 22.2790\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.2062 - val_loss: 22.4161\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 19.9252 - val_loss: 22.3868\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 20.0715 - val_loss: 22.4394\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.6183 - val_loss: 52.5188\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 45.7482 - val_loss: 44.4348\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 44.5587 - val_loss: 42.7130\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.6893 - val_loss: 41.4695\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.7897 - val_loss: 47.1727\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.5038 - val_loss: 41.9420\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.3740 - val_loss: 42.5194\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 39.6666 - val_loss: 39.9671\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.9078 - val_loss: 42.7140\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.4847 - val_loss: 39.5011\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 39.2297 - val_loss: 39.0620\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.5185 - val_loss: 40.0066\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.2499 - val_loss: 38.5028\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.9981 - val_loss: 38.2020\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.4335 - val_loss: 41.0493\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.2725 - val_loss: 36.9597\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.5093 - val_loss: 38.2083\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.9482 - val_loss: 37.9858\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.9438 - val_loss: 36.3644\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.4107 - val_loss: 36.1682\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.6216 - val_loss: 35.6630\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.4322 - val_loss: 36.9519\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.5606 - val_loss: 35.5620\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.0873 - val_loss: 35.6345\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.8377 - val_loss: 36.8807\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.3233 - val_loss: 35.2381\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.6520 - val_loss: 36.0846\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 35.1960 - val_loss: 42.0709\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.0524 - val_loss: 35.6819\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.0702 - val_loss: 36.8179\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.1773 - val_loss: 33.8830\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.0104 - val_loss: 33.6418\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.9577 - val_loss: 33.3686\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.9628 - val_loss: 35.9002\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.7776 - val_loss: 33.2153\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.5443 - val_loss: 38.1200\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.2926 - val_loss: 33.2792\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 30.5766 - val_loss: 31.9985\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.9057 - val_loss: 32.5342\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 624us/step - loss: 30.4887 - val_loss: 32.4096\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 31.6317 - val_loss: 35.0904\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.1440 - val_loss: 34.8131\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.4692 - val_loss: 32.6561\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.8756 - val_loss: 53.2704\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 47.7051 - val_loss: 48.2571\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 43.6727 - val_loss: 41.7013\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 41.6988 - val_loss: 41.3824\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 41.9595 - val_loss: 39.9183\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 43.0452 - val_loss: 39.8288\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 40.5596 - val_loss: 43.1789\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 40.8120 - val_loss: 39.6170\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.7383 - val_loss: 39.7803\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 38.2186 - val_loss: 37.4742\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 37.7038 - val_loss: 42.9655\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.9546 - val_loss: 40.8216\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.9256 - val_loss: 36.3272\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.7831 - val_loss: 37.2781\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.9827 - val_loss: 35.7373\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.3296 - val_loss: 37.8325\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.7991 - val_loss: 35.2415\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.9893 - val_loss: 34.1157\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.5050 - val_loss: 34.6068\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.4412 - val_loss: 33.5446\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.2345 - val_loss: 33.4316\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.6842 - val_loss: 32.8231\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.6551 - val_loss: 32.9147\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.2307 - val_loss: 34.6025\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 33.0464 - val_loss: 32.4003\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.9115 - val_loss: 31.8275\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.1037 - val_loss: 34.6320\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.3297 - val_loss: 31.6580\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.2140 - val_loss: 34.0613\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.0758 - val_loss: 31.3800\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.7710 - val_loss: 31.4913\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.0104 - val_loss: 32.2945\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.6178 - val_loss: 31.3671\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 30.5293 - val_loss: 30.3176\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.2124 - val_loss: 31.1474\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.4402 - val_loss: 31.0016\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.9945 - val_loss: 29.9874\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.4129 - val_loss: 30.1262\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.9420 - val_loss: 30.8781\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.5499 - val_loss: 31.5601\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.3595 - val_loss: 29.2477\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.0242 - val_loss: 30.4722\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 28.1546 - val_loss: 29.1290\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.0470 - val_loss: 29.9248\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.7274 - val_loss: 29.0622\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.7385 - val_loss: 29.2427\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.8704 - val_loss: 28.8292\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.3527 - val_loss: 32.9237\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.3923 - val_loss: 29.1656\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 26.9259 - val_loss: 27.7087\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.7163 - val_loss: 26.5464\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.8224 - val_loss: 26.8923\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.4671 - val_loss: 27.0651\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 25.7251 - val_loss: 25.9924\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.5558 - val_loss: 25.4548\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.1899 - val_loss: 25.2819\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.0206 - val_loss: 24.8055\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.5522 - val_loss: 24.5273\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 23.3965 - val_loss: 24.2176\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.1489 - val_loss: 23.9345\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 22.9106 - val_loss: 23.8726\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.6876 - val_loss: 24.1152\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.6622 - val_loss: 23.6814\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.4995 - val_loss: 23.5481\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.4322 - val_loss: 23.6842\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 22.2494 - val_loss: 23.4273\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.1234 - val_loss: 23.3546\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.1219 - val_loss: 23.2133\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.1865 - val_loss: 23.1220\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.8655 - val_loss: 23.0152\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.8164 - val_loss: 23.2308\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.9780 - val_loss: 23.3574\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8271 - val_loss: 23.0395\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 626us/step - loss: 21.7025 - val_loss: 22.9048\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.5537 - val_loss: 22.9505\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.4419 - val_loss: 22.7773\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.5076 - val_loss: 22.8425\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3585 - val_loss: 22.6697\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.1434 - val_loss: 22.6972\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.0477 - val_loss: 22.5700\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0047 - val_loss: 22.5656\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.9065 - val_loss: 22.4969\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.8572 - val_loss: 22.5065\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.8443 - val_loss: 22.4927\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.8099 - val_loss: 22.4616\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.8329 - val_loss: 22.3837\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.6547 - val_loss: 22.4489\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.7507 - val_loss: 22.4348\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.6522 - val_loss: 22.5278\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.7376 - val_loss: 22.5419\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 20.8694 - val_loss: 22.8283\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 86.5143 - val_loss: 52.8823\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 48.6328 - val_loss: 43.9209\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 45.0088 - val_loss: 42.6507\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 42.4925 - val_loss: 39.4729\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 40.7403 - val_loss: 38.8283\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.4078 - val_loss: 37.8195\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.3515 - val_loss: 37.3434\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.9888 - val_loss: 37.4651\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.1266 - val_loss: 40.1005\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.3949 - val_loss: 36.8755\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.1768 - val_loss: 35.8851\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.7998 - val_loss: 35.7549\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.2763 - val_loss: 35.0445\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 35.5803 - val_loss: 40.0299\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.7161 - val_loss: 34.1028\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.1876 - val_loss: 37.4365\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.2998 - val_loss: 34.7946\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.2673 - val_loss: 33.7814\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 34.2789 - val_loss: 36.0429\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.0624 - val_loss: 33.8063\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.3896 - val_loss: 32.8120\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.6200 - val_loss: 32.8253\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.6251 - val_loss: 37.6116\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.3254 - val_loss: 33.4968\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.1635 - val_loss: 32.5421\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.4984 - val_loss: 33.6854\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 33.4996 - val_loss: 32.0565\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.0683 - val_loss: 31.5271\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.9769 - val_loss: 31.3688\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.1413 - val_loss: 36.3189\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.7540 - val_loss: 32.0069\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.2791 - val_loss: 32.2658\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.3153 - val_loss: 30.7393\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.1554 - val_loss: 30.6561\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.0026 - val_loss: 33.7425\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.8504 - val_loss: 30.4885\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.5053 - val_loss: 33.6358\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.2674 - val_loss: 30.0805\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.5660 - val_loss: 31.1138\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.6707 - val_loss: 29.4917\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.0858 - val_loss: 29.5017\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 28.6773 - val_loss: 28.8674\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.5752 - val_loss: 29.9588\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 29.5569 - val_loss: 29.1460\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.9527 - val_loss: 28.8033\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.2033 - val_loss: 28.2776\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.8461 - val_loss: 30.0280\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.7027 - val_loss: 28.4663\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.2704 - val_loss: 27.3367\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 26.3835 - val_loss: 27.4482\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.0315 - val_loss: 27.2414\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 25.8347 - val_loss: 27.4128\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 26.0916 - val_loss: 26.1027\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.0159 - val_loss: 25.4826\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.5176 - val_loss: 25.3026\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 24.8695 - val_loss: 26.2737\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.5678 - val_loss: 25.8561\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.9869 - val_loss: 25.0737\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.9423 - val_loss: 24.6921\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 605us/step - loss: 24.0319 - val_loss: 25.0247\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.5417 - val_loss: 24.3932\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.3599 - val_loss: 24.2405\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 23.1905 - val_loss: 24.1807\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.2109 - val_loss: 24.7106\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.9386 - val_loss: 24.0235\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.9307 - val_loss: 23.9179\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.7193 - val_loss: 24.0246\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.5900 - val_loss: 23.9384\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.5988 - val_loss: 23.6665\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3875 - val_loss: 23.7711\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.4289 - val_loss: 23.6283\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.2199 - val_loss: 23.9552\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.2140 - val_loss: 23.4598\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 22.0479 - val_loss: 23.3714\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.9724 - val_loss: 23.3234\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8548 - val_loss: 23.2529\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.2408 - val_loss: 24.4527\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3102 - val_loss: 23.3440\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.9790 - val_loss: 23.7157\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8523 - val_loss: 23.3764\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.6411 - val_loss: 23.0408\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6549 - val_loss: 23.6292\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7645 - val_loss: 23.0198\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.5272 - val_loss: 23.0051\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3472 - val_loss: 22.9644\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2067 - val_loss: 22.9268\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1228 - val_loss: 22.8498\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.1801 - val_loss: 22.9139\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1008 - val_loss: 22.9054\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1030 - val_loss: 22.9525\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.3280 - val_loss: 22.9459\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.2033 - val_loss: 22.9376\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.0501 - val_loss: 46.1030\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 44.0894 - val_loss: 40.4659\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 40.9396 - val_loss: 38.7632\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 40.5367 - val_loss: 41.4010\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.3795 - val_loss: 36.9227\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.5974 - val_loss: 35.7100\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.9868 - val_loss: 35.7289\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.2146 - val_loss: 36.4422\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.2386 - val_loss: 35.5968\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.9977 - val_loss: 34.2386\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.6376 - val_loss: 37.6898\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 36.5872 - val_loss: 35.1998\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.4581 - val_loss: 34.0039\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.6076 - val_loss: 35.0100\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.1476 - val_loss: 34.9799\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8145 - val_loss: 33.1018\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.7328 - val_loss: 32.9248\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 33.3772 - val_loss: 32.8374\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.0204 - val_loss: 32.8247\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.7542 - val_loss: 31.9824\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.7850 - val_loss: 32.0031\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.7289 - val_loss: 32.7072\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.9708 - val_loss: 33.9148\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.6500 - val_loss: 32.3092\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.4442 - val_loss: 31.0099\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.5881 - val_loss: 31.1968\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 31.4899 - val_loss: 30.9942\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.0563 - val_loss: 30.2800\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.6591 - val_loss: 33.9277\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.9923 - val_loss: 32.2763\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.0209 - val_loss: 30.8493\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.9286 - val_loss: 34.0787\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.6424 - val_loss: 30.1758\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.9838 - val_loss: 29.4563\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.9132 - val_loss: 28.6425\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.5459 - val_loss: 28.4194\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 27.8983 - val_loss: 28.2238\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.8774 - val_loss: 27.1701\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 26.8154 - val_loss: 26.5353\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.6429 - val_loss: 27.6211\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.9262 - val_loss: 25.7322\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.0027 - val_loss: 25.5832\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 25.0659 - val_loss: 25.4866\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.5633 - val_loss: 24.5990\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 633us/step - loss: 24.3277 - val_loss: 25.0418\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.0549 - val_loss: 25.7440\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 24.3136 - val_loss: 24.6558\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.1892 - val_loss: 24.1026\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.6621 - val_loss: 23.7826\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.5324 - val_loss: 23.5949\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.3776 - val_loss: 23.6420\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.1799 - val_loss: 23.3789\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.9613 - val_loss: 23.3126\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.8487 - val_loss: 23.1345\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.8680 - val_loss: 23.2127\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.7476 - val_loss: 23.1072\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.7217 - val_loss: 22.9688\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.7434 - val_loss: 22.8652\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.7342 - val_loss: 22.8264\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.2943 - val_loss: 23.4988\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.3772 - val_loss: 22.6628\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.4067 - val_loss: 22.9965\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.2684 - val_loss: 22.5236\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 726us/step - loss: 21.9944 - val_loss: 22.4900\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 764us/step - loss: 21.8825 - val_loss: 22.4296\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 787us/step - loss: 21.8543 - val_loss: 22.4950\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.8765 - val_loss: 22.3755\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.1687 - val_loss: 22.4981\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.9892 - val_loss: 22.3053\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7107 - val_loss: 22.3851\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6507 - val_loss: 22.2703\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.5697 - val_loss: 22.2181\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.5702 - val_loss: 22.1887\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.4179 - val_loss: 22.1278\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 21.4797 - val_loss: 22.2042\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.5700 - val_loss: 22.4157\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.6204 - val_loss: 22.3957\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.5479 - val_loss: 22.0862\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 21.2380 - val_loss: 22.1053\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 531us/step - loss: 21.2964 - val_loss: 22.0859\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 304us/step - loss: 21.3147 - val_loss: 22.0161\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 310us/step - loss: 21.0995 - val_loss: 21.9165\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 449us/step - loss: 21.0676 - val_loss: 22.7659\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.1233 - val_loss: 21.8977\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 561us/step - loss: 21.1013 - val_loss: 22.3260\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.0095 - val_loss: 22.1159\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 560us/step - loss: 20.9664 - val_loss: 21.9239\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 545us/step - loss: 20.8702 - val_loss: 22.0963\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 537us/step - loss: 21.0747 - val_loss: 22.2144\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.0507 - val_loss: 47.2033\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 44.6108 - val_loss: 42.4004\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 42.0239 - val_loss: 40.3427\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 39.8305 - val_loss: 39.6303\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 38.8582 - val_loss: 40.1697\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 38.8709 - val_loss: 37.5626\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 36.8049 - val_loss: 37.8493\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 37.4474 - val_loss: 36.6355\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 36.7829 - val_loss: 36.2562\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 37.4848 - val_loss: 36.7046\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 35.9743 - val_loss: 35.6794\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 35.1384 - val_loss: 35.3277\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 35.3487 - val_loss: 36.0504\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 34.1175 - val_loss: 36.3252\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 33.7664 - val_loss: 34.2110\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 34.0335 - val_loss: 41.0718\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 35.5469 - val_loss: 34.0157\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 34.5173 - val_loss: 34.3146\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 32.7919 - val_loss: 35.1490\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.3933 - val_loss: 33.2985\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.6663 - val_loss: 33.1784\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 32.1211 - val_loss: 33.8731\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 32.2654 - val_loss: 33.8622\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 31.2182 - val_loss: 32.9562\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 31.2094 - val_loss: 31.9325\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 31.1737 - val_loss: 31.5395\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 30.7292 - val_loss: 32.5972\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 30.0955 - val_loss: 31.7950\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 30.7679 - val_loss: 32.4520\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 31.5914 - val_loss: 31.8298\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 30.5791 - val_loss: 30.6632\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.3951 - val_loss: 30.4009\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 956us/step - loss: 29.8427 - val_loss: 30.3060\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 29.7625 - val_loss: 31.4567\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 873us/step - loss: 28.8310 - val_loss: 30.3687\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 872us/step - loss: 28.7373 - val_loss: 29.8214\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 792us/step - loss: 28.9045 - val_loss: 29.6981\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.7276 - val_loss: 29.8675\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 28.7755 - val_loss: 29.2634\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.8886 - val_loss: 34.0032\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.4148 - val_loss: 29.7528\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 27.9303 - val_loss: 29.2897\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.8144 - val_loss: 28.5508\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.4398 - val_loss: 32.1224\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.2851 - val_loss: 28.6558\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.6013 - val_loss: 27.9278\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.3848 - val_loss: 27.7731\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 26.3807 - val_loss: 27.9388\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.6454 - val_loss: 27.9255\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.7909 - val_loss: 27.8183\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 25.7230 - val_loss: 27.1173\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.2358 - val_loss: 26.6339\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 25.4148 - val_loss: 26.3232\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.6115 - val_loss: 26.9672\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.2127 - val_loss: 25.5677\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.6914 - val_loss: 26.1443\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 24.2590 - val_loss: 24.8143\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.5806 - val_loss: 24.4723\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.2750 - val_loss: 24.3481\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.0938 - val_loss: 23.9755\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.8642 - val_loss: 24.6483\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.6712 - val_loss: 24.4506\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.7420 - val_loss: 24.4364\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3647 - val_loss: 23.6636\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.2179 - val_loss: 23.9494\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.2171 - val_loss: 23.1481\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.1093 - val_loss: 23.8032\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.8688 - val_loss: 22.9965\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.6760 - val_loss: 23.0188\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 21.6896 - val_loss: 22.8571\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 21.5304 - val_loss: 23.0602\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.6465 - val_loss: 22.8256\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.5869 - val_loss: 22.8182\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.2477 - val_loss: 22.6189\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2906 - val_loss: 22.6957\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 21.5004 - val_loss: 24.0838\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.6974 - val_loss: 22.7350\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.0776 - val_loss: 22.8553\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.8996 - val_loss: 22.4134\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.9971 - val_loss: 22.5875\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.8216 - val_loss: 22.4182\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.7976 - val_loss: 22.3211\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.8126 - val_loss: 22.4039\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.8969 - val_loss: 22.2771\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.6732 - val_loss: 22.3544\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.8080 - val_loss: 22.6970\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.5365 - val_loss: 22.1592\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.4941 - val_loss: 22.1689\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.4562 - val_loss: 22.6267\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.4085 - val_loss: 22.1665\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.4721 - val_loss: 22.3134\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.7331 - val_loss: 22.3528\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.4706 - val_loss: 47.4520\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 44.8978 - val_loss: 45.2529\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 41.9644 - val_loss: 41.8991\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.9970 - val_loss: 43.3716\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 41.9509 - val_loss: 38.9332\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.0576 - val_loss: 37.5933\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.4512 - val_loss: 41.6250\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.3730 - val_loss: 37.5847\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.9115 - val_loss: 36.3440\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.9539 - val_loss: 35.8968\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.0349 - val_loss: 38.0513\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.5203 - val_loss: 35.8163\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.8912 - val_loss: 35.3283\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.6039 - val_loss: 34.5782\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.3588 - val_loss: 35.0190\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.9921 - val_loss: 35.3646\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.6157 - val_loss: 38.2817\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 616us/step - loss: 34.2916 - val_loss: 33.6903\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.3172 - val_loss: 33.2524\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.0768 - val_loss: 33.1166\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.1569 - val_loss: 33.2980\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.5714 - val_loss: 35.0353\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.2312 - val_loss: 42.0093\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.8772 - val_loss: 33.4782\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.9364 - val_loss: 32.2033\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 31.9152 - val_loss: 35.0066\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.7987 - val_loss: 32.2815\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.5371 - val_loss: 34.6360\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.3446 - val_loss: 32.2410\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.6385 - val_loss: 33.8475\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.9563 - val_loss: 45.9927\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 44.3445 - val_loss: 42.0760\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 42.5263 - val_loss: 41.8802\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.5933 - val_loss: 40.3939\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.4470 - val_loss: 40.9498\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.0554 - val_loss: 38.3616\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.3284 - val_loss: 39.7732\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 38.3997 - val_loss: 38.2390\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 38.5297 - val_loss: 37.5781\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.9053 - val_loss: 37.5538\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.1411 - val_loss: 37.8259\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.1376 - val_loss: 41.3330\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 38.0688 - val_loss: 37.1610\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.2739 - val_loss: 36.0939\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.2197 - val_loss: 36.0599\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.8742 - val_loss: 37.6515\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.8242 - val_loss: 35.1793\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.4817 - val_loss: 36.2028\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.0343 - val_loss: 36.8823\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.1962 - val_loss: 35.5303\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.4412 - val_loss: 34.8017\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.3720 - val_loss: 33.6738\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.8496 - val_loss: 32.8379\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.1960 - val_loss: 33.2171\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.9172 - val_loss: 32.2392\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.4855 - val_loss: 33.8623\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.7885 - val_loss: 32.4688\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.5645 - val_loss: 34.4931\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.8706 - val_loss: 31.7561\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.1420 - val_loss: 32.8169\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.7082 - val_loss: 31.2170\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.0053 - val_loss: 33.2536\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 30.4226 - val_loss: 32.1769\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.4920 - val_loss: 34.2218\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.1853 - val_loss: 30.9445\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.3382 - val_loss: 35.0847\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.3226 - val_loss: 31.4105\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.0652 - val_loss: 31.2432\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.2468 - val_loss: 31.5255\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 30.4589 - val_loss: 30.2828\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.3117 - val_loss: 32.2695\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.1639 - val_loss: 31.3477\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.8407 - val_loss: 31.2310\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.8128 - val_loss: 29.6670\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.0007 - val_loss: 31.3607\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.8480 - val_loss: 29.9432\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.6944 - val_loss: 33.2837\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.8064 - val_loss: 31.2463\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.7399 - val_loss: 29.3342\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.0105 - val_loss: 29.5209\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.0085 - val_loss: 28.7702\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.5953 - val_loss: 29.9320\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 28.0068 - val_loss: 29.6288\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 778us/step - loss: 27.8681 - val_loss: 29.3064\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 809us/step - loss: 27.3575 - val_loss: 28.8077\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 27.0443 - val_loss: 29.7498\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.8349 - val_loss: 47.1017\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 43.0749 - val_loss: 42.1843\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.1012 - val_loss: 40.1478\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 38.5758 - val_loss: 39.1157\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.3866 - val_loss: 39.1154\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 37.6204 - val_loss: 38.5723\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.5774 - val_loss: 38.3416\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.7795 - val_loss: 38.1145\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.2684 - val_loss: 37.3793\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.2672 - val_loss: 37.1177\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.1625 - val_loss: 37.1996\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 35.5169 - val_loss: 36.7656\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.4957 - val_loss: 36.6076\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.5909 - val_loss: 36.8463\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.9807 - val_loss: 40.9225\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.6591 - val_loss: 35.2327\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.3096 - val_loss: 35.0165\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.5282 - val_loss: 35.8389\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.5192 - val_loss: 35.5954\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.7638 - val_loss: 33.9715\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.5362 - val_loss: 34.0115\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.2450 - val_loss: 37.1607\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.6287 - val_loss: 34.7807\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.8340 - val_loss: 33.4413\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.3041 - val_loss: 33.4342\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.3224 - val_loss: 38.9331\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8394 - val_loss: 34.1514\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 31.1777 - val_loss: 32.7694\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.8785 - val_loss: 33.3304\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.3393 - val_loss: 36.0854\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.0965 - val_loss: 33.2388\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.0250 - val_loss: 32.8612\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 30.3243 - val_loss: 32.3997\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.8092 - val_loss: 32.1429\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.6996 - val_loss: 32.2126\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.5629 - val_loss: 32.5623\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.0083 - val_loss: 33.4797\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.4299 - val_loss: 31.7862\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.4478 - val_loss: 32.7805\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 29.7175 - val_loss: 32.5313\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.4433 - val_loss: 32.2804\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.6447 - val_loss: 34.6394\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.2901 - val_loss: 31.1804\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.9347 - val_loss: 31.8637\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.3575 - val_loss: 31.0951\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.3410 - val_loss: 31.7332\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.7614 - val_loss: 33.1786\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.9337 - val_loss: 32.7619\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.4591 - val_loss: 31.9825\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.1274 - val_loss: 31.7319\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 79.1631 - val_loss: 48.0070\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 45.2176 - val_loss: 39.2212\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.0247 - val_loss: 36.7593\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.0027 - val_loss: 34.8713\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.3711 - val_loss: 36.1201\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.0765 - val_loss: 33.4575\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.8329 - val_loss: 38.2096\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.4976 - val_loss: 32.8517\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.8090 - val_loss: 34.2200\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.8988 - val_loss: 33.3524\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.7363 - val_loss: 31.7936\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.2276 - val_loss: 33.2412\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.5953 - val_loss: 31.5981\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.3957 - val_loss: 32.9305\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.3690 - val_loss: 31.8775\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.8012 - val_loss: 30.9621\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.0248 - val_loss: 30.5080\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.1208 - val_loss: 30.0656\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.6086 - val_loss: 29.5870\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.0194 - val_loss: 29.6799\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.5675 - val_loss: 29.1099\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.8276 - val_loss: 29.1088\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.7180 - val_loss: 30.4840\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.7219 - val_loss: 30.1647\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.4615 - val_loss: 28.8479\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.7609 - val_loss: 29.0796\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.2311 - val_loss: 29.1535\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.1621 - val_loss: 30.2674\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.7124 - val_loss: 28.6900\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.2171 - val_loss: 28.5602\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.6986 - val_loss: 28.6458\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 28.9348 - val_loss: 28.2336\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.5041 - val_loss: 29.0874\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.1916 - val_loss: 27.7065\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 611us/step - loss: 28.3745 - val_loss: 28.2755\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.7849 - val_loss: 27.3970\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.7592 - val_loss: 27.3339\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.5507 - val_loss: 28.9324\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.0163 - val_loss: 27.5442\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.5420 - val_loss: 26.8071\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 26.7871 - val_loss: 27.0580\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.4088 - val_loss: 28.2860\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.1471 - val_loss: 26.1206\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 26.1134 - val_loss: 26.7697\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 26.2366 - val_loss: 26.7298\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 820us/step - loss: 26.1045 - val_loss: 25.9401\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.7067 - val_loss: 26.2074\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 25.0703 - val_loss: 25.0084\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.5704 - val_loss: 24.9569\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.1537 - val_loss: 24.2660\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.7606 - val_loss: 23.9942\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.5213 - val_loss: 24.0970\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.8065 - val_loss: 23.8183\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.0113 - val_loss: 23.9144\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 23.0856 - val_loss: 23.5588\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.8016 - val_loss: 22.8973\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.4803 - val_loss: 22.9961\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.3008 - val_loss: 22.6515\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.1497 - val_loss: 22.6321\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.1437 - val_loss: 22.3861\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.0236 - val_loss: 22.4894\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9938 - val_loss: 22.3503\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.7141 - val_loss: 22.1328\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 21.5715 - val_loss: 22.1019\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5801 - val_loss: 22.5856\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.7470 - val_loss: 22.0001\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.3784 - val_loss: 21.8773\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.4354 - val_loss: 22.4647\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.6232 - val_loss: 22.1424\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.3410 - val_loss: 22.1370\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1539 - val_loss: 21.8436\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.1251 - val_loss: 21.8599\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.2655 - val_loss: 21.7567\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0118 - val_loss: 21.6391\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9257 - val_loss: 21.4800\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 20.8415 - val_loss: 21.8864\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.0662 - val_loss: 21.8657\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 21.0906 - val_loss: 21.5786\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.7885 - val_loss: 21.3948\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 20.6660 - val_loss: 21.4239\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.7590 - val_loss: 21.4363\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 20.5770 - val_loss: 21.3560\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.6273 - val_loss: 21.3462\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.6172 - val_loss: 21.3181\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.4485 - val_loss: 21.3566\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.4161 - val_loss: 21.2294\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 20.4861 - val_loss: 21.4443\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.5050 - val_loss: 21.3734\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.3778 - val_loss: 21.2441\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.2388 - val_loss: 21.1140\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.3838 - val_loss: 21.4115\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.2536 - val_loss: 21.1514\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.3107 - val_loss: 21.4297\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 20.1530 - val_loss: 21.0453\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 20.1345 - val_loss: 21.3418\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 20.0854 - val_loss: 21.1142\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.0840 - val_loss: 21.1703\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.2473 - val_loss: 21.6875\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 20.1919 - val_loss: 21.0527\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 103.4216 - val_loss: 88.0969\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 75.7103 - val_loss: 49.4028\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 45.4190 - val_loss: 48.8435\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 43.3183 - val_loss: 42.1509\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 40.6896 - val_loss: 42.2601\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 41.9926 - val_loss: 42.5826\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 40.5001 - val_loss: 42.5721\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 40.3116 - val_loss: 39.8478\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 38.1975 - val_loss: 38.8470\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 37.3785 - val_loss: 38.0488\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 38.2232 - val_loss: 38.2019\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.7488 - val_loss: 37.3865\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 617us/step - loss: 37.1379 - val_loss: 37.9345\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 37.3741 - val_loss: 37.2528\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 36.7320 - val_loss: 37.9509\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.3026 - val_loss: 38.8475\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.7795 - val_loss: 38.5752\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 36.3559 - val_loss: 36.5211\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.9118 - val_loss: 36.7939\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.6715 - val_loss: 36.7608\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 34.5849 - val_loss: 35.3713\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.8224 - val_loss: 35.3252\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 33.9246 - val_loss: 34.9892\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.0237 - val_loss: 34.8500\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.3327 - val_loss: 40.4936\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.9469 - val_loss: 34.9449\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.6178 - val_loss: 35.1226\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.6555 - val_loss: 34.2396\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.3835 - val_loss: 35.2473\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.5455 - val_loss: 34.7052\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.1519 - val_loss: 33.6831\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 31.8419 - val_loss: 32.9145\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.6003 - val_loss: 32.6492\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 709us/step - loss: 30.9303 - val_loss: 32.2092\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 693us/step - loss: 30.9559 - val_loss: 31.8632\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 820us/step - loss: 31.3333 - val_loss: 32.6048\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 780us/step - loss: 31.7397 - val_loss: 33.7525\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 30.2737 - val_loss: 34.9466\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.4737 - val_loss: 30.8039\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.2360 - val_loss: 29.8310\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.4565 - val_loss: 30.5970\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.7938 - val_loss: 28.2289\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.1476 - val_loss: 30.3538\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.1886 - val_loss: 27.7022\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 26.2193 - val_loss: 26.1393\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 718us/step - loss: 25.1570 - val_loss: 25.5045\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.8171 - val_loss: 25.0272\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.4383 - val_loss: 24.8572\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.5374 - val_loss: 24.8634\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 23.9696 - val_loss: 24.4231\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.7138 - val_loss: 24.1982\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.5584 - val_loss: 24.1009\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 23.4596 - val_loss: 23.8896\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.2852 - val_loss: 23.9213\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.2431 - val_loss: 23.6710\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.0783 - val_loss: 23.6378\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.9749 - val_loss: 23.4701\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.9593 - val_loss: 23.9348\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.9971 - val_loss: 23.6407\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.7676 - val_loss: 23.3124\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.6160 - val_loss: 23.2417\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.5783 - val_loss: 23.2000\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.4493 - val_loss: 23.2140\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.3400 - val_loss: 23.0439\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 748us/step - loss: 22.4078 - val_loss: 23.1257\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.5786 - val_loss: 23.1254\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.2386 - val_loss: 22.9073\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.1642 - val_loss: 22.9341\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0814 - val_loss: 22.8484\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0510 - val_loss: 22.7915\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.9486 - val_loss: 22.7544\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.8795 - val_loss: 22.7946\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.9639 - val_loss: 23.3452\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9353 - val_loss: 23.0700\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.7805 - val_loss: 22.6830\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.6619 - val_loss: 22.8307\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7087 - val_loss: 22.6795\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6347 - val_loss: 22.8562\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.5882 - val_loss: 22.8927\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.5889 - val_loss: 22.5738\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.6401 - val_loss: 22.8258\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.6632 - val_loss: 23.0950\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.6607 - val_loss: 22.5339\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 721us/step - loss: 21.3150 - val_loss: 22.5904\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.2021 - val_loss: 22.4987\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.2263 - val_loss: 22.8899\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.4500 - val_loss: 22.5976\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1010 - val_loss: 22.5121\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.0589 - val_loss: 22.7666\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.1668 - val_loss: 22.5075\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.8536 - val_loss: 48.4772\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 44.2490 - val_loss: 41.3883\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 40.6461 - val_loss: 39.8027\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 39.4575 - val_loss: 39.0607\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.6227 - val_loss: 37.0811\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 37.6784 - val_loss: 37.3289\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.8052 - val_loss: 36.0830\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.1834 - val_loss: 35.2575\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.6048 - val_loss: 34.8259\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.9032 - val_loss: 35.3584\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.7719 - val_loss: 34.9979\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.6015 - val_loss: 34.2048\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.2846 - val_loss: 35.3868\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.9013 - val_loss: 33.7974\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.7417 - val_loss: 35.9802\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.1541 - val_loss: 40.8167\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 34.0271 - val_loss: 33.1989\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.8908 - val_loss: 35.4012\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.6491 - val_loss: 32.5676\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.9395 - val_loss: 37.3917\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.1933 - val_loss: 32.7444\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 35.2936 - val_loss: 34.7633\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.8610 - val_loss: 33.5144\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.9515 - val_loss: 32.4754\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.7186 - val_loss: 31.4299\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.7156 - val_loss: 38.3390\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.0372 - val_loss: 32.9065\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.6527 - val_loss: 31.2301\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.8077 - val_loss: 30.7224\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.1808 - val_loss: 30.5714\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.2140 - val_loss: 31.1433\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.6376 - val_loss: 30.5557\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.4578 - val_loss: 34.2865\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.2352 - val_loss: 30.5756\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.3024 - val_loss: 32.8408\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.6485 - val_loss: 32.0704\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.9564 - val_loss: 29.5278\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.8973 - val_loss: 30.2764\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 29.1851 - val_loss: 28.6897\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.8462 - val_loss: 28.7754\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.1779 - val_loss: 28.3544\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.0286 - val_loss: 29.0974\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.0384 - val_loss: 29.1247\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.4458 - val_loss: 27.7955\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.0555 - val_loss: 27.2543\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 26.4704 - val_loss: 27.0949\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.6311 - val_loss: 27.5016\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 26.8900 - val_loss: 28.6156\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 25.4476 - val_loss: 25.8835\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 25.1981 - val_loss: 25.6605\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.5529 - val_loss: 25.4602\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.2191 - val_loss: 25.3011\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.9671 - val_loss: 24.7864\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.9721 - val_loss: 25.2820\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.8447 - val_loss: 24.6260\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.3757 - val_loss: 24.4844\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.1986 - val_loss: 24.2039\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 23.2538 - val_loss: 24.1075\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.9976 - val_loss: 23.9864\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.9173 - val_loss: 25.0642\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7859 - val_loss: 23.8618\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.5392 - val_loss: 23.8574\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.5711 - val_loss: 23.9253\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.5302 - val_loss: 23.8453\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.2134 - val_loss: 23.4825\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.1751 - val_loss: 23.5343\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.1463 - val_loss: 23.4154\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.0840 - val_loss: 23.5681\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.9825 - val_loss: 23.3540\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.8729 - val_loss: 23.4543\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.8836 - val_loss: 23.2923\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8136 - val_loss: 23.5595\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.7981 - val_loss: 23.5742\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.1598 - val_loss: 23.9736\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.8634 - val_loss: 23.2350\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.6119 - val_loss: 23.3547\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 21.4276 - val_loss: 23.1095\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.3641 - val_loss: 23.0196\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.2897 - val_loss: 23.2752\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4014 - val_loss: 22.9849\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.2286 - val_loss: 22.9908\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.1633 - val_loss: 22.9885\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2224 - val_loss: 23.7827\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.2840 - val_loss: 23.0107\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 20.9987 - val_loss: 22.9353\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.0709 - val_loss: 23.2729\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1945 - val_loss: 23.0266\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.0692 - val_loss: 23.2064\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.9600 - val_loss: 22.9014\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.7429 - val_loss: 22.9241\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.8392 - val_loss: 22.8993\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.6921 - val_loss: 23.2890\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.7861 - val_loss: 22.8802\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 20.7745 - val_loss: 23.0658\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.5798 - val_loss: 23.1062\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.5307 - val_loss: 23.0493\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.6934 - val_loss: 22.9601\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.4653 - val_loss: 22.9293\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.8305 - val_loss: 50.8368\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 44.5489 - val_loss: 41.8175\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 40.2978 - val_loss: 39.4883\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.9914 - val_loss: 39.5614\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.6389 - val_loss: 41.3096\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 37.1990 - val_loss: 37.8678\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 35.6890 - val_loss: 36.2433\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.4089 - val_loss: 37.0994\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.5705 - val_loss: 43.5686\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.4115 - val_loss: 36.4934\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 34.1035 - val_loss: 34.7751\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.7074 - val_loss: 34.3769\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 33.4170 - val_loss: 35.1107\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.3503 - val_loss: 35.0752\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.9234 - val_loss: 34.7279\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.7423 - val_loss: 36.4223\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.7609 - val_loss: 33.6129\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.6566 - val_loss: 32.4104\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.2905 - val_loss: 32.6760\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.2455 - val_loss: 34.7737\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.1502 - val_loss: 32.1483\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.4431 - val_loss: 32.5401\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.5267 - val_loss: 31.4112\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.4681 - val_loss: 32.2820\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.9938 - val_loss: 31.2748\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.2226 - val_loss: 31.0756\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.6427 - val_loss: 32.0554\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.7607 - val_loss: 31.1404\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.0156 - val_loss: 32.4593\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.1419 - val_loss: 30.2989\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.6183 - val_loss: 34.0423\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.4883 - val_loss: 30.8148\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.7924 - val_loss: 35.2070\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.8988 - val_loss: 30.2499\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.0358 - val_loss: 29.4360\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.0142 - val_loss: 29.9728\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.7105 - val_loss: 29.5190\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.2000 - val_loss: 29.7188\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.7822 - val_loss: 28.8522\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.1398 - val_loss: 28.8329\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.8423 - val_loss: 29.8327\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.6640 - val_loss: 28.8380\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.1831 - val_loss: 29.2967\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.8303 - val_loss: 28.3876\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 26.4469 - val_loss: 28.0404\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.6237 - val_loss: 28.2193\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.5412 - val_loss: 31.8785\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.8651 - val_loss: 28.2680\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.4971 - val_loss: 28.2249\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.5196 - val_loss: 28.2604\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.6963 - val_loss: 52.2376\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 49.8344 - val_loss: 48.5536\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 50.9086 - val_loss: 46.4838\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 45.4566 - val_loss: 45.3258\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 43.4794 - val_loss: 42.9642\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 40.9296 - val_loss: 40.9087\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 39.8318 - val_loss: 39.6617\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 39.0913 - val_loss: 41.3388\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 38.5530 - val_loss: 38.7134\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 37.7796 - val_loss: 39.5685\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 37.7009 - val_loss: 39.5506\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 37.0527 - val_loss: 37.8658\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.8104 - val_loss: 37.3070\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 35.9067 - val_loss: 36.8846\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.1267 - val_loss: 39.3473\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 37.0849 - val_loss: 37.5119\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 36.9172 - val_loss: 42.7248\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 36.9765 - val_loss: 36.6978\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 35.1577 - val_loss: 36.3325\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.9136 - val_loss: 35.5820\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.0797 - val_loss: 35.2751\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.0940 - val_loss: 35.1244\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.4165 - val_loss: 36.7238\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.0889 - val_loss: 35.0451\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.7781 - val_loss: 34.7312\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.0625 - val_loss: 35.5537\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.9883 - val_loss: 36.4321\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.4408 - val_loss: 35.3870\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 32.8990 - val_loss: 35.1931\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.9041 - val_loss: 34.4523\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.3624 - val_loss: 33.3147\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.4401 - val_loss: 32.5639\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.2161 - val_loss: 32.5113\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.9152 - val_loss: 31.7894\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 31.0201 - val_loss: 35.9067\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.8318 - val_loss: 30.9939\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.1936 - val_loss: 30.0586\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 28.6978 - val_loss: 34.6008\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.4607 - val_loss: 30.3725\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.3042 - val_loss: 29.3811\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 27.2607 - val_loss: 27.7670\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 26.5118 - val_loss: 28.2060\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 26.0818 - val_loss: 26.8878\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 25.9216 - val_loss: 26.7639\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 25.3866 - val_loss: 25.8891\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 25.0346 - val_loss: 28.1963\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 694us/step - loss: 25.5961 - val_loss: 25.9643\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.8331 - val_loss: 25.3901\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 24.3950 - val_loss: 25.2900\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.5075 - val_loss: 25.6958\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.3958 - val_loss: 24.7012\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.0427 - val_loss: 24.9844\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.0734 - val_loss: 25.4054\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.7880 - val_loss: 24.3866\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 23.3423 - val_loss: 24.0975\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.3365 - val_loss: 24.0294\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.3231 - val_loss: 24.2362\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.0081 - val_loss: 23.7378\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.7329 - val_loss: 23.5333\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 22.6664 - val_loss: 23.7137\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.5794 - val_loss: 23.2804\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.3943 - val_loss: 23.2196\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.2682 - val_loss: 23.0998\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.1673 - val_loss: 23.0886\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.1741 - val_loss: 23.1465\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.1546 - val_loss: 23.1234\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9932 - val_loss: 22.9094\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.8515 - val_loss: 22.9387\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7337 - val_loss: 22.6697\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 21.7087 - val_loss: 22.8810\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.5816 - val_loss: 22.7064\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.5895 - val_loss: 23.1093\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6442 - val_loss: 22.6445\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.3888 - val_loss: 22.6332\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.4930 - val_loss: 23.6545\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.7211 - val_loss: 22.5507\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.5040 - val_loss: 22.7788\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.1740 - val_loss: 22.7084\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.9946 - val_loss: 22.2174\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.9238 - val_loss: 22.1308\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.9974 - val_loss: 22.2677\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 611us/step - loss: 21.1103 - val_loss: 22.1175\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.8075 - val_loss: 22.3423\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.9143 - val_loss: 22.1118\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 20.6126 - val_loss: 22.0930\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 20.6231 - val_loss: 22.1255\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.7499 - val_loss: 22.5960\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 20.5912 - val_loss: 21.9788\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 20.4298 - val_loss: 21.9392\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.3579 - val_loss: 21.8949\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.3239 - val_loss: 21.8493\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.3054 - val_loss: 21.9271\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.2385 - val_loss: 21.8408\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.1922 - val_loss: 22.1864\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 20.1511 - val_loss: 21.7876\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.1476 - val_loss: 21.7890\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 19.9630 - val_loss: 21.7222\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.0269 - val_loss: 21.9328\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 558us/step - loss: 20.0714 - val_loss: 21.9037\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 559us/step - loss: 19.9185 - val_loss: 21.7517\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.8077 - val_loss: 48.0493\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 44.7420 - val_loss: 42.7586\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 41.9800 - val_loss: 41.4287\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 40.7664 - val_loss: 42.5074\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.4496 - val_loss: 39.7831\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 41.1800 - val_loss: 40.2262\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 41.4484 - val_loss: 41.4540\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 39.9448 - val_loss: 40.5389\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.2608 - val_loss: 37.1951\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.7168 - val_loss: 37.0520\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.7160 - val_loss: 37.2999\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.4267 - val_loss: 36.7586\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.2358 - val_loss: 38.7938\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.4568 - val_loss: 37.1262\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.5006 - val_loss: 35.7662\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.8932 - val_loss: 35.8203\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.7204 - val_loss: 38.2294\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.9612 - val_loss: 35.4091\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.2320 - val_loss: 34.3530\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.1862 - val_loss: 33.9098\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 33.7953 - val_loss: 34.0119\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 33.5675 - val_loss: 33.7127\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.8832 - val_loss: 33.8644\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.4127 - val_loss: 33.3225\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.1032 - val_loss: 33.1227\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.4187 - val_loss: 34.7571\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.0296 - val_loss: 35.8491\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.0534 - val_loss: 33.3875\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.7021 - val_loss: 33.1737\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.7067 - val_loss: 32.6030\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.1045 - val_loss: 35.3179\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.9532 - val_loss: 32.8076\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.5746 - val_loss: 32.1929\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.4000 - val_loss: 33.3732\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.6461 - val_loss: 31.6541\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.9871 - val_loss: 34.6584\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.9002 - val_loss: 32.0288\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.6612 - val_loss: 32.6695\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.9568 - val_loss: 31.4054\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.2447 - val_loss: 32.0696\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.9889 - val_loss: 30.4461\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.1043 - val_loss: 32.8863\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.9797 - val_loss: 30.6601\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.5949 - val_loss: 31.4133\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.2489 - val_loss: 29.9462\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.1727 - val_loss: 30.5499\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.3142 - val_loss: 31.5385\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.3125 - val_loss: 29.9351\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.3338 - val_loss: 29.4896\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.7218 - val_loss: 28.5196\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.4034 - val_loss: 28.5912\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 26.5875 - val_loss: 27.7087\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.0528 - val_loss: 27.9027\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.8518 - val_loss: 26.7669\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.6389 - val_loss: 26.2948\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 24.8600 - val_loss: 26.6480\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.3154 - val_loss: 25.4328\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.3210 - val_loss: 25.1704\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 617us/step - loss: 24.0063 - val_loss: 24.7177\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.9120 - val_loss: 24.5571\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.5854 - val_loss: 24.3406\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2284 - val_loss: 24.1887\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.0144 - val_loss: 23.8676\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.9584 - val_loss: 23.8882\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.8078 - val_loss: 23.7035\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.7324 - val_loss: 23.6708\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.9536 - val_loss: 23.7220\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.0071 - val_loss: 23.3434\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.3796 - val_loss: 23.2670\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.1723 - val_loss: 23.2389\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.0951 - val_loss: 23.4159\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.4361 - val_loss: 23.2168\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.9831 - val_loss: 22.9731\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.9911 - val_loss: 22.9399\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8759 - val_loss: 23.3153\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 21.8636 - val_loss: 22.8310\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.7329 - val_loss: 22.7673\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.8807 - val_loss: 22.8996\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.5943 - val_loss: 22.9322\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.5711 - val_loss: 22.6769\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4326 - val_loss: 22.8397\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.4528 - val_loss: 23.0136\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4229 - val_loss: 22.6849\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.3254 - val_loss: 22.5812\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.2081 - val_loss: 22.6554\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.4361 - val_loss: 22.6091\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1805 - val_loss: 22.5712\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.0384 - val_loss: 22.5448\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0308 - val_loss: 22.4115\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9552 - val_loss: 22.4045\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.0316 - val_loss: 22.7415\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.9860 - val_loss: 22.4126\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.0236 - val_loss: 22.7067\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8627 - val_loss: 22.3552\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.8171 - val_loss: 22.3268\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1417 - val_loss: 22.5249\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.9512 - val_loss: 22.3156\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.7167 - val_loss: 22.5627\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.7547 - val_loss: 22.3414\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.7369 - val_loss: 22.7679\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.7435 - val_loss: 49.4764\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 47.1864 - val_loss: 46.3893\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 44.8219 - val_loss: 42.4379\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 42.5102 - val_loss: 43.3512\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 42.9102 - val_loss: 40.4780\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 42.0113 - val_loss: 40.0790\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 40.7941 - val_loss: 40.3914\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 40.0651 - val_loss: 38.8066\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 39.2212 - val_loss: 38.5210\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.5734 - val_loss: 37.7333\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 37.9324 - val_loss: 36.8454\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 38.0916 - val_loss: 38.8565\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 38.5011 - val_loss: 37.5603\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.1745 - val_loss: 38.3678\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 36.0007 - val_loss: 35.4095\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 35.5886 - val_loss: 37.0288\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 37.1489 - val_loss: 36.8140\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.3623 - val_loss: 35.7409\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 35.3310 - val_loss: 37.2879\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 39.9328 - val_loss: 39.9012\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.1123 - val_loss: 49.1841\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 52.8986 - val_loss: 47.7835\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 48.0752 - val_loss: 44.9851\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 45.0078 - val_loss: 41.9470\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 43.1988 - val_loss: 41.2205\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 43.3859 - val_loss: 40.6644\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.0136 - val_loss: 39.7345\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 40.7458 - val_loss: 43.4369\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.3950 - val_loss: 40.7060\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.8546 - val_loss: 37.7097\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.2765 - val_loss: 37.2181\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.6987 - val_loss: 36.8108\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.5260 - val_loss: 36.5926\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.1832 - val_loss: 36.1122\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 38.1908 - val_loss: 36.0830\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.2353 - val_loss: 34.5638\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 38.3779 - val_loss: 35.5043\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 36.6592 - val_loss: 34.7403\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 36.2991 - val_loss: 35.1468\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.6277 - val_loss: 41.2959\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.2276 - val_loss: 36.9154\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.2460 - val_loss: 50.7343\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 46.4124 - val_loss: 46.8780\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 42.9485 - val_loss: 40.0899\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.4175 - val_loss: 40.3244\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.4071 - val_loss: 42.8382\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 41.5185 - val_loss: 42.6526\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.6245 - val_loss: 37.6815\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 38.7998 - val_loss: 38.0088\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.4180 - val_loss: 37.6033\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 711us/step - loss: 39.5591 - val_loss: 38.2717\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.1160 - val_loss: 36.5077\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.4420 - val_loss: 36.0403\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.9153 - val_loss: 35.6451\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.6295 - val_loss: 35.2975\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.9484 - val_loss: 35.2198\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.9974 - val_loss: 35.1488\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.8536 - val_loss: 35.4798\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.3528 - val_loss: 34.5447\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.1704 - val_loss: 40.8737\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.5006 - val_loss: 33.8268\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.8164 - val_loss: 34.0852\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.4083 - val_loss: 33.0482\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.7489 - val_loss: 33.2384\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.3747 - val_loss: 34.1760\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.7430 - val_loss: 32.6555\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.6236 - val_loss: 33.1484\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.9159 - val_loss: 32.7468\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.4588 - val_loss: 33.6812\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.3440 - val_loss: 32.6999\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.4097 - val_loss: 33.1218\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.4352 - val_loss: 50.8681\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 45.2791 - val_loss: 42.1411\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 41.0443 - val_loss: 39.8277\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.9583 - val_loss: 38.2103\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.1665 - val_loss: 37.9772\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 37.7215 - val_loss: 36.5484\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 36.4620 - val_loss: 41.3077\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.3251 - val_loss: 36.9482\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.1650 - val_loss: 38.6260\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.2085 - val_loss: 34.7366\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.6187 - val_loss: 33.9923\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.5669 - val_loss: 33.9014\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 725us/step - loss: 34.6095 - val_loss: 33.6067\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 808us/step - loss: 34.0812 - val_loss: 35.1260\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 33.7253 - val_loss: 32.8403\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.5499 - val_loss: 32.2634\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.8455 - val_loss: 38.3242\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.1652 - val_loss: 35.9965\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.0706 - val_loss: 32.6759\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.7111 - val_loss: 33.7841\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.6974 - val_loss: 31.6077\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.4942 - val_loss: 31.1405\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.0572 - val_loss: 32.6665\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.2857 - val_loss: 31.6048\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.0013 - val_loss: 30.8958\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.0963 - val_loss: 30.3980\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.5468 - val_loss: 30.4356\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.6026 - val_loss: 30.3154\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.2299 - val_loss: 30.5982\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.0718 - val_loss: 29.4234\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.0752 - val_loss: 30.8760\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.5033 - val_loss: 30.0119\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.0938 - val_loss: 29.4299\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.2602 - val_loss: 30.1419\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.4175 - val_loss: 28.8815\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 29.8680 - val_loss: 29.9717\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.8546 - val_loss: 29.1820\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.3856 - val_loss: 29.5634\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.6208 - val_loss: 29.3687\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.5258 - val_loss: 29.4426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.3151 - val_loss: 47.7182\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 45.7123 - val_loss: 42.1368\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.0649 - val_loss: 42.2963\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 39.6589 - val_loss: 38.0503\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.0047 - val_loss: 37.7854\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.3186 - val_loss: 40.5562\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.7481 - val_loss: 37.0509\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 37.3068 - val_loss: 39.3770\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.9599 - val_loss: 36.3165\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.1072 - val_loss: 36.7994\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.1965 - val_loss: 35.6799\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 717us/step - loss: 36.8520 - val_loss: 35.5903\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 738us/step - loss: 35.8316 - val_loss: 34.9859\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 776us/step - loss: 36.6015 - val_loss: 35.4845\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 825us/step - loss: 37.0234 - val_loss: 35.1065\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 843us/step - loss: 37.8272 - val_loss: 34.9191\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 818us/step - loss: 34.9833 - val_loss: 33.7242\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 874us/step - loss: 33.9520 - val_loss: 33.4956\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 873us/step - loss: 33.9294 - val_loss: 33.8680\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 728us/step - loss: 33.6476 - val_loss: 36.5762\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 828us/step - loss: 34.0250 - val_loss: 33.0465\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 689us/step - loss: 34.4845 - val_loss: 35.1023\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 698us/step - loss: 34.3942 - val_loss: 35.4820\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.5529 - val_loss: 33.0495\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 775us/step - loss: 34.9627 - val_loss: 34.0008\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 772us/step - loss: 34.8223 - val_loss: 38.0323\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 60.8907 - val_loss: 47.6563\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 49.0307 - val_loss: 47.3684\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 46.5838 - val_loss: 49.4518\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 45.8815 - val_loss: 41.7408\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 41.9575 - val_loss: 41.2681\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 43.0346 - val_loss: 40.9456\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 40.8016 - val_loss: 41.8322\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.5081 - val_loss: 39.3332\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 39.9453 - val_loss: 42.8622\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 39.8317 - val_loss: 38.7128\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 38.8820 - val_loss: 38.4967\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 38.3901 - val_loss: 37.3044\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 39.0193 - val_loss: 39.1320\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 38.6703 - val_loss: 43.7720\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 41.5660 - val_loss: 40.0017\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 39.2415 - val_loss: 36.9527\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 38.6498 - val_loss: 40.4522\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 712us/step - loss: 40.7031 - val_loss: 38.0345\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 37.5090 - val_loss: 38.3599\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 35.9846 - val_loss: 36.6384\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 38.6896 - val_loss: 37.4018\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 37.0529 - val_loss: 36.1600\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 717us/step - loss: 37.5166 - val_loss: 36.3114\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 715us/step - loss: 35.5374 - val_loss: 36.0240\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 810us/step - loss: 35.2926 - val_loss: 36.9274\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 35.3024 - val_loss: 33.5553\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 748us/step - loss: 34.2539 - val_loss: 33.7882\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.1049 - val_loss: 33.2136\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 33.7450 - val_loss: 36.3423\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 738us/step - loss: 33.5170 - val_loss: 32.5497\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 695us/step - loss: 32.4735 - val_loss: 37.5211\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 32.6079 - val_loss: 36.6145\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 31.9893 - val_loss: 33.4394\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.3635 - val_loss: 31.0362\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 32.0188 - val_loss: 32.3316\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 31.6141 - val_loss: 30.6403\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.8814 - val_loss: 34.6108\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 32.1102 - val_loss: 33.8892\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 31.2553 - val_loss: 29.8951\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 30.5058 - val_loss: 31.5030\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 31.0862 - val_loss: 30.4857\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 29.7873 - val_loss: 29.2795\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 695us/step - loss: 30.0865 - val_loss: 29.7414\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 29.4764 - val_loss: 32.3824\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 29.9938 - val_loss: 30.5079\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 29.9882 - val_loss: 32.3233\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 28.6666 - val_loss: 28.4376\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 27.7318 - val_loss: 28.0671\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 711us/step - loss: 27.3573 - val_loss: 26.4142\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 26.5846 - val_loss: 28.3589\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.3848 - val_loss: 26.4967\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.1303 - val_loss: 25.3701\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.7447 - val_loss: 24.8121\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.2365 - val_loss: 24.3171\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.8554 - val_loss: 24.3720\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 23.9810 - val_loss: 23.8779\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.5115 - val_loss: 23.5413\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.9948 - val_loss: 23.2538\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.8834 - val_loss: 23.6599\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.9556 - val_loss: 23.2794\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.9627 - val_loss: 23.0488\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.5136 - val_loss: 22.8782\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.4031 - val_loss: 23.0098\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.1469 - val_loss: 22.6107\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0974 - val_loss: 22.6895\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.0055 - val_loss: 22.6010\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.9437 - val_loss: 22.4765\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7135 - val_loss: 22.3321\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.6158 - val_loss: 22.2705\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5868 - val_loss: 22.6445\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.4763 - val_loss: 22.1926\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3666 - val_loss: 22.1267\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.4547 - val_loss: 22.7082\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.4128 - val_loss: 22.7650\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4482 - val_loss: 22.2994\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.1469 - val_loss: 21.9528\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1292 - val_loss: 23.1768\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3335 - val_loss: 21.9721\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.9633 - val_loss: 21.9101\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.8831 - val_loss: 21.8460\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.8044 - val_loss: 21.8259\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.8126 - val_loss: 21.7596\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.6544 - val_loss: 21.8432\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.7475 - val_loss: 21.7641\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.6248 - val_loss: 21.7919\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.4637 - val_loss: 21.6557\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.4435 - val_loss: 21.6752\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.3577 - val_loss: 21.8241\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.5493 - val_loss: 21.7054\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.4817 - val_loss: 21.6524\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.2406 - val_loss: 21.6039\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.2429 - val_loss: 22.0578\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.1907 - val_loss: 21.6780\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.2567 - val_loss: 21.6108\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.1114 - val_loss: 23.0008\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.4094 - val_loss: 21.5992\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 19.9688 - val_loss: 21.6723\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 19.9222 - val_loss: 21.7466\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 19.9747 - val_loss: 21.5378\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 19.7552 - val_loss: 21.4522\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.7899 - val_loss: 49.1393\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 45.0889 - val_loss: 44.7761\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 42.8326 - val_loss: 43.0957\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.5277 - val_loss: 44.4987\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.9617 - val_loss: 41.4496\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.7215 - val_loss: 40.2218\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.3124 - val_loss: 39.2777\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.5812 - val_loss: 40.2897\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.0124 - val_loss: 39.3118\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.4553 - val_loss: 37.3124\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.7472 - val_loss: 37.5424\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 35.9182 - val_loss: 37.7230\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.1160 - val_loss: 37.2647\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.4498 - val_loss: 39.4370\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.7675 - val_loss: 37.0242\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.9375 - val_loss: 39.2284\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 34.7915 - val_loss: 36.1499\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 34.7498 - val_loss: 37.7606\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.3179 - val_loss: 36.9016\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.4960 - val_loss: 34.7565\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 33.1089 - val_loss: 36.9678\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.4981 - val_loss: 36.7707\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.5880 - val_loss: 34.3796\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.2969 - val_loss: 35.3041\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 31.5040 - val_loss: 33.4516\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.5145 - val_loss: 34.5049\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.7723 - val_loss: 36.3184\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 640us/step - loss: 31.8040 - val_loss: 33.7003\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.5954 - val_loss: 35.0712\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 30.7747 - val_loss: 33.7206\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 82.6459 - val_loss: 53.1249\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 48.3404 - val_loss: 47.9951\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 44.3559 - val_loss: 44.1998\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 42.8515 - val_loss: 40.7675\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 42.3764 - val_loss: 39.6387\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 40.7719 - val_loss: 42.5026\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 40.5870 - val_loss: 39.6179\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 42.5227 - val_loss: 41.0288\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 43.1316 - val_loss: 39.4828\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.0477 - val_loss: 37.8969\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 39.8710 - val_loss: 39.2986\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.5869 - val_loss: 39.4357\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.7997 - val_loss: 37.9513\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.3432 - val_loss: 37.0391\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 36.9026 - val_loss: 37.4792\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.9521 - val_loss: 35.3218\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 36.2218 - val_loss: 36.2646\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.2205 - val_loss: 34.6857\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.6716 - val_loss: 36.5497\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.8033 - val_loss: 35.2112\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 34.8172 - val_loss: 34.1777\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.1900 - val_loss: 34.1728\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.9023 - val_loss: 33.4799\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.6376 - val_loss: 32.8043\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.7900 - val_loss: 34.1430\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.0307 - val_loss: 33.6881\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 33.6634 - val_loss: 36.7059\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.4355 - val_loss: 33.7206\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.3658 - val_loss: 35.1128\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.6281 - val_loss: 48.0490\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 46.8632 - val_loss: 42.9738\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 44.2759 - val_loss: 41.4278\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.1087 - val_loss: 40.9547\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 40.9577 - val_loss: 38.9966\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.2797 - val_loss: 37.8266\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.0556 - val_loss: 38.5792\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.7977 - val_loss: 38.3642\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.4237 - val_loss: 37.1934\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.8118 - val_loss: 35.7586\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.8338 - val_loss: 35.5022\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.2591 - val_loss: 36.4893\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.3835 - val_loss: 34.6899\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.7636 - val_loss: 35.7954\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.3435 - val_loss: 33.8885\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 33.7489 - val_loss: 33.7373\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.2899 - val_loss: 33.3425\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.0798 - val_loss: 33.2404\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.0295 - val_loss: 32.6233\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.6482 - val_loss: 33.4869\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.2408 - val_loss: 32.1418\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.3882 - val_loss: 32.9145\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.5723 - val_loss: 31.5115\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.0786 - val_loss: 33.6927\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 31.7764 - val_loss: 31.0180\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.0728 - val_loss: 32.3883\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.9766 - val_loss: 30.9554\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 30.4411 - val_loss: 30.0474\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.2511 - val_loss: 31.7916\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 30.3388 - val_loss: 31.2481\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.5417 - val_loss: 30.3848\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.2967 - val_loss: 30.0874\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.5210 - val_loss: 29.2371\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.5893 - val_loss: 29.0196\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 28.8792 - val_loss: 28.6477\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.1086 - val_loss: 28.6808\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.6103 - val_loss: 27.8092\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.5534 - val_loss: 27.3882\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 26.8712 - val_loss: 27.7285\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 26.5328 - val_loss: 28.1127\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.3853 - val_loss: 26.8461\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.8141 - val_loss: 26.0890\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 25.2816 - val_loss: 26.9942\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 25.2567 - val_loss: 25.8060\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.6323 - val_loss: 25.0878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 24.0748 - val_loss: 25.0749\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 741us/step - loss: 24.0014 - val_loss: 25.5135\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 741us/step - loss: 23.9574 - val_loss: 24.7243\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 885us/step - loss: 24.2889 - val_loss: 25.2358\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.7154 - val_loss: 24.4093\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.5705 - val_loss: 24.4262\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.4327 - val_loss: 24.3235\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.1350 - val_loss: 24.0786\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.0517 - val_loss: 23.9844\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.8834 - val_loss: 24.4433\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.8532 - val_loss: 23.9168\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.6774 - val_loss: 23.7876\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 22.5693 - val_loss: 24.1308\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.6138 - val_loss: 23.8465\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.4552 - val_loss: 23.5911\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 22.3359 - val_loss: 24.3288\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3520 - val_loss: 23.7248\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.5973 - val_loss: 23.5139\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.2274 - val_loss: 23.3788\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.9732 - val_loss: 23.3481\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.9450 - val_loss: 23.3485\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.8733 - val_loss: 23.3433\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.0171 - val_loss: 23.3426\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.8756 - val_loss: 23.3023\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.6615 - val_loss: 23.2562\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.8606 - val_loss: 23.1736\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.5679 - val_loss: 23.1511\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.5041 - val_loss: 23.1637\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5899 - val_loss: 23.0155\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.7064 - val_loss: 23.0063\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.5367 - val_loss: 23.2135\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.5428 - val_loss: 23.2711\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2422 - val_loss: 23.0657\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.1328 - val_loss: 22.9437\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.2049 - val_loss: 23.3654\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5697 - val_loss: 22.9974\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.0020 - val_loss: 22.8434\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.0537 - val_loss: 22.8358\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.9780 - val_loss: 23.1498\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.8357 - val_loss: 23.0548\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.0263 - val_loss: 22.8269\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.7542 - val_loss: 22.7941\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.2562 - val_loss: 23.1569\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.3783 - val_loss: 22.7990\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2604 - val_loss: 23.4191\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2370 - val_loss: 23.5181\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.8265 - val_loss: 22.6858\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.5735 - val_loss: 22.7486\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.4467 - val_loss: 22.7514\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.5895 - val_loss: 23.5105\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.8620 - val_loss: 22.6973\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.3876 - val_loss: 22.6383\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.2967 - val_loss: 22.6903\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.2370 - val_loss: 22.6514\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.3700 - val_loss: 22.7532\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.6202 - val_loss: 47.3983\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 44.9515 - val_loss: 42.1578\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.9171 - val_loss: 39.7972\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 40.2971 - val_loss: 38.4967\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.8125 - val_loss: 38.5350\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 38.8445 - val_loss: 37.9897\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.5156 - val_loss: 37.6086\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.0232 - val_loss: 37.6508\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.9927 - val_loss: 37.8556\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.7813 - val_loss: 35.8448\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.3973 - val_loss: 35.5533\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.8682 - val_loss: 34.4765\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 37.1070 - val_loss: 40.4081\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.5810 - val_loss: 38.0987\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.7996 - val_loss: 36.4077\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.2781 - val_loss: 33.8817\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.1294 - val_loss: 33.4338\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.9089 - val_loss: 35.7144\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.7346 - val_loss: 33.1776\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.0283 - val_loss: 33.0012\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.9430 - val_loss: 32.6988\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 551us/step - loss: 32.6411 - val_loss: 33.2403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.5564 - val_loss: 32.2745\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 32.4555 - val_loss: 32.8571\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.9193 - val_loss: 32.1918\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.5636 - val_loss: 39.4339\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.8586 - val_loss: 33.5017\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 32.6866 - val_loss: 32.5045\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 32.3016 - val_loss: 34.6470\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.9034 - val_loss: 31.6342\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.2931 - val_loss: 32.1980\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.2037 - val_loss: 31.0438\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.7611 - val_loss: 36.7794\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.7431 - val_loss: 32.2074\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.8309 - val_loss: 30.6118\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.0562 - val_loss: 29.9853\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.9907 - val_loss: 29.9368\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 31.3891 - val_loss: 31.1339\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.6090 - val_loss: 30.0709\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.0388 - val_loss: 30.9847\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 28.8293 - val_loss: 28.8652\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.0049 - val_loss: 29.2167\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.0653 - val_loss: 28.3547\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.3472 - val_loss: 27.3669\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 26.4129 - val_loss: 27.4261\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.6769 - val_loss: 26.1519\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 25.5936 - val_loss: 27.1245\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.0788 - val_loss: 25.1103\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.0492 - val_loss: 25.0503\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.6458 - val_loss: 25.0834\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.0707 - val_loss: 24.5415\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.2574 - val_loss: 24.7056\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.7950 - val_loss: 24.1595\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.9197 - val_loss: 24.2371\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.4819 - val_loss: 23.8617\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.4222 - val_loss: 23.7789\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.3542 - val_loss: 24.0356\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 23.2050 - val_loss: 23.6378\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.1345 - val_loss: 23.7199\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.9384 - val_loss: 23.4711\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.8972 - val_loss: 23.4376\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.9378 - val_loss: 23.3363\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.6530 - val_loss: 23.2795\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.5649 - val_loss: 23.2372\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.4803 - val_loss: 23.1121\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.5073 - val_loss: 23.0920\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.6040 - val_loss: 23.1588\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.3928 - val_loss: 23.1517\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.4243 - val_loss: 23.0969\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.2961 - val_loss: 23.1186\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.2551 - val_loss: 22.9500\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.0772 - val_loss: 22.8925\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.9576 - val_loss: 22.9436\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.0155 - val_loss: 22.7793\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.8740 - val_loss: 22.7681\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.9544 - val_loss: 23.3308\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 21.8490 - val_loss: 22.7647\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.0490 - val_loss: 22.9115\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8646 - val_loss: 22.6421\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.7948 - val_loss: 22.6688\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 785us/step - loss: 21.6304 - val_loss: 22.6686\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.6253 - val_loss: 22.6357\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.5233 - val_loss: 22.7278\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.4986 - val_loss: 22.7377\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.5116 - val_loss: 22.6084\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4556 - val_loss: 22.6226\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3325 - val_loss: 22.8617\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5735 - val_loss: 22.6719\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.4057 - val_loss: 22.4998\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.3159 - val_loss: 23.3052\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.4022 - val_loss: 22.5761\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.2437 - val_loss: 22.7555\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.2700 - val_loss: 22.6188\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.0829 - val_loss: 22.8350\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.1232 - val_loss: 52.8902\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 46.1948 - val_loss: 43.3011\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 42.3620 - val_loss: 41.4585\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.9608 - val_loss: 41.9144\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.6186 - val_loss: 40.1121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.5264 - val_loss: 39.2808\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.3870 - val_loss: 38.6655\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 38.1340 - val_loss: 37.5733\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.0288 - val_loss: 37.9733\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.7896 - val_loss: 38.3003\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.2010 - val_loss: 37.9113\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.6280 - val_loss: 37.3301\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.4708 - val_loss: 36.5045\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.7364 - val_loss: 35.5626\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.0161 - val_loss: 35.4363\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.0751 - val_loss: 34.9532\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.6015 - val_loss: 35.0785\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.4969 - val_loss: 36.7078\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.3776 - val_loss: 33.9154\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.8585 - val_loss: 35.4981\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.8917 - val_loss: 33.3440\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.3536 - val_loss: 33.9583\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.2694 - val_loss: 34.6663\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.4726 - val_loss: 32.5435\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.5517 - val_loss: 32.6704\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.2981 - val_loss: 33.6528\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 31.5425 - val_loss: 33.7035\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.1151 - val_loss: 32.2674\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.2469 - val_loss: 31.4614\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.4348 - val_loss: 33.3309\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.7657 - val_loss: 31.4516\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.4159 - val_loss: 32.0324\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.1938 - val_loss: 31.2165\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 29.2992 - val_loss: 30.1150\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.9085 - val_loss: 30.1681\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.7286 - val_loss: 29.8492\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.2666 - val_loss: 30.7098\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.9696 - val_loss: 29.2954\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.8090 - val_loss: 29.0270\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 28.5025 - val_loss: 28.3049\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.7153 - val_loss: 28.3576\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.4300 - val_loss: 27.0570\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 26.2016 - val_loss: 26.3853\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.1515 - val_loss: 25.7633\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.5498 - val_loss: 25.6324\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.5024 - val_loss: 25.0283\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.9441 - val_loss: 24.6672\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.5271 - val_loss: 24.3413\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.3689 - val_loss: 24.0584\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 23.1717 - val_loss: 23.8412\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.0697 - val_loss: 23.7258\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.9618 - val_loss: 23.7383\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.0156 - val_loss: 23.5410\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.8648 - val_loss: 23.4730\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.6850 - val_loss: 23.3811\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.3749 - val_loss: 23.3677\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.3827 - val_loss: 23.8770\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.3185 - val_loss: 23.2176\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.1816 - val_loss: 23.0183\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0549 - val_loss: 23.0442\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.0694 - val_loss: 22.8836\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.9052 - val_loss: 22.8376\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.9497 - val_loss: 22.8621\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.8382 - val_loss: 23.1585\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.7327 - val_loss: 22.9004\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.7825 - val_loss: 23.9249\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.0812 - val_loss: 22.8959\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 86.2812 - val_loss: 51.2587\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 47.8339 - val_loss: 44.0060\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 43.3524 - val_loss: 41.2317\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.5170 - val_loss: 40.6078\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 41.2803 - val_loss: 39.9503\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 39.8449 - val_loss: 38.1873\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.8780 - val_loss: 37.4020\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 37.1655 - val_loss: 37.3442\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.8939 - val_loss: 36.5447\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 36.1659 - val_loss: 35.7304\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.8112 - val_loss: 37.2318\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.4975 - val_loss: 36.6736\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.5970 - val_loss: 36.6001\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 34.5780 - val_loss: 34.5960\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.9316 - val_loss: 35.6915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.7692 - val_loss: 33.7400\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.9913 - val_loss: 33.4588\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 32.4035 - val_loss: 32.8569\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.0480 - val_loss: 32.9563\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.3500 - val_loss: 33.8558\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.1534 - val_loss: 32.7864\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.9880 - val_loss: 32.1092\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.3589 - val_loss: 31.1405\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.8241 - val_loss: 32.8014\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.1110 - val_loss: 30.9387\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.2948 - val_loss: 30.6566\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.4395 - val_loss: 31.2152\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.6616 - val_loss: 29.6563\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.9251 - val_loss: 29.8465\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.3849 - val_loss: 28.1215\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.8132 - val_loss: 27.6898\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 26.5578 - val_loss: 27.6430\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 26.0208 - val_loss: 26.4386\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.3919 - val_loss: 26.0732\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 25.0206 - val_loss: 25.7689\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.9804 - val_loss: 25.5726\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.8291 - val_loss: 25.7030\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.2479 - val_loss: 25.1671\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.2756 - val_loss: 25.5199\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.8997 - val_loss: 24.9904\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.6135 - val_loss: 24.7682\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.4592 - val_loss: 24.6845\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.3927 - val_loss: 24.4858\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 23.3111 - val_loss: 24.5685\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.3107 - val_loss: 24.5885\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.0149 - val_loss: 24.2351\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.8231 - val_loss: 24.2704\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.6819 - val_loss: 24.0686\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.5701 - val_loss: 24.0883\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3999 - val_loss: 23.9324\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.2256 - val_loss: 23.9208\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2296 - val_loss: 23.7136\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.0346 - val_loss: 24.0150\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.3281 - val_loss: 23.9049\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.9333 - val_loss: 23.6299\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.7669 - val_loss: 23.7218\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7266 - val_loss: 23.8426\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.7570 - val_loss: 23.6184\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4454 - val_loss: 23.5634\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3924 - val_loss: 23.7228\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.3255 - val_loss: 23.5265\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.3402 - val_loss: 23.6066\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.3924 - val_loss: 23.5762\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.2399 - val_loss: 23.4103\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3253 - val_loss: 23.5447\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9002 - val_loss: 23.3644\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.7498 - val_loss: 23.6188\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.7309 - val_loss: 23.4655\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.5896 - val_loss: 23.4007\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.4780 - val_loss: 23.4124\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.5559 - val_loss: 23.7773\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.8294 - val_loss: 48.5094\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 47.2129 - val_loss: 43.4873\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 43.4460 - val_loss: 45.2341\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 42.8243 - val_loss: 40.6102\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 41.1310 - val_loss: 40.5930\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.3600 - val_loss: 38.5417\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.8872 - val_loss: 40.3776\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.4047 - val_loss: 37.9169\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.7859 - val_loss: 36.6402\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 37.4084 - val_loss: 36.5798\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.1229 - val_loss: 36.8714\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.9162 - val_loss: 35.7732\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.7724 - val_loss: 35.3837\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.7323 - val_loss: 36.1852\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.1016 - val_loss: 36.3920\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.3301 - val_loss: 36.5523\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.1021 - val_loss: 34.3895\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.5454 - val_loss: 33.9145\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.8006 - val_loss: 33.6026\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.2087 - val_loss: 33.7808\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.0984 - val_loss: 33.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.3476 - val_loss: 33.1972\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.4265 - val_loss: 34.1706\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.5729 - val_loss: 37.6295\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.4006 - val_loss: 33.0165\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.4652 - val_loss: 31.9531\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.5255 - val_loss: 32.3608\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.2651 - val_loss: 31.6504\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.5288 - val_loss: 34.7796\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.9518 - val_loss: 31.5611\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.2518 - val_loss: 34.2134\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.2531 - val_loss: 31.0338\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 30.0585 - val_loss: 30.9957\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.9235 - val_loss: 31.3157\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.3182 - val_loss: 35.1423\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.7036 - val_loss: 31.4099\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.6489 - val_loss: 34.1787\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.9165 - val_loss: 31.1027\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.3272 - val_loss: 47.1988\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 46.1376 - val_loss: 45.0002\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 42.2938 - val_loss: 43.1714\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 41.1511 - val_loss: 41.5540\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.0849 - val_loss: 39.6843\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 38.7030 - val_loss: 39.3532\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.7410 - val_loss: 39.1590\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 38.0126 - val_loss: 39.3817\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 37.0079 - val_loss: 38.0098\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 37.5586 - val_loss: 37.7410\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 37.2549 - val_loss: 37.9410\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 37.0476 - val_loss: 37.9131\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.0600 - val_loss: 37.4067\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 34.4808 - val_loss: 35.6742\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 34.3580 - val_loss: 36.1604\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 34.9354 - val_loss: 35.9542\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.7196 - val_loss: 36.1378\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 33.8689 - val_loss: 34.6732\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.1216 - val_loss: 37.9954\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.9716 - val_loss: 37.8160\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.4917 - val_loss: 37.7940\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.8163 - val_loss: 33.9566\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 31.7863 - val_loss: 33.7139\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 31.6531 - val_loss: 33.7967\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.8311 - val_loss: 34.6174\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.1357 - val_loss: 36.2519\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 32.1683 - val_loss: 35.1617\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.1590 - val_loss: 35.3963\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 98.3468 - val_loss: 63.8119\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 51.5907 - val_loss: 45.9438\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 44.1253 - val_loss: 40.4352\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 41.1246 - val_loss: 39.6855\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 40.1582 - val_loss: 37.9449\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 902us/step - loss: 38.0689 - val_loss: 36.3711\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 997us/step - loss: 38.4765 - val_loss: 36.2625\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 857us/step - loss: 36.9748 - val_loss: 34.8285\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 833us/step - loss: 37.7975 - val_loss: 40.9336\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 740us/step - loss: 37.2673 - val_loss: 34.5047\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 35.3432 - val_loss: 35.1073\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.9837 - val_loss: 33.3916\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.1233 - val_loss: 32.8472\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 33.8207 - val_loss: 32.6075\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.3623 - val_loss: 34.8906\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 34.2539 - val_loss: 34.4375\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.3461 - val_loss: 34.5233\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.7993 - val_loss: 33.7524\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.3079 - val_loss: 32.2142\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.4381 - val_loss: 31.3933\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.4606 - val_loss: 37.8961\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.5096 - val_loss: 30.9702\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.8296 - val_loss: 32.0097\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.7932 - val_loss: 30.4255\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.2754 - val_loss: 31.5114\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.3039 - val_loss: 31.8827\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 31.6436 - val_loss: 29.9395\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.4166 - val_loss: 30.9322\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.3387 - val_loss: 31.3736\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.0093 - val_loss: 30.4988\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.9015 - val_loss: 29.9264\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.3434 - val_loss: 29.7914\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.1905 - val_loss: 30.3485\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 29.5417 - val_loss: 29.2910\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7728 - val_loss: 30.9643\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.7839 - val_loss: 29.4211\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 554us/step - loss: 29.6463 - val_loss: 31.9496\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 29.7956 - val_loss: 28.7570\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.0348 - val_loss: 28.0975\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 28.1541 - val_loss: 28.5716\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 27.9296 - val_loss: 27.6499\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 27.5864 - val_loss: 27.1305\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 29.0018 - val_loss: 30.0885\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 745us/step - loss: 28.0459 - val_loss: 31.7612\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 28.1684 - val_loss: 27.5989\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 943us/step - loss: 26.5386 - val_loss: 26.4660\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 882us/step - loss: 26.2492 - val_loss: 27.2926\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 871us/step - loss: 26.5725 - val_loss: 26.9714\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 903us/step - loss: 25.9954 - val_loss: 26.5532\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 919us/step - loss: 26.0064 - val_loss: 25.6594\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 931us/step - loss: 24.8221 - val_loss: 25.0706\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 903us/step - loss: 24.1887 - val_loss: 24.5888\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 888us/step - loss: 23.7692 - val_loss: 23.9323\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 854us/step - loss: 23.5122 - val_loss: 24.8175\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 942us/step - loss: 23.5667 - val_loss: 23.5856\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 880us/step - loss: 23.3052 - val_loss: 24.9307\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 843us/step - loss: 23.0872 - val_loss: 23.3930\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 877us/step - loss: 22.6024 - val_loss: 22.9455\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 882us/step - loss: 22.4329 - val_loss: 23.5018\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 891us/step - loss: 22.3597 - val_loss: 22.7161\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 866us/step - loss: 22.1721 - val_loss: 22.8677\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 918us/step - loss: 21.9998 - val_loss: 22.4817\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 846us/step - loss: 21.9002 - val_loss: 22.6722\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.9169 - val_loss: 22.8238\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 22.0551 - val_loss: 22.4794\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 779us/step - loss: 21.7159 - val_loss: 22.1903\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.4808 - val_loss: 22.0569\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.5045 - val_loss: 22.0537\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4566 - val_loss: 22.1763\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5552 - val_loss: 21.9214\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.3199 - val_loss: 21.8100\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.2505 - val_loss: 22.2018\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.1403 - val_loss: 22.2151\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1606 - val_loss: 22.0592\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.0953 - val_loss: 21.7103\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1511 - val_loss: 21.7469\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.1633 - val_loss: 21.8625\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.0788 - val_loss: 21.5156\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.8774 - val_loss: 21.4834\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.7895 - val_loss: 21.5504\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.6852 - val_loss: 21.4666\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.7191 - val_loss: 21.4009\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.7386 - val_loss: 21.5044\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.6616 - val_loss: 21.4858\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.9764 - val_loss: 22.3639\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.8169 - val_loss: 21.5708\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.5308 - val_loss: 21.2653\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.4269 - val_loss: 21.2306\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.4730 - val_loss: 21.2595\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.4588 - val_loss: 21.8334\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.5529 - val_loss: 21.7069\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.6644 - val_loss: 21.4392\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.3730 - val_loss: 21.2115\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.2858 - val_loss: 21.1877\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.2830 - val_loss: 21.2962\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.1709 - val_loss: 21.3395\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.1672 - val_loss: 21.1750\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.2213 - val_loss: 21.7142\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.1933 - val_loss: 21.2282\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.0765 - val_loss: 21.3101\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.3323 - val_loss: 48.2275\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 45.9815 - val_loss: 44.2030\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 43.1754 - val_loss: 45.7522\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 42.4536 - val_loss: 41.9541\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 40.2746 - val_loss: 40.2110\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 39.5459 - val_loss: 41.5847\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 40.2122 - val_loss: 41.2355\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.9886 - val_loss: 39.1266\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 640us/step - loss: 37.7953 - val_loss: 40.6543\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 38.2873 - val_loss: 38.4809\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.1225 - val_loss: 38.7236\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 36.6325 - val_loss: 37.5653\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 36.5174 - val_loss: 38.3553\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.9235 - val_loss: 36.8042\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 36.6916 - val_loss: 37.2282\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.5675 - val_loss: 36.5741\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.8918 - val_loss: 37.5419\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.8751 - val_loss: 36.1155\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.0220 - val_loss: 35.3848\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.7979 - val_loss: 36.8606\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.4728 - val_loss: 35.9015\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.7663 - val_loss: 34.7294\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.8058 - val_loss: 34.9792\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.8464 - val_loss: 34.0501\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.6390 - val_loss: 38.8187\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.2636 - val_loss: 36.3828\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.5202 - val_loss: 34.6148\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 34.8414 - val_loss: 35.5791\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.0685 - val_loss: 41.2595\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.4919 - val_loss: 47.3526\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 46.9153 - val_loss: 43.6480\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 43.8892 - val_loss: 49.9214\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 45.1846 - val_loss: 43.4987\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 41.0214 - val_loss: 39.1805\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 39.9357 - val_loss: 38.4473\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 38.5169 - val_loss: 37.6946\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.9174 - val_loss: 37.7267\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.1280 - val_loss: 36.9496\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.7123 - val_loss: 36.0914\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.7389 - val_loss: 35.4941\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.8028 - val_loss: 41.6567\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.8691 - val_loss: 34.9638\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.9910 - val_loss: 35.0045\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.0502 - val_loss: 37.7748\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.9030 - val_loss: 34.2279\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.6646 - val_loss: 34.5952\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.2162 - val_loss: 35.3426\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.7592 - val_loss: 34.8715\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.4124 - val_loss: 34.3551\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.7799 - val_loss: 33.4082\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.9180 - val_loss: 35.4628\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.4055 - val_loss: 33.6463\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.2272 - val_loss: 32.9922\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.6949 - val_loss: 34.5050\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.9685 - val_loss: 33.1848\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.1422 - val_loss: 33.9010\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.5905 - val_loss: 32.6358\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.0086 - val_loss: 31.8421\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.2823 - val_loss: 31.2478\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.6426 - val_loss: 31.6128\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.8355 - val_loss: 35.9207\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.3337 - val_loss: 31.7414\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 31.2902 - val_loss: 30.9875\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.7711 - val_loss: 30.7368\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.1461 - val_loss: 31.2041\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.9977 - val_loss: 31.1163\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.2387 - val_loss: 32.5856\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.7402 - val_loss: 29.7499\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.3022 - val_loss: 29.7033\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 29.3640 - val_loss: 33.5451\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.5956 - val_loss: 30.2189\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.9004 - val_loss: 29.8000\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.4548 - val_loss: 29.7640\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 28.7106 - val_loss: 29.8189\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 87.5871 - val_loss: 70.6967\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 56.4781 - val_loss: 42.8951\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 41.7342 - val_loss: 46.6045\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 39.3995 - val_loss: 38.0528\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.9423 - val_loss: 37.4430\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.4716 - val_loss: 36.0478\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.0374 - val_loss: 36.5628\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 37.3620 - val_loss: 36.1688\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.9372 - val_loss: 34.4090\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.9537 - val_loss: 34.2014\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.4292 - val_loss: 32.9682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.4968 - val_loss: 33.0783\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.3884 - val_loss: 34.1476\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.0191 - val_loss: 31.6990\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.4726 - val_loss: 31.5390\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.8933 - val_loss: 30.9797\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.0159 - val_loss: 30.4329\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.0949 - val_loss: 30.7889\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.8892 - val_loss: 29.9806\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.1118 - val_loss: 30.1462\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.9559 - val_loss: 30.2813\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.7361 - val_loss: 29.0973\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.3759 - val_loss: 31.0019\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.4180 - val_loss: 30.0956\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.5369 - val_loss: 30.9866\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.9671 - val_loss: 32.0415\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.3135 - val_loss: 29.4431\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.4437 - val_loss: 53.7781\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 49.8132 - val_loss: 46.7165\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 46.6597 - val_loss: 45.0146\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 44.8736 - val_loss: 43.2059\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 42.9465 - val_loss: 42.8949\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 42.0602 - val_loss: 41.5854\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 41.3226 - val_loss: 42.7901\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 40.2036 - val_loss: 40.1065\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.0208 - val_loss: 39.3418\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.8517 - val_loss: 39.9395\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.9705 - val_loss: 39.3865\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.7729 - val_loss: 40.7238\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.8722 - val_loss: 39.1562\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.9977 - val_loss: 38.1346\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.6324 - val_loss: 37.9276\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.9585 - val_loss: 37.6717\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.0496 - val_loss: 36.3851\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.5416 - val_loss: 36.5845\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.7279 - val_loss: 35.7727\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 34.3652 - val_loss: 35.4654\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.3453 - val_loss: 36.2318\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.5105 - val_loss: 34.9977\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.4357 - val_loss: 36.6046\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.0684 - val_loss: 37.1509\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.1096 - val_loss: 34.6766\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.1751 - val_loss: 35.4281\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 32.7731 - val_loss: 35.0633\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.6453 - val_loss: 34.1031\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.1909 - val_loss: 34.9944\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.3926 - val_loss: 32.5111\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.5922 - val_loss: 32.0631\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.6623 - val_loss: 32.1157\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.5708 - val_loss: 35.5542\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.4875 - val_loss: 32.3467\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.9882 - val_loss: 33.4953\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.7248 - val_loss: 30.1382\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.3458 - val_loss: 29.9359\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.4749 - val_loss: 32.4815\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.4362 - val_loss: 29.6992\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.4418 - val_loss: 28.0042\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 26.8239 - val_loss: 27.9449\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.8489 - val_loss: 29.0034\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.9078 - val_loss: 27.3256\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 26.3042 - val_loss: 26.5358\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.3368 - val_loss: 26.5050\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.1491 - val_loss: 25.9182\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 24.9113 - val_loss: 26.0097\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 24.6801 - val_loss: 25.4569\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.3171 - val_loss: 25.3913\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 24.5335 - val_loss: 26.6196\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.3089 - val_loss: 24.9889\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 23.8273 - val_loss: 26.1583\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.8269 - val_loss: 25.1761\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 23.7540 - val_loss: 24.7063\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 23.4040 - val_loss: 24.6071\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 23.3505 - val_loss: 24.3800\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.3773 - val_loss: 24.3747\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.4664 - val_loss: 24.2718\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 23.1977 - val_loss: 25.3434\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.5241 - val_loss: 25.6503\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.9125 - val_loss: 23.8745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.6233 - val_loss: 24.6345\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.5659 - val_loss: 23.7874\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.5123 - val_loss: 23.8450\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.5480 - val_loss: 23.9510\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.2476 - val_loss: 23.6973\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.4525 - val_loss: 23.8054\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.1227 - val_loss: 23.4710\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.1340 - val_loss: 23.4101\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.8816 - val_loss: 23.3360\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.7817 - val_loss: 23.2687\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.9065 - val_loss: 23.4098\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.0200 - val_loss: 23.1012\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.5542 - val_loss: 23.0864\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.5379 - val_loss: 23.1772\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.4555 - val_loss: 23.0268\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.5369 - val_loss: 22.9620\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.4735 - val_loss: 22.9910\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.7399 - val_loss: 22.9203\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.4432 - val_loss: 23.0355\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.1211 - val_loss: 23.5381\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.1780 - val_loss: 22.8261\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.8802 - val_loss: 22.8356\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.8931 - val_loss: 22.6950\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.0291 - val_loss: 23.7860\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8625 - val_loss: 22.7491\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.7034 - val_loss: 22.6781\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.5770 - val_loss: 22.9376\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.5969 - val_loss: 22.8494\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 20.8170 - val_loss: 22.8025\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.8028 - val_loss: 22.5430\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.5059 - val_loss: 22.5591\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.6332 - val_loss: 22.5607\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.6073 - val_loss: 23.1082\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.3046 - val_loss: 22.6721\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.1765 - val_loss: 22.4837\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.0704 - val_loss: 22.4462\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.0345 - val_loss: 23.1056\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.1369 - val_loss: 22.5638\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 19.9796 - val_loss: 22.6200\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.6132 - val_loss: 51.6269\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 46.8073 - val_loss: 42.9117\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.0744 - val_loss: 41.2256\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.3167 - val_loss: 41.8408\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.3313 - val_loss: 41.5325\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 40.7057 - val_loss: 44.0017\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.8580 - val_loss: 39.6571\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.2273 - val_loss: 37.4788\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.4109 - val_loss: 37.9277\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.0278 - val_loss: 36.6407\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.0279 - val_loss: 37.1267\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.0952 - val_loss: 36.8903\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 35.2969 - val_loss: 36.0528\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.0907 - val_loss: 41.0182\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.5510 - val_loss: 36.3506\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.0052 - val_loss: 36.4460\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.8864 - val_loss: 34.8209\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.8059 - val_loss: 37.3220\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.7296 - val_loss: 35.2559\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.7395 - val_loss: 38.3259\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.2207 - val_loss: 35.2750\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.7394 - val_loss: 33.7451\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.7484 - val_loss: 34.6737\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.1451 - val_loss: 34.7676\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.6092 - val_loss: 33.7383\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.7823 - val_loss: 33.0052\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.3115 - val_loss: 33.3145\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.1535 - val_loss: 33.4859\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.2050 - val_loss: 33.1187\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.3529 - val_loss: 32.6724\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.6858 - val_loss: 33.8341\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 32.8693 - val_loss: 35.2927\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.6430 - val_loss: 32.2290\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.7669 - val_loss: 31.6775\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.4690 - val_loss: 31.8811\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.2824 - val_loss: 31.3663\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.2717 - val_loss: 32.3506\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.4064 - val_loss: 32.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.5362 - val_loss: 31.8528\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.8127 - val_loss: 31.3075\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.7800 - val_loss: 32.3521\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.5107 - val_loss: 31.9299\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.8034 - val_loss: 30.4483\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.3520 - val_loss: 30.6317\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 27.9239 - val_loss: 29.3040\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.5555 - val_loss: 28.8298\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.1711 - val_loss: 32.5052\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.2165 - val_loss: 28.1151\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 26.5906 - val_loss: 28.4938\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.7765 - val_loss: 27.4350\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 26.0741 - val_loss: 26.7394\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.5925 - val_loss: 26.9808\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 25.1278 - val_loss: 27.2968\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.8081 - val_loss: 26.1819\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.5679 - val_loss: 25.0922\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.9679 - val_loss: 24.9482\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.9136 - val_loss: 24.7944\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.6017 - val_loss: 24.6047\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.5566 - val_loss: 24.4446\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.2530 - val_loss: 24.2661\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.1282 - val_loss: 24.0846\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.1426 - val_loss: 24.0158\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.0021 - val_loss: 24.2022\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.8291 - val_loss: 24.0809\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.7952 - val_loss: 23.9437\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.9037 - val_loss: 23.7816\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.7975 - val_loss: 23.8396\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.5307 - val_loss: 23.7234\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6535 - val_loss: 24.1076\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.4971 - val_loss: 23.4763\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.2468 - val_loss: 23.3808\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.2178 - val_loss: 23.8847\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.2380 - val_loss: 23.4581\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.2528 - val_loss: 23.5044\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.1873 - val_loss: 23.3259\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.9281 - val_loss: 23.1166\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.9451 - val_loss: 23.4308\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.0567 - val_loss: 23.1237\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.9345 - val_loss: 23.0563\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.7606 - val_loss: 23.1759\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.7467 - val_loss: 23.1589\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.6014 - val_loss: 23.0320\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5817 - val_loss: 22.9483\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.4415 - val_loss: 22.9454\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5014 - val_loss: 22.8566\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5359 - val_loss: 22.9020\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3349 - val_loss: 22.8348\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.2987 - val_loss: 22.9446\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.3480 - val_loss: 22.7942\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.1912 - val_loss: 22.8942\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.1956 - val_loss: 22.9483\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.3857 - val_loss: 22.7147\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.2410 - val_loss: 22.8110\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0946 - val_loss: 22.7275\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0073 - val_loss: 22.7343\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0175 - val_loss: 22.9087\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0070 - val_loss: 22.9070\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 98.3653 - val_loss: 79.6003\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 55.8720 - val_loss: 47.6372\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 47.9498 - val_loss: 46.9065\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 44.2405 - val_loss: 42.1328\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 44.9616 - val_loss: 42.1670\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.7707 - val_loss: 40.2708\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 40.9198 - val_loss: 39.5887\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 39.2202 - val_loss: 38.7792\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.5907 - val_loss: 37.4546\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.7774 - val_loss: 36.9094\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.4789 - val_loss: 37.5048\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.4239 - val_loss: 37.7167\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.9452 - val_loss: 36.4011\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.2610 - val_loss: 37.8019\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.7005 - val_loss: 38.3993\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.3128 - val_loss: 36.0238\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.9196 - val_loss: 35.6552\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.6868 - val_loss: 36.1350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.1901 - val_loss: 35.4075\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.3231 - val_loss: 36.1256\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 38.0433 - val_loss: 36.5952\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.7876 - val_loss: 35.2180\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.6089 - val_loss: 37.4440\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.9537 - val_loss: 35.1154\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.2925 - val_loss: 36.2609\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.4015 - val_loss: 33.8239\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.0465 - val_loss: 34.8073\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.9307 - val_loss: 36.6104\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 705us/step - loss: 35.2326 - val_loss: 33.2831\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 696us/step - loss: 32.8329 - val_loss: 32.9408\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 801us/step - loss: 32.7384 - val_loss: 33.2575\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.1538 - val_loss: 35.7768\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.9801 - val_loss: 36.8492\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 32.3322 - val_loss: 31.3735\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.2584 - val_loss: 30.9853\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.9978 - val_loss: 30.4706\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 29.3632 - val_loss: 30.9442\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.8293 - val_loss: 29.1144\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.5201 - val_loss: 28.4420\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.2759 - val_loss: 27.2988\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 25.9995 - val_loss: 26.7432\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 25.6490 - val_loss: 26.8572\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 25.3877 - val_loss: 25.9816\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 24.7571 - val_loss: 25.9938\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 24.5814 - val_loss: 26.4516\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 24.4189 - val_loss: 25.1765\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.0354 - val_loss: 24.8646\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.7009 - val_loss: 24.5393\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.4875 - val_loss: 24.3043\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.4666 - val_loss: 24.8395\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.2424 - val_loss: 23.9998\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.9219 - val_loss: 24.0325\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.9295 - val_loss: 23.7719\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.7207 - val_loss: 23.8171\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.5676 - val_loss: 23.6228\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4458 - val_loss: 23.6934\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.3939 - val_loss: 23.3894\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.2269 - val_loss: 23.3853\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.2496 - val_loss: 23.4614\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.3403 - val_loss: 23.4857\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 22.0128 - val_loss: 23.2466\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.0328 - val_loss: 23.8452\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.1205 - val_loss: 23.1490\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.8786 - val_loss: 23.0915\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.7496 - val_loss: 23.0143\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.7924 - val_loss: 23.3025\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.5884 - val_loss: 23.0096\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5215 - val_loss: 22.9679\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.4046 - val_loss: 22.9777\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.4186 - val_loss: 22.9542\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.4031 - val_loss: 22.9829\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3140 - val_loss: 22.7968\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1823 - val_loss: 22.8776\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.2230 - val_loss: 22.8748\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.3304 - val_loss: 22.8050\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.2725 - val_loss: 22.8793\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.0113 - val_loss: 22.7018\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.8836 - val_loss: 22.7383\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.8495 - val_loss: 22.7186\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 20.8812 - val_loss: 22.7272\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.9803 - val_loss: 23.2036\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 729us/step - loss: 20.8832 - val_loss: 22.7382\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.1613 - val_loss: 49.3720\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 50.1131 - val_loss: 45.0206\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 46.8511 - val_loss: 44.4970\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 43.9564 - val_loss: 41.9023\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 43.7797 - val_loss: 44.4084\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 44.6775 - val_loss: 42.6710\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 44.0597 - val_loss: 40.4905\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 41.6967 - val_loss: 39.7086\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 42.5970 - val_loss: 40.8599\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 42.5517 - val_loss: 38.8747\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.7909 - val_loss: 38.6467\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 40.4594 - val_loss: 37.6316\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.0335 - val_loss: 37.2692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.0648 - val_loss: 37.1568\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 39.0013 - val_loss: 38.6505\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 39.4528 - val_loss: 36.8604\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.6770 - val_loss: 36.8559\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.7486 - val_loss: 39.3959\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.9743 - val_loss: 39.4323\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.5283 - val_loss: 35.8422\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.1296 - val_loss: 37.0280\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.5301 - val_loss: 35.2614\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.0396 - val_loss: 36.9415\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.2524 - val_loss: 36.2533\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.7794 - val_loss: 35.6478\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.3990 - val_loss: 34.6866\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.8858 - val_loss: 37.9960\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.3455 - val_loss: 33.5536\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.4653 - val_loss: 32.7795\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.9752 - val_loss: 34.3916\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.7397 - val_loss: 37.7564\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.2270 - val_loss: 33.5385\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.6129 - val_loss: 32.4264\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.3566 - val_loss: 34.9179\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.5276 - val_loss: 33.0431\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.2989 - val_loss: 32.0909\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.5566 - val_loss: 30.8644\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.4045 - val_loss: 30.3329\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.9926 - val_loss: 30.8822\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.1630 - val_loss: 29.7430\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.3237 - val_loss: 29.0351\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.3495 - val_loss: 29.9528\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.0669 - val_loss: 28.2173\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.3119 - val_loss: 28.2511\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 28.7832 - val_loss: 27.3344\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.2553 - val_loss: 26.4748\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.9212 - val_loss: 25.5290\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.9768 - val_loss: 24.8029\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.3704 - val_loss: 24.4458\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.0503 - val_loss: 24.4282\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.8298 - val_loss: 23.7823\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.4098 - val_loss: 23.5248\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 23.2438 - val_loss: 23.4490\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0237 - val_loss: 23.1913\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.8653 - val_loss: 23.3258\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.8950 - val_loss: 23.0971\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.6019 - val_loss: 22.8579\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.4647 - val_loss: 22.8159\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3971 - val_loss: 22.8765\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2306 - val_loss: 22.7297\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.1128 - val_loss: 22.6742\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.1060 - val_loss: 22.4304\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.9573 - val_loss: 22.3996\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.8732 - val_loss: 22.2993\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8717 - val_loss: 22.2535\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.7401 - val_loss: 22.2102\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.7527 - val_loss: 22.4288\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.6582 - val_loss: 22.2100\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.5118 - val_loss: 22.1480\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.4562 - val_loss: 22.0651\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.4262 - val_loss: 22.2363\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.5134 - val_loss: 22.0861\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.3604 - val_loss: 21.9615\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.3007 - val_loss: 21.9090\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.2639 - val_loss: 21.8787\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3380 - val_loss: 21.9988\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.1909 - val_loss: 21.9981\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.2279 - val_loss: 21.7946\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.2339 - val_loss: 22.0806\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.1088 - val_loss: 21.8511\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1288 - val_loss: 21.8097\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.1829 - val_loss: 21.7082\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.9990 - val_loss: 21.7050\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8975 - val_loss: 21.7119\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0409 - val_loss: 21.8266\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.9297 - val_loss: 21.7058\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.9711 - val_loss: 21.9644\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.8543 - val_loss: 21.6947\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.9282 - val_loss: 21.6836\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1709 - val_loss: 21.9036\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.8751 - val_loss: 22.1470\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.8025 - val_loss: 21.6278\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.6579 - val_loss: 21.6708\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.6764 - val_loss: 22.0021\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.6098 - val_loss: 21.5985\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.5555 - val_loss: 21.5524\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.5438 - val_loss: 21.8184\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.5890 - val_loss: 21.6668\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.5623 - val_loss: 21.8352\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.5545 - val_loss: 21.7586\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.8769 - val_loss: 49.4426\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 48.7309 - val_loss: 43.3518\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 44.1933 - val_loss: 40.6071\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 42.5591 - val_loss: 39.7859\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.9497 - val_loss: 39.2940\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.2294 - val_loss: 37.4390\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.8430 - val_loss: 39.2245\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 39.1241 - val_loss: 44.9471\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.8765 - val_loss: 38.9851\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.7274 - val_loss: 42.1321\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.0051 - val_loss: 37.7951\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 84.0863 - val_loss: 49.3475\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 47.0844 - val_loss: 44.3260\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.6523 - val_loss: 39.8629\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 40.1004 - val_loss: 38.2528\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 39.2855 - val_loss: 37.6510\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.0030 - val_loss: 37.2196\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.3288 - val_loss: 37.3059\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.0155 - val_loss: 35.3621\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 35.7430 - val_loss: 34.6642\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.9589 - val_loss: 34.6443\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.7821 - val_loss: 34.0775\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.8434 - val_loss: 33.6561\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.1737 - val_loss: 33.2140\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.6149 - val_loss: 34.0874\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 33.9340 - val_loss: 33.2412\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.9291 - val_loss: 33.8023\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.0496 - val_loss: 32.3695\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 32.7207 - val_loss: 32.1187\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.0492 - val_loss: 32.4442\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.9705 - val_loss: 32.9374\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.1313 - val_loss: 32.3072\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.5921 - val_loss: 31.4034\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 31.2596 - val_loss: 30.7136\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.5451 - val_loss: 33.1292\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.9974 - val_loss: 34.2046\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.1125 - val_loss: 30.7353\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.9845 - val_loss: 31.0083\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.5716 - val_loss: 31.9000\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.7206 - val_loss: 48.7104\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 48.5338 - val_loss: 43.7485\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.8800 - val_loss: 43.2112\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.1280 - val_loss: 40.5404\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.2362 - val_loss: 38.4734\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 39.4161 - val_loss: 41.4221\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.7673 - val_loss: 37.7989\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.4898 - val_loss: 37.5651\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.9688 - val_loss: 37.1399\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.4489 - val_loss: 37.3856\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.5663 - val_loss: 35.3902\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.4732 - val_loss: 37.2538\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.2514 - val_loss: 34.6964\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.2089 - val_loss: 36.3363\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.9698 - val_loss: 34.3976\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.0675 - val_loss: 34.0759\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.9849 - val_loss: 35.6532\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.6020 - val_loss: 36.5738\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.6557 - val_loss: 34.9222\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.7107 - val_loss: 35.9862\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.0172 - val_loss: 35.1224\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.2972 - val_loss: 47.8536\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 47.7951 - val_loss: 44.4365\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 43.9041 - val_loss: 42.3964\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 44.1283 - val_loss: 50.1168\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 42.1169 - val_loss: 46.0307\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 42.2145 - val_loss: 40.3183\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 342us/step - loss: 41.9492 - val_loss: 43.1261\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 41.9942 - val_loss: 39.3827\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 39.5755 - val_loss: 38.5558\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 40.1778 - val_loss: 43.8980\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.5794 - val_loss: 44.2873\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 38.9863 - val_loss: 45.4307\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 39.8418 - val_loss: 37.1464\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.6969 - val_loss: 36.5956\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.6208 - val_loss: 36.7397\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.7142 - val_loss: 35.6360\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 35.8462 - val_loss: 35.5365\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 37.2914 - val_loss: 37.3279\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 36.7048 - val_loss: 35.5935\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 36.6110 - val_loss: 35.7114\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.2648 - val_loss: 34.5974\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.1971 - val_loss: 33.4901\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.8201 - val_loss: 34.6638\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 34.5867 - val_loss: 40.5301\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 36.1630 - val_loss: 33.2402\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.4514 - val_loss: 33.0647\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.2220 - val_loss: 31.4721\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 31.3808 - val_loss: 31.9830\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 31.4427 - val_loss: 30.9276\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 30.6986 - val_loss: 31.0483\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 31.5466 - val_loss: 30.1087\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 29.5918 - val_loss: 33.6303\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.2844 - val_loss: 27.9019\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 27.1956 - val_loss: 26.5582\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 26.1829 - val_loss: 25.9574\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 25.6046 - val_loss: 25.3207\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 24.9643 - val_loss: 25.0299\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 24.9020 - val_loss: 24.7454\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 24.4958 - val_loss: 24.8798\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.3086 - val_loss: 24.5491\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 24.0135 - val_loss: 24.1159\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.7792 - val_loss: 24.1318\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 23.7416 - val_loss: 24.1889\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 23.4009 - val_loss: 23.6177\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 23.2164 - val_loss: 23.7839\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 23.1154 - val_loss: 23.8252\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 23.1879 - val_loss: 23.7184\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.9140 - val_loss: 23.2423\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.8407 - val_loss: 23.1975\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.7763 - val_loss: 23.0578\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 22.6057 - val_loss: 23.1523\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.4894 - val_loss: 23.1515\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.2855 - val_loss: 22.9832\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.1700 - val_loss: 22.7833\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.1110 - val_loss: 22.7165\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 22.1426 - val_loss: 22.6287\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.8959 - val_loss: 22.4796\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.8111 - val_loss: 22.5939\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.8387 - val_loss: 22.5528\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.8032 - val_loss: 22.4359\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.5759 - val_loss: 22.3448\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.5118 - val_loss: 22.5300\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 21.4593 - val_loss: 22.6934\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.5023 - val_loss: 22.3898\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.4036 - val_loss: 22.2014\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.3889 - val_loss: 22.6341\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.4283 - val_loss: 22.3985\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.4914 - val_loss: 23.1635\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.3107 - val_loss: 22.1749\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.2056 - val_loss: 22.0492\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 21.0694 - val_loss: 22.0427\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.9749 - val_loss: 22.1831\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.8981 - val_loss: 21.9801\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.8192 - val_loss: 22.1191\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 21.1474 - val_loss: 22.4347\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 21.3088 - val_loss: 22.1895\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.8447 - val_loss: 22.1091\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.6504 - val_loss: 22.1328\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 87.0990 - val_loss: 52.2379\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 47.6875 - val_loss: 44.7275\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 43.2430 - val_loss: 42.0778\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.8253 - val_loss: 51.8369\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 41.4291 - val_loss: 42.8138\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 609us/step - loss: 39.5872 - val_loss: 39.7895\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 39.5133 - val_loss: 39.3888\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 547us/step - loss: 38.6085 - val_loss: 38.7947\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 37.0182 - val_loss: 37.6994\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.4779 - val_loss: 38.0732\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 37.6472 - val_loss: 37.4542\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 39.0080 - val_loss: 39.3664\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.7521 - val_loss: 38.4344\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 36.1092 - val_loss: 35.8215\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.9757 - val_loss: 37.3181\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 35.4851 - val_loss: 35.9583\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.2517 - val_loss: 36.2693\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 33.2252 - val_loss: 34.9595\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.0334 - val_loss: 35.8541\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.0381 - val_loss: 34.3665\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.8156 - val_loss: 34.5657\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.0050 - val_loss: 36.5900\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.4755 - val_loss: 38.6128\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 34.1638 - val_loss: 34.5940\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 33.3190 - val_loss: 33.7825\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.2860 - val_loss: 35.4686\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.8888 - val_loss: 33.4962\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.6250 - val_loss: 34.9359\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 543us/step - loss: 32.1151 - val_loss: 35.6528\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 560us/step - loss: 31.7038 - val_loss: 32.5734\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.3130 - val_loss: 32.3141\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 30.5675 - val_loss: 33.3037\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.4812 - val_loss: 32.3190\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.4937 - val_loss: 32.4223\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 31.5019 - val_loss: 37.3165\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 32.4656 - val_loss: 32.2489\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.2753 - val_loss: 31.3557\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 701us/step - loss: 28.9108 - val_loss: 30.6033\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 30.3965 - val_loss: 32.7939\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.0522 - val_loss: 30.0700\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.4783 - val_loss: 29.4918\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.1239 - val_loss: 31.5501\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.1252 - val_loss: 29.5133\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.2683 - val_loss: 27.9398\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.8390 - val_loss: 27.3763\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 25.2919 - val_loss: 26.5771\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.5745 - val_loss: 25.9858\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.5440 - val_loss: 26.3169\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 24.2592 - val_loss: 26.2665\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.3779 - val_loss: 25.5251\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.5343 - val_loss: 24.9396\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.3375 - val_loss: 24.8385\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.2362 - val_loss: 24.5652\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.9307 - val_loss: 24.1879\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.6619 - val_loss: 24.0768\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.8589 - val_loss: 23.9894\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.5191 - val_loss: 23.7949\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.2808 - val_loss: 23.7350\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.4157 - val_loss: 23.6166\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.4374 - val_loss: 23.9481\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.3188 - val_loss: 23.5818\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.9406 - val_loss: 23.5852\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.1605 - val_loss: 23.8404\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.0300 - val_loss: 23.6282\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8142 - val_loss: 23.1719\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.6071 - val_loss: 23.5753\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5203 - val_loss: 23.0461\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.4410 - val_loss: 22.9898\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.3434 - val_loss: 23.1091\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.2833 - val_loss: 22.9185\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.2627 - val_loss: 22.9659\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.2217 - val_loss: 22.8621\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.2534 - val_loss: 22.7659\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.0885 - val_loss: 22.7748\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.0118 - val_loss: 23.0886\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.1861 - val_loss: 23.0676\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.0547 - val_loss: 22.7178\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.7842 - val_loss: 22.7796\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.8850 - val_loss: 22.7800\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 20.7250 - val_loss: 22.5323\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.8109 - val_loss: 22.5433\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.6594 - val_loss: 22.4619\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.5074 - val_loss: 22.4766\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.5370 - val_loss: 22.4243\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.4623 - val_loss: 22.3810\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.4966 - val_loss: 22.4298\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.3730 - val_loss: 22.3126\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.5270 - val_loss: 22.6308\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.4165 - val_loss: 22.4185\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.1907 - val_loss: 22.3821\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.1939 - val_loss: 22.7689\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.3382 - val_loss: 22.3625\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.4389 - val_loss: 50.2717\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 46.6737 - val_loss: 43.5392\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 43.4854 - val_loss: 42.0197\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 41.0200 - val_loss: 39.9595\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 41.0708 - val_loss: 38.9644\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.8724 - val_loss: 39.9568\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 39.3822 - val_loss: 37.9200\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 38.8358 - val_loss: 38.2344\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.7576 - val_loss: 37.1798\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.5505 - val_loss: 39.5266\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.8469 - val_loss: 36.5240\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 37.6938 - val_loss: 38.4508\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.4716 - val_loss: 37.9086\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.1275 - val_loss: 35.4100\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.1424 - val_loss: 35.1502\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.2112 - val_loss: 34.3060\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.9878 - val_loss: 33.8942\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.9983 - val_loss: 41.2048\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.0970 - val_loss: 33.5556\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.9507 - val_loss: 35.6443\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.9078 - val_loss: 34.4676\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.9563 - val_loss: 34.5797\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.3926 - val_loss: 32.6198\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.0100 - val_loss: 33.1023\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.2393 - val_loss: 32.9583\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.4984 - val_loss: 32.2875\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 31.3072 - val_loss: 32.5302\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.4061 - val_loss: 32.2067\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.4674 - val_loss: 30.9454\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.5172 - val_loss: 31.6016\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.4922 - val_loss: 31.6085\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.9160 - val_loss: 30.6337\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.2606 - val_loss: 31.3468\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.3646 - val_loss: 31.1814\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.7096 - val_loss: 30.5764\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.6347 - val_loss: 30.7261\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.8614 - val_loss: 28.6604\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 28.6038 - val_loss: 30.7407\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.8266 - val_loss: 27.9299\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.5717 - val_loss: 27.3625\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.2234 - val_loss: 26.8202\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.9411 - val_loss: 26.8915\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 26.1812 - val_loss: 26.2036\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.4427 - val_loss: 26.3789\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 25.1685 - val_loss: 26.9172\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 24.8424 - val_loss: 25.1822\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.1796 - val_loss: 24.9422\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 23.8545 - val_loss: 25.0484\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.5939 - val_loss: 24.7033\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.6580 - val_loss: 24.6489\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.3397 - val_loss: 24.3029\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.1387 - val_loss: 24.0954\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.9369 - val_loss: 23.9819\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.8707 - val_loss: 24.0654\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.7985 - val_loss: 23.9490\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.6057 - val_loss: 23.7212\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.5285 - val_loss: 23.6393\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3749 - val_loss: 23.7793\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3971 - val_loss: 23.4567\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.4962 - val_loss: 23.4042\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.1646 - val_loss: 23.2973\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.0431 - val_loss: 23.3299\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.0984 - val_loss: 23.1797\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.9361 - val_loss: 23.1039\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.9555 - val_loss: 23.0813\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7488 - val_loss: 23.1049\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.6200 - val_loss: 22.9604\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 614us/step - loss: 21.5018 - val_loss: 22.9403\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.4563 - val_loss: 22.8194\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.4733 - val_loss: 23.0701\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3281 - val_loss: 23.1260\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.2513 - val_loss: 22.9129\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3233 - val_loss: 22.7529\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.3776 - val_loss: 22.8710\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0561 - val_loss: 22.6573\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.0694 - val_loss: 22.8792\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.0140 - val_loss: 22.8665\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1602 - val_loss: 22.5615\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.8472 - val_loss: 22.4632\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 20.7806 - val_loss: 22.4803\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.8401 - val_loss: 22.4523\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.6903 - val_loss: 22.3911\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.6059 - val_loss: 22.4420\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6575 - val_loss: 22.8060\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.6203 - val_loss: 22.4270\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.4414 - val_loss: 22.2618\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.3844 - val_loss: 22.2934\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 20.3739 - val_loss: 22.3236\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 20.3472 - val_loss: 22.2997\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.2949 - val_loss: 22.2607\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.2525 - val_loss: 22.3854\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.4547 - val_loss: 22.1937\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.2472 - val_loss: 22.2337\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.0732 - val_loss: 22.1173\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.1410 - val_loss: 22.3517\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.0402 - val_loss: 22.1114\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 19.9484 - val_loss: 22.3166\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 19.9946 - val_loss: 22.1762\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 19.9344 - val_loss: 22.1132\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 19.7492 - val_loss: 22.0735\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.9766 - val_loss: 50.5115\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 46.7916 - val_loss: 44.6240\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 42.4761 - val_loss: 40.3596\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 40.9773 - val_loss: 40.7459\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 40.3889 - val_loss: 39.3049\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.2942 - val_loss: 37.5638\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.8291 - val_loss: 40.0032\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.3536 - val_loss: 36.9887\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.7794 - val_loss: 37.2317\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.0574 - val_loss: 36.4926\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.5076 - val_loss: 35.8527\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.3394 - val_loss: 35.2196\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.9024 - val_loss: 34.3709\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.8447 - val_loss: 33.5393\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.9653 - val_loss: 34.5373\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.5267 - val_loss: 34.5054\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.1093 - val_loss: 35.3494\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.9756 - val_loss: 33.4569\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 33.7953 - val_loss: 32.1626\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.0367 - val_loss: 32.2039\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.8424 - val_loss: 33.1809\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.0266 - val_loss: 32.9018\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 33.2268 - val_loss: 31.9625\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.6673 - val_loss: 31.3766\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.6046 - val_loss: 30.5996\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.3912 - val_loss: 32.5483\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.2505 - val_loss: 30.9625\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.0783 - val_loss: 30.9281\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.2011 - val_loss: 31.2489\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.3785 - val_loss: 30.6938\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 82.5594 - val_loss: 49.9342\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 47.0025 - val_loss: 43.1604\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 43.8836 - val_loss: 40.8957\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.3632 - val_loss: 39.7561\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 41.5513 - val_loss: 40.3031\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.0818 - val_loss: 37.6204\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.8781 - val_loss: 37.9297\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.5829 - val_loss: 37.2622\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.4190 - val_loss: 36.3301\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.4856 - val_loss: 35.0956\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.6307 - val_loss: 34.6463\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.7950 - val_loss: 35.4067\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.2933 - val_loss: 33.7584\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.1819 - val_loss: 34.1286\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 35.2073 - val_loss: 34.2605\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.2963 - val_loss: 33.8280\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 34.6011 - val_loss: 35.2931\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.6530 - val_loss: 32.6162\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.5289 - val_loss: 32.9561\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.0941 - val_loss: 33.0129\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.6687 - val_loss: 32.6959\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.8060 - val_loss: 32.1708\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.2426 - val_loss: 32.3995\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.3457 - val_loss: 31.0780\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.7508 - val_loss: 31.0121\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 32.4878 - val_loss: 31.2081\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.4295 - val_loss: 30.1462\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.3688 - val_loss: 29.6806\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.6964 - val_loss: 31.5685\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.1350 - val_loss: 29.7727\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.3974 - val_loss: 31.1134\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 28.8208 - val_loss: 30.2855\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.6868 - val_loss: 29.0033\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.8503 - val_loss: 26.7918\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.3757 - val_loss: 26.0228\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.5479 - val_loss: 25.3329\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.0187 - val_loss: 25.0210\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.5947 - val_loss: 24.7408\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 24.4039 - val_loss: 24.4669\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.0914 - val_loss: 24.2179\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.8002 - val_loss: 23.9580\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.5100 - val_loss: 23.8681\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.4404 - val_loss: 23.8891\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.2084 - val_loss: 23.6973\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.2234 - val_loss: 23.5465\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.4038 - val_loss: 23.5327\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 23.2356 - val_loss: 23.7051\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.7047 - val_loss: 23.0568\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.4147 - val_loss: 22.9753\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.2542 - val_loss: 22.8387\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 22.1354 - val_loss: 22.8875\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.1627 - val_loss: 23.1055\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.9749 - val_loss: 22.6521\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.0289 - val_loss: 22.8403\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.8597 - val_loss: 22.5333\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.6944 - val_loss: 22.4940\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.5900 - val_loss: 22.4722\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.6019 - val_loss: 22.4837\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.4296 - val_loss: 22.4415\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.3895 - val_loss: 22.6382\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.3731 - val_loss: 22.6372\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.4932 - val_loss: 22.8557\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.5063 - val_loss: 22.4717\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.2567 - val_loss: 22.9704\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.5748 - val_loss: 48.3970\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 45.0456 - val_loss: 44.1798\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 42.7325 - val_loss: 41.2584\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.2179 - val_loss: 41.0155\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.2979 - val_loss: 39.0289\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.6468 - val_loss: 38.6346\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 37.7316 - val_loss: 37.1652\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 36.4578 - val_loss: 36.7674\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 36.3036 - val_loss: 36.4435\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.6835 - val_loss: 36.4350\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 34.9738 - val_loss: 36.4739\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.6286 - val_loss: 36.2141\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 35.3126 - val_loss: 35.2811\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.0145 - val_loss: 36.2882\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.9232 - val_loss: 34.8002\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.0396 - val_loss: 34.9906\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.2845 - val_loss: 34.5919\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.8110 - val_loss: 34.0893\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.3404 - val_loss: 35.6942\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.5370 - val_loss: 34.7213\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.0436 - val_loss: 34.8024\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.8596 - val_loss: 33.7665\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.9127 - val_loss: 33.8948\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.7492 - val_loss: 33.5652\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.4017 - val_loss: 33.4472\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.9247 - val_loss: 32.2382\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 625us/step - loss: 31.1967 - val_loss: 37.9043\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.6617 - val_loss: 31.9163\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.7166 - val_loss: 33.8750\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.5305 - val_loss: 31.5335\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.4262 - val_loss: 31.3721\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.4094 - val_loss: 31.3355\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 29.9023 - val_loss: 30.9463\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.6838 - val_loss: 32.4173\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.1002 - val_loss: 31.3398\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.2798 - val_loss: 31.0064\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.6847 - val_loss: 31.3603\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.8685 - val_loss: 30.6311\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.4516 - val_loss: 30.0821\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.0770 - val_loss: 30.7219\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.3265 - val_loss: 30.5294\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.4776 - val_loss: 30.0290\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.4973 - val_loss: 30.9548\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 28.1593 - val_loss: 30.9620\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 27.9538 - val_loss: 29.3569\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 27.1978 - val_loss: 29.2497\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.3411 - val_loss: 29.5526\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 27.1213 - val_loss: 29.3722\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 27.0502 - val_loss: 28.3317\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.7841 - val_loss: 29.8060\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 26.3995 - val_loss: 27.9500\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 25.6910 - val_loss: 27.4868\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.4482 - val_loss: 27.8333\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.8068 - val_loss: 28.2619\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.4292 - val_loss: 27.2189\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.0697 - val_loss: 27.8966\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.6386 - val_loss: 27.0791\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.8214 - val_loss: 26.6333\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 24.2351 - val_loss: 25.9179\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.6004 - val_loss: 25.2567\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 24.0377 - val_loss: 25.5220\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.9659 - val_loss: 25.4129\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.2686 - val_loss: 25.3725\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.1707 - val_loss: 24.5821\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 22.8838 - val_loss: 24.4857\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.4847 - val_loss: 24.9704\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.5282 - val_loss: 24.4835\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.3647 - val_loss: 23.8822\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.0990 - val_loss: 23.9722\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.9982 - val_loss: 24.3058\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.9397 - val_loss: 24.0045\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.9037 - val_loss: 24.2134\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7527 - val_loss: 23.7182\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.9660 - val_loss: 23.8796\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.7494 - val_loss: 23.3911\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5308 - val_loss: 23.4863\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.4775 - val_loss: 23.3497\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4580 - val_loss: 23.3276\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.3012 - val_loss: 23.4475\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.2906 - val_loss: 23.2810\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.0917 - val_loss: 23.2240\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.1168 - val_loss: 23.2484\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1107 - val_loss: 23.5996\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1828 - val_loss: 23.6173\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.2059 - val_loss: 23.4917\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.9540 - val_loss: 23.3763\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.1550 - val_loss: 52.5434\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 47.4763 - val_loss: 45.2436\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 42.7233 - val_loss: 40.8293\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.4357 - val_loss: 40.3699\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.8588 - val_loss: 40.2068\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.0648 - val_loss: 39.7951\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.7552 - val_loss: 41.9938\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.1214 - val_loss: 39.5946\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.7945 - val_loss: 38.4686\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.0072 - val_loss: 37.3078\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.9481 - val_loss: 35.8272\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.3898 - val_loss: 35.4935\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.1037 - val_loss: 35.2143\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.3194 - val_loss: 34.6008\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.0996 - val_loss: 36.1315\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.6007 - val_loss: 35.2226\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.9605 - val_loss: 35.8971\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 608us/step - loss: 34.5671 - val_loss: 33.4090\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.3999 - val_loss: 33.3834\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.4407 - val_loss: 33.2153\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.4588 - val_loss: 34.4893\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.7605 - val_loss: 33.4842\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.8755 - val_loss: 32.7828\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.4977 - val_loss: 32.9311\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.1290 - val_loss: 31.8972\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.2111 - val_loss: 32.1524\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.6239 - val_loss: 32.3086\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.1714 - val_loss: 31.5292\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.9002 - val_loss: 32.6775\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.9073 - val_loss: 32.1037\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.6764 - val_loss: 30.8632\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.3955 - val_loss: 30.5805\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.9699 - val_loss: 30.9445\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.0154 - val_loss: 30.6350\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 29.9509 - val_loss: 31.2225\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.8733 - val_loss: 30.4778\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.1605 - val_loss: 30.6511\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.4569 - val_loss: 30.3083\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.5421 - val_loss: 30.1530\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.2053 - val_loss: 29.6408\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 29.0251 - val_loss: 28.8567\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.1546 - val_loss: 28.4847\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.4352 - val_loss: 29.0773\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.1063 - val_loss: 30.4140\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 28.1013 - val_loss: 29.2095\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 27.7007 - val_loss: 30.6397\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.7991 - val_loss: 27.6417\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.4727 - val_loss: 27.3663\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.8027 - val_loss: 26.0835\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.7805 - val_loss: 25.3807\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.3555 - val_loss: 25.3086\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.1441 - val_loss: 24.9741\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.9125 - val_loss: 26.1796\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 24.0171 - val_loss: 25.1687\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.6450 - val_loss: 24.4351\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.6078 - val_loss: 24.6007\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.4336 - val_loss: 24.7967\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.4040 - val_loss: 24.2726\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.0176 - val_loss: 23.9073\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.7736 - val_loss: 23.7667\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.7241 - val_loss: 23.8305\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.5999 - val_loss: 23.7210\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4387 - val_loss: 23.5959\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3773 - val_loss: 23.7954\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.5699 - val_loss: 23.4531\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.4949 - val_loss: 24.0051\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.4545 - val_loss: 23.3894\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0126 - val_loss: 23.2760\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9351 - val_loss: 23.2763\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8582 - val_loss: 23.4106\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.7883 - val_loss: 23.1489\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.8045 - val_loss: 23.1681\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5793 - val_loss: 23.1211\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5963 - val_loss: 23.2636\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.6507 - val_loss: 23.1552\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.5089 - val_loss: 23.1698\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3487 - val_loss: 23.1003\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3041 - val_loss: 23.2190\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.3121 - val_loss: 22.9650\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3406 - val_loss: 23.0774\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.1369 - val_loss: 23.0008\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 21.0400 - val_loss: 22.9453\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.9722 - val_loss: 23.0069\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9760 - val_loss: 22.9406\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.9686 - val_loss: 23.2993\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.0778 - val_loss: 22.9657\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.8099 - val_loss: 22.8852\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.6865 - val_loss: 22.8892\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.6870 - val_loss: 22.8798\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.5554 - val_loss: 22.9912\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7615 - val_loss: 22.9072\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.4381 - val_loss: 22.9542\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.4871 - val_loss: 23.2072\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.4448 - val_loss: 22.8033\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.3612 - val_loss: 22.8847\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.4061 - val_loss: 22.9054\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.3258 - val_loss: 22.9418\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.0937 - val_loss: 23.1884\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.3539 - val_loss: 22.9546\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.6504 - val_loss: 47.9743\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 46.2152 - val_loss: 44.0817\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 42.3144 - val_loss: 45.5740\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 41.9985 - val_loss: 40.6849\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.9561 - val_loss: 39.2980\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 39.7890 - val_loss: 39.1143\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.2177 - val_loss: 45.3049\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 39.5258 - val_loss: 43.0526\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.4703 - val_loss: 40.4255\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.7913 - val_loss: 38.4588\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 37.6168 - val_loss: 37.1181\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 37.0526 - val_loss: 44.0460\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.5423 - val_loss: 35.8060\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.2484 - val_loss: 36.1595\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 35.1548 - val_loss: 35.0839\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 738us/step - loss: 37.5252 - val_loss: 37.1510\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 741us/step - loss: 35.5390 - val_loss: 36.2038\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 781us/step - loss: 33.9927 - val_loss: 34.2095\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.4066 - val_loss: 40.4121\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.8316 - val_loss: 34.5752\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.3420 - val_loss: 34.5312\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.4813 - val_loss: 35.1758\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.0084 - val_loss: 33.2646\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.7717 - val_loss: 33.8652\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.2475 - val_loss: 34.9236\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.2913 - val_loss: 33.3429\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 695us/step - loss: 31.9453 - val_loss: 33.9140\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.8023 - val_loss: 32.9144\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.2656 - val_loss: 32.2432\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 31.0260 - val_loss: 32.3700\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.0334 - val_loss: 32.0023\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 30.9685 - val_loss: 31.4769\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.5864 - val_loss: 31.8500\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.0199 - val_loss: 33.3002\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.5383 - val_loss: 31.7566\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.9203 - val_loss: 31.2115\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.4367 - val_loss: 31.3063\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.2444 - val_loss: 32.0105\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.0961 - val_loss: 31.2114\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.6377 - val_loss: 30.3619\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.9144 - val_loss: 31.1093\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.6665 - val_loss: 29.8904\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.5834 - val_loss: 30.3565\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.5513 - val_loss: 29.4625\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.4780 - val_loss: 29.6936\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 28.3593 - val_loss: 30.3005\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.7563 - val_loss: 28.0157\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.1591 - val_loss: 28.5767\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.9586 - val_loss: 27.3966\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 26.5011 - val_loss: 27.3942\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.7609 - val_loss: 26.4256\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.5143 - val_loss: 25.9367\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 25.4621 - val_loss: 26.1342\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 26.0221 - val_loss: 25.2284\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.7273 - val_loss: 24.8378\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.9545 - val_loss: 24.4262\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.6063 - val_loss: 24.1717\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 23.3697 - val_loss: 24.0297\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2421 - val_loss: 23.8378\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 23.0925 - val_loss: 23.8510\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.8679 - val_loss: 23.5309\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.6909 - val_loss: 23.5786\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.5907 - val_loss: 23.5455\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.5154 - val_loss: 23.2183\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4207 - val_loss: 23.1297\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.3581 - val_loss: 23.0762\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.3444 - val_loss: 23.0192\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.0773 - val_loss: 23.2580\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.0510 - val_loss: 22.8416\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.8999 - val_loss: 22.7478\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.8426 - val_loss: 22.6591\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.6989 - val_loss: 22.9987\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 608us/step - loss: 21.6185 - val_loss: 22.7638\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.8686 - val_loss: 22.5755\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.4889 - val_loss: 22.5625\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.5197 - val_loss: 22.8704\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.5656 - val_loss: 22.3919\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.4173 - val_loss: 22.5721\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.2384 - val_loss: 22.3407\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.3196 - val_loss: 22.4597\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 21.2627 - val_loss: 22.6436\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 21.1546 - val_loss: 22.4107\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.1675 - val_loss: 22.2965\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.9587 - val_loss: 22.2152\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.9271 - val_loss: 22.2477\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.8210 - val_loss: 22.2543\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.8184 - val_loss: 22.3871\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.8896 - val_loss: 22.3056\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.8637 - val_loss: 22.3700\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.8018 - val_loss: 45.4962\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 43.9944 - val_loss: 44.5224\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.7716 - val_loss: 45.5587\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.6203 - val_loss: 42.9340\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.5207 - val_loss: 39.9060\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.2214 - val_loss: 39.7283\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 37.7621 - val_loss: 39.3278\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 37.3034 - val_loss: 38.1123\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 37.1581 - val_loss: 38.2585\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.5561 - val_loss: 37.4886\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 38.6112 - val_loss: 41.6712\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 37.1817 - val_loss: 38.2645\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.5144 - val_loss: 39.1558\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.4855 - val_loss: 37.6385\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.9852 - val_loss: 36.8822\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.5091 - val_loss: 36.1866\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 33.9073 - val_loss: 36.9045\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.6166 - val_loss: 35.0708\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.6066 - val_loss: 38.4270\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.7974 - val_loss: 35.6395\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.5463 - val_loss: 36.4183\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.1144 - val_loss: 35.2527\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.4001 - val_loss: 35.1867\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.1430 - val_loss: 49.9433\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 47.2221 - val_loss: 41.2989\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 41.6687 - val_loss: 38.7375\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.7759 - val_loss: 38.7128\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.4951 - val_loss: 37.5987\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.8453 - val_loss: 36.2865\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.1254 - val_loss: 35.0543\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.7171 - val_loss: 35.0573\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 36.0480 - val_loss: 33.7582\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.0502 - val_loss: 34.5754\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.7870 - val_loss: 34.0132\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.5825 - val_loss: 37.9619\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.6209 - val_loss: 33.8667\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.6842 - val_loss: 32.5300\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.0629 - val_loss: 32.0210\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.2912 - val_loss: 36.5562\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.3139 - val_loss: 33.0826\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.0056 - val_loss: 33.0597\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.5950 - val_loss: 32.0349\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.4217 - val_loss: 33.5166\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.8298 - val_loss: 47.8075\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 45.4423 - val_loss: 45.9768\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 41.9887 - val_loss: 42.5644\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 41.7778 - val_loss: 41.0469\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 40.0468 - val_loss: 40.8163\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.9262 - val_loss: 41.6574\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.9964 - val_loss: 44.6378\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.3639 - val_loss: 38.8123\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 37.6492 - val_loss: 38.4951\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.5692 - val_loss: 41.0803\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.8148 - val_loss: 38.0087\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.5197 - val_loss: 40.8666\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.4500 - val_loss: 39.3962\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.8296 - val_loss: 37.8143\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.1118 - val_loss: 36.4178\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.4654 - val_loss: 36.4504\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.9598 - val_loss: 39.1346\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.2017 - val_loss: 37.9593\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.9355 - val_loss: 37.6765\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.5119 - val_loss: 38.1818\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 85.9177 - val_loss: 53.5076\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 50.4565 - val_loss: 45.9769\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 44.8222 - val_loss: 47.8345\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 43.5830 - val_loss: 43.5461\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 40.7048 - val_loss: 38.6385\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 39.0729 - val_loss: 37.9677\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 39.1351 - val_loss: 39.8234\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 38.5358 - val_loss: 47.5216\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.3153 - val_loss: 37.1733\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.4717 - val_loss: 35.7859\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.4230 - val_loss: 35.9485\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.1618 - val_loss: 35.2395\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.9425 - val_loss: 34.8909\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 34.9484 - val_loss: 34.2676\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.1936 - val_loss: 34.1412\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.2064 - val_loss: 33.7120\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 34.4196 - val_loss: 33.9153\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.9595 - val_loss: 34.2149\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 34.1686 - val_loss: 32.6759\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.9997 - val_loss: 32.4624\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.2549 - val_loss: 32.4399\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 32.1215 - val_loss: 33.7755\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.1306 - val_loss: 33.8736\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.9826 - val_loss: 31.0439\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.1022 - val_loss: 31.7196\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.3309 - val_loss: 30.3754\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.6677 - val_loss: 29.6680\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.1788 - val_loss: 28.9950\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.2777 - val_loss: 29.7808\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 28.0456 - val_loss: 29.5498\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 26.9063 - val_loss: 27.5119\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.3375 - val_loss: 26.9941\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.3197 - val_loss: 25.8173\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.0561 - val_loss: 25.5259\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.8233 - val_loss: 25.4717\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.2883 - val_loss: 24.9580\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.0040 - val_loss: 24.5522\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.7263 - val_loss: 24.3784\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.8516 - val_loss: 24.5110\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.5059 - val_loss: 24.0518\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.2541 - val_loss: 24.0712\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.0299 - val_loss: 23.7877\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.9064 - val_loss: 23.6815\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.7562 - val_loss: 23.6768\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.6866 - val_loss: 23.8070\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.7771 - val_loss: 23.8162\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.6183 - val_loss: 23.5105\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3471 - val_loss: 23.3755\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.2866 - val_loss: 23.4191\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.2918 - val_loss: 23.2009\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.1455 - val_loss: 23.1615\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.0275 - val_loss: 23.4633\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.1710 - val_loss: 23.1732\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.8672 - val_loss: 23.0951\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.8760 - val_loss: 23.0654\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.7305 - val_loss: 22.9766\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 21.7857 - val_loss: 22.9106\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.6944 - val_loss: 22.9182\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.6007 - val_loss: 22.8251\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 21.5661 - val_loss: 22.8570\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.4682 - val_loss: 22.8633\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.4688 - val_loss: 22.7508\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.3832 - val_loss: 22.8559\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.4070 - val_loss: 22.6920\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.1879 - val_loss: 23.1298\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.4479 - val_loss: 22.7192\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 21.2413 - val_loss: 22.7025\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.4384 - val_loss: 22.8444\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.1531 - val_loss: 22.6317\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.1060 - val_loss: 22.5830\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.9727 - val_loss: 22.6596\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.9164 - val_loss: 23.0868\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.9556 - val_loss: 22.7064\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 647us/step - loss: 20.8635 - val_loss: 22.5722\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.1156 - val_loss: 23.2953\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 20.8808 - val_loss: 22.6426\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.6820 - val_loss: 22.5944\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.6182 - val_loss: 22.5927\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.5632 - val_loss: 22.5616\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.5386 - val_loss: 22.6481\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.4885 - val_loss: 22.6335\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.6612 - val_loss: 22.6614\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.3839 - val_loss: 22.6856\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.3295 - val_loss: 22.5952\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.7308 - val_loss: 44.0474\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 44.4065 - val_loss: 40.8211\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 899us/step - loss: 40.9846 - val_loss: 39.6045\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 38.9546 - val_loss: 36.2481\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 848us/step - loss: 37.5906 - val_loss: 35.3422\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 854us/step - loss: 36.2899 - val_loss: 35.1933\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 797us/step - loss: 36.3278 - val_loss: 35.5012\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.8482 - val_loss: 34.9973\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 36.6649 - val_loss: 34.4198\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.3829 - val_loss: 32.5592\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.0933 - val_loss: 32.6517\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.9596 - val_loss: 31.4986\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 31.6766 - val_loss: 32.7186\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.5170 - val_loss: 31.4281\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.0937 - val_loss: 34.5106\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.2584 - val_loss: 31.3988\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.7388 - val_loss: 31.5161\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.4087 - val_loss: 30.1900\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 30.3275 - val_loss: 33.4678\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.5984 - val_loss: 30.4122\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.5432 - val_loss: 30.0845\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.1376 - val_loss: 29.0652\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.2685 - val_loss: 30.4388\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.3111 - val_loss: 29.2539\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 29.4315 - val_loss: 28.5467\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 559us/step - loss: 28.9435 - val_loss: 28.4025\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 28.0870 - val_loss: 28.0223\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 28.6065 - val_loss: 31.4591\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.6391 - val_loss: 27.8207\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 556us/step - loss: 29.5665 - val_loss: 28.2935\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.6151 - val_loss: 31.9164\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.9599 - val_loss: 28.0344\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.5169 - val_loss: 28.2817\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 27.2237 - val_loss: 27.3044\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 27.1585 - val_loss: 27.3568\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.4641 - val_loss: 27.5205\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 27.0102 - val_loss: 26.9293\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.8216 - val_loss: 26.7597\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.0536 - val_loss: 28.3372\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.3249 - val_loss: 26.9503\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 26.4311 - val_loss: 26.6421\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.1301 - val_loss: 26.9614\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.0300 - val_loss: 27.3245\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 26.0744 - val_loss: 26.5278\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.6788 - val_loss: 28.4454\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.6738 - val_loss: 31.5067\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.0976 - val_loss: 26.5315\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.3878 - val_loss: 25.8154\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 547us/step - loss: 25.2739 - val_loss: 26.3882\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.2033 - val_loss: 25.8366\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.4084 - val_loss: 25.5863\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 24.9755 - val_loss: 25.5034\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 25.1656 - val_loss: 25.3577\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 25.0859 - val_loss: 25.4955\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 25.3079 - val_loss: 25.5178\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 24.4463 - val_loss: 25.4189\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.6514 - val_loss: 25.7881\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 24.2552 - val_loss: 24.9698\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.2508 - val_loss: 24.8081\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 24.0293 - val_loss: 24.8230\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.2014 - val_loss: 25.8650\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 25.0987 - val_loss: 26.4360\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 25.4116 - val_loss: 25.5958\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.4471 - val_loss: 24.9942\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.0796 - val_loss: 67.2049\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 56.1215 - val_loss: 44.3113\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 45.6983 - val_loss: 42.4221\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 45.4394 - val_loss: 46.6851\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 42.6723 - val_loss: 40.4737\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 41.6530 - val_loss: 41.0117\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 40.0151 - val_loss: 39.0345\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.0338 - val_loss: 38.2759\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.4636 - val_loss: 42.7292\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.5907 - val_loss: 38.5578\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 38.6092 - val_loss: 37.0786\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.4464 - val_loss: 39.9728\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.0749 - val_loss: 36.7710\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.7277 - val_loss: 35.6855\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.1218 - val_loss: 35.4510\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.2620 - val_loss: 35.7852\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.1213 - val_loss: 36.2945\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.9450 - val_loss: 34.4907\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.2072 - val_loss: 37.6759\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.2731 - val_loss: 36.6875\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.0722 - val_loss: 34.5831\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8607 - val_loss: 34.6197\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.7041 - val_loss: 35.1225\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.2474 - val_loss: 52.1274\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 46.9600 - val_loss: 44.4146\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 43.0734 - val_loss: 48.5384\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 42.2917 - val_loss: 42.6953\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.3408 - val_loss: 44.2272\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.3473 - val_loss: 39.6387\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 38.5004 - val_loss: 40.7017\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.1942 - val_loss: 39.5471\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.7949 - val_loss: 41.4338\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.7688 - val_loss: 39.4223\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.0350 - val_loss: 37.0614\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.7990 - val_loss: 36.3847\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.0550 - val_loss: 36.7436\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.8924 - val_loss: 38.8211\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.2831 - val_loss: 37.5897\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 37.0898 - val_loss: 36.2900\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.3969 - val_loss: 35.6218\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.9880 - val_loss: 35.4685\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.6961 - val_loss: 34.5766\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.4365 - val_loss: 34.8971\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.3172 - val_loss: 35.2146\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.2576 - val_loss: 34.7080\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.2273 - val_loss: 34.7826\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.3372 - val_loss: 34.9492\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.5342 - val_loss: 49.5908\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 47.1104 - val_loss: 43.6036\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 45.3316 - val_loss: 42.6583\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 42.6382 - val_loss: 41.6687\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.4113 - val_loss: 39.8819\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.8428 - val_loss: 39.1683\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.0663 - val_loss: 41.0138\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.8780 - val_loss: 38.3620\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 690us/step - loss: 38.6569 - val_loss: 38.1829\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.8997 - val_loss: 38.0929\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 686us/step - loss: 37.0128 - val_loss: 38.1805\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 908us/step - loss: 36.4664 - val_loss: 38.4393\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 36.1519 - val_loss: 36.9506\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.0444 - val_loss: 36.9289\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.1584 - val_loss: 35.5753\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.5430 - val_loss: 36.4397\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.9014 - val_loss: 35.8807\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.5027 - val_loss: 34.6615\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.5213 - val_loss: 34.8536\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.3274 - val_loss: 34.0348\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 33.3797 - val_loss: 33.5541\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.9956 - val_loss: 35.0559\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.5235 - val_loss: 32.9040\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.4057 - val_loss: 32.8735\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.7365 - val_loss: 35.1072\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 34.5277 - val_loss: 32.8173\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.1542 - val_loss: 33.5533\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.9230 - val_loss: 32.8932\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.3010 - val_loss: 32.2373\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.3250 - val_loss: 31.3825\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.4810 - val_loss: 31.3491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.6382 - val_loss: 31.1202\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.7649 - val_loss: 30.9464\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.5107 - val_loss: 30.0097\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.3223 - val_loss: 30.3770\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.5453 - val_loss: 28.5952\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 27.2921 - val_loss: 28.2764\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 27.1784 - val_loss: 27.5683\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 26.8568 - val_loss: 26.8657\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 25.5881 - val_loss: 26.0457\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.0653 - val_loss: 25.5566\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.8343 - val_loss: 25.4393\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 24.3136 - val_loss: 25.1148\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.1748 - val_loss: 24.8176\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.9532 - val_loss: 24.5298\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.5517 - val_loss: 24.3260\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.4492 - val_loss: 24.2614\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 23.3049 - val_loss: 24.5709\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.3000 - val_loss: 23.9937\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.0576 - val_loss: 23.8623\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.8332 - val_loss: 24.0944\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.8772 - val_loss: 23.8071\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.6873 - val_loss: 23.6007\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.4495 - val_loss: 23.5458\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.5194 - val_loss: 23.7818\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.6867 - val_loss: 23.9480\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.2417 - val_loss: 23.3073\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.0589 - val_loss: 23.3558\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.0085 - val_loss: 23.3656\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.0460 - val_loss: 23.4485\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.9111 - val_loss: 23.2122\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7336 - val_loss: 23.1696\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.6789 - val_loss: 23.1360\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.5705 - val_loss: 23.1689\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.5079 - val_loss: 23.1823\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 21.5908 - val_loss: 23.1016\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 21.4187 - val_loss: 23.3353\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2893 - val_loss: 23.1403\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.1705 - val_loss: 23.1256\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.2169 - val_loss: 23.2429\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1713 - val_loss: 23.2764\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 79.7017 - val_loss: 60.3268\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 51.4295 - val_loss: 54.3138\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 48.3751 - val_loss: 45.3844\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 44.1452 - val_loss: 43.2284\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 43.1915 - val_loss: 42.6018\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 42.5362 - val_loss: 41.2940\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.2480 - val_loss: 40.8866\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.9084 - val_loss: 42.1073\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 40.8282 - val_loss: 40.5825\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.3034 - val_loss: 40.9776\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 41.7854 - val_loss: 44.5977\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 41.0617 - val_loss: 38.5528\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.4593 - val_loss: 41.5479\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 38.0863 - val_loss: 38.8704\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.8534 - val_loss: 37.2588\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.0154 - val_loss: 36.5992\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.7149 - val_loss: 36.4486\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.3360 - val_loss: 35.7041\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.8151 - val_loss: 37.6782\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.8449 - val_loss: 35.3460\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.9542 - val_loss: 35.8515\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.1148 - val_loss: 35.0362\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.8214 - val_loss: 34.9649\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.8970 - val_loss: 35.1452\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.1549 - val_loss: 35.1819\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.9845 - val_loss: 32.9875\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.4362 - val_loss: 35.2665\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.7179 - val_loss: 31.9709\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.6260 - val_loss: 31.6243\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.1030 - val_loss: 32.7203\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.0392 - val_loss: 33.3018\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.2829 - val_loss: 29.8522\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.8979 - val_loss: 29.1719\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.1147 - val_loss: 27.7547\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 27.8790 - val_loss: 27.8125\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.9119 - val_loss: 27.0478\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.2230 - val_loss: 26.1437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.4721 - val_loss: 26.1371\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.4886 - val_loss: 26.1946\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.0660 - val_loss: 25.4434\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.7953 - val_loss: 25.2624\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 24.2237 - val_loss: 24.8647\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.0478 - val_loss: 25.0277\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.9933 - val_loss: 24.5735\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 23.6678 - val_loss: 24.3413\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.4677 - val_loss: 24.2212\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 23.3927 - val_loss: 24.0988\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.2131 - val_loss: 23.9524\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.0567 - val_loss: 23.8535\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.8549 - val_loss: 23.8601\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.7787 - val_loss: 23.6144\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.6143 - val_loss: 23.5930\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.6283 - val_loss: 23.4780\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.4373 - val_loss: 23.3707\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.4010 - val_loss: 23.5262\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.4058 - val_loss: 23.3395\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4706 - val_loss: 23.7325\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 22.4407 - val_loss: 23.2170\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 22.0439 - val_loss: 23.1308\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.0363 - val_loss: 23.6190\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.3469 - val_loss: 23.2460\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8677 - val_loss: 22.9323\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6562 - val_loss: 23.0133\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.5903 - val_loss: 23.0594\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.5438 - val_loss: 22.8835\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.4237 - val_loss: 22.8058\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5136 - val_loss: 22.8376\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.3650 - val_loss: 22.7667\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.2417 - val_loss: 22.7962\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 761us/step - loss: 21.1154 - val_loss: 22.7151\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.2222 - val_loss: 23.1825\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.1475 - val_loss: 22.7179\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.0394 - val_loss: 22.6667\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9905 - val_loss: 22.6237\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.9238 - val_loss: 22.6640\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8226 - val_loss: 22.8677\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.8005 - val_loss: 22.5928\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.8681 - val_loss: 22.6051\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9486 - val_loss: 22.6429\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.0044 - val_loss: 22.5686\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.7527 - val_loss: 22.9892\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 20.5638 - val_loss: 22.7792\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.4783 - val_loss: 22.5780\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.4913 - val_loss: 22.4933\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.4111 - val_loss: 22.6542\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.5299 - val_loss: 22.4396\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.3992 - val_loss: 22.5459\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.1663 - val_loss: 22.3461\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.2139 - val_loss: 22.5992\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.2739 - val_loss: 22.5497\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.0677 - val_loss: 22.5873\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.0031 - val_loss: 22.4800\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 19.8789 - val_loss: 22.4856\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.0331 - val_loss: 50.1970\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 44.9822 - val_loss: 41.7244\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 41.5079 - val_loss: 39.5372\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 41.5228 - val_loss: 41.6383\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 41.6426 - val_loss: 40.4937\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 39.6095 - val_loss: 38.2229\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.7053 - val_loss: 37.2416\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 37.5231 - val_loss: 38.5736\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 37.4682 - val_loss: 36.0513\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 37.6659 - val_loss: 37.1965\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.8988 - val_loss: 35.2869\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.6828 - val_loss: 36.7657\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 36.2039 - val_loss: 40.7399\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 37.0227 - val_loss: 34.9339\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 35.0777 - val_loss: 41.0939\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 36.6934 - val_loss: 36.1928\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 34.4985 - val_loss: 35.4421\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 33.8480 - val_loss: 33.8347\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 33.8072 - val_loss: 33.2584\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 33.0119 - val_loss: 32.5733\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.7908 - val_loss: 33.3997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 33.3053 - val_loss: 32.7588\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.8452 - val_loss: 35.4784\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.2080 - val_loss: 32.6342\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 32.1193 - val_loss: 33.3434\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.3814 - val_loss: 49.7178\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 44.6260 - val_loss: 42.7080\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 42.0497 - val_loss: 39.5468\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.9955 - val_loss: 40.9208\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 41.1338 - val_loss: 38.5966\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.6528 - val_loss: 38.8813\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.7488 - val_loss: 38.2951\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.4480 - val_loss: 41.8347\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.6757 - val_loss: 36.2364\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.9992 - val_loss: 37.9684\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.1195 - val_loss: 35.6553\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.6441 - val_loss: 35.4520\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 801us/step - loss: 35.2593 - val_loss: 34.9124\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 34.6945 - val_loss: 35.4846\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.2503 - val_loss: 36.2844\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.0970 - val_loss: 33.7612\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 33.6618 - val_loss: 33.2512\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.9041 - val_loss: 34.2027\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.6374 - val_loss: 37.8709\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.3022 - val_loss: 36.7591\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.1167 - val_loss: 32.7611\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.8989 - val_loss: 32.5194\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.9774 - val_loss: 33.2356\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.8591 - val_loss: 31.6997\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.3442 - val_loss: 31.4295\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.9825 - val_loss: 31.7423\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.1910 - val_loss: 31.5119\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.5155 - val_loss: 31.8003\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.2950 - val_loss: 31.1805\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.0960 - val_loss: 31.2155\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 31.2769 - val_loss: 38.1098\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.5843 - val_loss: 33.0406\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.3456 - val_loss: 30.5633\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.1472 - val_loss: 30.7508\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.7153 - val_loss: 31.4658\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.1165 - val_loss: 30.6219\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.9974 - val_loss: 33.5337\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.5652 - val_loss: 32.3736\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.5814 - val_loss: 45.1207\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 44.1147 - val_loss: 41.6048\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 41.5511 - val_loss: 40.4045\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.0530 - val_loss: 39.1607\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.4548 - val_loss: 41.6033\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.6319 - val_loss: 41.7963\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.0311 - val_loss: 41.8844\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.9277 - val_loss: 38.0474\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.1909 - val_loss: 41.2127\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 38.7851 - val_loss: 37.6882\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.7882 - val_loss: 37.0612\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.4539 - val_loss: 45.9561\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.6406 - val_loss: 38.2408\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.6651 - val_loss: 36.3011\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.9702 - val_loss: 37.0195\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.4061 - val_loss: 38.5766\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.4383 - val_loss: 37.5472\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.9172 - val_loss: 34.3473\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.4890 - val_loss: 37.5212\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.9973 - val_loss: 35.7913\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.8305 - val_loss: 42.8569\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.5694 - val_loss: 37.5745\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.5334 - val_loss: 33.7744\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.0795 - val_loss: 33.6559\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.2839 - val_loss: 33.4431\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.3805 - val_loss: 32.5075\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.6060 - val_loss: 34.7192\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.4346 - val_loss: 33.4036\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.4488 - val_loss: 36.8072\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.7811 - val_loss: 32.6564\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.8687 - val_loss: 32.5412\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 76.6172 - val_loss: 49.2954\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 46.3502 - val_loss: 43.8375\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 43.8846 - val_loss: 42.9908\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 41.2715 - val_loss: 39.8464\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.8576 - val_loss: 39.1437\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.7001 - val_loss: 38.6003\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.4885 - val_loss: 37.7093\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.0381 - val_loss: 40.8395\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.9192 - val_loss: 51.2760\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.9034 - val_loss: 39.0375\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.5552 - val_loss: 37.5153\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.0983 - val_loss: 44.2596\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 39.1830 - val_loss: 36.9467\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.5651 - val_loss: 37.5425\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.4428 - val_loss: 36.3180\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 36.4976 - val_loss: 36.2416\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.2167 - val_loss: 36.2624\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.6954 - val_loss: 34.9792\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.1745 - val_loss: 35.1584\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.0886 - val_loss: 36.4649\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.9156 - val_loss: 37.4791\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.1433 - val_loss: 33.7334\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.0845 - val_loss: 34.0112\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.8502 - val_loss: 33.2115\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.1788 - val_loss: 33.6755\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 33.0575 - val_loss: 33.7636\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.9146 - val_loss: 32.7078\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.6831 - val_loss: 39.6692\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.3850 - val_loss: 33.4140\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 32.0197 - val_loss: 34.0691\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.5689 - val_loss: 31.2517\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.2643 - val_loss: 33.1338\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.4195 - val_loss: 31.5472\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.6141 - val_loss: 31.9408\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.0634 - val_loss: 31.6530\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 30.3845 - val_loss: 31.5863\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.7069 - val_loss: 47.1206\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 44.7796 - val_loss: 40.4039\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 43.0690 - val_loss: 43.2744\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 45.0590 - val_loss: 39.3304\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.1568 - val_loss: 38.5451\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.5591 - val_loss: 36.9039\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.6457 - val_loss: 36.8750\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.4584 - val_loss: 36.2977\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.2360 - val_loss: 35.7590\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.6215 - val_loss: 40.2659\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.4632 - val_loss: 36.0577\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.1868 - val_loss: 34.8423\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.8371 - val_loss: 36.6221\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.4930 - val_loss: 35.9292\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.7326 - val_loss: 33.7807\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.8049 - val_loss: 35.1705\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.9013 - val_loss: 33.5663\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.1169 - val_loss: 34.7349\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.8777 - val_loss: 36.0492\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.1651 - val_loss: 34.3337\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.8191 - val_loss: 32.7191\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.8503 - val_loss: 33.8303\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.2377 - val_loss: 33.1525\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.6429 - val_loss: 32.9273\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.3049 - val_loss: 35.1255\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.0675 - val_loss: 39.6008\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.9879 - val_loss: 50.2656\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 45.4116 - val_loss: 42.5845\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 43.6841 - val_loss: 43.6318\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.9915 - val_loss: 40.9468\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 41.9622 - val_loss: 40.4415\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.5416 - val_loss: 40.8221\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 40.1939 - val_loss: 40.3154\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.4581 - val_loss: 41.3477\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.7563 - val_loss: 42.1955\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.4269 - val_loss: 38.3471\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.0412 - val_loss: 40.2278\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 38.0617 - val_loss: 38.4999\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.0417 - val_loss: 36.5488\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.3929 - val_loss: 36.4301\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.6113 - val_loss: 36.6772\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.9031 - val_loss: 35.5393\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.9667 - val_loss: 35.8166\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.2389 - val_loss: 37.3949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.1802 - val_loss: 37.1213\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.7831 - val_loss: 36.0772\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.3085 - val_loss: 35.9509\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.6982 - val_loss: 49.8690\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 46.9815 - val_loss: 43.3181\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.5733 - val_loss: 41.4777\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 475us/step - loss: 42.5896 - val_loss: 40.3886\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 773us/step - loss: 40.9238 - val_loss: 39.4003\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 776us/step - loss: 39.8098 - val_loss: 38.7526\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 39.6040 - val_loss: 38.1640\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 37.2263 - val_loss: 36.0206\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.4761 - val_loss: 35.7192\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.9864 - val_loss: 38.4506\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 39.7748 - val_loss: 42.1819\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.9973 - val_loss: 35.7568\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.0766 - val_loss: 35.6256\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.0834 - val_loss: 34.8729\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.7317 - val_loss: 34.8117\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.7779 - val_loss: 34.9773\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.9242 - val_loss: 34.9500\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.5658 - val_loss: 35.0776\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.2803 - val_loss: 33.7037\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 33.5927 - val_loss: 36.0760\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.5996 - val_loss: 33.2155\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.9293 - val_loss: 32.7120\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.8143 - val_loss: 34.7749\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.3151 - val_loss: 35.5444\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.7929 - val_loss: 32.9350\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.0525 - val_loss: 31.7814\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.6957 - val_loss: 34.8410\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.6061 - val_loss: 32.2495\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.3036 - val_loss: 32.5382\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.4827 - val_loss: 32.2123\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.1863 - val_loss: 32.6436\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.5294 - val_loss: 45.1850\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 43.4235 - val_loss: 44.7844\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 41.7639 - val_loss: 39.8297\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 41.2543 - val_loss: 39.7456\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.2064 - val_loss: 40.1971\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.8965 - val_loss: 37.7571\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.1368 - val_loss: 35.7134\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.7572 - val_loss: 37.4652\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.8633 - val_loss: 36.4408\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.3507 - val_loss: 34.7902\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.2012 - val_loss: 35.1474\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.9075 - val_loss: 33.8449\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.0933 - val_loss: 34.6593\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.1595 - val_loss: 33.9875\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.3108 - val_loss: 33.1233\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.7327 - val_loss: 33.6513\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.5257 - val_loss: 32.8694\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.5677 - val_loss: 32.4618\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.2386 - val_loss: 33.0046\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.9424 - val_loss: 34.6877\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.8896 - val_loss: 31.9105\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.7102 - val_loss: 31.7761\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.7820 - val_loss: 30.9667\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.7161 - val_loss: 30.6844\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.9860 - val_loss: 30.7794\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.8164 - val_loss: 31.6888\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.5381 - val_loss: 30.7322\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9883 - val_loss: 30.8663\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.1940 - val_loss: 31.7529\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.9145 - val_loss: 46.5944\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 43.5826 - val_loss: 40.7044\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.7104 - val_loss: 40.3384\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.4068 - val_loss: 37.6512\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.7748 - val_loss: 37.3956\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.7008 - val_loss: 36.7013\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.1336 - val_loss: 36.8702\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 37.1671 - val_loss: 35.8294\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.2918 - val_loss: 34.8205\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 35.2609 - val_loss: 34.3235\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.0938 - val_loss: 34.1048\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.3451 - val_loss: 34.9536\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 34.2493 - val_loss: 33.1446\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.7288 - val_loss: 34.1266\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.0698 - val_loss: 33.0769\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.1291 - val_loss: 34.0212\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.7438 - val_loss: 32.3380\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.8215 - val_loss: 32.5271\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.0926 - val_loss: 36.7987\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.5331 - val_loss: 32.7272\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.0367 - val_loss: 31.7579\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.4589 - val_loss: 31.2658\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.2211 - val_loss: 31.3174\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.3536 - val_loss: 32.3527\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.3533 - val_loss: 31.6948\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.6195 - val_loss: 30.4232\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.2606 - val_loss: 30.2910\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.2454 - val_loss: 30.2774\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.9201 - val_loss: 30.1855\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.7490 - val_loss: 29.8667\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.1787 - val_loss: 29.6073\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.3042 - val_loss: 30.0815\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.7896 - val_loss: 31.0170\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.4100 - val_loss: 31.4379\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 29.4239 - val_loss: 29.5620\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.0454 - val_loss: 29.1002\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.2361 - val_loss: 29.3641\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.6109 - val_loss: 30.4808\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.7198 - val_loss: 29.1552\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.0186 - val_loss: 29.5757\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.1360 - val_loss: 28.2464\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.3682 - val_loss: 28.1603\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.3848 - val_loss: 27.6410\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.1429 - val_loss: 28.9918\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.5915 - val_loss: 28.5273\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 26.7802 - val_loss: 27.5786\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 26.4627 - val_loss: 27.2285\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.1699 - val_loss: 26.6274\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.8588 - val_loss: 26.2668\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.0455 - val_loss: 26.0995\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 25.9699 - val_loss: 26.2042\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.9470 - val_loss: 25.4908\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 24.6508 - val_loss: 25.3363\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 24.0798 - val_loss: 25.6690\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 23.8633 - val_loss: 24.6528\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.6095 - val_loss: 24.6590\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.4835 - val_loss: 25.0555\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.7014 - val_loss: 24.1904\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.9440 - val_loss: 23.9831\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.7705 - val_loss: 23.7027\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.0084 - val_loss: 23.6054\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.6337 - val_loss: 23.4953\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.9500 - val_loss: 23.9534\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.8698 - val_loss: 23.8524\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.4662 - val_loss: 23.5610\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.1706 - val_loss: 23.4283\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 22.1129 - val_loss: 23.6751\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0447 - val_loss: 23.1074\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4723 - val_loss: 23.2698\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.2023 - val_loss: 23.1262\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8683 - val_loss: 23.0233\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.7427 - val_loss: 22.8905\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.8182 - val_loss: 22.9414\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.9637 - val_loss: 22.9826\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6811 - val_loss: 22.8714\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.4874 - val_loss: 22.7301\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.4886 - val_loss: 22.8280\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.4707 - val_loss: 22.6799\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.2864 - val_loss: 22.6435\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.2443 - val_loss: 23.0174\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.2174 - val_loss: 22.6209\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.1092 - val_loss: 22.5776\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.1564 - val_loss: 22.7222\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.6435 - val_loss: 22.6527\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.6910 - val_loss: 22.7812\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.0564 - val_loss: 22.5141\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.9708 - val_loss: 22.6269\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0248 - val_loss: 22.6775\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.9845 - val_loss: 22.8895\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.8398 - val_loss: 22.4348\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 630us/step - loss: 21.2841 - val_loss: 22.6321\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2941 - val_loss: 22.4680\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.6972 - val_loss: 22.4201\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.6263 - val_loss: 22.5151\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 351us/step - loss: 20.7206 - val_loss: 22.4066\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 20.5809 - val_loss: 22.3905\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.5401 - val_loss: 22.5195\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.5981 - val_loss: 22.4136\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 20.4414 - val_loss: 22.4182\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.4522 - val_loss: 22.3749\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.3637 - val_loss: 49.3208\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 46.5084 - val_loss: 44.6320\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 42.3752 - val_loss: 46.2972\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 44.1599 - val_loss: 41.3302\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 40.7339 - val_loss: 39.6670\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.9750 - val_loss: 38.9323\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.9772 - val_loss: 38.8882\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 38.6555 - val_loss: 37.6902\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.5906 - val_loss: 37.8965\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 39.5974 - val_loss: 41.5647\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.2727 - val_loss: 36.7742\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.9186 - val_loss: 36.6336\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 36.0592 - val_loss: 35.6544\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 36.0293 - val_loss: 43.2508\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 37.8207 - val_loss: 37.1360\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 36.6740 - val_loss: 37.1797\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 36.4269 - val_loss: 36.2041\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 35.0492 - val_loss: 34.3977\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.7029 - val_loss: 38.1007\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 35.0043 - val_loss: 34.1867\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 34.7848 - val_loss: 33.6788\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.6441 - val_loss: 33.5001\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 33.9123 - val_loss: 33.4112\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 34.8755 - val_loss: 36.5642\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.4066 - val_loss: 34.6440\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 33.9490 - val_loss: 35.0277\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.2662 - val_loss: 36.4810\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.6074 - val_loss: 32.5243\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.3436 - val_loss: 33.1352\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.2718 - val_loss: 31.6661\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 32.5555 - val_loss: 33.6217\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.9551 - val_loss: 32.5315\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.3102 - val_loss: 31.3771\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 810us/step - loss: 33.9624 - val_loss: 34.5801\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 886us/step - loss: 32.6365 - val_loss: 32.6305\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 31.9958 - val_loss: 31.0839\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 899us/step - loss: 31.5223 - val_loss: 32.3373\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 884us/step - loss: 31.2651 - val_loss: 32.3124\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 30.0886 - val_loss: 30.2782\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.0124 - val_loss: 30.6289\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 29.8402 - val_loss: 30.2028\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.3257 - val_loss: 30.6323\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.3258 - val_loss: 30.3323\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.4937 - val_loss: 33.4211\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.0349 - val_loss: 29.3217\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.6080 - val_loss: 29.6669\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.6812 - val_loss: 30.6144\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.5836 - val_loss: 29.0794\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.3795 - val_loss: 28.8056\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.3268 - val_loss: 30.5770\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 28.6379 - val_loss: 31.4250\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.6049 - val_loss: 29.4298\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.6137 - val_loss: 34.1532\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.7173 - val_loss: 28.5218\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.2998 - val_loss: 27.5832\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 27.1141 - val_loss: 27.9228\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 26.5235 - val_loss: 26.8745\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.4279 - val_loss: 27.3921\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 26.0362 - val_loss: 26.6100\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.9147 - val_loss: 26.0955\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.1054 - val_loss: 26.5488\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 25.0660 - val_loss: 25.4547\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.2240 - val_loss: 25.2831\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 24.0566 - val_loss: 24.7414\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.7005 - val_loss: 24.6110\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2859 - val_loss: 24.3004\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.1719 - val_loss: 24.8214\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 620us/step - loss: 23.2216 - val_loss: 24.7313\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 561us/step - loss: 23.0240 - val_loss: 23.9534\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.8323 - val_loss: 23.9205\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.5530 - val_loss: 23.7753\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.4025 - val_loss: 24.1042\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.4590 - val_loss: 23.5352\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.2899 - val_loss: 23.3011\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.0007 - val_loss: 23.2105\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 21.9938 - val_loss: 23.3857\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.3482 - val_loss: 23.1591\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.8287 - val_loss: 23.0187\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.6347 - val_loss: 22.9342\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.5676 - val_loss: 22.9054\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 558us/step - loss: 21.5339 - val_loss: 22.8274\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.4546 - val_loss: 22.8472\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.3554 - val_loss: 22.9141\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3797 - val_loss: 22.9641\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.2248 - val_loss: 22.7489\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.2749 - val_loss: 22.7038\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.0440 - val_loss: 22.7316\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.9666 - val_loss: 22.5339\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.8505 - val_loss: 22.9722\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.0419 - val_loss: 22.5993\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.7491 - val_loss: 22.6590\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.9245 - val_loss: 22.5326\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 20.7879 - val_loss: 22.4312\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.5675 - val_loss: 22.4432\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 20.5641 - val_loss: 22.4838\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.8958 - val_loss: 22.9846\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.4642 - val_loss: 22.7493\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.4830 - val_loss: 22.4351\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.2975 - val_loss: 46.7422\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 45.3586 - val_loss: 41.7619\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.8522 - val_loss: 40.0370\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.6378 - val_loss: 39.3452\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.0902 - val_loss: 39.1630\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.8417 - val_loss: 38.5449\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.9227 - val_loss: 38.8948\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.3530 - val_loss: 36.4386\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.5183 - val_loss: 37.2405\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 37.4952 - val_loss: 35.8329\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.9515 - val_loss: 37.1260\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.9691 - val_loss: 36.3151\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.9890 - val_loss: 35.2909\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.1635 - val_loss: 34.6448\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.9337 - val_loss: 33.8577\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.1223 - val_loss: 35.0181\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.8184 - val_loss: 35.9874\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.4946 - val_loss: 32.6608\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 32.7346 - val_loss: 32.3852\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.8300 - val_loss: 33.1105\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.3832 - val_loss: 32.3322\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.0537 - val_loss: 32.7509\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.3667 - val_loss: 31.9057\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.1913 - val_loss: 32.2628\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.2556 - val_loss: 34.7782\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.8103 - val_loss: 31.9872\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.4825 - val_loss: 32.0816\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.6810 - val_loss: 31.5318\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 31.3078 - val_loss: 31.9353\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.5772 - val_loss: 31.1190\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.0194 - val_loss: 31.6895\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.1619 - val_loss: 30.8398\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.2428 - val_loss: 30.5447\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.7118 - val_loss: 30.7274\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.5651 - val_loss: 30.8708\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.0848 - val_loss: 30.8901\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 29.9258 - val_loss: 31.2871\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.5599 - val_loss: 30.6829\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.6689 - val_loss: 45.6230\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 46.5329 - val_loss: 43.4180\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 42.5641 - val_loss: 43.5542\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.6602 - val_loss: 40.1690\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 41.3421 - val_loss: 44.6425\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.9452 - val_loss: 40.2590\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.5155 - val_loss: 37.6592\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.3666 - val_loss: 40.1465\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.8389 - val_loss: 36.9628\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.5698 - val_loss: 37.1296\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 39.7560 - val_loss: 38.7141\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.6166 - val_loss: 37.1006\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 35.8535 - val_loss: 36.0253\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.6539 - val_loss: 36.7215\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.6735 - val_loss: 34.5874\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 34.5930 - val_loss: 34.5464\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.6990 - val_loss: 35.4921\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.6051 - val_loss: 39.3080\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.3592 - val_loss: 34.9029\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.8280 - val_loss: 33.7194\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.7212 - val_loss: 33.4862\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.0563 - val_loss: 38.1531\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 34.0084 - val_loss: 33.9169\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.7657 - val_loss: 33.1516\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.4627 - val_loss: 33.0143\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.0679 - val_loss: 33.1945\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.3545 - val_loss: 33.9163\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.8180 - val_loss: 32.3486\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.9501 - val_loss: 32.0120\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.6971 - val_loss: 31.9708\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.0384 - val_loss: 31.6680\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.6599 - val_loss: 33.4801\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 31.5384 - val_loss: 32.3455\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.9054 - val_loss: 31.4782\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.3204 - val_loss: 32.1705\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.8920 - val_loss: 31.5397\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.4397 - val_loss: 34.3387\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 30.1413 - val_loss: 31.5066\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 30.1530 - val_loss: 33.9565\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 92.1682 - val_loss: 47.4603\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 43.4044 - val_loss: 39.5586\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.8082 - val_loss: 37.1726\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 563us/step - loss: 38.3610 - val_loss: 36.0030\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.9870 - val_loss: 37.5606\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.7932 - val_loss: 34.2607\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.6035 - val_loss: 33.3536\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.6448 - val_loss: 32.8419\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.8583 - val_loss: 32.5671\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.5463 - val_loss: 31.8702\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 32.8717 - val_loss: 35.4146\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.7917 - val_loss: 31.3054\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.4103 - val_loss: 30.6117\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.8163 - val_loss: 30.6903\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.8400 - val_loss: 30.1705\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.9341 - val_loss: 31.3255\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.6473 - val_loss: 30.0610\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.2584 - val_loss: 29.8867\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 29.5986 - val_loss: 29.2684\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 30.5867 - val_loss: 29.6903\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.1504 - val_loss: 29.2712\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.1682 - val_loss: 29.2984\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.4882 - val_loss: 29.6400\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.3859 - val_loss: 29.1950\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.1645 - val_loss: 28.5118\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 28.2109 - val_loss: 28.0226\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.6235 - val_loss: 29.2294\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.6730 - val_loss: 28.8253\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.5542 - val_loss: 28.0235\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.1422 - val_loss: 28.8512\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 29.3029 - val_loss: 31.8108\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.5459 - val_loss: 53.2901\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 787us/step - loss: 48.3276 - val_loss: 44.5518\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 707us/step - loss: 44.4843 - val_loss: 43.5116\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.5600 - val_loss: 40.3472\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 42.6910 - val_loss: 40.2435\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 40.9897 - val_loss: 39.1776\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 40.4312 - val_loss: 39.6357\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.1693 - val_loss: 38.6981\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.4755 - val_loss: 37.9798\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.9699 - val_loss: 39.8707\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.4205 - val_loss: 36.0345\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 37.5943 - val_loss: 36.6574\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.1025 - val_loss: 36.8176\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.8062 - val_loss: 37.7770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.0273 - val_loss: 35.4654\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 36.6233 - val_loss: 35.7887\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.2001 - val_loss: 36.3970\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.7177 - val_loss: 35.8500\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.9549 - val_loss: 34.5618\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.2297 - val_loss: 34.0612\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.8505 - val_loss: 35.3117\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.6965 - val_loss: 35.1225\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.1280 - val_loss: 34.6453\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.4568 - val_loss: 33.5932\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.8134 - val_loss: 34.0873\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.1670 - val_loss: 32.4312\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.8018 - val_loss: 32.5960\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.0609 - val_loss: 32.6833\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.5668 - val_loss: 33.0228\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.8822 - val_loss: 31.3113\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.3060 - val_loss: 31.2561\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.4742 - val_loss: 31.6825\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.1120 - val_loss: 36.6155\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.9900 - val_loss: 31.7979\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.0829 - val_loss: 31.2944\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.6523 - val_loss: 30.6148\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.6534 - val_loss: 31.6583\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.0277 - val_loss: 31.7796\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.0567 - val_loss: 30.3043\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.6072 - val_loss: 29.5012\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.1779 - val_loss: 30.4121\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 29.7407 - val_loss: 29.2800\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.7310 - val_loss: 28.5750\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 27.5878 - val_loss: 28.2547\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.2322 - val_loss: 28.2884\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 26.3903 - val_loss: 26.3817\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.5438 - val_loss: 25.3393\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.5643 - val_loss: 24.8911\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 24.3643 - val_loss: 24.7045\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 24.0625 - val_loss: 24.2685\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.7025 - val_loss: 24.1116\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.4631 - val_loss: 23.9748\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.1802 - val_loss: 23.7266\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.0414 - val_loss: 23.5067\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.8844 - val_loss: 23.4037\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7566 - val_loss: 23.3899\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.6461 - val_loss: 23.2466\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.5690 - val_loss: 23.2648\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.5862 - val_loss: 23.3792\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3541 - val_loss: 23.0416\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.3152 - val_loss: 22.9829\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.1931 - val_loss: 22.8953\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.0725 - val_loss: 22.8110\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.0413 - val_loss: 22.9590\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.1020 - val_loss: 22.7105\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.0166 - val_loss: 22.7829\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.9123 - val_loss: 22.7474\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.8327 - val_loss: 22.6679\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7829 - val_loss: 22.8549\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.7033 - val_loss: 22.5386\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.6348 - val_loss: 22.5717\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7099 - val_loss: 22.5423\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.7277 - val_loss: 22.5562\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4977 - val_loss: 22.5190\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.4460 - val_loss: 22.8734\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4749 - val_loss: 22.4571\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3501 - val_loss: 22.3702\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.3198 - val_loss: 22.6040\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.3510 - val_loss: 22.4128\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.3405 - val_loss: 22.3934\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.1883 - val_loss: 22.4472\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.3339 - val_loss: 22.3441\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.2511 - val_loss: 22.4004\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.1226 - val_loss: 22.2984\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0350 - val_loss: 22.3424\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0890 - val_loss: 22.4512\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.0382 - val_loss: 22.2599\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.9796 - val_loss: 22.3872\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.3081 - val_loss: 22.6024\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.9314 - val_loss: 22.3111\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0306 - val_loss: 22.4229\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.8303 - val_loss: 22.3693\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.2933 - val_loss: 48.4374\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 47.6290 - val_loss: 42.8831\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 42.6809 - val_loss: 40.9230\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 41.6125 - val_loss: 39.3993\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 40.4796 - val_loss: 38.4457\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.4175 - val_loss: 39.2107\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 38.7731 - val_loss: 38.5960\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 39.1994 - val_loss: 37.3354\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 37.6524 - val_loss: 40.9130\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.3811 - val_loss: 36.5023\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.9517 - val_loss: 35.6897\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.8117 - val_loss: 35.8714\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.0172 - val_loss: 34.7757\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 34.9322 - val_loss: 37.0164\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.8070 - val_loss: 34.7880\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.0052 - val_loss: 35.6661\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.9525 - val_loss: 33.5600\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.8704 - val_loss: 33.7523\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.3876 - val_loss: 34.3830\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.6786 - val_loss: 32.8552\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.3965 - val_loss: 33.1065\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 34.7329 - val_loss: 33.7505\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 33.5696 - val_loss: 32.5409\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.6645 - val_loss: 33.8264\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.0117 - val_loss: 36.0110\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 32.0467 - val_loss: 31.8713\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.0315 - val_loss: 33.3268\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.8038 - val_loss: 31.5749\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.6730 - val_loss: 31.4599\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.6918 - val_loss: 31.6067\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 30.0719 - val_loss: 31.5084\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.1259 - val_loss: 32.3852\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 31.4595 - val_loss: 32.3350\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.5540 - val_loss: 30.7767\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 30.2118 - val_loss: 31.0615\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.5655 - val_loss: 29.9914\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.2934 - val_loss: 30.2399\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.2088 - val_loss: 30.2122\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.9041 - val_loss: 30.6613\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 28.9896 - val_loss: 29.9799\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.5198 - val_loss: 29.4940\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 28.2291 - val_loss: 29.1569\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 27.9730 - val_loss: 28.6831\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.8901 - val_loss: 28.5327\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.1441 - val_loss: 28.7730\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.0488 - val_loss: 28.4558\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.7149 - val_loss: 28.1609\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.0673 - val_loss: 27.5920\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.5885 - val_loss: 27.3223\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.2233 - val_loss: 27.6242\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.0396 - val_loss: 27.1368\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.5092 - val_loss: 26.8919\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.4828 - val_loss: 27.4705\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 25.4397 - val_loss: 25.7467\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.5131 - val_loss: 25.3099\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.3712 - val_loss: 24.9676\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.9848 - val_loss: 24.6924\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.9459 - val_loss: 24.5864\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.4950 - val_loss: 24.4315\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.4190 - val_loss: 24.5590\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 23.3444 - val_loss: 24.1277\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.2339 - val_loss: 24.0515\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.4714 - val_loss: 24.5471\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.3603 - val_loss: 23.6660\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.7362 - val_loss: 23.7039\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.6918 - val_loss: 23.5539\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7203 - val_loss: 23.6104\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.5984 - val_loss: 23.3349\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.3561 - val_loss: 23.3766\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.3330 - val_loss: 23.2141\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.1401 - val_loss: 23.0773\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0665 - val_loss: 23.2463\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.9370 - val_loss: 22.9706\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.9497 - val_loss: 22.9565\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.8608 - val_loss: 22.8990\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.9486 - val_loss: 22.8262\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 600us/step - loss: 21.7069 - val_loss: 22.8062\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9078 - val_loss: 22.8540\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.7285 - val_loss: 22.7450\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.6610 - val_loss: 22.6908\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5218 - val_loss: 22.6595\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.3945 - val_loss: 22.7067\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.3614 - val_loss: 22.6031\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.3035 - val_loss: 22.5127\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.4120 - val_loss: 22.5385\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 21.2560 - val_loss: 22.6472\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.1981 - val_loss: 22.5940\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1278 - val_loss: 22.4914\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 21.1118 - val_loss: 22.4491\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.0325 - val_loss: 22.4371\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 21.0984 - val_loss: 22.3683\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.9097 - val_loss: 22.4007\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.0093 - val_loss: 22.5326\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.7828 - val_loss: 22.3758\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.0360 - val_loss: 22.3223\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.7631 - val_loss: 22.2378\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.6768 - val_loss: 22.5275\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.6017 - val_loss: 22.3441\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.6869 - val_loss: 22.3440\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 20.9837 - val_loss: 22.5205\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.7830 - val_loss: 46.0483\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 44.8145 - val_loss: 40.9594\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.9878 - val_loss: 40.6688\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.5255 - val_loss: 36.1467\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.7951 - val_loss: 35.2858\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.6253 - val_loss: 34.8597\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.0831 - val_loss: 34.0975\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.8118 - val_loss: 34.1541\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 35.2074 - val_loss: 35.1566\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.6849 - val_loss: 34.2588\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.4012 - val_loss: 32.4452\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.0943 - val_loss: 34.0234\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.9066 - val_loss: 34.5496\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.8149 - val_loss: 32.5561\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.5900 - val_loss: 31.5121\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.3591 - val_loss: 30.9761\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 32.7261 - val_loss: 31.0862\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.9517 - val_loss: 30.5366\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.3265 - val_loss: 30.1225\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.8877 - val_loss: 30.0148\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 30.7020 - val_loss: 29.9129\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 30.5847 - val_loss: 29.8979\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.7443 - val_loss: 30.6546\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 29.9508 - val_loss: 32.6838\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.4987 - val_loss: 29.1577\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.2219 - val_loss: 28.3685\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.2311 - val_loss: 32.3511\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.4333 - val_loss: 29.8491\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.4860 - val_loss: 28.4402\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.6522 - val_loss: 27.9603\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.1777 - val_loss: 28.1369\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.8701 - val_loss: 27.4156\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 28.4934 - val_loss: 28.0776\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 27.7957 - val_loss: 27.7389\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.8399 - val_loss: 27.9997\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.8292 - val_loss: 27.0217\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.8471 - val_loss: 27.3728\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.0936 - val_loss: 29.5201\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.2959 - val_loss: 27.6470\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.3979 - val_loss: 26.6297\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.6168 - val_loss: 26.4278\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.9883 - val_loss: 27.9087\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.2576 - val_loss: 26.5404\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.7982 - val_loss: 30.8172\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.3485 - val_loss: 27.3943\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.5619 - val_loss: 26.3026\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.3606 - val_loss: 28.1211\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.6002 - val_loss: 26.3637\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.7240 - val_loss: 25.7946\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 25.8636 - val_loss: 26.0616\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 25.7982 - val_loss: 28.0658\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.7291 - val_loss: 26.6326\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 26.5272 - val_loss: 26.3286\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 603us/step - loss: 26.4000 - val_loss: 27.0123\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 86.7914 - val_loss: 72.2961\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 63.6486 - val_loss: 50.2593\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 48.9563 - val_loss: 43.9398\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 44.7203 - val_loss: 43.4725\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 44.0650 - val_loss: 41.0866\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 42.0361 - val_loss: 39.6619\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.2880 - val_loss: 40.2186\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 40.9394 - val_loss: 38.2571\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.1441 - val_loss: 38.8092\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.8682 - val_loss: 39.3401\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.0397 - val_loss: 36.5742\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.2919 - val_loss: 36.2328\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.6047 - val_loss: 35.7347\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.6515 - val_loss: 35.2907\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.7031 - val_loss: 36.1946\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.0178 - val_loss: 35.6231\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.1825 - val_loss: 34.6877\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.2877 - val_loss: 36.7572\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.4934 - val_loss: 34.1973\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.6642 - val_loss: 36.6453\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.1484 - val_loss: 34.4966\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.3040 - val_loss: 33.5438\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.0743 - val_loss: 34.4654\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.7754 - val_loss: 33.0487\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.6001 - val_loss: 32.5063\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.1765 - val_loss: 31.9742\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.7117 - val_loss: 33.0715\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.8079 - val_loss: 32.8741\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.3067 - val_loss: 30.1324\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.6598 - val_loss: 28.7156\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.5122 - val_loss: 28.8934\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 27.9915 - val_loss: 27.3921\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.1512 - val_loss: 27.2015\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 26.6685 - val_loss: 27.0128\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.0173 - val_loss: 26.2201\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.7615 - val_loss: 25.6198\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.2484 - val_loss: 25.3602\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.1109 - val_loss: 25.3962\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.6928 - val_loss: 25.0328\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.9266 - val_loss: 25.0488\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.4760 - val_loss: 24.5148\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.1607 - val_loss: 24.3070\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.9362 - val_loss: 24.1898\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.7086 - val_loss: 24.0707\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.5697 - val_loss: 23.9858\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 23.3540 - val_loss: 23.6697\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.3360 - val_loss: 24.1276\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.1541 - val_loss: 23.6643\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.9850 - val_loss: 23.6510\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.2445 - val_loss: 23.3228\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.7976 - val_loss: 23.2919\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.6072 - val_loss: 23.2843\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.5176 - val_loss: 23.0918\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.5008 - val_loss: 23.4478\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.6439 - val_loss: 23.2207\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.6881 - val_loss: 22.9160\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.3616 - val_loss: 22.8755\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2596 - val_loss: 22.7755\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.0604 - val_loss: 22.7249\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.1434 - val_loss: 22.6191\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.5660 - val_loss: 23.3953\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.9745 - val_loss: 22.5752\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.7675 - val_loss: 22.5495\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6925 - val_loss: 22.4471\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8290 - val_loss: 22.4940\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.6149 - val_loss: 22.4408\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5245 - val_loss: 22.3579\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5180 - val_loss: 22.3457\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.5573 - val_loss: 22.2557\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.5879 - val_loss: 22.3486\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3130 - val_loss: 22.1906\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2123 - val_loss: 22.1497\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.2884 - val_loss: 22.7857\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.4754 - val_loss: 22.2388\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3010 - val_loss: 22.3929\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2494 - val_loss: 22.0183\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 619us/step - loss: 20.9642 - val_loss: 22.0303\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 20.8915 - val_loss: 22.0129\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.0004 - val_loss: 22.0743\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.9135 - val_loss: 21.8643\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.8685 - val_loss: 21.9089\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.7449 - val_loss: 21.8975\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.6189 - val_loss: 22.0166\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.7331 - val_loss: 21.9325\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.6795 - val_loss: 21.8920\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.6565 - val_loss: 48.3420\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 44.9013 - val_loss: 42.5724\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.1425 - val_loss: 41.4530\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 40.7007 - val_loss: 42.6256\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.5420 - val_loss: 38.2578\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.8593 - val_loss: 38.2579\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.7166 - val_loss: 39.3193\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 39.1157 - val_loss: 37.6334\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 36.7304 - val_loss: 36.1358\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.1204 - val_loss: 39.9298\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.8287 - val_loss: 35.9604\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.4657 - val_loss: 39.5815\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.5401 - val_loss: 40.1336\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.0071 - val_loss: 37.2407\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.3656 - val_loss: 34.7269\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 34.5187 - val_loss: 34.0623\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.9238 - val_loss: 36.1654\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.3363 - val_loss: 35.6347\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.7220 - val_loss: 34.1218\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.8648 - val_loss: 33.5317\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.5848 - val_loss: 35.0579\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.6714 - val_loss: 33.1897\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 33.2578 - val_loss: 34.2728\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.3964 - val_loss: 32.8932\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.1746 - val_loss: 32.6061\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.9715 - val_loss: 32.1278\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.4451 - val_loss: 31.8966\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.1660 - val_loss: 31.5278\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.3176 - val_loss: 34.6335\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.7440 - val_loss: 31.5189\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.1057 - val_loss: 32.5892\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.8606 - val_loss: 34.7638\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.5364 - val_loss: 30.6649\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.9480 - val_loss: 33.7505\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.9495 - val_loss: 31.4971\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.6740 - val_loss: 30.7638\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.8661 - val_loss: 30.7804\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.2311 - val_loss: 32.2467\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.2118 - val_loss: 47.5658\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 46.7683 - val_loss: 43.7846\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 42.8129 - val_loss: 41.4828\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.4767 - val_loss: 41.3504\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.3833 - val_loss: 39.7383\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.9171 - val_loss: 39.5279\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 39.1078 - val_loss: 38.4363\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.6972 - val_loss: 39.6977\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.6473 - val_loss: 39.2497\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.7552 - val_loss: 37.9048\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.0746 - val_loss: 37.5941\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.5720 - val_loss: 39.3347\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.5906 - val_loss: 38.9719\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.1591 - val_loss: 37.6822\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.2739 - val_loss: 36.4733\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.3554 - val_loss: 36.5737\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.0842 - val_loss: 38.6635\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.7015 - val_loss: 35.7862\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.8121 - val_loss: 35.9178\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.2060 - val_loss: 37.5284\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.6687 - val_loss: 34.9819\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.5373 - val_loss: 34.4173\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.0387 - val_loss: 35.3201\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.9886 - val_loss: 34.5049\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.7437 - val_loss: 34.1053\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.8127 - val_loss: 33.4833\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.1975 - val_loss: 35.9451\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.8584 - val_loss: 37.4746\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.1495 - val_loss: 34.0328\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.1160 - val_loss: 32.7257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.6345 - val_loss: 33.2633\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.5861 - val_loss: 33.1592\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.2442 - val_loss: 32.5126\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.4446 - val_loss: 32.6155\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.3930 - val_loss: 33.7460\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.5860 - val_loss: 32.3302\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 30.6415 - val_loss: 34.4594\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 31.5235 - val_loss: 31.9372\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.7723 - val_loss: 32.0185\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.8609 - val_loss: 30.2902\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.7390 - val_loss: 29.7052\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.3572 - val_loss: 31.0640\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 29.4786 - val_loss: 29.2280\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.8330 - val_loss: 28.4534\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.8512 - val_loss: 30.7457\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 28.0466 - val_loss: 27.2231\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 25.8448 - val_loss: 26.2573\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 25.2586 - val_loss: 25.6286\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 491us/step - loss: 24.5765 - val_loss: 25.2609\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 485us/step - loss: 24.3834 - val_loss: 25.2979\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 478us/step - loss: 24.3324 - val_loss: 24.5796\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 484us/step - loss: 23.7314 - val_loss: 24.2523\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.5675 - val_loss: 24.2598\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 733us/step - loss: 23.4004 - val_loss: 24.3086\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 845us/step - loss: 23.2426 - val_loss: 24.0543\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.1704 - val_loss: 23.8913\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.8526 - val_loss: 23.6767\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.7802 - val_loss: 23.8574\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.7091 - val_loss: 24.2018\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 22.6613 - val_loss: 23.5554\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 22.4704 - val_loss: 23.4315\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.3802 - val_loss: 23.4087\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.3565 - val_loss: 23.3876\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.2503 - val_loss: 23.4732\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.2149 - val_loss: 23.2293\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.0706 - val_loss: 23.3129\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9831 - val_loss: 23.2627\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.9826 - val_loss: 23.3602\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 22.1241 - val_loss: 23.1450\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.9006 - val_loss: 23.0297\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 558us/step - loss: 21.6943 - val_loss: 23.0478\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6559 - val_loss: 23.2909\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.6370 - val_loss: 23.0750\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.6299 - val_loss: 22.9711\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5890 - val_loss: 23.0735\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.4524 - val_loss: 22.8564\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3873 - val_loss: 23.0018\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.3470 - val_loss: 23.2690\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3873 - val_loss: 22.8502\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3057 - val_loss: 23.2337\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.2310 - val_loss: 22.8341\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 21.0561 - val_loss: 22.8111\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.0170 - val_loss: 22.7864\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.1801 - val_loss: 23.1905\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.3257 - val_loss: 23.2865\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2110 - val_loss: 22.9731\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.9328 - val_loss: 22.9936\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.9289 - val_loss: 22.9838\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.3298 - val_loss: 53.0341\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 47.0063 - val_loss: 47.2754\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 46.7233 - val_loss: 45.8750\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 44.4530 - val_loss: 44.7550\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 43.1666 - val_loss: 44.1029\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 43.9345 - val_loss: 42.6597\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.3245 - val_loss: 41.7608\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.1577 - val_loss: 41.9581\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.7611 - val_loss: 40.9208\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.7343 - val_loss: 42.7010\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 43.1282 - val_loss: 46.4681\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 42.4882 - val_loss: 42.5957\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.5237 - val_loss: 40.4585\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.8605 - val_loss: 40.4140\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.9314 - val_loss: 39.3702\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.9134 - val_loss: 42.7628\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.3790 - val_loss: 39.9943\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.9607 - val_loss: 38.8600\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.2225 - val_loss: 38.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.9536 - val_loss: 42.2514\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.2650 - val_loss: 36.9113\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.3693 - val_loss: 37.8847\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.9830 - val_loss: 38.6248\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.2077 - val_loss: 38.3623\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 36.8117 - val_loss: 40.5922\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.6267 - val_loss: 39.7968\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.2669 - val_loss: 49.9406\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 46.4942 - val_loss: 42.6438\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 43.7097 - val_loss: 41.1717\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.1691 - val_loss: 38.8788\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.7449 - val_loss: 38.1239\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.4202 - val_loss: 44.8154\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.3994 - val_loss: 39.2119\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 37.6397 - val_loss: 36.9652\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.9282 - val_loss: 35.4906\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 36.0819 - val_loss: 36.1619\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.5874 - val_loss: 34.5119\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.1584 - val_loss: 36.6026\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.9025 - val_loss: 40.0263\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.8836 - val_loss: 37.5049\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.5760 - val_loss: 33.8950\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.7160 - val_loss: 33.6275\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.3829 - val_loss: 32.9466\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 295us/step - loss: 33.0389 - val_loss: 37.0612\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 35.7793 - val_loss: 34.9206\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 33.1781 - val_loss: 33.8478\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.5193 - val_loss: 34.2184\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.9051 - val_loss: 32.8805\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.1351 - val_loss: 32.0737\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 32.0967 - val_loss: 32.1649\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.1559 - val_loss: 33.0839\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.6759 - val_loss: 31.6607\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.3461 - val_loss: 32.1422\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.3453 - val_loss: 33.1077\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 30.9369 - val_loss: 30.9712\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 30.8726 - val_loss: 32.0250\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 686us/step - loss: 31.0661 - val_loss: 32.8089\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 31.4974 - val_loss: 31.1295\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 30.1976 - val_loss: 31.2028\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 31.3819 - val_loss: 31.0864\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.3674 - val_loss: 52.1867\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 48.8806 - val_loss: 46.8031\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 44.0572 - val_loss: 42.0739\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 41.6199 - val_loss: 40.1656\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 39.5986 - val_loss: 38.9454\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 38.9066 - val_loss: 37.8618\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 38.0983 - val_loss: 42.5963\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 38.4413 - val_loss: 36.8945\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 36.6301 - val_loss: 36.0916\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 40.0636 - val_loss: 39.9097\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 36.8756 - val_loss: 37.6804\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 37.3813 - val_loss: 35.5661\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 35.3714 - val_loss: 36.8068\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.3452 - val_loss: 34.8011\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 33.6709 - val_loss: 34.2350\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 33.8712 - val_loss: 36.0828\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 35.7247 - val_loss: 33.7339\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.4314 - val_loss: 34.0268\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 33.4242 - val_loss: 33.2254\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 33.0760 - val_loss: 32.6241\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 32.4558 - val_loss: 32.6547\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.7556 - val_loss: 34.5697\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 855us/step - loss: 33.2799 - val_loss: 32.1956\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 918us/step - loss: 32.3289 - val_loss: 34.7806\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 909us/step - loss: 31.6881 - val_loss: 33.9247\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 921us/step - loss: 30.8937 - val_loss: 33.3932\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 884us/step - loss: 31.1618 - val_loss: 31.1264\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.4127 - val_loss: 31.0624\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.3738 - val_loss: 30.9828\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.4054 - val_loss: 33.9596\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.7980 - val_loss: 32.2105\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.2720 - val_loss: 30.5506\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.5443 - val_loss: 30.7757\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.0538 - val_loss: 32.7196\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.2900 - val_loss: 30.2438\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.0872 - val_loss: 30.2870\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.1882 - val_loss: 30.2772\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.5636 - val_loss: 30.4799\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.1604 - val_loss: 29.7457\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.4801 - val_loss: 31.1422\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.8346 - val_loss: 30.2801\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 28.5490 - val_loss: 29.2675\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 27.7894 - val_loss: 29.2362\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.8371 - val_loss: 28.8976\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.1706 - val_loss: 29.1935\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 27.7072 - val_loss: 29.7605\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.0680 - val_loss: 30.1903\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.6225 - val_loss: 28.9768\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.0625 - val_loss: 28.6747\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.9370 - val_loss: 28.6151\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 26.9586 - val_loss: 29.6800\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 26.9448 - val_loss: 28.1836\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.5656 - val_loss: 29.3687\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.5335 - val_loss: 27.0057\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.6344 - val_loss: 26.8255\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.5528 - val_loss: 26.6598\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 25.2940 - val_loss: 26.4284\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.1882 - val_loss: 26.9619\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 25.3661 - val_loss: 26.2346\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 25.4290 - val_loss: 25.5269\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 24.3961 - val_loss: 25.7776\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 24.2596 - val_loss: 25.2927\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.3954 - val_loss: 26.6427\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 23.9169 - val_loss: 24.8220\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.4401 - val_loss: 24.6380\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.1821 - val_loss: 24.5031\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.3827 - val_loss: 25.2421\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.3773 - val_loss: 24.6657\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.9709 - val_loss: 24.4432\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 23.2456 - val_loss: 24.1173\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.6240 - val_loss: 23.9928\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.4913 - val_loss: 23.9838\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.4224 - val_loss: 23.8696\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.3131 - val_loss: 23.8497\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.1826 - val_loss: 23.7870\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.0591 - val_loss: 23.9742\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0496 - val_loss: 23.8429\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0290 - val_loss: 23.5962\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9606 - val_loss: 23.6835\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.8106 - val_loss: 23.5315\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.8686 - val_loss: 23.8486\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.8571 - val_loss: 23.7403\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.7615 - val_loss: 23.6517\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.6169 - val_loss: 23.5612\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.6857 - val_loss: 23.3119\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3514 - val_loss: 23.3099\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.2332 - val_loss: 23.2739\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.4073 - val_loss: 23.6269\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3777 - val_loss: 23.2830\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0965 - val_loss: 23.3855\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 799us/step - loss: 21.0287 - val_loss: 23.3036\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.8525 - val_loss: 23.2882\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.6420 - val_loss: 51.4960\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 43.8224 - val_loss: 43.3403\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 40.9292 - val_loss: 46.7637\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 44.2152 - val_loss: 41.4261\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 40.0643 - val_loss: 39.4359\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 38.6856 - val_loss: 41.6778\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 38.2142 - val_loss: 37.8854\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 38.9993 - val_loss: 42.5312\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 40.1396 - val_loss: 43.0241\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 40.0305 - val_loss: 41.6328\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.6305 - val_loss: 37.8756\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 37.8929 - val_loss: 36.9254\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.0744 - val_loss: 37.1999\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.7233 - val_loss: 36.8973\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.7515 - val_loss: 37.4829\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 36.5406 - val_loss: 36.6242\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.6857 - val_loss: 35.4456\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 36.1524 - val_loss: 36.2652\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.0089 - val_loss: 37.0816\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 35.1090 - val_loss: 36.4758\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 661us/step - loss: 35.2803 - val_loss: 38.2766\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.0126 - val_loss: 34.7996\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.2329 - val_loss: 37.1084\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.0698 - val_loss: 34.8653\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 33.1016 - val_loss: 35.3298\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.3709 - val_loss: 37.1046\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.6774 - val_loss: 36.0919\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.4718 - val_loss: 51.3403\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 45.9675 - val_loss: 42.1136\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 41.2744 - val_loss: 40.2503\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.9968 - val_loss: 39.4180\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.3971 - val_loss: 46.6722\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.9458 - val_loss: 41.3885\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.3936 - val_loss: 38.7366\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.2279 - val_loss: 47.6841\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.0753 - val_loss: 38.1928\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.0327 - val_loss: 37.5277\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.3335 - val_loss: 38.0671\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.4086 - val_loss: 36.7992\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.9668 - val_loss: 36.1341\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.4476 - val_loss: 35.9456\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 38.3082 - val_loss: 36.7632\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.8857 - val_loss: 39.7026\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.3282 - val_loss: 35.8355\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.5835 - val_loss: 35.2922\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.0524 - val_loss: 37.2094\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.4847 - val_loss: 35.8546\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.6867 - val_loss: 35.7514\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.8176 - val_loss: 34.6141\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.1215 - val_loss: 42.9552\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.0258 - val_loss: 35.9990\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.8499 - val_loss: 34.4373\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.0285 - val_loss: 34.5375\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.1582 - val_loss: 34.5510\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.2165 - val_loss: 35.2796\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.9663 - val_loss: 32.7865\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.6424 - val_loss: 32.4290\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.2522 - val_loss: 32.3175\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.9281 - val_loss: 32.6574\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.5941 - val_loss: 31.8864\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.0067 - val_loss: 32.2925\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.6912 - val_loss: 32.8339\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 31.1799 - val_loss: 32.6346\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.3571 - val_loss: 34.2662\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.0726 - val_loss: 32.3241\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.9073 - val_loss: 47.6452\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 46.2490 - val_loss: 40.7824\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 42.7343 - val_loss: 39.9694\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 44.1215 - val_loss: 39.7910\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 41.3124 - val_loss: 37.7697\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.6491 - val_loss: 39.5013\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.4741 - val_loss: 37.0914\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 42.4929 - val_loss: 38.0643\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 41.5885 - val_loss: 37.1785\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 39.1643 - val_loss: 35.9810\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.7757 - val_loss: 36.7007\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.5936 - val_loss: 38.1760\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.1984 - val_loss: 35.8672\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.0124 - val_loss: 35.5612\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.4955 - val_loss: 36.3950\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.4400 - val_loss: 35.1688\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.6700 - val_loss: 34.2439\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.9321 - val_loss: 32.6082\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.2089 - val_loss: 34.9848\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.1293 - val_loss: 32.8217\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.6739 - val_loss: 35.1057\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.4789 - val_loss: 35.0096\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.6878 - val_loss: 33.0769\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 76.1832 - val_loss: 53.1363\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 46.6086 - val_loss: 43.5925\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 43.3327 - val_loss: 42.9087\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 41.9508 - val_loss: 40.7705\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.7642 - val_loss: 41.0427\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.8313 - val_loss: 40.2322\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.7198 - val_loss: 39.3726\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.9672 - val_loss: 38.2578\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.0194 - val_loss: 38.7011\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.4994 - val_loss: 38.1493\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.3150 - val_loss: 38.4295\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.7118 - val_loss: 36.8756\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.9781 - val_loss: 36.4070\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.5455 - val_loss: 35.7285\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.3243 - val_loss: 35.7241\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.6980 - val_loss: 34.9198\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.4590 - val_loss: 35.0485\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.2268 - val_loss: 38.4664\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.6488 - val_loss: 34.8137\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.9369 - val_loss: 34.6464\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 34.2037 - val_loss: 34.4638\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.4050 - val_loss: 33.7911\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.3756 - val_loss: 33.5986\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.0679 - val_loss: 34.9558\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 32.0749 - val_loss: 33.0640\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.8278 - val_loss: 33.4142\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.4728 - val_loss: 36.4298\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.2680 - val_loss: 33.4351\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.7002 - val_loss: 32.7713\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.3449 - val_loss: 32.2791\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.2171 - val_loss: 32.5557\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.9394 - val_loss: 31.7080\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.6789 - val_loss: 31.0220\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.2339 - val_loss: 31.5512\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 29.1445 - val_loss: 32.2223\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.2679 - val_loss: 31.7801\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.8016 - val_loss: 31.6796\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.9280 - val_loss: 32.2389\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 78.9415 - val_loss: 50.6758\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 49.7710 - val_loss: 44.7074\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 44.2796 - val_loss: 44.7682\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 43.7059 - val_loss: 42.6759\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.2160 - val_loss: 39.2374\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.7941 - val_loss: 39.7292\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 40.1898 - val_loss: 38.5916\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.7112 - val_loss: 37.4353\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.0700 - val_loss: 38.1613\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.3111 - val_loss: 37.4194\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.9711 - val_loss: 35.6514\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.5459 - val_loss: 35.9115\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.8875 - val_loss: 35.1308\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 35.8636 - val_loss: 35.2637\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 710us/step - loss: 36.0739 - val_loss: 34.9052\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 730us/step - loss: 34.8137 - val_loss: 35.4280\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 915us/step - loss: 37.2108 - val_loss: 35.6554\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.5491 - val_loss: 35.6776\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.7105 - val_loss: 34.8883\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.9453 - val_loss: 34.6867\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.4527 - val_loss: 33.6291\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.6005 - val_loss: 33.4992\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.1302 - val_loss: 32.9736\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.1567 - val_loss: 33.8691\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.9680 - val_loss: 34.3738\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 33.0598 - val_loss: 33.7018\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.4132 - val_loss: 31.8387\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.5781 - val_loss: 31.9140\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.2265 - val_loss: 31.3812\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.2297 - val_loss: 31.3380\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.4997 - val_loss: 32.1296\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.0721 - val_loss: 30.8488\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.3717 - val_loss: 32.8960\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.3735 - val_loss: 31.2681\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.7722 - val_loss: 30.5038\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.3222 - val_loss: 30.2357\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.1140 - val_loss: 31.0969\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.1019 - val_loss: 30.5100\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.0007 - val_loss: 30.9030\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.9832 - val_loss: 31.1590\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9139 - val_loss: 32.3384\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.4558 - val_loss: 45.8196\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 43.7935 - val_loss: 41.3511\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.6469 - val_loss: 38.1834\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.9335 - val_loss: 37.5729\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 37.8427 - val_loss: 38.3940\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 657us/step - loss: 38.4410 - val_loss: 41.5997\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.8413 - val_loss: 36.5215\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.9286 - val_loss: 35.8893\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.7343 - val_loss: 38.2916\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.3707 - val_loss: 37.5682\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.0575 - val_loss: 34.8519\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.2980 - val_loss: 38.0274\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.8519 - val_loss: 34.3944\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 34.8619 - val_loss: 35.1797\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.7736 - val_loss: 36.4693\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.1862 - val_loss: 35.0080\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 33.8272 - val_loss: 33.1592\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.7126 - val_loss: 33.5579\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 34.1181 - val_loss: 32.9300\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.0988 - val_loss: 33.8379\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.3694 - val_loss: 33.8001\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.4750 - val_loss: 32.5322\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 32.5759 - val_loss: 31.8245\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.5085 - val_loss: 33.7114\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.6671 - val_loss: 31.8466\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.4486 - val_loss: 36.0240\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.6259 - val_loss: 35.2161\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 33.2040 - val_loss: 31.7280\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.9191 - val_loss: 32.9520\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.3029 - val_loss: 31.2322\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.3528 - val_loss: 30.7104\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 30.2404 - val_loss: 31.0259\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 30.4437 - val_loss: 32.0994\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.4595 - val_loss: 31.6935\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.9081 - val_loss: 30.3335\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.0163 - val_loss: 29.7796\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 29.1687 - val_loss: 29.9566\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 28.9865 - val_loss: 29.4777\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.6496 - val_loss: 29.1557\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.2187 - val_loss: 30.4672\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.0601 - val_loss: 29.4087\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.7188 - val_loss: 28.3518\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.9773 - val_loss: 28.0443\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.3450 - val_loss: 28.0803\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.5114 - val_loss: 27.1933\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 26.8265 - val_loss: 27.2339\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.6323 - val_loss: 26.9098\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.2281 - val_loss: 26.1076\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 25.3301 - val_loss: 27.4374\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.8727 - val_loss: 25.2652\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.5659 - val_loss: 26.4877\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.9376 - val_loss: 24.9284\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 24.1755 - val_loss: 24.6800\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.7524 - val_loss: 24.6317\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.5494 - val_loss: 24.1192\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.2096 - val_loss: 23.7962\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.3187 - val_loss: 24.0683\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.1310 - val_loss: 23.6558\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7247 - val_loss: 23.6292\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.8527 - val_loss: 23.7610\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.7098 - val_loss: 23.3622\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.6565 - val_loss: 23.5516\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.5809 - val_loss: 24.0618\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.5869 - val_loss: 23.5005\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.2388 - val_loss: 23.0798\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.2201 - val_loss: 23.4983\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8776 - val_loss: 22.9689\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.7807 - val_loss: 23.2109\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.0504 - val_loss: 22.9624\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.6878 - val_loss: 22.9126\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.5431 - val_loss: 22.8217\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4629 - val_loss: 22.8160\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.4373 - val_loss: 23.0194\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4936 - val_loss: 22.9033\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.3920 - val_loss: 22.9517\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.4612 - val_loss: 22.8595\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.3559 - val_loss: 23.2474\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.9400 - val_loss: 47.6616\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 44.7875 - val_loss: 41.7934\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.6630 - val_loss: 40.1512\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 40.1223 - val_loss: 39.6399\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.2064 - val_loss: 39.1705\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 618us/step - loss: 39.1362 - val_loss: 40.2883\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 39.2078 - val_loss: 41.6881\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.1398 - val_loss: 40.8227\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.5604 - val_loss: 38.0281\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.0849 - val_loss: 36.0828\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.8071 - val_loss: 39.3229\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.5035 - val_loss: 35.9295\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.4352 - val_loss: 34.7433\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 34.3513 - val_loss: 34.4320\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.1182 - val_loss: 35.0586\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 556us/step - loss: 35.7689 - val_loss: 35.4340\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.3935 - val_loss: 35.0759\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.4249 - val_loss: 37.1574\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.6033 - val_loss: 34.6349\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.4900 - val_loss: 48.4161\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 45.6335 - val_loss: 42.6687\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 43.0689 - val_loss: 42.5962\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 42.5775 - val_loss: 41.0265\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.0722 - val_loss: 39.1176\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.1595 - val_loss: 39.3838\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.9160 - val_loss: 37.5149\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.4521 - val_loss: 37.6913\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.9820 - val_loss: 37.9319\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.4333 - val_loss: 37.2058\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.7132 - val_loss: 35.6636\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.6303 - val_loss: 35.5788\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.5760 - val_loss: 36.5608\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.1331 - val_loss: 35.8423\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.1136 - val_loss: 35.6591\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.5918 - val_loss: 34.4515\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.1465 - val_loss: 34.0397\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.8782 - val_loss: 34.0222\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.3224 - val_loss: 36.7954\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.4575 - val_loss: 34.3496\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.1582 - val_loss: 33.4040\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.2169 - val_loss: 36.6082\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 33.1088 - val_loss: 34.9362\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.8862 - val_loss: 33.7857\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.9648 - val_loss: 32.2452\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.2892 - val_loss: 31.8610\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.3145 - val_loss: 31.9744\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.0021 - val_loss: 31.7674\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7690 - val_loss: 33.2271\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 31.8637 - val_loss: 31.3702\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.4419 - val_loss: 31.3791\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.7876 - val_loss: 32.3250\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.2235 - val_loss: 32.3635\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.6258 - val_loss: 31.0662\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.4890 - val_loss: 30.3001\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.1976 - val_loss: 30.3386\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.1685 - val_loss: 30.8753\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.5348 - val_loss: 30.1198\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.5628 - val_loss: 29.8846\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.2058 - val_loss: 30.4088\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.0562 - val_loss: 29.7902\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.7358 - val_loss: 28.9693\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.4069 - val_loss: 29.8563\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.2693 - val_loss: 29.0158\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.8873 - val_loss: 28.9165\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.7109 - val_loss: 28.7507\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.7870 - val_loss: 29.2680\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 28.1747 - val_loss: 28.3104\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.3277 - val_loss: 27.3806\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 26.7487 - val_loss: 27.0952\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.9584 - val_loss: 27.1131\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 26.7756 - val_loss: 26.6792\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 25.6239 - val_loss: 26.3733\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 25.3526 - val_loss: 25.4337\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.5131 - val_loss: 25.6730\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 24.7149 - val_loss: 24.8365\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.9526 - val_loss: 24.5823\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.2838 - val_loss: 24.9540\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.0425 - val_loss: 24.3495\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.7237 - val_loss: 24.9327\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.3334 - val_loss: 24.0975\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.5082 - val_loss: 23.8108\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 23.1947 - val_loss: 23.6986\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 632us/step - loss: 22.8043 - val_loss: 24.0460\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.6431 - val_loss: 23.4071\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.4732 - val_loss: 23.3955\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.4474 - val_loss: 23.4783\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.2691 - val_loss: 23.2660\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2848 - val_loss: 23.6744\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.1133 - val_loss: 23.1583\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.9663 - val_loss: 23.1396\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.0481 - val_loss: 23.1375\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.8466 - val_loss: 23.1817\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.8551 - val_loss: 23.3001\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8289 - val_loss: 23.1108\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7175 - val_loss: 22.9571\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5297 - val_loss: 22.8918\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5011 - val_loss: 22.8934\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.4552 - val_loss: 22.8126\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.3493 - val_loss: 22.9417\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.4235 - val_loss: 22.8373\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2920 - val_loss: 22.8084\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.2058 - val_loss: 22.9602\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1403 - val_loss: 22.7602\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.0875 - val_loss: 23.3101\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1273 - val_loss: 22.6781\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.8927 - val_loss: 22.7079\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9476 - val_loss: 22.6901\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.9898 - val_loss: 22.8447\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.8525 - val_loss: 22.6431\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 20.7889 - val_loss: 22.5976\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.6756 - val_loss: 22.6960\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.5593 - val_loss: 22.6347\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.5284 - val_loss: 22.6361\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.6052 - val_loss: 22.7193\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.4551 - val_loss: 22.7517\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 78.5650 - val_loss: 49.5712\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 47.1586 - val_loss: 43.8773\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.3742 - val_loss: 40.1075\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.6716 - val_loss: 41.7483\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.8363 - val_loss: 38.4876\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.7338 - val_loss: 38.5255\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.7440 - val_loss: 38.6064\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.8296 - val_loss: 37.0154\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.4189 - val_loss: 35.5846\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.8962 - val_loss: 35.5039\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.0079 - val_loss: 34.5201\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.7509 - val_loss: 35.3148\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.8540 - val_loss: 34.6831\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.2892 - val_loss: 33.6701\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.6351 - val_loss: 33.5568\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.4410 - val_loss: 33.4336\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.9905 - val_loss: 35.4241\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.9710 - val_loss: 33.1775\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.8412 - val_loss: 33.1461\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.9192 - val_loss: 33.7812\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.8751 - val_loss: 31.9163\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.4943 - val_loss: 32.4054\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.8826 - val_loss: 34.9645\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.9635 - val_loss: 32.7548\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.9772 - val_loss: 32.3458\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.2555 - val_loss: 36.5546\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.2752 - val_loss: 46.5385\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 45.0182 - val_loss: 41.4759\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 42.8151 - val_loss: 40.0741\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.9227 - val_loss: 40.7831\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 41.2609 - val_loss: 39.5872\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.6310 - val_loss: 40.4097\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.9449 - val_loss: 38.1786\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.5989 - val_loss: 38.4915\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.1396 - val_loss: 37.0817\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.1562 - val_loss: 35.7870\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.5387 - val_loss: 38.2253\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.6595 - val_loss: 37.6007\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 37.0981 - val_loss: 36.1271\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.2995 - val_loss: 35.1573\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.3943 - val_loss: 34.5424\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.1436 - val_loss: 34.2973\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.0994 - val_loss: 35.8591\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.5766 - val_loss: 33.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.9409 - val_loss: 34.5634\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 561us/step - loss: 34.3457 - val_loss: 35.2929\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 33.6261 - val_loss: 33.6226\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.9881 - val_loss: 34.0438\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.8755 - val_loss: 34.5338\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.1889 - val_loss: 46.6493\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 43.1258 - val_loss: 40.5644\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.2465 - val_loss: 37.1840\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.1462 - val_loss: 36.9278\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.4573 - val_loss: 34.5008\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.5773 - val_loss: 35.3625\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.0837 - val_loss: 33.7657\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.9065 - val_loss: 32.5796\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.0163 - val_loss: 34.2523\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.7291 - val_loss: 33.0674\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.4755 - val_loss: 31.8679\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.4359 - val_loss: 31.3426\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.0300 - val_loss: 32.6467\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.5193 - val_loss: 31.6500\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 33.1161 - val_loss: 31.2084\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 31.8403 - val_loss: 30.9154\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.4932 - val_loss: 30.4350\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.7771 - val_loss: 31.1149\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.0650 - val_loss: 30.4406\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.5917 - val_loss: 30.0354\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.2616 - val_loss: 29.5667\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 30.2852 - val_loss: 31.7343\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.5714 - val_loss: 29.3482\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.0650 - val_loss: 29.4515\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.6674 - val_loss: 30.4960\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.7414 - val_loss: 29.0357\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.3017 - val_loss: 29.0119\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 29.3786 - val_loss: 29.2478\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.0322 - val_loss: 30.8032\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.4078 - val_loss: 32.7592\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.0039 - val_loss: 28.9229\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.7592 - val_loss: 28.7715\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 28.7370 - val_loss: 28.2779\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.7057 - val_loss: 28.2622\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.9998 - val_loss: 29.8597\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.9683 - val_loss: 27.7624\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.8888 - val_loss: 27.5569\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.7647 - val_loss: 28.7844\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.7883 - val_loss: 27.9478\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 27.5410 - val_loss: 27.1978\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.9204 - val_loss: 27.4720\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.1728 - val_loss: 27.1035\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.7693 - val_loss: 26.6628\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.9101 - val_loss: 27.5805\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 26.9626 - val_loss: 27.7308\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 27.3434 - val_loss: 26.5171\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 26.2220 - val_loss: 26.4726\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 25.5793 - val_loss: 25.9932\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 26.0581 - val_loss: 25.9686\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.6758 - val_loss: 25.7608\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.5884 - val_loss: 24.8377\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 24.3793 - val_loss: 24.4960\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.1080 - val_loss: 24.5080\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.8148 - val_loss: 23.8277\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.6567 - val_loss: 23.6370\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.1296 - val_loss: 23.3272\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 565us/step - loss: 22.9266 - val_loss: 23.5385\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.1502 - val_loss: 24.4744\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 22.8071 - val_loss: 22.9826\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3269 - val_loss: 22.9828\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.5141 - val_loss: 22.6839\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.0722 - val_loss: 22.5397\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.0769 - val_loss: 23.2274\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.7898 - val_loss: 22.7350\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.0584 - val_loss: 22.4010\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.8453 - val_loss: 22.4909\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.8470 - val_loss: 22.5057\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6319 - val_loss: 22.1100\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7049 - val_loss: 22.1265\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.6235 - val_loss: 22.1689\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4343 - val_loss: 21.9999\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3554 - val_loss: 22.0340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.3101 - val_loss: 21.8418\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.2797 - val_loss: 22.1898\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2635 - val_loss: 22.6253\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.6665 - val_loss: 22.5006\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.4653 - val_loss: 21.8534\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.0831 - val_loss: 21.5916\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.9544 - val_loss: 21.6795\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.0878 - val_loss: 21.6893\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1311 - val_loss: 21.6490\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.8093 - val_loss: 21.7045\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.8391 - val_loss: 21.8723\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.0268 - val_loss: 49.9483\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 44.9328 - val_loss: 43.0629\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 41.9791 - val_loss: 40.4796\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.1483 - val_loss: 39.6870\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 39.4213 - val_loss: 39.2235\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 39.2397 - val_loss: 38.4474\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.0759 - val_loss: 43.1037\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.0696 - val_loss: 38.7633\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.7211 - val_loss: 38.5312\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 37.9826 - val_loss: 37.9707\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.9333 - val_loss: 37.6158\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 698us/step - loss: 37.5416 - val_loss: 36.7340\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 37.0757 - val_loss: 36.6436\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 741us/step - loss: 37.8075 - val_loss: 39.6185\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 779us/step - loss: 36.7463 - val_loss: 37.1695\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.8098 - val_loss: 37.6535\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.9055 - val_loss: 37.7172\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.5943 - val_loss: 36.1699\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.6619 - val_loss: 38.1102\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.7607 - val_loss: 41.0332\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.9311 - val_loss: 35.0710\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.0821 - val_loss: 38.7626\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 35.2553 - val_loss: 36.3235\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 35.3166 - val_loss: 33.8678\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.1531 - val_loss: 34.2008\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.2559 - val_loss: 37.0194\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.5177 - val_loss: 33.9427\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.5890 - val_loss: 33.3741\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.6086 - val_loss: 34.1734\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.9346 - val_loss: 33.0396\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.9913 - val_loss: 32.6359\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.3255 - val_loss: 32.4527\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.4518 - val_loss: 32.3514\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.1032 - val_loss: 31.6708\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 31.5408 - val_loss: 31.7063\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 32.7577 - val_loss: 31.7167\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.3801 - val_loss: 31.9205\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.4728 - val_loss: 31.1927\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.4897 - val_loss: 32.1671\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 713us/step - loss: 31.9306 - val_loss: 32.6922\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.7624 - val_loss: 31.1111\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.6761 - val_loss: 30.5058\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.5362 - val_loss: 31.7530\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.5786 - val_loss: 30.2639\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.3703 - val_loss: 30.6935\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.7829 - val_loss: 32.3592\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.3851 - val_loss: 29.6881\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.6126 - val_loss: 31.9459\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.2378 - val_loss: 30.0318\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.9391 - val_loss: 28.7420\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.2639 - val_loss: 29.9049\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.6331 - val_loss: 32.3696\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.6641 - val_loss: 28.1421\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 27.0000 - val_loss: 29.0606\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.1386 - val_loss: 26.1766\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 25.5327 - val_loss: 25.8073\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.8408 - val_loss: 24.9510\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.2418 - val_loss: 24.5633\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.9146 - val_loss: 24.3991\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.0779 - val_loss: 24.5201\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.7652 - val_loss: 24.3097\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 23.2868 - val_loss: 23.5218\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.2097 - val_loss: 23.5343\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.9145 - val_loss: 23.3002\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.6393 - val_loss: 23.3023\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.4804 - val_loss: 23.1519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4255 - val_loss: 23.1808\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.3366 - val_loss: 22.9503\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.2591 - val_loss: 22.9372\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.1922 - val_loss: 22.7698\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.0174 - val_loss: 22.7454\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.9794 - val_loss: 22.6729\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.9387 - val_loss: 22.7150\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.8925 - val_loss: 22.6620\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7392 - val_loss: 22.4977\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.6747 - val_loss: 22.5690\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.6555 - val_loss: 22.4851\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 305us/step - loss: 21.5675 - val_loss: 22.5599\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.4730 - val_loss: 22.8619\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.4902 - val_loss: 22.3976\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.4410 - val_loss: 22.3692\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3271 - val_loss: 22.3039\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2693 - val_loss: 22.2720\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.2273 - val_loss: 22.2152\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.2040 - val_loss: 22.3941\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.3670 - val_loss: 22.2580\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3392 - val_loss: 22.5545\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.2666 - val_loss: 22.2595\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.0885 - val_loss: 22.2214\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.7874 - val_loss: 46.1854\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 45.4848 - val_loss: 43.7469\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 42.9795 - val_loss: 46.8198\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 42.6012 - val_loss: 40.9156\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 40.1979 - val_loss: 39.3887\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 38.8126 - val_loss: 38.5466\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 37.9201 - val_loss: 38.1471\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 38.5887 - val_loss: 38.1948\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.3739 - val_loss: 36.1351\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 36.7125 - val_loss: 36.5512\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 36.7137 - val_loss: 38.0619\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 37.8792 - val_loss: 37.0822\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 35.4551 - val_loss: 34.9481\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 35.0724 - val_loss: 35.3683\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.5254 - val_loss: 36.0639\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.0507 - val_loss: 35.1227\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 33.6041 - val_loss: 33.9162\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.9538 - val_loss: 33.9316\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.8217 - val_loss: 36.9755\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.7629 - val_loss: 32.8806\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 31.6617 - val_loss: 32.9500\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.0946 - val_loss: 33.3098\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 31.9247 - val_loss: 32.7081\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.2545 - val_loss: 32.7272\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 30.4128 - val_loss: 31.2443\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 30.1673 - val_loss: 34.5090\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 30.9150 - val_loss: 33.2043\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.0913 - val_loss: 31.7853\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 902us/step - loss: 30.0387 - val_loss: 30.1577\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 29.6003 - val_loss: 30.0721\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 848us/step - loss: 29.8882 - val_loss: 30.8496\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 888us/step - loss: 29.4677 - val_loss: 29.8175\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 827us/step - loss: 28.6772 - val_loss: 29.6257\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 27.7274 - val_loss: 28.6394\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 27.0495 - val_loss: 29.9036\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 26.6877 - val_loss: 27.1000\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 26.3785 - val_loss: 26.8558\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.5434 - val_loss: 26.9175\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.0272 - val_loss: 26.2311\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.1750 - val_loss: 25.6270\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.5961 - val_loss: 25.2956\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.3832 - val_loss: 25.3404\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.3186 - val_loss: 25.5637\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.4945 - val_loss: 24.9414\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.7524 - val_loss: 24.5566\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.6195 - val_loss: 24.4161\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.3887 - val_loss: 24.4769\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.4527 - val_loss: 24.3130\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 23.1912 - val_loss: 24.3287\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.3138 - val_loss: 24.2016\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.9811 - val_loss: 24.0539\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 708us/step - loss: 22.8328 - val_loss: 24.0076\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 22.5851 - val_loss: 23.8733\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.6164 - val_loss: 23.8002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.4450 - val_loss: 24.1463\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.6425 - val_loss: 23.8511\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.3874 - val_loss: 23.7106\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.0971 - val_loss: 23.7570\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0143 - val_loss: 23.6224\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.9327 - val_loss: 23.5454\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.8527 - val_loss: 23.5180\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.7666 - val_loss: 23.5297\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.7455 - val_loss: 23.5723\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6151 - val_loss: 23.4864\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.5082 - val_loss: 23.3872\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.4136 - val_loss: 23.6479\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5143 - val_loss: 23.3502\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.4163 - val_loss: 23.3541\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.2419 - val_loss: 23.3999\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.2228 - val_loss: 23.3951\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 558us/step - loss: 21.1869 - val_loss: 23.4936\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.0357 - val_loss: 23.3512\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.6448 - val_loss: 45.0184\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 43.5730 - val_loss: 38.9111\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.2586 - val_loss: 38.3024\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.6948 - val_loss: 38.4689\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.7977 - val_loss: 36.5408\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.7595 - val_loss: 38.4071\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.2697 - val_loss: 35.6593\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.2245 - val_loss: 35.0128\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.7269 - val_loss: 33.8204\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.4454 - val_loss: 32.9213\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.9704 - val_loss: 33.3564\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.9156 - val_loss: 33.9638\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.4779 - val_loss: 31.7874\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.9745 - val_loss: 33.5435\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.4193 - val_loss: 31.4786\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.7449 - val_loss: 35.2146\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.4768 - val_loss: 30.2653\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.4154 - val_loss: 30.3603\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.7176 - val_loss: 29.5813\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.0980 - val_loss: 29.3826\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.7558 - val_loss: 29.7768\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.8682 - val_loss: 32.6996\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.8735 - val_loss: 29.7808\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.2327 - val_loss: 30.6247\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 28.8497 - val_loss: 28.5004\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.1801 - val_loss: 27.9666\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 29.1596 - val_loss: 32.3717\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.9194 - val_loss: 28.6047\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.1451 - val_loss: 28.0293\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.1842 - val_loss: 27.7717\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 29.4582 - val_loss: 32.1216\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.9768 - val_loss: 27.4551\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.2446 - val_loss: 26.7625\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.6285 - val_loss: 26.9602\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.8039 - val_loss: 26.7901\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.7534 - val_loss: 27.8449\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.1792 - val_loss: 28.6233\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.7479 - val_loss: 27.2298\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 93.2242 - val_loss: 86.9126\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 76.5303 - val_loss: 50.1986\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 49.1498 - val_loss: 49.1618\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 45.7375 - val_loss: 46.9827\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 42.7818 - val_loss: 40.1518\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.1817 - val_loss: 39.8887\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.8053 - val_loss: 37.9269\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 39.1411 - val_loss: 38.3139\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.6151 - val_loss: 39.2332\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.8040 - val_loss: 37.9208\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.9063 - val_loss: 39.3717\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.9226 - val_loss: 36.2787\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 36.5701 - val_loss: 36.1569\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.9993 - val_loss: 35.8504\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.3516 - val_loss: 34.9296\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.2209 - val_loss: 34.3453\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.0710 - val_loss: 36.5359\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.5146 - val_loss: 34.2783\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.7784 - val_loss: 35.3352\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 35.2530 - val_loss: 34.0897\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.5462 - val_loss: 32.6360\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.1012 - val_loss: 35.5772\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.7854 - val_loss: 32.8795\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.5150 - val_loss: 34.8212\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.2032 - val_loss: 30.2103\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 29.6339 - val_loss: 29.9846\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.8449 - val_loss: 28.3246\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.9467 - val_loss: 28.4849\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.7230 - val_loss: 28.0041\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.0382 - val_loss: 27.1394\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.6072 - val_loss: 26.7893\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 26.0486 - val_loss: 26.3033\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.6859 - val_loss: 26.3493\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.3150 - val_loss: 25.6909\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.2924 - val_loss: 25.4423\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.7546 - val_loss: 25.3278\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.5229 - val_loss: 24.9376\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.4080 - val_loss: 24.9622\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.1901 - val_loss: 24.4363\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.8448 - val_loss: 24.2612\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.6633 - val_loss: 24.7843\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.7131 - val_loss: 24.3336\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.3104 - val_loss: 23.7391\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.1247 - val_loss: 23.6143\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.9668 - val_loss: 23.5083\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.9482 - val_loss: 23.6772\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.6516 - val_loss: 23.3668\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.5320 - val_loss: 23.4286\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4085 - val_loss: 23.3031\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.4718 - val_loss: 23.1737\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.1770 - val_loss: 23.0055\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.1714 - val_loss: 23.1476\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.1413 - val_loss: 23.3921\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.0086 - val_loss: 22.8794\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.8760 - val_loss: 22.8059\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.9828 - val_loss: 22.8154\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.7210 - val_loss: 22.6718\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.5551 - val_loss: 22.6697\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.4581 - val_loss: 22.7409\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.4225 - val_loss: 22.9010\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.4698 - val_loss: 22.6305\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.3453 - val_loss: 22.7045\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.3391 - val_loss: 22.4881\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.1668 - val_loss: 22.4323\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.1402 - val_loss: 22.5397\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.0585 - val_loss: 22.3944\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.9596 - val_loss: 22.3793\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.8568 - val_loss: 22.5266\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.9029 - val_loss: 22.4687\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.8751 - val_loss: 22.3280\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.6794 - val_loss: 22.3429\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.6979 - val_loss: 22.4466\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.7020 - val_loss: 22.3591\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.6702 - val_loss: 22.3283\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.5428 - val_loss: 22.2295\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.4502 - val_loss: 22.2192\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 20.3313 - val_loss: 22.2016\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.2910 - val_loss: 22.1139\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.3574 - val_loss: 22.1772\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 556us/step - loss: 20.4445 - val_loss: 22.3933\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 20.2254 - val_loss: 22.4356\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.0748 - val_loss: 22.0979\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.0805 - val_loss: 22.6296\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.4672 - val_loss: 22.5856\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.3371 - val_loss: 22.0700\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 19.9133 - val_loss: 22.1466\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 19.7889 - val_loss: 22.6674\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 19.8420 - val_loss: 22.2231\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 19.7179 - val_loss: 21.9605\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 19.5723 - val_loss: 22.0403\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 19.5374 - val_loss: 21.9468\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 19.7491 - val_loss: 22.2076\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 19.5747 - val_loss: 21.9058\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 19.7311 - val_loss: 22.1159\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 19.7105 - val_loss: 21.9565\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 19.7109 - val_loss: 22.9719\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 19.8454 - val_loss: 22.1673\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 614us/step - loss: 19.4361 - val_loss: 21.9703\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.0123 - val_loss: 56.0564\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 48.8588 - val_loss: 48.6864\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 44.4708 - val_loss: 42.0314\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 41.1078 - val_loss: 40.9519\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 40.7487 - val_loss: 39.7332\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 39.1624 - val_loss: 38.5914\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 38.3064 - val_loss: 40.9315\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 39.4190 - val_loss: 39.1892\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.7647 - val_loss: 38.5413\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.8356 - val_loss: 37.2479\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.7250 - val_loss: 35.8459\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 35.2593 - val_loss: 35.6487\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.4355 - val_loss: 37.7830\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.3639 - val_loss: 38.0093\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 37.1913 - val_loss: 36.4959\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.6716 - val_loss: 36.6886\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 35.1702 - val_loss: 34.6981\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.3773 - val_loss: 34.1870\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.9401 - val_loss: 34.2046\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.1747 - val_loss: 34.1986\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.9245 - val_loss: 34.1708\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.2173 - val_loss: 34.0450\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.4675 - val_loss: 34.6770\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.0729 - val_loss: 34.7093\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 32.9406 - val_loss: 34.4927\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.6102 - val_loss: 34.5899\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.0542 - val_loss: 40.5752\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.6181 - val_loss: 49.8175\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 46.1461 - val_loss: 43.2252\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 42.6436 - val_loss: 43.7998\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 44.5968 - val_loss: 42.2541\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.3292 - val_loss: 41.1170\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 40.1539 - val_loss: 39.5115\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 41.2216 - val_loss: 39.7024\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.3166 - val_loss: 39.3637\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 42.8028 - val_loss: 40.4629\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.0505 - val_loss: 38.5241\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.7477 - val_loss: 37.5805\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.9473 - val_loss: 38.0146\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 36.8684 - val_loss: 37.1284\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.3662 - val_loss: 36.4080\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 37.0162 - val_loss: 37.2371\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.7557 - val_loss: 36.5953\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.8767 - val_loss: 36.5009\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 36.7849 - val_loss: 36.8540\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.5955 - val_loss: 42.7337\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 98.1761 - val_loss: 87.4105\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 62.0488 - val_loss: 51.3656\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 46.9599 - val_loss: 44.6423\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 42.9209 - val_loss: 42.5691\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.9415 - val_loss: 41.6197\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.7053 - val_loss: 41.8432\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.1261 - val_loss: 39.3972\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.7503 - val_loss: 39.2726\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.0082 - val_loss: 37.9503\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.0666 - val_loss: 46.7465\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.6215 - val_loss: 38.0453\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.2307 - val_loss: 37.7277\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.5124 - val_loss: 36.8883\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.8900 - val_loss: 35.8672\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.2041 - val_loss: 37.1989\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.3624 - val_loss: 35.0235\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.3935 - val_loss: 35.4174\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.6474 - val_loss: 34.1532\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.5944 - val_loss: 34.7790\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.1418 - val_loss: 33.3311\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.9857 - val_loss: 34.0135\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.1585 - val_loss: 33.1738\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 32.2326 - val_loss: 34.5969\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.9094 - val_loss: 36.0599\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 31.3099 - val_loss: 30.7874\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 29.5962 - val_loss: 29.0755\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.4812 - val_loss: 30.6285\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.3778 - val_loss: 27.9699\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 26.4948 - val_loss: 26.2740\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 25.5466 - val_loss: 25.6617\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.0107 - val_loss: 25.3982\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 24.6494 - val_loss: 24.9577\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 24.3667 - val_loss: 24.9519\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 24.1328 - val_loss: 24.5550\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.9956 - val_loss: 24.3593\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.6315 - val_loss: 24.1294\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.3148 - val_loss: 23.7973\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 23.1915 - val_loss: 23.6249\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.8714 - val_loss: 23.5552\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.8140 - val_loss: 23.3756\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 22.6054 - val_loss: 23.1988\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.4538 - val_loss: 23.1232\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.3699 - val_loss: 23.1727\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 22.2378 - val_loss: 22.9484\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.2012 - val_loss: 22.8632\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.0589 - val_loss: 22.8145\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.9441 - val_loss: 22.8134\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.9410 - val_loss: 22.6789\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.8990 - val_loss: 22.5745\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.7020 - val_loss: 22.5351\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6882 - val_loss: 22.5876\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6447 - val_loss: 22.8407\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.6073 - val_loss: 22.4728\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.6015 - val_loss: 22.4266\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.4669 - val_loss: 22.5800\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.3799 - val_loss: 22.3252\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.2420 - val_loss: 22.3674\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 21.2525 - val_loss: 22.6912\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 760us/step - loss: 21.2008 - val_loss: 22.5712\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 790us/step - loss: 21.2042 - val_loss: 22.4221\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 959us/step - loss: 21.1791 - val_loss: 22.3745\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.2079 - val_loss: 47.9248\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 46.5548 - val_loss: 45.5182\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 43.1121 - val_loss: 42.2600\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.1691 - val_loss: 39.2336\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 40.2026 - val_loss: 40.4519\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.4865 - val_loss: 38.7026\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.1617 - val_loss: 39.8274\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.6282 - val_loss: 41.7664\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.1402 - val_loss: 36.5665\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.5406 - val_loss: 35.9321\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.7869 - val_loss: 37.2140\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.3451 - val_loss: 37.2356\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.9533 - val_loss: 36.6265\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 39.0669 - val_loss: 36.5044\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.4625 - val_loss: 35.8979\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.8479 - val_loss: 35.0985\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 35.2879 - val_loss: 34.6467\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.0527 - val_loss: 34.4288\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.8496 - val_loss: 35.0421\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.0221 - val_loss: 33.7411\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.1870 - val_loss: 34.8349\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.4066 - val_loss: 34.5352\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.2073 - val_loss: 34.9244\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.8908 - val_loss: 34.1122\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 33.4438 - val_loss: 33.1174\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.9647 - val_loss: 33.0742\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.5153 - val_loss: 40.1861\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 36.1722 - val_loss: 33.2812\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.8337 - val_loss: 33.9881\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.4486 - val_loss: 33.3641\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.6288 - val_loss: 33.2231\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.4283 - val_loss: 49.6336\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 46.5703 - val_loss: 43.7023\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 42.3107 - val_loss: 40.1191\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.5842 - val_loss: 38.9682\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.8365 - val_loss: 42.3547\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.5654 - val_loss: 37.2171\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.8609 - val_loss: 36.8044\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.2610 - val_loss: 36.7682\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.9493 - val_loss: 38.2262\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.7618 - val_loss: 37.1323\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.5977 - val_loss: 34.8746\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.2648 - val_loss: 33.9898\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.5539 - val_loss: 34.4698\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 34.4277 - val_loss: 35.3733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.8469 - val_loss: 34.3046\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.9674 - val_loss: 33.6806\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.7489 - val_loss: 33.4156\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.5341 - val_loss: 34.5699\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 33.9314 - val_loss: 33.4633\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.5914 - val_loss: 32.7708\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 32.2784 - val_loss: 32.0224\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.0457 - val_loss: 32.4070\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.6251 - val_loss: 34.2230\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.1612 - val_loss: 33.1231\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.9826 - val_loss: 32.2971\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.9179 - val_loss: 32.7196\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 88.4066 - val_loss: 48.3156\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 46.1582 - val_loss: 45.8957\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 43.3677 - val_loss: 42.5364\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 41.5268 - val_loss: 40.7599\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.4385 - val_loss: 39.2965\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.9583 - val_loss: 44.8610\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.5977 - val_loss: 39.6654\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.5432 - val_loss: 38.6928\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 38.7044 - val_loss: 37.9954\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.6155 - val_loss: 39.5048\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.2160 - val_loss: 38.5793\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.8931 - val_loss: 36.0478\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.0710 - val_loss: 35.9936\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.1895 - val_loss: 36.4175\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.9277 - val_loss: 40.0579\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.8925 - val_loss: 35.9214\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 34.5343 - val_loss: 34.5729\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.6543 - val_loss: 38.5558\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.3947 - val_loss: 37.4370\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.4209 - val_loss: 35.9502\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.7305 - val_loss: 38.3034\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.9627 - val_loss: 35.0367\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 79.3238 - val_loss: 50.2944\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 46.9465 - val_loss: 43.9178\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 44.0543 - val_loss: 42.6388\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 41.7957 - val_loss: 41.1778\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 42.1519 - val_loss: 40.8979\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 44.2283 - val_loss: 41.9595\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 41.8829 - val_loss: 41.0312\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.5485 - val_loss: 41.3553\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 40.1307 - val_loss: 45.9058\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.5745 - val_loss: 40.3364\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.4457 - val_loss: 39.8369\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 39.0243 - val_loss: 37.6935\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.8173 - val_loss: 38.2493\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 38.0256 - val_loss: 40.4930\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.1970 - val_loss: 38.0264\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.3199 - val_loss: 37.5308\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 38.0679 - val_loss: 37.9455\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.3985 - val_loss: 40.0892\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.9585 - val_loss: 36.4064\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 35.0090 - val_loss: 34.5561\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 35.0827 - val_loss: 35.5808\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8789 - val_loss: 34.1283\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 33.6175 - val_loss: 33.4391\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.2754 - val_loss: 36.8979\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.1823 - val_loss: 35.8579\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.3771 - val_loss: 41.3892\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.7318 - val_loss: 34.6144\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.2831 - val_loss: 33.6222\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.5714 - val_loss: 49.1002\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 44.9785 - val_loss: 40.8264\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.1777 - val_loss: 38.7160\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 41.8621 - val_loss: 38.2805\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.0233 - val_loss: 39.3627\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 40.3259 - val_loss: 37.4243\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.3378 - val_loss: 36.7153\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.4393 - val_loss: 40.3100\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 39.6916 - val_loss: 37.2768\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.7255 - val_loss: 39.1060\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.8238 - val_loss: 35.4182\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.6764 - val_loss: 38.9490\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 38.4547 - val_loss: 36.3243\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.9105 - val_loss: 36.3281\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.3848 - val_loss: 34.1198\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.2757 - val_loss: 36.3266\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.7758 - val_loss: 34.4594\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.7981 - val_loss: 33.5683\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.0435 - val_loss: 33.7182\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.1280 - val_loss: 37.0112\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.1571 - val_loss: 36.3383\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.8449 - val_loss: 33.1188\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.9690 - val_loss: 34.2244\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.7456 - val_loss: 34.3977\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.9710 - val_loss: 32.6155\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.5803 - val_loss: 34.3196\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.3742 - val_loss: 32.5569\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.3934 - val_loss: 32.6859\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.3778 - val_loss: 34.5952\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.2207 - val_loss: 34.9341\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.5725 - val_loss: 32.8253\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.3715 - val_loss: 33.0365\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 83.2677 - val_loss: 52.7689\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 46.1329 - val_loss: 45.3804\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 42.7786 - val_loss: 43.1593\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.1135 - val_loss: 45.4160\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.1424 - val_loss: 40.9556\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.6037 - val_loss: 40.6792\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.6499 - val_loss: 39.7019\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.3017 - val_loss: 42.8787\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.6163 - val_loss: 38.8078\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.6991 - val_loss: 48.6247\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.9746 - val_loss: 43.8431\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.0943 - val_loss: 37.4056\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.0109 - val_loss: 36.7316\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.1493 - val_loss: 37.4637\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.8516 - val_loss: 37.0112\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.9562 - val_loss: 38.5044\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.6477 - val_loss: 35.3141\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.0268 - val_loss: 35.5278\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.7356 - val_loss: 36.1657\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.0801 - val_loss: 35.2035\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 33.0439 - val_loss: 36.2631\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 33.0173 - val_loss: 35.1674\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.7578 - val_loss: 37.7988\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.9461 - val_loss: 35.5977\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.5422 - val_loss: 33.7904\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.6981 - val_loss: 33.1209\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.3936 - val_loss: 35.5460\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.3446 - val_loss: 33.4389\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.2646 - val_loss: 34.1469\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.8318 - val_loss: 33.7212\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.8318 - val_loss: 35.2829\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.6061 - val_loss: 51.4963\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 47.7045 - val_loss: 44.3074\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 43.9312 - val_loss: 41.0793\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.8463 - val_loss: 39.3539\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 40.9102 - val_loss: 39.1456\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.9985 - val_loss: 39.6406\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.5607 - val_loss: 40.3921\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.3673 - val_loss: 37.8043\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.0338 - val_loss: 38.9569\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.6768 - val_loss: 35.9964\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.6002 - val_loss: 36.9498\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.0755 - val_loss: 37.0872\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.7881 - val_loss: 35.9416\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 36.0206 - val_loss: 36.2606\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.8583 - val_loss: 36.1000\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.7301 - val_loss: 34.4592\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.0771 - val_loss: 36.9987\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.3396 - val_loss: 33.2052\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.0927 - val_loss: 35.7781\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.6086 - val_loss: 33.2007\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.1475 - val_loss: 36.4860\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.4198 - val_loss: 34.2028\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8301 - val_loss: 39.5646\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.7848 - val_loss: 34.0681\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.8198 - val_loss: 32.7652\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.4711 - val_loss: 32.4329\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.6715 - val_loss: 32.2046\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.5796 - val_loss: 32.2038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.2764 - val_loss: 31.3295\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.0104 - val_loss: 31.4621\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.4758 - val_loss: 32.3470\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.2600 - val_loss: 31.2475\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.8790 - val_loss: 31.0115\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.9544 - val_loss: 37.9358\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.1263 - val_loss: 32.5888\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.7159 - val_loss: 34.1311\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.7042 - val_loss: 33.7209\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.2453 - val_loss: 31.3822\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.5008 - val_loss: 47.7689\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 45.6375 - val_loss: 43.2076\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.0056 - val_loss: 40.1840\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 40.7906 - val_loss: 40.3937\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.4063 - val_loss: 38.2714\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.8861 - val_loss: 37.9350\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.0545 - val_loss: 40.0345\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.0010 - val_loss: 36.7626\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.7750 - val_loss: 36.0159\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 37.2740 - val_loss: 38.2130\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.9753 - val_loss: 38.5853\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.2712 - val_loss: 35.6531\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.9381 - val_loss: 37.3010\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8311 - val_loss: 34.4639\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.4129 - val_loss: 34.8236\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.0796 - val_loss: 37.4252\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.3207 - val_loss: 34.3152\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.2159 - val_loss: 35.6960\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.6195 - val_loss: 34.0076\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.7736 - val_loss: 33.5048\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.1440 - val_loss: 33.0625\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.2756 - val_loss: 32.5904\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.6927 - val_loss: 34.6899\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.3026 - val_loss: 33.7400\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.1411 - val_loss: 32.4391\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.0656 - val_loss: 32.5054\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.5381 - val_loss: 32.4541\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.5388 - val_loss: 32.6885\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.3075 - val_loss: 33.2653\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.2904 - val_loss: 32.0137\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.2201 - val_loss: 33.3016\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.5653 - val_loss: 31.0320\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.9511 - val_loss: 32.9392\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.3735 - val_loss: 32.3054\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.0099 - val_loss: 30.6697\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.4422 - val_loss: 30.5772\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.5175 - val_loss: 30.1614\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.8347 - val_loss: 29.9805\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.7841 - val_loss: 29.7154\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.7070 - val_loss: 29.9242\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.6989 - val_loss: 31.0537\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 28.1221 - val_loss: 28.6025\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.4748 - val_loss: 28.7754\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.9286 - val_loss: 27.7504\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 27.0360 - val_loss: 27.2605\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.0575 - val_loss: 27.9840\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 25.7427 - val_loss: 26.1907\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.4294 - val_loss: 27.1150\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.8676 - val_loss: 25.7524\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.8781 - val_loss: 25.0387\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 24.1621 - val_loss: 24.7000\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.8771 - val_loss: 24.7640\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.9320 - val_loss: 24.3634\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.6186 - val_loss: 24.1176\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.1117 - val_loss: 23.6621\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 23.0389 - val_loss: 24.2764\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.9233 - val_loss: 23.4745\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.7642 - val_loss: 23.3715\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.6775 - val_loss: 23.5168\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.4184 - val_loss: 23.0320\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.3524 - val_loss: 23.1458\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.1946 - val_loss: 22.9556\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.1681 - val_loss: 22.7819\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0103 - val_loss: 22.8646\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.1681 - val_loss: 22.7668\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.8718 - val_loss: 22.6702\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.7171 - val_loss: 22.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.6947 - val_loss: 22.4817\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.6106 - val_loss: 22.4967\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6555 - val_loss: 22.5168\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.6608 - val_loss: 22.3640\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4729 - val_loss: 22.8325\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.4541 - val_loss: 23.4575\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.9237 - val_loss: 22.5886\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.3823 - val_loss: 22.3637\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.3108 - val_loss: 22.3982\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3543 - val_loss: 22.4643\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2090 - val_loss: 22.1435\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.0939 - val_loss: 22.1342\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1485 - val_loss: 22.1656\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.1106 - val_loss: 22.1380\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.0968 - val_loss: 22.1847\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.1039 - val_loss: 22.2184\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9686 - val_loss: 22.0755\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.9628 - val_loss: 22.2519\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.8766 - val_loss: 22.3479\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.9309 - val_loss: 22.0931\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.1371 - val_loss: 22.0916\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.8906 - val_loss: 21.9778\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.7533 - val_loss: 22.1592\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.8873 - val_loss: 22.2842\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.6827 - val_loss: 22.2322\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.7243 - val_loss: 21.9887\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.7134 - val_loss: 22.0050\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.7134 - val_loss: 50.1646\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 47.2155 - val_loss: 47.3241\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 45.3053 - val_loss: 42.2856\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 41.8443 - val_loss: 42.6456\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 41.4789 - val_loss: 41.4137\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 40.4729 - val_loss: 39.4721\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 39.7318 - val_loss: 39.2350\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 793us/step - loss: 40.3957 - val_loss: 38.6845\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 38.7489 - val_loss: 37.9313\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 787us/step - loss: 38.8948 - val_loss: 37.7769\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 898us/step - loss: 37.8587 - val_loss: 37.2595\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 36.7923 - val_loss: 35.9150\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 35.9308 - val_loss: 41.2635\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 36.9921 - val_loss: 35.4821\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 36.2552 - val_loss: 36.0609\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 36.2362 - val_loss: 34.9422\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 34.8895 - val_loss: 37.0560\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 34.5162 - val_loss: 34.6679\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 725us/step - loss: 33.7474 - val_loss: 33.8273\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 694us/step - loss: 34.1788 - val_loss: 35.1231\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 33.8936 - val_loss: 33.2892\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.5289 - val_loss: 33.4326\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 708us/step - loss: 32.7096 - val_loss: 33.4769\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 33.0653 - val_loss: 33.6168\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 32.1178 - val_loss: 33.3890\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.0260 - val_loss: 32.1012\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 31.2559 - val_loss: 34.2656\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 32.1962 - val_loss: 32.8044\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 31.9704 - val_loss: 31.6579\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 31.2199 - val_loss: 32.4641\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 32.0195 - val_loss: 32.0456\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.3573 - val_loss: 32.0712\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 30.7199 - val_loss: 31.2284\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 30.0062 - val_loss: 30.7210\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 30.0953 - val_loss: 30.4084\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 29.3773 - val_loss: 31.0688\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 29.8935 - val_loss: 29.8973\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 29.0544 - val_loss: 29.5727\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.0898 - val_loss: 29.8984\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 29.3211 - val_loss: 29.5071\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 28.7173 - val_loss: 30.1552\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 29.2309 - val_loss: 32.8227\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 29.1924 - val_loss: 29.1910\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 28.4636 - val_loss: 30.0734\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 27.0715 - val_loss: 28.0163\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 26.3977 - val_loss: 27.4263\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 26.4654 - val_loss: 28.8262\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 26.3091 - val_loss: 26.3076\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 25.2792 - val_loss: 26.0299\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 698us/step - loss: 24.8615 - val_loss: 25.4273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 24.2643 - val_loss: 24.7739\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.7571 - val_loss: 24.5828\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.5778 - val_loss: 24.2999\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 23.4887 - val_loss: 25.1805\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.6127 - val_loss: 24.6983\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 23.4579 - val_loss: 24.0103\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 23.1065 - val_loss: 23.8029\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 22.8482 - val_loss: 23.4984\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 22.7169 - val_loss: 23.9190\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.7278 - val_loss: 23.4453\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.2863 - val_loss: 23.3531\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.2443 - val_loss: 23.9471\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.3656 - val_loss: 23.2561\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 865us/step - loss: 22.0235 - val_loss: 23.0715\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.8843 - val_loss: 22.9766\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.8255 - val_loss: 23.0169\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 933us/step - loss: 21.7378 - val_loss: 23.0212\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 798us/step - loss: 21.7178 - val_loss: 22.9842\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 533us/step - loss: 21.7733 - val_loss: 23.3568\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.6267 - val_loss: 22.9727\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.7954 - val_loss: 23.2483\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 21.5294 - val_loss: 22.7699\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3494 - val_loss: 22.7243\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.3762 - val_loss: 22.6296\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2545 - val_loss: 23.0370\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.3132 - val_loss: 22.7727\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.0764 - val_loss: 22.6295\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.0125 - val_loss: 22.6604\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1449 - val_loss: 22.7758\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.3158 - val_loss: 22.7194\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9599 - val_loss: 22.7513\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.7758 - val_loss: 22.4564\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7398 - val_loss: 22.4434\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.6367 - val_loss: 22.6075\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.5552 - val_loss: 22.5476\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.5341 - val_loss: 22.5626\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.5327 - val_loss: 22.5116\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6192 - val_loss: 22.8454\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 91.7176 - val_loss: 57.9275\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 49.0921 - val_loss: 45.9444\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 43.8930 - val_loss: 43.6485\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.1300 - val_loss: 39.6364\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.5089 - val_loss: 39.8007\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.9445 - val_loss: 38.5262\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 38.7231 - val_loss: 37.6466\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.0982 - val_loss: 37.7810\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 36.7422 - val_loss: 35.7296\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.2320 - val_loss: 35.2172\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 36.1817 - val_loss: 35.9213\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.0707 - val_loss: 37.4604\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.2908 - val_loss: 34.7341\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.0619 - val_loss: 33.8683\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 34.6536 - val_loss: 34.7552\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 35.5615 - val_loss: 34.7310\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 34.2113 - val_loss: 38.6352\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.5800 - val_loss: 32.8050\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 747us/step - loss: 34.6305 - val_loss: 35.4736\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 34.2636 - val_loss: 33.2745\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.9520 - val_loss: 32.7849\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.3488 - val_loss: 32.0588\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.9136 - val_loss: 32.3637\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.9013 - val_loss: 31.8577\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.5752 - val_loss: 32.7450\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.3005 - val_loss: 32.2411\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.4250 - val_loss: 31.2876\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.7343 - val_loss: 33.0136\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.8010 - val_loss: 31.1210\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.2666 - val_loss: 30.6393\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.8458 - val_loss: 33.1253\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.3418 - val_loss: 30.7178\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.4099 - val_loss: 34.8060\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.3819 - val_loss: 30.3172\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.7387 - val_loss: 29.9341\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.9246 - val_loss: 30.6592\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.6162 - val_loss: 31.5147\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.5595 - val_loss: 30.5975\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.7821 - val_loss: 28.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.2945 - val_loss: 28.6567\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.1155 - val_loss: 28.0793\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 27.7270 - val_loss: 28.3011\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.0647 - val_loss: 28.7187\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.0299 - val_loss: 27.4304\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 26.1850 - val_loss: 26.8566\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.9984 - val_loss: 26.3900\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 25.4402 - val_loss: 26.4995\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.1116 - val_loss: 25.5620\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.4540 - val_loss: 25.0246\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.4423 - val_loss: 27.2477\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.7800 - val_loss: 25.0268\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.8541 - val_loss: 24.5164\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 23.6026 - val_loss: 24.2432\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 23.3517 - val_loss: 24.1665\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.3148 - val_loss: 24.1168\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.0493 - val_loss: 23.8868\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.0321 - val_loss: 23.8050\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7746 - val_loss: 23.6476\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.7734 - val_loss: 23.7245\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.8019 - val_loss: 23.7093\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6718 - val_loss: 23.5430\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.6460 - val_loss: 23.8797\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.4164 - val_loss: 23.3155\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2015 - val_loss: 23.2006\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.1400 - val_loss: 23.2340\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9701 - val_loss: 23.1424\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.9396 - val_loss: 23.0754\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.8412 - val_loss: 22.9922\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.7532 - val_loss: 23.2338\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.8536 - val_loss: 22.9492\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 21.6015 - val_loss: 22.9249\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.6822 - val_loss: 22.8768\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.5239 - val_loss: 22.8188\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.4513 - val_loss: 22.8957\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3792 - val_loss: 22.7618\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.2823 - val_loss: 22.9436\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.4264 - val_loss: 23.7509\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.4786 - val_loss: 22.7586\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.3088 - val_loss: 22.6192\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.1148 - val_loss: 22.6512\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.1074 - val_loss: 22.8724\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.1151 - val_loss: 22.6659\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.0642 - val_loss: 22.5951\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9459 - val_loss: 22.6361\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.9674 - val_loss: 22.6203\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.8638 - val_loss: 22.5380\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.9062 - val_loss: 23.0650\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.9577 - val_loss: 22.6869\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.7195 - val_loss: 22.5950\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.7206 - val_loss: 22.7542\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6126 - val_loss: 22.5647\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.8885 - val_loss: 55.7340\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 48.9110 - val_loss: 44.6625\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 44.3961 - val_loss: 42.2502\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 42.1154 - val_loss: 42.3759\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.4726 - val_loss: 40.5380\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.3802 - val_loss: 40.1967\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.3958 - val_loss: 38.3335\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.8332 - val_loss: 38.0511\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.1291 - val_loss: 37.1777\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.1237 - val_loss: 36.5614\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.8266 - val_loss: 35.7089\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.1985 - val_loss: 37.7417\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.0186 - val_loss: 35.5876\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.0616 - val_loss: 34.5256\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.5374 - val_loss: 34.2738\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.6942 - val_loss: 38.0683\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.3768 - val_loss: 36.0765\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.3189 - val_loss: 33.6503\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.4211 - val_loss: 33.3211\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.3976 - val_loss: 33.7256\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.2269 - val_loss: 33.9568\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.5979 - val_loss: 32.5050\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.9190 - val_loss: 32.8820\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 32.5104 - val_loss: 35.9713\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 34.3755 - val_loss: 33.3251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.1407 - val_loss: 32.1945\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.0495 - val_loss: 32.7018\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.8740 - val_loss: 31.7588\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.9101 - val_loss: 31.7231\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.5797 - val_loss: 31.8451\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.0539 - val_loss: 33.1488\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.9361 - val_loss: 32.0765\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.7450 - val_loss: 34.6729\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.2790 - val_loss: 31.7559\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.4360 - val_loss: 48.1756\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 44.5645 - val_loss: 42.5251\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 42.3728 - val_loss: 40.3580\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 41.2582 - val_loss: 42.5170\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 40.2265 - val_loss: 40.1819\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.6042 - val_loss: 37.7926\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.9321 - val_loss: 38.7050\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.1529 - val_loss: 37.8556\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.3477 - val_loss: 37.0571\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.9155 - val_loss: 36.7943\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.6229 - val_loss: 37.2341\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.4876 - val_loss: 36.4693\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.2618 - val_loss: 37.2817\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.5554 - val_loss: 37.2304\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.7462 - val_loss: 36.9944\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.3017 - val_loss: 34.7765\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.2223 - val_loss: 36.2720\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.1817 - val_loss: 35.8659\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.1301 - val_loss: 34.0312\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.6196 - val_loss: 38.2284\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.4771 - val_loss: 33.3832\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 33.1184 - val_loss: 34.4603\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.7648 - val_loss: 32.6856\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.0735 - val_loss: 32.4209\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.0284 - val_loss: 32.6171\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.2953 - val_loss: 36.3592\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.4389 - val_loss: 34.8435\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.1751 - val_loss: 32.2713\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.6773 - val_loss: 31.8408\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.4790 - val_loss: 33.0107\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.8858 - val_loss: 31.1763\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.6793 - val_loss: 31.8114\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.4094 - val_loss: 31.3782\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.4510 - val_loss: 30.6094\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.1295 - val_loss: 31.0774\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.7906 - val_loss: 30.8973\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.0998 - val_loss: 30.7405\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.2401 - val_loss: 30.1458\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.7696 - val_loss: 32.1660\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.8671 - val_loss: 33.3429\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.0547 - val_loss: 33.6875\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.0633 - val_loss: 29.9642\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.8183 - val_loss: 31.3744\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 29.7449 - val_loss: 31.4268\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.3213 - val_loss: 29.9430\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.8503 - val_loss: 29.6421\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.3628 - val_loss: 30.2598\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.7246 - val_loss: 29.2764\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.1893 - val_loss: 29.7998\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.6066 - val_loss: 29.3638\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.3066 - val_loss: 29.7478\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.7640 - val_loss: 30.9156\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.1405 - val_loss: 30.3366\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.4097 - val_loss: 46.0282\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 46.6653 - val_loss: 45.4691\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 42.2501 - val_loss: 38.9989\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.1558 - val_loss: 37.8362\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.2601 - val_loss: 36.9884\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.4011 - val_loss: 36.1817\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 37.1330 - val_loss: 35.5665\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.2446 - val_loss: 35.8471\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.9180 - val_loss: 34.1352\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.2459 - val_loss: 35.8300\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.2282 - val_loss: 33.3146\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 34.6961 - val_loss: 33.5000\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.1294 - val_loss: 32.9886\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.1457 - val_loss: 33.6836\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.0031 - val_loss: 34.3154\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.5372 - val_loss: 32.9342\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.1701 - val_loss: 32.5210\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.4708 - val_loss: 33.2561\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.4975 - val_loss: 32.5671\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.4558 - val_loss: 34.2251\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.0900 - val_loss: 37.2715\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 34.6563 - val_loss: 31.5229\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.9420 - val_loss: 30.9644\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.7436 - val_loss: 30.4922\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.5859 - val_loss: 30.5477\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.3916 - val_loss: 29.8819\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.2323 - val_loss: 29.8312\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.7234 - val_loss: 29.6066\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.4946 - val_loss: 30.8635\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.4969 - val_loss: 29.8448\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.5689 - val_loss: 30.4108\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.5894 - val_loss: 28.8380\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.1552 - val_loss: 28.8570\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.3209 - val_loss: 28.6157\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 30.8150 - val_loss: 29.3423\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 29.4518 - val_loss: 29.8138\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 28.4003 - val_loss: 27.9723\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.6973 - val_loss: 28.5814\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.2895 - val_loss: 27.1666\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 26.9074 - val_loss: 27.0092\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.5926 - val_loss: 28.0424\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 27.0192 - val_loss: 28.0034\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.6196 - val_loss: 26.1359\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 25.4651 - val_loss: 25.3386\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.7422 - val_loss: 25.2734\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 24.6256 - val_loss: 25.0476\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.3737 - val_loss: 24.7305\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.8609 - val_loss: 24.3115\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 23.7097 - val_loss: 23.9252\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.7490 - val_loss: 23.9875\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.3448 - val_loss: 23.6044\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.6611 - val_loss: 23.8632\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.4640 - val_loss: 24.0207\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.8537 - val_loss: 22.9869\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.4539 - val_loss: 22.9510\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.5007 - val_loss: 22.8834\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.4746 - val_loss: 22.6908\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.2709 - val_loss: 22.6719\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.1268 - val_loss: 23.4657\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.2868 - val_loss: 22.9041\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2492 - val_loss: 22.7770\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.0914 - val_loss: 22.3203\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.7800 - val_loss: 22.3400\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6041 - val_loss: 22.0668\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.4690 - val_loss: 22.3829\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.7171 - val_loss: 22.2129\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.5507 - val_loss: 22.0289\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.4080 - val_loss: 21.9132\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 766us/step - loss: 21.2693 - val_loss: 21.9324\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.1254 - val_loss: 21.8810\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.0757 - val_loss: 21.8134\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.2770 - val_loss: 22.2965\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1901 - val_loss: 21.6932\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2657 - val_loss: 21.9267\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0088 - val_loss: 21.6166\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.8160 - val_loss: 21.6168\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.7582 - val_loss: 21.5364\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.7877 - val_loss: 21.5377\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.6664 - val_loss: 21.6750\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.6550 - val_loss: 22.0120\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.7257 - val_loss: 21.4776\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.5984 - val_loss: 21.5291\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.6194 - val_loss: 21.5751\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 20.4864 - val_loss: 21.4633\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 20.4440 - val_loss: 21.3448\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.4637 - val_loss: 21.7097\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.4520 - val_loss: 21.3801\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.2701 - val_loss: 21.3320\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.2710 - val_loss: 21.3678\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.2762 - val_loss: 21.2554\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.0904 - val_loss: 21.3330\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 659us/step - loss: 20.1192 - val_loss: 21.4227\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.1052 - val_loss: 21.2585\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.0165 - val_loss: 21.4906\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.0067 - val_loss: 21.3691\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.3392 - val_loss: 47.0932\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 45.7335 - val_loss: 47.3990\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 42.9077 - val_loss: 43.6224\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.1826 - val_loss: 40.2299\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 40.7398 - val_loss: 40.2025\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 41.1066 - val_loss: 40.0486\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.3726 - val_loss: 38.5142\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 39.2565 - val_loss: 38.8409\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 39.8091 - val_loss: 37.8553\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 37.7551 - val_loss: 37.3248\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 38.9454 - val_loss: 39.3225\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.0591 - val_loss: 43.0516\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 38.5394 - val_loss: 36.9061\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 37.2266 - val_loss: 37.9174\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 38.4048 - val_loss: 37.2151\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 36.2120 - val_loss: 35.2358\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 35.1055 - val_loss: 35.4865\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.4914 - val_loss: 34.2814\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.1725 - val_loss: 34.6633\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.5024 - val_loss: 34.3749\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.3582 - val_loss: 34.2004\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.2588 - val_loss: 33.9891\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.5894 - val_loss: 33.4173\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.2411 - val_loss: 36.2808\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.9929 - val_loss: 32.1644\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.3270 - val_loss: 32.0219\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.3024 - val_loss: 33.5749\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 33.3442 - val_loss: 36.5317\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.7776 - val_loss: 33.1473\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.3026 - val_loss: 31.0476\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.5597 - val_loss: 30.7199\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.1849 - val_loss: 31.7783\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.5364 - val_loss: 29.2988\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.7722 - val_loss: 29.9644\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.4896 - val_loss: 28.3440\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.8121 - val_loss: 27.1669\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.2711 - val_loss: 26.3503\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 25.3780 - val_loss: 25.6487\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.2069 - val_loss: 25.4591\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.7993 - val_loss: 25.1041\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.4181 - val_loss: 24.7015\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.0067 - val_loss: 24.4557\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.7449 - val_loss: 24.2789\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.6117 - val_loss: 24.1120\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.4232 - val_loss: 23.8797\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.2872 - val_loss: 23.9020\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.3516 - val_loss: 23.7367\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0594 - val_loss: 23.7571\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.9048 - val_loss: 23.5152\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.8509 - val_loss: 23.4260\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.6725 - val_loss: 23.4512\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.7026 - val_loss: 23.4856\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.7505 - val_loss: 23.2505\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.4419 - val_loss: 23.1570\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.2930 - val_loss: 23.2434\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.2730 - val_loss: 23.0620\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.3096 - val_loss: 23.0366\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.3053 - val_loss: 23.1211\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0896 - val_loss: 23.0460\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 748us/step - loss: 22.0418 - val_loss: 22.9979\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 21.9084 - val_loss: 22.8671\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 784us/step - loss: 21.7683 - val_loss: 22.8681\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 870us/step - loss: 21.7567 - val_loss: 22.8506\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.7953 - val_loss: 23.0594\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.6548 - val_loss: 22.9671\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.6071 - val_loss: 22.8884\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.5064 - val_loss: 22.9426\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.4128 - val_loss: 22.7164\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.7190 - val_loss: 23.0447\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.4531 - val_loss: 23.0080\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.4870 - val_loss: 23.0444\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 21.2499 - val_loss: 22.7660\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.1870 - val_loss: 22.9660\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 1s 2ms/step - loss: 85.7750 - val_loss: 70.8498\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 51.4983 - val_loss: 44.2348\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 43.2659 - val_loss: 41.6876\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 41.1959 - val_loss: 40.4128\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 40.3037 - val_loss: 40.3595\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.5927 - val_loss: 40.6600\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.1233 - val_loss: 38.1292\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.1064 - val_loss: 37.9582\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.1849 - val_loss: 37.2006\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.0571 - val_loss: 39.1108\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.0986 - val_loss: 37.6273\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.3589 - val_loss: 36.8787\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.8836 - val_loss: 38.5721\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.7250 - val_loss: 35.3855\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.3340 - val_loss: 35.3135\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.7487 - val_loss: 35.2300\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.0077 - val_loss: 36.8787\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.4205 - val_loss: 34.5869\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.1249 - val_loss: 34.3509\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.0470 - val_loss: 35.0152\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 35.1994 - val_loss: 34.9967\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.3803 - val_loss: 33.2476\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.6492 - val_loss: 34.7276\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.3153 - val_loss: 32.9735\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.0309 - val_loss: 34.6150\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.7863 - val_loss: 32.6196\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.5821 - val_loss: 32.1433\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.5168 - val_loss: 32.8758\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.6923 - val_loss: 31.7560\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.0316 - val_loss: 35.2922\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.3312 - val_loss: 31.3624\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 30.7669 - val_loss: 31.8214\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.9919 - val_loss: 31.7724\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.8496 - val_loss: 32.7467\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.1178 - val_loss: 30.3786\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.5124 - val_loss: 31.8704\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.6451 - val_loss: 29.7909\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.6865 - val_loss: 29.6253\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.9632 - val_loss: 33.3404\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.4546 - val_loss: 29.1848\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.4636 - val_loss: 29.0526\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.3473 - val_loss: 28.4703\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.4646 - val_loss: 28.0245\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.7974 - val_loss: 27.3572\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.4717 - val_loss: 27.3822\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.2853 - val_loss: 26.7116\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.6021 - val_loss: 26.4666\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.6278 - val_loss: 27.5567\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 24.9210 - val_loss: 25.0947\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 24.4010 - val_loss: 24.8786\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.1288 - val_loss: 25.7724\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.3056 - val_loss: 24.6482\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.7436 - val_loss: 24.5651\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.4916 - val_loss: 24.3025\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.3468 - val_loss: 23.8218\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.0957 - val_loss: 23.7764\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.1508 - val_loss: 23.9710\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.1569 - val_loss: 23.6117\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.7259 - val_loss: 23.4683\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.5676 - val_loss: 23.3402\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.5479 - val_loss: 23.3901\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.6945 - val_loss: 23.2738\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.3942 - val_loss: 23.1666\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.4778 - val_loss: 23.1517\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.4547 - val_loss: 23.2349\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.2312 - val_loss: 23.1261\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0402 - val_loss: 23.6521\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.0501 - val_loss: 23.0494\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.9182 - val_loss: 22.9522\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.9379 - val_loss: 23.1322\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.8861 - val_loss: 22.8823\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.8510 - val_loss: 22.8784\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.7999 - val_loss: 22.7099\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6055 - val_loss: 22.8454\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.4834 - val_loss: 22.6395\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.5132 - val_loss: 22.5584\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.4890 - val_loss: 23.0877\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5202 - val_loss: 22.8107\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.5523 - val_loss: 22.5427\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.3066 - val_loss: 22.5313\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.1631 - val_loss: 22.6295\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.1373 - val_loss: 22.4923\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 21.2602 - val_loss: 22.7440\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 565us/step - loss: 21.0764 - val_loss: 22.5158\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.9538 - val_loss: 22.4972\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9376 - val_loss: 22.5748\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.0897 - val_loss: 22.6348\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.1842 - val_loss: 48.3411\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 46.9151 - val_loss: 41.3614\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.4476 - val_loss: 41.1001\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.5779 - val_loss: 36.7133\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.2286 - val_loss: 37.3840\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.3312 - val_loss: 34.9047\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.1605 - val_loss: 34.7692\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.4236 - val_loss: 34.6454\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.8082 - val_loss: 37.8472\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 36.1216 - val_loss: 34.8175\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.5150 - val_loss: 36.0943\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.1104 - val_loss: 34.0938\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.5904 - val_loss: 32.0207\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.0830 - val_loss: 31.1855\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.4650 - val_loss: 30.6675\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.4427 - val_loss: 30.5946\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.4093 - val_loss: 31.1638\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.4683 - val_loss: 30.1405\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.8602 - val_loss: 31.5190\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.4863 - val_loss: 31.2900\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.5146 - val_loss: 29.5506\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.7067 - val_loss: 30.1355\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.2593 - val_loss: 29.0271\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.4392 - val_loss: 29.0266\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.9036 - val_loss: 28.6577\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.7044 - val_loss: 28.8314\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.8670 - val_loss: 28.1804\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.6293 - val_loss: 28.3836\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.3633 - val_loss: 27.6496\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.9652 - val_loss: 28.9886\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.4278 - val_loss: 27.9492\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.9187 - val_loss: 27.6718\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.8520 - val_loss: 29.5404\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.5195 - val_loss: 27.6286\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.4685 - val_loss: 27.1028\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.1098 - val_loss: 27.6664\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.4929 - val_loss: 27.0048\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.2712 - val_loss: 27.4530\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.5503 - val_loss: 28.6104\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 27.8919 - val_loss: 27.9238\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.2979 - val_loss: 26.6255\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.7165 - val_loss: 27.8823\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 27.0818 - val_loss: 26.9507\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 27.3667 - val_loss: 26.8365\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.1609 - val_loss: 26.8828\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 26.9332 - val_loss: 27.5017\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.5785 - val_loss: 53.8715\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 50.7947 - val_loss: 46.6457\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 49.0335 - val_loss: 45.7786\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 47.1269 - val_loss: 43.2644\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 43.6717 - val_loss: 44.2618\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 43.4201 - val_loss: 40.9354\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 41.3506 - val_loss: 40.7015\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 40.7619 - val_loss: 40.8253\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.0682 - val_loss: 38.8105\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.8533 - val_loss: 37.8568\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.6551 - val_loss: 38.9515\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.0335 - val_loss: 37.2180\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.9933 - val_loss: 37.7187\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.3117 - val_loss: 35.9729\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.4711 - val_loss: 35.5749\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.2912 - val_loss: 41.6752\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.7548 - val_loss: 35.7037\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.9965 - val_loss: 34.4361\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.4375 - val_loss: 34.2760\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.6796 - val_loss: 34.3363\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.9285 - val_loss: 33.3958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.2583 - val_loss: 34.2383\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.4742 - val_loss: 31.6824\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.9939 - val_loss: 33.4484\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.3697 - val_loss: 32.3990\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.3258 - val_loss: 31.5606\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.7404 - val_loss: 34.7046\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.7660 - val_loss: 31.0653\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.7638 - val_loss: 30.4846\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.8564 - val_loss: 28.3440\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.0759 - val_loss: 27.0796\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 26.7804 - val_loss: 27.1070\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.3208 - val_loss: 26.3322\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.6684 - val_loss: 25.9784\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.4619 - val_loss: 25.7040\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 25.0807 - val_loss: 25.4029\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.5529 - val_loss: 25.7400\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.7691 - val_loss: 25.2895\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.4996 - val_loss: 24.8802\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.5800 - val_loss: 24.8605\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.2440 - val_loss: 24.7209\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.9278 - val_loss: 24.3339\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.6895 - val_loss: 24.2800\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 23.8353 - val_loss: 24.5620\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.4706 - val_loss: 23.8848\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.3071 - val_loss: 23.7443\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.1747 - val_loss: 23.7088\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.5364 - val_loss: 24.2844\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.0288 - val_loss: 23.6888\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.9683 - val_loss: 23.7601\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7635 - val_loss: 23.3315\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.5366 - val_loss: 23.4197\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.7742 - val_loss: 23.4546\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.5550 - val_loss: 23.1740\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.6177 - val_loss: 23.0651\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.3543 - val_loss: 23.1584\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.1566 - val_loss: 22.9918\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.0236 - val_loss: 22.9596\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.9881 - val_loss: 24.6015\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0431 - val_loss: 22.7470\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.8525 - val_loss: 22.6745\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.8197 - val_loss: 22.6413\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5649 - val_loss: 22.5825\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.5046 - val_loss: 22.7002\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5419 - val_loss: 22.5534\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.4454 - val_loss: 22.5752\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6495 - val_loss: 22.4694\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.3504 - val_loss: 22.7058\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.2768 - val_loss: 22.4261\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.1403 - val_loss: 22.6296\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3985 - val_loss: 22.2997\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1966 - val_loss: 22.6665\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0691 - val_loss: 22.3535\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.8579 - val_loss: 22.2938\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.0576 - val_loss: 22.2377\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0159 - val_loss: 22.6794\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.7953 - val_loss: 22.3995\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.7148 - val_loss: 22.3126\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.6419 - val_loss: 22.1099\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.4962 - val_loss: 22.1301\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.5233 - val_loss: 22.1615\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.4877 - val_loss: 22.2137\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.0332 - val_loss: 22.7783\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.8698 - val_loss: 22.3823\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.1908 - val_loss: 50.9727\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 46.5625 - val_loss: 47.0351\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 43.0454 - val_loss: 46.6911\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.1287 - val_loss: 40.2025\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.9033 - val_loss: 41.5356\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.1364 - val_loss: 38.7380\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.6021 - val_loss: 41.6473\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.2961 - val_loss: 39.0005\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.9268 - val_loss: 37.3267\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.5649 - val_loss: 37.6406\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 38.6064 - val_loss: 37.4216\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.2908 - val_loss: 37.5874\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.4868 - val_loss: 40.9876\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.3094 - val_loss: 38.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 76.8884 - val_loss: 50.5666\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 48.4079 - val_loss: 47.0097\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 45.6889 - val_loss: 43.9090\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 43.6441 - val_loss: 41.8920\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.5432 - val_loss: 45.9832\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 44.1480 - val_loss: 44.7128\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 42.2443 - val_loss: 40.0326\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 39.9084 - val_loss: 40.0651\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 38.7729 - val_loss: 38.2515\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.6655 - val_loss: 38.8825\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.7641 - val_loss: 37.3091\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.1395 - val_loss: 38.0751\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.0192 - val_loss: 37.0992\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.5436 - val_loss: 40.2984\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.1423 - val_loss: 38.6943\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.9400 - val_loss: 39.4996\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.2182 - val_loss: 35.7156\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.6448 - val_loss: 41.8265\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 36.6827 - val_loss: 35.5937\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.7339 - val_loss: 36.9909\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.2936 - val_loss: 35.4140\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.4947 - val_loss: 34.7867\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.2734 - val_loss: 36.3150\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.3104 - val_loss: 34.7363\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.5015 - val_loss: 34.6454\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.6018 - val_loss: 34.7586\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.4753 - val_loss: 35.7751\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.2291 - val_loss: 33.6487\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.3266 - val_loss: 34.7021\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.1077 - val_loss: 34.8093\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.3780 - val_loss: 33.9280\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.8796 - val_loss: 34.4780\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.6267 - val_loss: 32.3006\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.8517 - val_loss: 32.2220\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.5980 - val_loss: 32.8383\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.4500 - val_loss: 30.6930\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.6405 - val_loss: 30.6519\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.2601 - val_loss: 30.1934\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.3107 - val_loss: 28.6917\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.7117 - val_loss: 29.2454\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.2790 - val_loss: 27.2126\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.0202 - val_loss: 26.9364\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.3602 - val_loss: 25.7186\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 24.9154 - val_loss: 25.4839\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.7952 - val_loss: 25.4088\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.5406 - val_loss: 24.8391\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.1113 - val_loss: 24.5671\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.7533 - val_loss: 24.2913\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.6551 - val_loss: 25.0721\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.8278 - val_loss: 24.6787\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.3710 - val_loss: 24.4135\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.2854 - val_loss: 23.9667\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.1791 - val_loss: 23.7670\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.1517 - val_loss: 23.7800\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.0289 - val_loss: 23.5580\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.8437 - val_loss: 24.6043\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.1050 - val_loss: 24.5126\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.7297 - val_loss: 23.3209\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 22.4768 - val_loss: 23.4000\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.3887 - val_loss: 23.1944\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.2573 - val_loss: 23.1271\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.2148 - val_loss: 23.0739\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.1434 - val_loss: 23.0641\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.0860 - val_loss: 23.0113\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.0791 - val_loss: 22.9441\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.9910 - val_loss: 22.8984\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.1681 - val_loss: 23.6342\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.2384 - val_loss: 22.9638\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0936 - val_loss: 23.0774\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.7575 - val_loss: 22.7527\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6883 - val_loss: 22.8558\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6254 - val_loss: 22.8682\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.5774 - val_loss: 22.7521\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.5079 - val_loss: 22.7372\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.5919 - val_loss: 22.9001\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4412 - val_loss: 22.6545\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.4894 - val_loss: 22.5899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.3705 - val_loss: 22.6232\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5264 - val_loss: 23.0530\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.3294 - val_loss: 22.5788\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.2952 - val_loss: 22.5934\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1867 - val_loss: 22.7352\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.1134 - val_loss: 22.6775\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.1062 - val_loss: 22.6767\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0997 - val_loss: 22.6069\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.4445 - val_loss: 53.1233\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 46.8949 - val_loss: 46.0095\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 44.5422 - val_loss: 45.6927\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 44.2574 - val_loss: 45.4292\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 42.7470 - val_loss: 41.9658\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 42.0647 - val_loss: 43.3585\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 40.9539 - val_loss: 40.6185\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 41.0507 - val_loss: 40.2078\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 39.7387 - val_loss: 39.4345\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 39.3042 - val_loss: 41.1476\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 38.4334 - val_loss: 39.2505\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 40.3345 - val_loss: 41.6914\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 38.6683 - val_loss: 38.4211\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 39.0050 - val_loss: 40.3011\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 37.4446 - val_loss: 38.1719\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 37.8920 - val_loss: 38.4125\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.1709 - val_loss: 37.3920\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 695us/step - loss: 38.0106 - val_loss: 38.0579\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.5703 - val_loss: 38.2567\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 35.6418 - val_loss: 35.4573\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 36.1942 - val_loss: 35.9174\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 35.4376 - val_loss: 35.1708\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.3891 - val_loss: 35.0941\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 35.6081 - val_loss: 36.2150\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.0709 - val_loss: 34.6533\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.8700 - val_loss: 34.8372\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.6528 - val_loss: 33.8886\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 33.8500 - val_loss: 34.7992\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.9876 - val_loss: 34.3310\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 35.5190 - val_loss: 37.0444\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.6123 - val_loss: 33.7338\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 34.2374 - val_loss: 32.8926\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 32.5258 - val_loss: 34.4313\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 32.1776 - val_loss: 31.7161\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 35.6499 - val_loss: 34.1713\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.9079 - val_loss: 32.3542\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 31.6909 - val_loss: 34.7361\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 31.0888 - val_loss: 30.6660\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 30.2007 - val_loss: 31.1522\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 29.9114 - val_loss: 32.0783\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 29.5557 - val_loss: 29.5058\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.9061 - val_loss: 31.9660\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.0594 - val_loss: 29.7108\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 29.2876 - val_loss: 31.4133\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.1318 - val_loss: 27.7120\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 27.2434 - val_loss: 28.5794\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 26.8158 - val_loss: 26.4671\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 25.6185 - val_loss: 26.4843\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 25.5921 - val_loss: 26.0764\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 24.9922 - val_loss: 24.9021\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 24.4658 - val_loss: 24.8933\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 23.9894 - val_loss: 24.3529\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 23.7276 - val_loss: 24.2305\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 23.5416 - val_loss: 24.3321\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 23.5616 - val_loss: 23.9885\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 23.2649 - val_loss: 24.3568\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 23.1756 - val_loss: 23.6738\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 23.1298 - val_loss: 23.4381\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.9136 - val_loss: 23.6227\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.8035 - val_loss: 23.4710\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 22.9056 - val_loss: 23.1631\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 741us/step - loss: 22.5829 - val_loss: 23.1198\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 807us/step - loss: 22.4087 - val_loss: 23.4012\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 945us/step - loss: 22.5353 - val_loss: 23.0694\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 22.6579 - val_loss: 23.3080\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 945us/step - loss: 22.5114 - val_loss: 22.8814\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 917us/step - loss: 22.1391 - val_loss: 23.1771\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 903us/step - loss: 22.3134 - val_loss: 22.8243\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 22.1439 - val_loss: 22.8030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 22.0582 - val_loss: 22.5723\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.8858 - val_loss: 22.5023\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.8015 - val_loss: 22.4591\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.6714 - val_loss: 22.4739\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 21.7625 - val_loss: 22.4551\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.6112 - val_loss: 22.3362\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.5649 - val_loss: 22.6523\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.5217 - val_loss: 22.4638\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8097 - val_loss: 22.2893\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.5147 - val_loss: 23.0745\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.7712 - val_loss: 22.2391\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.3811 - val_loss: 22.1910\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2777 - val_loss: 22.1397\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1285 - val_loss: 22.0753\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.1005 - val_loss: 22.1990\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2906 - val_loss: 22.4432\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1880 - val_loss: 22.0110\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.0460 - val_loss: 22.1437\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.0953 - val_loss: 22.0222\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0740 - val_loss: 22.3033\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9815 - val_loss: 22.1567\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 20.9689 - val_loss: 22.1507\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.8364 - val_loss: 46.9348\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.5808 - val_loss: 41.4742\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 42.2933 - val_loss: 40.4387\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 41.1270 - val_loss: 39.9428\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.6140 - val_loss: 39.2045\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.1927 - val_loss: 37.9321\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.7407 - val_loss: 38.8429\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.8981 - val_loss: 36.4534\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.9344 - val_loss: 35.9214\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.7065 - val_loss: 37.7749\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.8649 - val_loss: 36.7086\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.9650 - val_loss: 35.9956\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 793us/step - loss: 36.1327 - val_loss: 35.3510\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.2543 - val_loss: 34.8681\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.8400 - val_loss: 35.9454\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.2983 - val_loss: 34.9670\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.0850 - val_loss: 34.8900\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.5942 - val_loss: 34.5339\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.6332 - val_loss: 34.4643\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.8663 - val_loss: 34.8330\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.8801 - val_loss: 35.2186\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 32.9039 - val_loss: 33.1808\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.7418 - val_loss: 34.5343\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.1627 - val_loss: 32.8508\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.5908 - val_loss: 34.2777\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.9266 - val_loss: 34.4818\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.2208 - val_loss: 32.6518\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.1247 - val_loss: 35.4645\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.0702 - val_loss: 33.4115\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 31.7515 - val_loss: 31.4829\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 31.9539 - val_loss: 31.1857\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.0413 - val_loss: 30.5628\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.2253 - val_loss: 30.8339\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 30.7335 - val_loss: 30.5181\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.6648 - val_loss: 30.4464\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 29.4952 - val_loss: 30.3789\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.9609 - val_loss: 29.7407\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 28.8263 - val_loss: 32.6390\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.2285 - val_loss: 29.8039\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.5324 - val_loss: 29.0481\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.5790 - val_loss: 30.5696\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 27.8730 - val_loss: 29.0208\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 27.4512 - val_loss: 28.0316\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 26.9547 - val_loss: 27.9392\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 26.9738 - val_loss: 28.1654\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.2809 - val_loss: 26.9981\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 25.9528 - val_loss: 27.2435\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 25.8371 - val_loss: 26.0749\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 25.0465 - val_loss: 25.8120\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.7083 - val_loss: 25.9371\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.3449 - val_loss: 25.6592\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.0414 - val_loss: 24.6165\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.5956 - val_loss: 24.5655\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 23.6731 - val_loss: 24.5073\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 23.5394 - val_loss: 24.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.0459 - val_loss: 24.2204\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.1136 - val_loss: 24.2575\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.9429 - val_loss: 23.6982\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.5713 - val_loss: 23.5529\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.3976 - val_loss: 23.4536\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.3678 - val_loss: 23.5769\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.2565 - val_loss: 23.3158\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.3382 - val_loss: 23.4351\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.1675 - val_loss: 23.5814\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.1016 - val_loss: 23.1791\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8875 - val_loss: 23.2272\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8584 - val_loss: 23.1036\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.7751 - val_loss: 22.9373\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.6482 - val_loss: 23.0504\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.5841 - val_loss: 22.8857\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.5471 - val_loss: 22.9157\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.6509 - val_loss: 23.2215\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.5534 - val_loss: 22.9296\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4851 - val_loss: 22.8181\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.3749 - val_loss: 22.9597\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.2998 - val_loss: 22.9619\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.1893 - val_loss: 22.8320\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.1685 - val_loss: 22.7717\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.0192 - val_loss: 22.7061\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.9900 - val_loss: 22.6568\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 20.9739 - val_loss: 22.8803\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.0625 - val_loss: 22.6984\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.0071 - val_loss: 22.9308\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.8700 - val_loss: 22.6129\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.9079 - val_loss: 22.7086\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 849us/step - loss: 20.7809 - val_loss: 22.5245\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 785us/step - loss: 20.9640 - val_loss: 22.7800\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.8558 - val_loss: 22.6604\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.7929 - val_loss: 22.6461\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.6057 - val_loss: 22.5956\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.5307 - val_loss: 22.6597\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.7559 - val_loss: 48.6455\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 45.4889 - val_loss: 41.5683\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 44.4295 - val_loss: 40.1897\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 41.2594 - val_loss: 39.4978\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.8353 - val_loss: 38.7496\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.5902 - val_loss: 44.9886\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 38.9912 - val_loss: 38.9029\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 38.7497 - val_loss: 36.5419\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 36.2812 - val_loss: 36.8046\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.8996 - val_loss: 35.7049\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 35.5320 - val_loss: 35.3417\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.3944 - val_loss: 34.0450\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.2107 - val_loss: 34.9546\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.4057 - val_loss: 33.6447\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 35.3809 - val_loss: 36.4646\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.8006 - val_loss: 34.7494\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 34.2526 - val_loss: 38.5064\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.8993 - val_loss: 35.4764\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.2143 - val_loss: 32.9049\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.3650 - val_loss: 32.6119\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.9100 - val_loss: 32.7117\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.9363 - val_loss: 33.5996\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.9710 - val_loss: 32.2157\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 31.8762 - val_loss: 35.3494\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 31.7282 - val_loss: 32.0519\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.0337 - val_loss: 31.0842\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.9524 - val_loss: 31.4738\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 31.4323 - val_loss: 31.1934\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.5393 - val_loss: 31.5813\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.9468 - val_loss: 31.6595\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.6311 - val_loss: 30.3339\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.5737 - val_loss: 30.7175\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.6027 - val_loss: 29.9525\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.7505 - val_loss: 30.6383\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.4757 - val_loss: 31.4108\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.6155 - val_loss: 30.2516\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.6145 - val_loss: 30.2706\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.6321 - val_loss: 29.6845\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.1084 - val_loss: 31.6638\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.8238 - val_loss: 30.2925\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 29.0645 - val_loss: 29.2842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.5987 - val_loss: 28.9733\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.0007 - val_loss: 28.7741\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.2468 - val_loss: 29.3887\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.1979 - val_loss: 30.3641\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.2771 - val_loss: 28.5439\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.5711 - val_loss: 28.6587\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.4036 - val_loss: 28.4465\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.5860 - val_loss: 29.7209\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.4221 - val_loss: 27.9043\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 26.8077 - val_loss: 27.9654\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.4047 - val_loss: 30.1638\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.5408 - val_loss: 27.5865\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 26.7375 - val_loss: 27.4308\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.9017 - val_loss: 27.5733\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 25.9623 - val_loss: 26.8277\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.9938 - val_loss: 26.5551\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 25.4973 - val_loss: 27.6056\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.9054 - val_loss: 26.5879\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.5287 - val_loss: 29.9833\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.6327 - val_loss: 26.2328\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.5105 - val_loss: 26.1804\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.8595 - val_loss: 25.5087\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.1598 - val_loss: 25.7040\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.2386 - val_loss: 25.4826\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 24.1842 - val_loss: 26.6926\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.3041 - val_loss: 24.8123\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.6961 - val_loss: 24.9194\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.4259 - val_loss: 24.3811\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.8082 - val_loss: 24.0038\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.7363 - val_loss: 24.0566\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.4980 - val_loss: 23.6049\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.4879 - val_loss: 23.7087\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1869 - val_loss: 23.6021\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 22.1004 - val_loss: 23.2664\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.9545 - val_loss: 23.3912\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.8746 - val_loss: 23.1284\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7747 - val_loss: 22.9955\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.7443 - val_loss: 22.9780\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6192 - val_loss: 23.0543\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5010 - val_loss: 22.8349\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.4332 - val_loss: 22.7792\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.4326 - val_loss: 23.3810\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.4902 - val_loss: 23.6503\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.4798 - val_loss: 22.8846\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2442 - val_loss: 22.7765\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.2010 - val_loss: 22.6099\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.1013 - val_loss: 22.6415\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.2027 - val_loss: 22.7278\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.0044 - val_loss: 22.5952\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.8858 - val_loss: 22.5681\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.8856 - val_loss: 22.5625\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.8420 - val_loss: 22.5772\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9155 - val_loss: 22.6200\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.7288 - val_loss: 22.5332\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.6156 - val_loss: 22.4071\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.5601 - val_loss: 22.6073\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.6531 - val_loss: 23.1714\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.0945 - val_loss: 22.4967\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.7149 - val_loss: 22.4811\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.0777 - val_loss: 53.3539\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 46.0197 - val_loss: 44.0485\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 44.2489 - val_loss: 43.4643\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 42.1587 - val_loss: 40.7565\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.8132 - val_loss: 44.1074\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.9752 - val_loss: 39.2110\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.3119 - val_loss: 39.5403\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.4280 - val_loss: 37.9519\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.8812 - val_loss: 38.6127\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.5798 - val_loss: 36.7664\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.8539 - val_loss: 41.3649\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.4275 - val_loss: 44.2244\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.3999 - val_loss: 36.5239\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.4665 - val_loss: 35.9466\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.7552 - val_loss: 36.8325\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.1951 - val_loss: 35.6586\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.3622 - val_loss: 35.7490\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.9050 - val_loss: 37.4293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.7268 - val_loss: 38.6143\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.9681 - val_loss: 39.5971\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 35.1070 - val_loss: 35.1425\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.7682 - val_loss: 33.8406\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.6039 - val_loss: 35.9324\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.2892 - val_loss: 34.0388\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.8795 - val_loss: 35.3943\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.0132 - val_loss: 35.3698\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.3876 - val_loss: 34.0263\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 94.5575 - val_loss: 58.5634\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 48.1928 - val_loss: 45.8508\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 44.3666 - val_loss: 42.8367\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.8054 - val_loss: 41.5190\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 40.9247 - val_loss: 40.7793\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.7032 - val_loss: 40.3178\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.9395 - val_loss: 41.5651\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 40.0502 - val_loss: 39.2641\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.9328 - val_loss: 40.8459\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 42.1983 - val_loss: 40.2312\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.4191 - val_loss: 40.1366\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 38.3069 - val_loss: 38.3457\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.5089 - val_loss: 37.5614\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.1672 - val_loss: 36.5636\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.9275 - val_loss: 35.7355\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.7204 - val_loss: 37.9287\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.7194 - val_loss: 36.7234\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.1705 - val_loss: 35.9801\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.0849 - val_loss: 34.9579\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 35.9032 - val_loss: 37.9049\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.2326 - val_loss: 35.2748\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.5827 - val_loss: 33.9369\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.1323 - val_loss: 33.7243\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.5603 - val_loss: 33.6761\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.7847 - val_loss: 32.5369\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.8937 - val_loss: 32.1036\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.1971 - val_loss: 32.9378\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.3063 - val_loss: 31.8694\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.1345 - val_loss: 34.7245\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.0673 - val_loss: 31.6120\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 33.3289 - val_loss: 31.8570\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.9387 - val_loss: 30.7185\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 30.3947 - val_loss: 40.6860\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.4286 - val_loss: 31.3868\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 30.0431 - val_loss: 29.7002\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 29.0716 - val_loss: 29.2320\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 28.6172 - val_loss: 28.4356\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 28.7608 - val_loss: 30.4937\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 27.6856 - val_loss: 27.5739\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.8200 - val_loss: 27.1812\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 25.6537 - val_loss: 25.9045\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 25.1033 - val_loss: 25.2340\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 24.6212 - val_loss: 24.6573\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 24.0657 - val_loss: 24.5312\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 23.7302 - val_loss: 23.9917\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 23.5232 - val_loss: 23.7425\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 23.1829 - val_loss: 23.4578\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.9942 - val_loss: 23.3967\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.8799 - val_loss: 23.2183\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 23.2268 - val_loss: 23.7309\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.7517 - val_loss: 23.0014\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.4588 - val_loss: 23.4259\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3809 - val_loss: 22.7601\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.2025 - val_loss: 23.0198\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.3177 - val_loss: 23.2144\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.2840 - val_loss: 23.1225\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.0589 - val_loss: 22.5845\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.9289 - val_loss: 22.6018\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 21.9785 - val_loss: 22.4805\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.8084 - val_loss: 22.3854\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.6717 - val_loss: 22.3426\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.5828 - val_loss: 22.1877\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.6513 - val_loss: 22.2860\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.4660 - val_loss: 22.2149\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.4356 - val_loss: 22.1430\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.4796 - val_loss: 22.1999\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.3438 - val_loss: 22.1283\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 21.2658 - val_loss: 22.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.1439 - val_loss: 22.0379\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.0449 - val_loss: 22.0302\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 21.0265 - val_loss: 21.9796\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.0196 - val_loss: 21.9937\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.0029 - val_loss: 21.9120\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.8849 - val_loss: 21.8926\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.0226 - val_loss: 21.8722\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.7709 - val_loss: 21.8576\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.7653 - val_loss: 22.2803\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.7836 - val_loss: 21.8535\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.5339 - val_loss: 21.7955\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.5999 - val_loss: 21.8830\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 20.5213 - val_loss: 21.7962\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.4162 - val_loss: 22.1777\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 20.4239 - val_loss: 21.7457\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.3765 - val_loss: 21.7723\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.3402 - val_loss: 21.9557\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 20.2326 - val_loss: 21.7530\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.3687 - val_loss: 21.7909\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.1943 - val_loss: 21.6825\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.2155 - val_loss: 21.8523\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.1048 - val_loss: 21.7901\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 20.1245 - val_loss: 22.0871\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.0627 - val_loss: 21.8038\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.0590 - val_loss: 22.1380\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.1547 - val_loss: 45.4801\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 46.1280 - val_loss: 41.6477\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 43.8392 - val_loss: 42.0218\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 41.3086 - val_loss: 42.6844\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 42.0479 - val_loss: 42.8145\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.9938 - val_loss: 38.7110\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.0176 - val_loss: 39.0277\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.4390 - val_loss: 38.8778\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.1151 - val_loss: 39.3127\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.9280 - val_loss: 37.5212\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.3802 - val_loss: 37.8856\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.8141 - val_loss: 35.6120\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.9103 - val_loss: 38.5481\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.1086 - val_loss: 38.2624\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.0570 - val_loss: 35.0708\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.9342 - val_loss: 34.0356\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.8192 - val_loss: 34.0539\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.1592 - val_loss: 34.2875\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.7910 - val_loss: 32.9450\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.1767 - val_loss: 32.7147\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.7203 - val_loss: 34.6834\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.0006 - val_loss: 32.3067\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.7969 - val_loss: 32.5920\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.2841 - val_loss: 33.1960\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.6369 - val_loss: 34.1009\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.9328 - val_loss: 33.5594\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.4722 - val_loss: 33.2433\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.9213 - val_loss: 48.3620\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 46.6036 - val_loss: 46.9185\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 42.1626 - val_loss: 42.0821\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 41.6129 - val_loss: 41.9389\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.0336 - val_loss: 40.0033\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.9155 - val_loss: 41.3516\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.4305 - val_loss: 40.1716\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.1328 - val_loss: 40.6770\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.1321 - val_loss: 39.3560\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 38.6835 - val_loss: 39.6897\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.3665 - val_loss: 37.7882\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 765us/step - loss: 37.8405 - val_loss: 38.0394\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 725us/step - loss: 38.0912 - val_loss: 38.5317\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 922us/step - loss: 37.0626 - val_loss: 38.3179\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 36.9041 - val_loss: 37.6563\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 35.4849 - val_loss: 37.6047\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.2901 - val_loss: 35.7009\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 34.2573 - val_loss: 37.3861\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.2439 - val_loss: 34.8435\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.8110 - val_loss: 34.7232\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.7277 - val_loss: 39.0054\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.9530 - val_loss: 36.2211\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 710us/step - loss: 33.3706 - val_loss: 34.4512\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 33.3077 - val_loss: 35.2856\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.6187 - val_loss: 35.0743\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.0894 - val_loss: 33.8619\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 33.0551 - val_loss: 34.2360\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.8858 - val_loss: 33.5003\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.7272 - val_loss: 35.5291\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.7733 - val_loss: 33.1867\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.8461 - val_loss: 38.2366\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 34.0933 - val_loss: 34.5792\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.0872 - val_loss: 34.3964\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.0210 - val_loss: 33.0515\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.3630 - val_loss: 33.0882\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.8951 - val_loss: 33.5166\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.1771 - val_loss: 32.5101\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.1114 - val_loss: 32.2570\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.1667 - val_loss: 34.8918\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.3512 - val_loss: 31.7157\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.4560 - val_loss: 32.2021\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.0460 - val_loss: 33.2441\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.2567 - val_loss: 32.2356\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.1348 - val_loss: 35.4755\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.4213 - val_loss: 31.6080\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.9552 - val_loss: 31.7275\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.2231 - val_loss: 31.2664\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.6403 - val_loss: 30.6839\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.1251 - val_loss: 31.3637\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 27.7768 - val_loss: 31.2146\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.2858 - val_loss: 30.5189\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 27.3186 - val_loss: 30.5093\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.4156 - val_loss: 30.6767\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.9649 - val_loss: 38.8579\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.8114 - val_loss: 30.8373\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.2827 - val_loss: 29.7416\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 27.3559 - val_loss: 30.3075\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.5409 - val_loss: 29.5955\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 26.5454 - val_loss: 28.9629\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.8761 - val_loss: 31.2562\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 26.4517 - val_loss: 28.3007\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.4301 - val_loss: 28.2188\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.4486 - val_loss: 27.4904\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.8597 - val_loss: 27.6007\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 24.8390 - val_loss: 27.3943\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.0871 - val_loss: 27.7204\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.5185 - val_loss: 26.9213\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.8998 - val_loss: 25.8010\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 23.6129 - val_loss: 26.6708\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.7621 - val_loss: 25.8549\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.2689 - val_loss: 24.9543\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.7686 - val_loss: 24.7513\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.7121 - val_loss: 24.4503\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4036 - val_loss: 24.3963\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.2678 - val_loss: 24.1779\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.1691 - val_loss: 24.0358\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.9654 - val_loss: 24.2688\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.1503 - val_loss: 24.2880\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.9812 - val_loss: 24.1288\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.8580 - val_loss: 23.7211\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.4948 - val_loss: 23.7020\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.4926 - val_loss: 23.5230\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.3099 - val_loss: 23.4129\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.2074 - val_loss: 23.3467\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1770 - val_loss: 23.1858\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.0743 - val_loss: 24.2423\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.2523 - val_loss: 23.4580\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.9892 - val_loss: 23.1484\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.8939 - val_loss: 23.1286\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 20.7135 - val_loss: 23.0164\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.6416 - val_loss: 23.0139\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.6477 - val_loss: 22.9256\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.5563 - val_loss: 23.0781\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.6479 - val_loss: 22.8549\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.4759 - val_loss: 23.0195\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.9244 - val_loss: 23.5624\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.6957 - val_loss: 22.8757\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.2814 - val_loss: 22.9694\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.3643 - val_loss: 22.5724\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 20.2248 - val_loss: 22.5936\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.2854 - val_loss: 47.9331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 47.0513 - val_loss: 45.3286\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 43.3176 - val_loss: 40.4943\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 41.2768 - val_loss: 40.0062\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.3551 - val_loss: 39.1444\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 38.6493 - val_loss: 38.7887\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.5074 - val_loss: 38.1102\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.8279 - val_loss: 39.0231\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.6930 - val_loss: 36.7660\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.4265 - val_loss: 38.0900\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.2717 - val_loss: 36.6551\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 35.8686 - val_loss: 36.5339\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.9465 - val_loss: 37.1192\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.1981 - val_loss: 41.4266\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.7223 - val_loss: 35.4594\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.1367 - val_loss: 37.5607\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.5884 - val_loss: 35.5870\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.9266 - val_loss: 36.0389\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.5215 - val_loss: 37.5185\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.6471 - val_loss: 36.3529\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.9854 - val_loss: 51.7280\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 47.8023 - val_loss: 44.0663\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 42.8818 - val_loss: 41.7586\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 41.9831 - val_loss: 39.8225\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 39.6211 - val_loss: 38.5058\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.1671 - val_loss: 40.9595\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.9527 - val_loss: 38.9119\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.8005 - val_loss: 40.2564\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.4226 - val_loss: 37.0985\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.9011 - val_loss: 35.8556\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.8163 - val_loss: 36.2110\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.6740 - val_loss: 36.4042\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.3847 - val_loss: 38.2657\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.5052 - val_loss: 34.8963\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 34.8681 - val_loss: 34.5091\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.3238 - val_loss: 34.4215\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.1049 - val_loss: 34.5952\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.8708 - val_loss: 34.4156\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.4793 - val_loss: 33.9739\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 34.4301 - val_loss: 34.8939\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.8895 - val_loss: 33.2234\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.0716 - val_loss: 33.1399\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.2934 - val_loss: 34.0957\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.8880 - val_loss: 33.4778\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.1381 - val_loss: 32.1346\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.2629 - val_loss: 33.4648\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.5269 - val_loss: 32.7379\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.0762 - val_loss: 33.6598\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.0781 - val_loss: 31.9113\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.6982 - val_loss: 32.2238\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.1560 - val_loss: 32.0132\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.6070 - val_loss: 31.6600\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.2256 - val_loss: 31.6239\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.4480 - val_loss: 30.6853\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.4502 - val_loss: 32.0289\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.9398 - val_loss: 30.8904\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.2815 - val_loss: 30.8731\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.0354 - val_loss: 30.4391\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.9023 - val_loss: 31.2485\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.7741 - val_loss: 29.6540\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.6989 - val_loss: 30.8447\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.2603 - val_loss: 31.2293\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.1784 - val_loss: 29.4167\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.8913 - val_loss: 27.1291\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 26.5003 - val_loss: 26.7457\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.5099 - val_loss: 25.6683\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.0083 - val_loss: 25.1440\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 24.5228 - val_loss: 24.9375\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.3242 - val_loss: 26.0440\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.9128 - val_loss: 25.0474\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.6723 - val_loss: 24.2214\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.5195 - val_loss: 24.3116\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.3387 - val_loss: 23.8078\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.0121 - val_loss: 23.9520\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.9511 - val_loss: 23.5688\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.7365 - val_loss: 24.4221\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.6546 - val_loss: 23.7225\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.6034 - val_loss: 23.3354\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 625us/step - loss: 22.4963 - val_loss: 23.5215\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.2339 - val_loss: 23.0024\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0522 - val_loss: 22.9123\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.0395 - val_loss: 22.9929\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8184 - val_loss: 22.8564\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 22.1305 - val_loss: 22.8028\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.1348 - val_loss: 22.6612\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.6738 - val_loss: 22.6280\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.6733 - val_loss: 22.7074\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7348 - val_loss: 22.5810\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.4368 - val_loss: 22.5718\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3877 - val_loss: 22.4871\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3216 - val_loss: 22.5086\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2660 - val_loss: 22.5192\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.1720 - val_loss: 22.5275\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.5958 - val_loss: 22.6332\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 21.6747 - val_loss: 22.8645\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 94.5500 - val_loss: 87.0647\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 561us/step - loss: 60.1978 - val_loss: 50.5239\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 44.2795 - val_loss: 41.1805\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 41.4086 - val_loss: 39.9920\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.0611 - val_loss: 39.4729\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.4125 - val_loss: 40.4931\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 39.4907 - val_loss: 37.2882\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.7735 - val_loss: 37.9756\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.9202 - val_loss: 36.9562\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.2651 - val_loss: 36.5944\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.9222 - val_loss: 35.1741\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 35.5275 - val_loss: 35.4031\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.1744 - val_loss: 39.6340\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 559us/step - loss: 36.3415 - val_loss: 35.5669\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.1724 - val_loss: 34.7795\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.5903 - val_loss: 33.8446\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.4329 - val_loss: 36.3736\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.1926 - val_loss: 33.0974\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.3608 - val_loss: 34.0397\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.6725 - val_loss: 33.5885\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.2504 - val_loss: 33.2093\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.5768 - val_loss: 36.6004\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.0422 - val_loss: 33.2758\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.4194 - val_loss: 52.6177\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 47.0631 - val_loss: 43.1693\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 42.5156 - val_loss: 42.4681\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 40.8154 - val_loss: 39.8191\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.8490 - val_loss: 42.9821\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.9780 - val_loss: 39.2640\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 40.0383 - val_loss: 46.6836\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 41.1644 - val_loss: 39.3354\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.8263 - val_loss: 37.7185\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.7179 - val_loss: 36.8586\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.5282 - val_loss: 36.9180\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.5309 - val_loss: 37.0184\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 36.4347 - val_loss: 39.3056\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.7430 - val_loss: 35.5379\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.0430 - val_loss: 35.1347\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.4960 - val_loss: 36.2253\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.9791 - val_loss: 34.5617\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.5214 - val_loss: 35.3441\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.7400 - val_loss: 33.7934\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 34.7309 - val_loss: 33.4459\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.0625 - val_loss: 33.3796\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.8657 - val_loss: 32.9945\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 33.6415 - val_loss: 33.8848\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.8447 - val_loss: 33.4907\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.4719 - val_loss: 34.1339\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.4346 - val_loss: 31.9459\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.1163 - val_loss: 32.7048\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 33.3161 - val_loss: 33.3706\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.2422 - val_loss: 32.0621\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.0499 - val_loss: 31.5936\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.7177 - val_loss: 32.0358\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.6493 - val_loss: 33.0968\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.6689 - val_loss: 31.7936\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.5915 - val_loss: 33.6847\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.6394 - val_loss: 31.0936\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.1619 - val_loss: 30.8740\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.4922 - val_loss: 30.8270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.7260 - val_loss: 31.2679\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.1804 - val_loss: 31.3346\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.2914 - val_loss: 30.3509\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.1537 - val_loss: 30.6799\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.8169 - val_loss: 30.1542\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.4684 - val_loss: 34.0143\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.1683 - val_loss: 30.0292\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.3731 - val_loss: 30.2875\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.6884 - val_loss: 34.6208\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.2381 - val_loss: 31.4270\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.0048 - val_loss: 30.1059\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.6214 - val_loss: 29.5571\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.7470 - val_loss: 31.2565\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.9309 - val_loss: 29.9604\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.5389 - val_loss: 32.1135\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.7603 - val_loss: 29.0329\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.5229 - val_loss: 28.6781\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.9326 - val_loss: 28.8574\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.0606 - val_loss: 28.5362\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.7683 - val_loss: 29.0804\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.5684 - val_loss: 28.8232\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.2813 - val_loss: 28.1907\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 28.2253 - val_loss: 31.3492\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.9532 - val_loss: 28.1005\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.0954 - val_loss: 27.7884\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.0754 - val_loss: 29.2154\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.7815 - val_loss: 27.7294\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.5359 - val_loss: 26.9368\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 26.8590 - val_loss: 29.3430\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.3449 - val_loss: 26.5197\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.2290 - val_loss: 27.5570\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 26.1948 - val_loss: 26.7803\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.1910 - val_loss: 25.9131\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 24.8613 - val_loss: 25.4510\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.4534 - val_loss: 28.3268\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.6921 - val_loss: 24.8478\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 23.9694 - val_loss: 25.3117\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.1254 - val_loss: 24.4371\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 23.5536 - val_loss: 24.5943\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.4723 - val_loss: 23.9417\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.2532 - val_loss: 24.4009\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 23.1834 - val_loss: 23.8737\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.7509 - val_loss: 24.4485\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.6271 - val_loss: 24.1813\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.6764 - val_loss: 23.5420\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.3865 - val_loss: 23.2799\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.4567 - val_loss: 23.4206\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.2660 - val_loss: 23.2860\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.3220 - val_loss: 23.4393\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.1415 - val_loss: 23.2054\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.9763 - val_loss: 23.1560\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.2506 - val_loss: 23.2494\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.9366 - val_loss: 23.3070\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0827 - val_loss: 23.3137\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.6243 - val_loss: 22.9180\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.7534 - val_loss: 23.2020\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.7727 - val_loss: 22.8505\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.5385 - val_loss: 22.8940\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.3924 - val_loss: 22.7987\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.3804 - val_loss: 22.8276\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3564 - val_loss: 22.8882\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.3087 - val_loss: 23.0104\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.2616 - val_loss: 23.0151\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.8920 - val_loss: 47.5466\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 48.1525 - val_loss: 44.6975\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 42.3626 - val_loss: 42.8204\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 40.5589 - val_loss: 42.3437\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 39.6578 - val_loss: 39.3484\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 39.6558 - val_loss: 40.8264\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.0255 - val_loss: 37.6907\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 37.4925 - val_loss: 37.0090\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 37.3803 - val_loss: 36.8609\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 37.2223 - val_loss: 38.6040\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 36.4851 - val_loss: 35.5882\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 36.2315 - val_loss: 36.8671\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 35.7897 - val_loss: 35.5448\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.8064 - val_loss: 35.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 34.5976 - val_loss: 34.6644\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 34.2704 - val_loss: 34.4172\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 35.3723 - val_loss: 34.5107\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.5437 - val_loss: 33.6253\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.1111 - val_loss: 33.0245\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.1863 - val_loss: 33.5323\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 33.3884 - val_loss: 32.9712\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.7536 - val_loss: 34.7860\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.0624 - val_loss: 35.1611\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.7794 - val_loss: 33.3949\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.8986 - val_loss: 31.6631\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.6897 - val_loss: 34.1885\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 32.7053 - val_loss: 35.1735\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.1242 - val_loss: 32.5338\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.2630 - val_loss: 32.2065\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 30.8289 - val_loss: 31.4908\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.4984 - val_loss: 33.4632\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.2534 - val_loss: 32.8615\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.4653 - val_loss: 30.9273\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.0654 - val_loss: 30.8683\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 30.4192 - val_loss: 30.5344\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.4386 - val_loss: 30.3682\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.0081 - val_loss: 32.2593\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 30.9465 - val_loss: 32.3284\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.7171 - val_loss: 30.7296\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.3540 - val_loss: 29.7987\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 29.1243 - val_loss: 30.6243\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 28.8089 - val_loss: 29.2457\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 28.4352 - val_loss: 31.5282\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 28.3348 - val_loss: 28.6335\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 28.4331 - val_loss: 28.6253\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 28.3451 - val_loss: 31.3927\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.3152 - val_loss: 28.3768\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 27.0013 - val_loss: 27.0237\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 25.9813 - val_loss: 26.2125\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.0484 - val_loss: 25.7646\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 863us/step - loss: 25.0472 - val_loss: 26.3786\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 24.6664 - val_loss: 24.9522\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 850us/step - loss: 23.8239 - val_loss: 24.5321\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 883us/step - loss: 23.8045 - val_loss: 25.7305\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 867us/step - loss: 23.6569 - val_loss: 24.2237\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.1455 - val_loss: 23.9493\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 22.9488 - val_loss: 23.9813\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.8399 - val_loss: 23.6761\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.6910 - val_loss: 23.9182\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.6350 - val_loss: 23.6784\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.5039 - val_loss: 23.4145\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.3758 - val_loss: 23.3857\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4341 - val_loss: 23.5461\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 22.3950 - val_loss: 23.5812\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1608 - val_loss: 23.2027\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.0177 - val_loss: 23.1726\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.9087 - val_loss: 22.9318\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.9035 - val_loss: 23.3487\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8012 - val_loss: 22.9493\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6903 - val_loss: 23.0898\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.6812 - val_loss: 22.7579\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4635 - val_loss: 22.9399\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6049 - val_loss: 22.7832\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.5664 - val_loss: 23.0997\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.5907 - val_loss: 22.7712\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5653 - val_loss: 22.7512\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.2195 - val_loss: 22.6391\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 21.1960 - val_loss: 22.6283\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2319 - val_loss: 22.5721\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.1626 - val_loss: 22.5442\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.0469 - val_loss: 22.6746\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.0529 - val_loss: 22.4578\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.8813 - val_loss: 22.4637\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.9310 - val_loss: 22.5491\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.8488 - val_loss: 22.4845\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.7712 - val_loss: 22.4979\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.8379 - val_loss: 22.6932\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.5998 - val_loss: 51.1735\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 47.5923 - val_loss: 43.2283\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 42.4437 - val_loss: 44.1305\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 41.2075 - val_loss: 39.8365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.0518 - val_loss: 41.4250\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.3270 - val_loss: 39.6770\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.2949 - val_loss: 38.9218\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.5996 - val_loss: 39.6338\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.4358 - val_loss: 37.5447\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.3994 - val_loss: 37.3241\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.8079 - val_loss: 37.1062\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.0490 - val_loss: 35.9260\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.1309 - val_loss: 36.6648\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.2904 - val_loss: 36.1843\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.3649 - val_loss: 36.9760\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.8642 - val_loss: 34.9354\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8005 - val_loss: 34.4432\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.4553 - val_loss: 34.5646\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.3037 - val_loss: 35.0813\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.5887 - val_loss: 35.8759\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.9248 - val_loss: 34.4764\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.2607 - val_loss: 33.8730\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.3481 - val_loss: 32.8414\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.4036 - val_loss: 38.6205\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.8699 - val_loss: 33.4084\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.9916 - val_loss: 32.9592\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.2464 - val_loss: 32.3008\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.0115 - val_loss: 32.8298\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.9072 - val_loss: 32.6441\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.4156 - val_loss: 33.1723\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.2347 - val_loss: 33.6390\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.0030 - val_loss: 31.9598\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 30.6314 - val_loss: 31.5705\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.6374 - val_loss: 31.8017\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.9926 - val_loss: 32.2555\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.8074 - val_loss: 30.7440\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.8601 - val_loss: 33.7536\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.6029 - val_loss: 31.3628\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.8126 - val_loss: 32.1968\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.5507 - val_loss: 31.1441\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.3532 - val_loss: 32.3097\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.7590 - val_loss: 46.7180\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 43.9775 - val_loss: 46.1501\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 42.3241 - val_loss: 39.0525\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.9519 - val_loss: 40.1662\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.3563 - val_loss: 38.9536\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.1018 - val_loss: 36.9974\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.1695 - val_loss: 35.4491\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 35.8345 - val_loss: 35.4125\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.4039 - val_loss: 34.2056\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.8971 - val_loss: 33.5715\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.6102 - val_loss: 33.1184\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.0092 - val_loss: 33.1988\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.2490 - val_loss: 32.0630\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.4599 - val_loss: 35.1591\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.5618 - val_loss: 33.4075\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.2032 - val_loss: 33.7121\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.1068 - val_loss: 31.7117\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.0143 - val_loss: 30.6684\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.1537 - val_loss: 30.5771\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.6778 - val_loss: 30.4131\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.1778 - val_loss: 32.3649\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.6691 - val_loss: 30.4062\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.4239 - val_loss: 30.1962\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 30.9799 - val_loss: 29.6799\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.2252 - val_loss: 31.1761\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.9293 - val_loss: 30.1057\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.6365 - val_loss: 29.7275\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 30.5385 - val_loss: 31.2285\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.4503 - val_loss: 30.0984\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.1383 - val_loss: 46.5483\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 45.6281 - val_loss: 42.3389\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 43.6786 - val_loss: 41.1768\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 41.8580 - val_loss: 40.2077\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.6878 - val_loss: 39.8968\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.9253 - val_loss: 42.0961\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 41.6611 - val_loss: 41.5755\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.7131 - val_loss: 41.0090\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.7963 - val_loss: 37.8429\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 37.6324 - val_loss: 37.4950\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.9482 - val_loss: 36.4090\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.9557 - val_loss: 39.4215\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.7429 - val_loss: 37.5817\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.5851 - val_loss: 39.7934\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 37.7892 - val_loss: 39.3723\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.1096 - val_loss: 37.7177\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.1096 - val_loss: 47.1485\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 48.5642 - val_loss: 46.6182\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 44.4388 - val_loss: 42.6292\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 41.2724 - val_loss: 40.0210\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 40.1142 - val_loss: 38.8928\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.2577 - val_loss: 38.6359\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.9389 - val_loss: 39.8166\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.9615 - val_loss: 37.5873\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.0004 - val_loss: 39.2372\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.0409 - val_loss: 37.4530\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.3450 - val_loss: 37.1116\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.0515 - val_loss: 34.9316\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.4790 - val_loss: 39.0660\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.3723 - val_loss: 34.7997\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.7911 - val_loss: 34.2766\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.2079 - val_loss: 33.4929\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.1154 - val_loss: 33.8058\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.8615 - val_loss: 33.1313\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.0747 - val_loss: 32.9871\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.7414 - val_loss: 33.4766\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.7032 - val_loss: 33.8205\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.4398 - val_loss: 35.0261\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.4247 - val_loss: 32.5997\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.1310 - val_loss: 32.9942\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.8827 - val_loss: 33.1855\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.7934 - val_loss: 31.5481\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 31.4005 - val_loss: 31.6287\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.9087 - val_loss: 31.4159\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.6525 - val_loss: 31.3365\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.5562 - val_loss: 31.4284\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.2650 - val_loss: 30.6602\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.2471 - val_loss: 31.2874\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.2364 - val_loss: 30.2701\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.1948 - val_loss: 30.1476\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.3483 - val_loss: 29.4066\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.4154 - val_loss: 32.5774\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.5282 - val_loss: 29.8734\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.8534 - val_loss: 28.9999\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.9640 - val_loss: 29.1436\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.4304 - val_loss: 31.7037\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.0163 - val_loss: 28.3749\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.2279 - val_loss: 27.4817\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.7007 - val_loss: 26.9830\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.0587 - val_loss: 27.9365\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.0108 - val_loss: 29.6084\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 26.7468 - val_loss: 26.9284\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 25.2666 - val_loss: 25.2048\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.4203 - val_loss: 25.6126\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.1800 - val_loss: 24.7215\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 23.8487 - val_loss: 24.2817\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.6294 - val_loss: 24.1874\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.4954 - val_loss: 24.0680\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.2626 - val_loss: 24.1193\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.1875 - val_loss: 23.7526\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.9393 - val_loss: 23.9032\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.9205 - val_loss: 23.5621\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.7897 - val_loss: 23.4312\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.7461 - val_loss: 23.3454\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.5884 - val_loss: 23.4016\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.6861 - val_loss: 23.6182\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3145 - val_loss: 23.0939\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.3627 - val_loss: 23.1262\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.1339 - val_loss: 23.0321\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.1164 - val_loss: 22.9331\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.9409 - val_loss: 22.8710\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2602 - val_loss: 24.5613\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2438 - val_loss: 23.4385\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.0322 - val_loss: 23.3303\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.9041 - val_loss: 22.7545\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.7436 - val_loss: 22.7708\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.6823 - val_loss: 22.7137\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 621us/step - loss: 21.6997 - val_loss: 22.7148\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.4840 - val_loss: 22.7200\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.6521 - val_loss: 22.7817\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.6229 - val_loss: 22.6152\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.5617 - val_loss: 22.6893\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.3069 - val_loss: 22.6456\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.2661 - val_loss: 22.6525\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2624 - val_loss: 22.5453\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2577 - val_loss: 22.8697\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.3379 - val_loss: 22.6446\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.2546 - val_loss: 22.5604\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.1278 - val_loss: 22.4664\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.0122 - val_loss: 22.4509\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.0455 - val_loss: 22.5789\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.8759 - val_loss: 22.4591\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.9220 - val_loss: 22.4017\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.8286 - val_loss: 22.7093\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9518 - val_loss: 22.4321\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9491 - val_loss: 23.2015\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.9323 - val_loss: 22.7267\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.8003 - val_loss: 22.3775\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.5647 - val_loss: 22.4324\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6422 - val_loss: 22.4292\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.7168 - val_loss: 22.8125\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 20.4636 - val_loss: 22.3578\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.6716 - val_loss: 22.4005\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.4967 - val_loss: 22.7845\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.4221 - val_loss: 22.4083\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.4055 - val_loss: 22.8221\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.5599 - val_loss: 45.4595\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 43.4079 - val_loss: 41.2537\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.0029 - val_loss: 39.9965\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.0172 - val_loss: 38.8894\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.8451 - val_loss: 36.1615\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.3247 - val_loss: 34.6682\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.7620 - val_loss: 36.2342\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 35.5441 - val_loss: 37.1126\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.6629 - val_loss: 33.2492\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.6846 - val_loss: 32.6225\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.3379 - val_loss: 32.0471\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 32.5089 - val_loss: 32.9796\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 31.3032 - val_loss: 32.3739\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 34.0877 - val_loss: 33.4329\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.9306 - val_loss: 31.3220\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 30.9664 - val_loss: 31.2389\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.9992 - val_loss: 31.0534\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 31.4201 - val_loss: 33.2373\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 30.4753 - val_loss: 30.3484\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.1530 - val_loss: 33.3326\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.1946 - val_loss: 30.2490\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 29.6761 - val_loss: 33.7413\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 29.6363 - val_loss: 29.9868\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 29.4025 - val_loss: 30.2203\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.2273 - val_loss: 29.1460\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 28.7444 - val_loss: 31.6691\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 28.8362 - val_loss: 29.4819\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 29.6292 - val_loss: 29.2094\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 28.5207 - val_loss: 28.6975\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 27.9621 - val_loss: 28.8688\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 27.6700 - val_loss: 28.9257\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 27.7753 - val_loss: 28.5145\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 27.7029 - val_loss: 29.3569\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.1386 - val_loss: 33.9512\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 29.5352 - val_loss: 28.8814\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 27.4653 - val_loss: 28.7112\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 26.9007 - val_loss: 28.7774\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 87.1829 - val_loss: 56.1003\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 52.2499 - val_loss: 46.6098\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 46.2194 - val_loss: 43.1419\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 44.1475 - val_loss: 43.0329\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 43.5986 - val_loss: 41.0718\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 41.8194 - val_loss: 41.7846\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.3542 - val_loss: 40.0919\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.2667 - val_loss: 39.3019\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.7158 - val_loss: 41.0571\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 38.6215 - val_loss: 37.6313\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.8632 - val_loss: 37.1197\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.5543 - val_loss: 36.6895\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.0177 - val_loss: 35.7338\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.6719 - val_loss: 35.7939\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.6905 - val_loss: 37.7588\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.5424 - val_loss: 35.6705\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.8252 - val_loss: 34.9743\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 35.6250 - val_loss: 36.3492\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.2063 - val_loss: 34.0579\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.2658 - val_loss: 33.6399\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.3860 - val_loss: 32.0883\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.0912 - val_loss: 35.6839\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.3149 - val_loss: 31.6396\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.3819 - val_loss: 32.7674\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.2468 - val_loss: 32.6907\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.4677 - val_loss: 29.3467\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.5721 - val_loss: 29.4238\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.2603 - val_loss: 27.9132\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.6484 - val_loss: 28.2224\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.9537 - val_loss: 27.0524\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.5201 - val_loss: 27.8507\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.3540 - val_loss: 26.2705\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 25.9431 - val_loss: 26.7125\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.9786 - val_loss: 27.2227\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.1453 - val_loss: 26.0822\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.2476 - val_loss: 25.4264\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.9960 - val_loss: 25.2061\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 24.7502 - val_loss: 24.9576\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.4141 - val_loss: 24.8503\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.2735 - val_loss: 24.7141\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.1281 - val_loss: 24.4930\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.9158 - val_loss: 24.3892\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.6978 - val_loss: 24.4881\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.6053 - val_loss: 24.1477\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.4685 - val_loss: 24.2008\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.3712 - val_loss: 24.1506\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.1825 - val_loss: 24.0043\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.0234 - val_loss: 23.8403\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.8419 - val_loss: 23.9396\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.8000 - val_loss: 23.3249\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.6026 - val_loss: 23.2917\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.4158 - val_loss: 23.2475\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.3009 - val_loss: 23.1683\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.1405 - val_loss: 22.9252\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.0126 - val_loss: 22.8434\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.1174 - val_loss: 23.7485\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 22.2242 - val_loss: 22.9288\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.9119 - val_loss: 22.6934\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.7386 - val_loss: 22.6397\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.6768 - val_loss: 22.5074\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.5497 - val_loss: 22.5797\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.5928 - val_loss: 22.5508\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.5320 - val_loss: 22.4729\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5510 - val_loss: 22.6324\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.3505 - val_loss: 22.3600\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1531 - val_loss: 22.3511\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0564 - val_loss: 22.3745\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.2872 - val_loss: 22.3518\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.1598 - val_loss: 22.4428\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.2497 - val_loss: 22.4726\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.2899 - val_loss: 22.1732\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.1032 - val_loss: 22.3423\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.7828 - val_loss: 22.1968\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.7525 - val_loss: 22.0746\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.6582 - val_loss: 22.5029\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.6044 - val_loss: 22.2548\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.5515 - val_loss: 22.1556\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 20.8954 - val_loss: 22.6251\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.7501 - val_loss: 22.4792\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.3686 - val_loss: 47.6500\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 46.8345 - val_loss: 44.4007\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 42.7141 - val_loss: 43.5279\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.8406 - val_loss: 40.5101\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 40.5583 - val_loss: 39.1093\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.5426 - val_loss: 41.8406\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.1180 - val_loss: 39.1509\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.3081 - val_loss: 39.3619\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 626us/step - loss: 37.2841 - val_loss: 37.2824\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.7708 - val_loss: 37.1442\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 37.3977 - val_loss: 37.5081\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 37.2872 - val_loss: 36.3399\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 37.3741 - val_loss: 36.2096\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.3551 - val_loss: 38.1242\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 35.6184 - val_loss: 37.5886\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 35.4837 - val_loss: 34.9399\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 34.0754 - val_loss: 34.7505\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.8626 - val_loss: 34.8652\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.8226 - val_loss: 44.5305\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.7635 - val_loss: 37.1565\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 35.2163 - val_loss: 34.3653\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 33.8309 - val_loss: 34.8188\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 34.1200 - val_loss: 37.7857\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.8996 - val_loss: 35.8848\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.0633 - val_loss: 33.0167\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.5996 - val_loss: 33.2426\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.1707 - val_loss: 35.2724\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.1276 - val_loss: 34.2979\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.8900 - val_loss: 34.7442\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.1123 - val_loss: 34.1167\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 79.6560 - val_loss: 51.1317\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 47.2080 - val_loss: 43.5511\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 43.1997 - val_loss: 41.2419\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.6479 - val_loss: 41.7729\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 40.7374 - val_loss: 42.6011\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 39.9581 - val_loss: 39.0444\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.0054 - val_loss: 38.1616\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.8651 - val_loss: 39.0128\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.6280 - val_loss: 37.0999\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.0307 - val_loss: 40.5002\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.7182 - val_loss: 38.4321\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.9039 - val_loss: 36.2104\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.7351 - val_loss: 35.4383\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.7667 - val_loss: 35.3523\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 35.0794 - val_loss: 35.0014\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 36.8459 - val_loss: 36.3870\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.5711 - val_loss: 37.8008\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 752us/step - loss: 35.4844 - val_loss: 34.0525\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 512us/step - loss: 34.5782 - val_loss: 33.9704\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 33.3299 - val_loss: 34.7444\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 721us/step - loss: 34.7050 - val_loss: 33.8032\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 756us/step - loss: 32.6783 - val_loss: 34.5153\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 32.3874 - val_loss: 32.9548\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.8519 - val_loss: 34.8285\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.0841 - val_loss: 33.8920\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.8475 - val_loss: 33.8626\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.8460 - val_loss: 32.2203\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.0402 - val_loss: 32.0566\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.1450 - val_loss: 31.8385\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.8581 - val_loss: 31.6295\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.9546 - val_loss: 34.1684\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.9171 - val_loss: 31.2123\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.1375 - val_loss: 30.0047\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.0777 - val_loss: 29.9150\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.5858 - val_loss: 29.0380\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 27.8775 - val_loss: 28.1488\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.9622 - val_loss: 28.2608\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.6792 - val_loss: 26.6640\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 25.9116 - val_loss: 26.9899\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.3114 - val_loss: 25.4940\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.8943 - val_loss: 26.0119\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 25.5035 - val_loss: 25.1913\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 25.2449 - val_loss: 25.0192\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 24.0768 - val_loss: 24.3284\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.9167 - val_loss: 24.2278\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.7180 - val_loss: 24.1920\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.7463 - val_loss: 23.9755\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.3091 - val_loss: 23.8023\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.2292 - val_loss: 23.7326\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.0401 - val_loss: 23.7513\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.9527 - val_loss: 23.5294\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 22.8199 - val_loss: 23.4371\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 22.9406 - val_loss: 23.4385\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.8531 - val_loss: 23.5675\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.5560 - val_loss: 23.3491\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 614us/step - loss: 22.5475 - val_loss: 23.1794\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.3722 - val_loss: 23.2182\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.3044 - val_loss: 23.3768\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.2927 - val_loss: 23.1540\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.2766 - val_loss: 23.0232\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.1717 - val_loss: 22.9826\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.2222 - val_loss: 23.0930\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.0400 - val_loss: 22.8943\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.9492 - val_loss: 22.9625\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8837 - val_loss: 22.9552\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.8996 - val_loss: 22.8272\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.7821 - val_loss: 22.8883\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.6746 - val_loss: 22.7052\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 21.8146 - val_loss: 22.9753\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.7436 - val_loss: 22.7049\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.6127 - val_loss: 22.6733\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6399 - val_loss: 22.6226\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.5126 - val_loss: 22.7927\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4379 - val_loss: 22.6973\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.4390 - val_loss: 22.9096\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 21.5655 - val_loss: 22.5949\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.2749 - val_loss: 22.5845\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.2779 - val_loss: 22.5573\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.1775 - val_loss: 22.4786\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1195 - val_loss: 22.5090\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.2938 - val_loss: 22.8733\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.1946 - val_loss: 22.5661\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0745 - val_loss: 22.4923\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1191 - val_loss: 22.4812\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.3534 - val_loss: 54.7983\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 49.6643 - val_loss: 49.1177\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 47.0492 - val_loss: 45.1385\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 44.9678 - val_loss: 44.6042\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 44.5070 - val_loss: 45.9923\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 44.0980 - val_loss: 43.5553\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 42.9413 - val_loss: 46.6427\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.4778 - val_loss: 40.9080\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 41.8960 - val_loss: 40.7985\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.2326 - val_loss: 41.9831\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 40.8648 - val_loss: 40.5603\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.9340 - val_loss: 39.2289\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.7124 - val_loss: 38.3981\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.1738 - val_loss: 38.1966\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.8714 - val_loss: 38.7786\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.1772 - val_loss: 38.0327\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.0081 - val_loss: 38.4077\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.3368 - val_loss: 36.5367\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.5416 - val_loss: 37.8682\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.7875 - val_loss: 36.4139\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.9949 - val_loss: 35.9617\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.5067 - val_loss: 37.3905\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.9615 - val_loss: 35.0701\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.3128 - val_loss: 34.5645\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.8743 - val_loss: 35.4442\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.6057 - val_loss: 34.7077\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.0577 - val_loss: 33.9548\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.2868 - val_loss: 34.6530\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.2060 - val_loss: 34.4931\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.7489 - val_loss: 33.5101\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.9819 - val_loss: 34.2583\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.8966 - val_loss: 32.5677\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.3891 - val_loss: 32.6572\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.3826 - val_loss: 35.3180\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.4359 - val_loss: 33.0985\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.8047 - val_loss: 31.4564\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.3428 - val_loss: 31.0979\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.9365 - val_loss: 29.7998\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.6505 - val_loss: 29.9089\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.9865 - val_loss: 28.9484\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.4425 - val_loss: 28.0484\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.1668 - val_loss: 27.4988\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 26.2214 - val_loss: 26.7545\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.3765 - val_loss: 25.9646\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.7538 - val_loss: 25.3773\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.2251 - val_loss: 25.0194\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 24.1698 - val_loss: 25.9888\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.9886 - val_loss: 24.6284\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 636us/step - loss: 23.5656 - val_loss: 24.3400\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.3799 - val_loss: 24.5360\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.2277 - val_loss: 24.6870\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.1655 - val_loss: 24.2923\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.0718 - val_loss: 23.8283\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.2135 - val_loss: 23.6819\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.9319 - val_loss: 23.4885\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.7105 - val_loss: 23.4712\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.5391 - val_loss: 23.7011\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3691 - val_loss: 23.1946\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.4977 - val_loss: 23.1944\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.3519 - val_loss: 23.5606\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.2157 - val_loss: 23.0010\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 22.2276 - val_loss: 23.3706\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2475 - val_loss: 23.0211\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.0359 - val_loss: 23.3429\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.8626 - val_loss: 22.7980\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.8385 - val_loss: 22.8266\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.0382 - val_loss: 23.1895\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.0905 - val_loss: 22.8096\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.7060 - val_loss: 22.6900\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.6124 - val_loss: 22.7052\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5665 - val_loss: 22.5917\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3762 - val_loss: 22.6977\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5212 - val_loss: 22.5340\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.3687 - val_loss: 23.1969\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.2723 - val_loss: 22.4659\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1600 - val_loss: 22.5447\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 21.1472 - val_loss: 22.4778\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.0715 - val_loss: 22.6717\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.2318 - val_loss: 22.6546\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.0894 - val_loss: 22.4387\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.2535 - val_loss: 22.5355\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.1161 - val_loss: 22.4102\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.9065 - val_loss: 22.6144\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.8599 - val_loss: 22.5319\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7923 - val_loss: 22.4213\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.6996 - val_loss: 22.4627\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.6980 - val_loss: 22.3256\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.6688 - val_loss: 23.5446\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.6255 - val_loss: 23.1456\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1266 - val_loss: 22.3727\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.5076 - val_loss: 22.3438\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.4149 - val_loss: 22.2804\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.3881 - val_loss: 22.4384\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.2263 - val_loss: 22.3326\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.3105 - val_loss: 22.3523\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.1653 - val_loss: 22.3223\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.0902 - val_loss: 22.3253\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.3340 - val_loss: 45.6868\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 43.8452 - val_loss: 41.2926\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 41.3735 - val_loss: 40.4165\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.0645 - val_loss: 39.1444\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.5652 - val_loss: 40.2021\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.2664 - val_loss: 37.2477\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.6281 - val_loss: 36.7226\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.7009 - val_loss: 36.0912\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.7964 - val_loss: 35.2409\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.1117 - val_loss: 35.2006\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.9114 - val_loss: 33.8977\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.0413 - val_loss: 33.8652\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.7835 - val_loss: 35.0437\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.3364 - val_loss: 34.3030\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.0379 - val_loss: 41.2176\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.8728 - val_loss: 34.5728\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.7910 - val_loss: 32.8617\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.2887 - val_loss: 33.0946\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.7031 - val_loss: 33.8799\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.2180 - val_loss: 32.7491\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.4136 - val_loss: 32.3784\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.8282 - val_loss: 33.4854\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.3974 - val_loss: 32.8512\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.2498 - val_loss: 33.5071\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.8834 - val_loss: 33.6792\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.0158 - val_loss: 31.5460\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.3116 - val_loss: 32.8626\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.6163 - val_loss: 32.8975\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 601us/step - loss: 32.9331 - val_loss: 35.5472\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.7501 - val_loss: 32.8158\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.9138 - val_loss: 31.3460\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.1057 - val_loss: 31.3839\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.0336 - val_loss: 30.0097\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.4936 - val_loss: 29.8055\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 30.6809 - val_loss: 36.2540\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.9187 - val_loss: 33.3548\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.1827 - val_loss: 30.3723\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.9239 - val_loss: 30.2050\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.6931 - val_loss: 29.6312\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.2344 - val_loss: 29.5719\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.8754 - val_loss: 28.8311\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 28.4457 - val_loss: 28.5746\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.9471 - val_loss: 28.0859\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.6711 - val_loss: 30.0999\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 27.8613 - val_loss: 29.0536\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 29.6842 - val_loss: 29.4675\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.0427 - val_loss: 27.6947\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.2206 - val_loss: 26.9489\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.2128 - val_loss: 26.9193\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.5573 - val_loss: 25.7720\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.8390 - val_loss: 26.0290\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 25.0533 - val_loss: 25.4576\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.4220 - val_loss: 28.2311\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.9985 - val_loss: 24.9066\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.8259 - val_loss: 24.4711\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.8300 - val_loss: 24.2094\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.4522 - val_loss: 23.9802\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.2039 - val_loss: 23.6147\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.0929 - val_loss: 24.2348\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.0123 - val_loss: 23.4318\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.7599 - val_loss: 23.7391\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.6324 - val_loss: 23.2617\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.6477 - val_loss: 23.1394\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.5168 - val_loss: 23.2671\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.3701 - val_loss: 23.2915\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.3689 - val_loss: 23.1725\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.5016 - val_loss: 23.2895\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.1642 - val_loss: 22.7559\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.1137 - val_loss: 22.7675\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.9614 - val_loss: 23.6095\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.9584 - val_loss: 22.7822\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9501 - val_loss: 22.9477\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.9273 - val_loss: 22.7129\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.7640 - val_loss: 22.6869\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6237 - val_loss: 22.5508\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.6725 - val_loss: 22.5610\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.5995 - val_loss: 22.5761\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.4817 - val_loss: 22.3897\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.4856 - val_loss: 22.8734\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6681 - val_loss: 22.3827\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.3552 - val_loss: 22.3510\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.5279 - val_loss: 22.4802\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.4023 - val_loss: 22.2957\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.4036 - val_loss: 22.2904\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.3070 - val_loss: 22.3784\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4861 - val_loss: 22.4727\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.1319 - val_loss: 22.2406\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.0393 - val_loss: 22.1869\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0107 - val_loss: 22.2129\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0514 - val_loss: 22.2398\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.0836 - val_loss: 22.3761\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.0780 - val_loss: 22.1577\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9718 - val_loss: 22.4458\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.1324 - val_loss: 22.1216\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.8273 - val_loss: 22.1882\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.7563 - val_loss: 22.1420\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.7029 - val_loss: 22.3804\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.6816 - val_loss: 22.2570\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.6519 - val_loss: 22.3023\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.0720 - val_loss: 47.2691\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 44.1988 - val_loss: 41.3995\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.1015 - val_loss: 39.9701\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 40.0471 - val_loss: 42.2932\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.1601 - val_loss: 38.4606\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.2181 - val_loss: 37.2099\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 624us/step - loss: 39.3909 - val_loss: 37.6727\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 37.4028 - val_loss: 36.8743\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.1850 - val_loss: 36.5275\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.3043 - val_loss: 36.6829\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.4541 - val_loss: 37.8094\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 370us/step - loss: 35.7211 - val_loss: 35.4196\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 498us/step - loss: 34.9567 - val_loss: 36.1066\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.2549 - val_loss: 34.7791\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.1206 - val_loss: 36.8184\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.6571 - val_loss: 34.7177\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.5239 - val_loss: 34.4910\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.7712 - val_loss: 33.8100\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.9834 - val_loss: 34.3418\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.4757 - val_loss: 33.0738\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.8574 - val_loss: 32.6722\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.3708 - val_loss: 33.0207\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 32.3979 - val_loss: 32.4951\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 31.8358 - val_loss: 32.9227\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 31.6317 - val_loss: 33.6530\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 31.1486 - val_loss: 31.7818\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 31.6096 - val_loss: 32.1379\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 30.6314 - val_loss: 31.5702\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 30.3250 - val_loss: 31.5075\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 30.7496 - val_loss: 35.3532\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 31.4759 - val_loss: 31.7288\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 32.6462 - val_loss: 32.6586\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 31.7245 - val_loss: 35.2770\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 30.9393 - val_loss: 31.2710\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.0209 - val_loss: 31.1728\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.2746 - val_loss: 30.5152\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 29.5594 - val_loss: 30.4948\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 28.9252 - val_loss: 31.1875\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 28.5886 - val_loss: 30.0028\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 28.6342 - val_loss: 29.6933\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 28.9730 - val_loss: 30.0800\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 30.4208 - val_loss: 30.1488\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 28.9740 - val_loss: 29.5692\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 27.9218 - val_loss: 29.3216\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 27.8084 - val_loss: 29.6539\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 27.7171 - val_loss: 29.1444\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 28.1618 - val_loss: 29.5821\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 28.4174 - val_loss: 29.4009\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 28.1049 - val_loss: 29.3142\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 27.6664 - val_loss: 28.8940\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 27.0787 - val_loss: 29.3928\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 27.7323 - val_loss: 28.5359\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 26.8134 - val_loss: 28.2227\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 26.4542 - val_loss: 28.3759\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 26.7967 - val_loss: 28.2526\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 26.8490 - val_loss: 28.3404\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 26.4828 - val_loss: 28.0656\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 26.4496 - val_loss: 27.8641\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 26.2939 - val_loss: 27.1239\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 25.8811 - val_loss: 27.0671\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 25.4874 - val_loss: 31.6633\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 26.5845 - val_loss: 26.9971\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 25.1371 - val_loss: 26.3706\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 24.6822 - val_loss: 25.8765\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 24.5862 - val_loss: 25.8397\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.3990 - val_loss: 26.1181\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 24.4886 - val_loss: 25.7843\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 23.7843 - val_loss: 25.3022\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 23.4747 - val_loss: 25.1005\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.3257 - val_loss: 24.5140\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 23.3671 - val_loss: 24.5797\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 23.1062 - val_loss: 24.4980\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 22.7873 - val_loss: 24.7156\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 22.7485 - val_loss: 24.0245\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 23.0592 - val_loss: 24.3972\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 22.9368 - val_loss: 23.9150\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 22.4297 - val_loss: 24.0047\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.3510 - val_loss: 23.6988\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 22.2219 - val_loss: 23.7503\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.3583 - val_loss: 23.5665\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.0913 - val_loss: 23.6117\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.9759 - val_loss: 23.3805\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.8044 - val_loss: 23.3610\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 21.8306 - val_loss: 23.3919\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 903us/step - loss: 21.8347 - val_loss: 23.3385\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 21.7413 - val_loss: 23.4142\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 859us/step - loss: 21.6739 - val_loss: 23.1786\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 21.5273 - val_loss: 23.3306\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 772us/step - loss: 21.5168 - val_loss: 23.0854\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.3737 - val_loss: 23.2108\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.7512 - val_loss: 24.2622\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.6850 - val_loss: 23.1954\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3628 - val_loss: 23.0689\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2743 - val_loss: 23.0580\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1904 - val_loss: 22.9519\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.2337 - val_loss: 23.0896\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.2175 - val_loss: 23.4130\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.0921 - val_loss: 23.0909\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.0331 - val_loss: 23.1289\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8898 - val_loss: 23.0073\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.1592 - val_loss: 44.5947\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 44.9241 - val_loss: 40.4668\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.0277 - val_loss: 40.6277\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.1149 - val_loss: 39.0935\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 40.5407 - val_loss: 37.5395\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.3036 - val_loss: 38.5676\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.0140 - val_loss: 37.1763\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 38.1230 - val_loss: 37.6247\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.8683 - val_loss: 35.8364\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.8310 - val_loss: 37.5689\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.0259 - val_loss: 41.6346\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.2392 - val_loss: 35.1214\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.9310 - val_loss: 34.5508\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.8395 - val_loss: 34.4257\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 36.0672 - val_loss: 35.3577\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.8523 - val_loss: 38.6982\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.4095 - val_loss: 34.7416\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.7308 - val_loss: 33.5711\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.9016 - val_loss: 34.7365\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.0803 - val_loss: 34.6106\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.0455 - val_loss: 35.4102\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.5083 - val_loss: 33.0053\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 35.0537 - val_loss: 41.9583\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 750us/step - loss: 36.1238 - val_loss: 33.9086\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.8106 - val_loss: 32.6493\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.1432 - val_loss: 37.5990\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.8809 - val_loss: 32.0146\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.3229 - val_loss: 32.2489\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.1129 - val_loss: 31.3681\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.7432 - val_loss: 34.8909\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.1567 - val_loss: 32.7579\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.0951 - val_loss: 30.9159\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.4079 - val_loss: 30.9480\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.9103 - val_loss: 31.3697\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.5197 - val_loss: 31.5724\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.7422 - val_loss: 30.6682\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.4099 - val_loss: 29.9738\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.5374 - val_loss: 29.8420\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.1671 - val_loss: 29.7814\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.8669 - val_loss: 29.8243\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.7597 - val_loss: 31.5859\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.0055 - val_loss: 30.8950\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.3514 - val_loss: 29.2497\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.4190 - val_loss: 30.0526\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.0936 - val_loss: 29.2384\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.0290 - val_loss: 28.8354\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.2571 - val_loss: 28.4517\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.1307 - val_loss: 28.6025\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 28.9636 - val_loss: 29.1952\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.8343 - val_loss: 27.9052\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.0027 - val_loss: 27.2594\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 28.0066 - val_loss: 27.1408\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.0977 - val_loss: 26.7634\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.5199 - val_loss: 30.5527\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 29.0089 - val_loss: 28.4476\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.3713 - val_loss: 25.8362\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.0528 - val_loss: 24.9673\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 24.4231 - val_loss: 26.5798\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.2107 - val_loss: 24.2235\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.7028 - val_loss: 24.2135\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 629us/step - loss: 23.5060 - val_loss: 23.6548\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.2685 - val_loss: 24.7574\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.3927 - val_loss: 23.5763\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.8596 - val_loss: 23.4142\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.8013 - val_loss: 23.2080\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3993 - val_loss: 22.9968\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3036 - val_loss: 22.9183\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.0928 - val_loss: 23.0593\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.9892 - val_loss: 22.7083\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.7985 - val_loss: 22.9127\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.6812 - val_loss: 22.6053\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6247 - val_loss: 22.8973\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6832 - val_loss: 22.4826\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.5574 - val_loss: 22.5787\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.6736 - val_loss: 23.1402\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 746us/step - loss: 21.5079 - val_loss: 22.3496\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 741us/step - loss: 21.2418 - val_loss: 22.9626\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 900us/step - loss: 21.3218 - val_loss: 22.3056\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 762us/step - loss: 21.1265 - val_loss: 22.4587\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.9443 - val_loss: 22.4278\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.0412 - val_loss: 22.2139\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9563 - val_loss: 22.2865\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.7148 - val_loss: 22.1394\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.6085 - val_loss: 22.1262\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.5893 - val_loss: 22.1271\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.4694 - val_loss: 22.0082\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 20.5567 - val_loss: 22.0744\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 20.3404 - val_loss: 21.9363\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.2514 - val_loss: 21.9066\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.2123 - val_loss: 21.9995\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.2142 - val_loss: 21.9668\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.0698 - val_loss: 21.9717\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 19.9742 - val_loss: 21.9779\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.0270 - val_loss: 22.0559\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.4140 - val_loss: 57.2002\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 45.6586 - val_loss: 41.5932\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.6283 - val_loss: 39.9804\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 40.5914 - val_loss: 39.8394\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.4235 - val_loss: 46.5026\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 41.5134 - val_loss: 38.4529\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.8154 - val_loss: 37.9216\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 39.3639 - val_loss: 39.3760\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.6418 - val_loss: 38.3706\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.6694 - val_loss: 37.3150\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 41.0692 - val_loss: 40.3763\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.2704 - val_loss: 36.6094\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.4924 - val_loss: 36.6879\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.8300 - val_loss: 36.3519\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 37.1409 - val_loss: 35.8575\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.1529 - val_loss: 37.3405\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 37.8897 - val_loss: 41.9214\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.5773 - val_loss: 35.7544\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.5335 - val_loss: 35.1566\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.0094 - val_loss: 35.6426\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.4193 - val_loss: 34.0585\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.6509 - val_loss: 34.4991\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.3036 - val_loss: 34.6235\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.0743 - val_loss: 34.7494\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.1564 - val_loss: 33.1540\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.4170 - val_loss: 36.6722\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.8553 - val_loss: 38.1948\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.9107 - val_loss: 36.1466\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 34.4219 - val_loss: 33.8583\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.6417 - val_loss: 40.7301\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.7715 - val_loss: 46.1090\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 44.2775 - val_loss: 42.5097\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.9631 - val_loss: 40.8469\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 40.5890 - val_loss: 40.3449\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 40.0745 - val_loss: 39.2037\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 40.6250 - val_loss: 39.2511\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.0326 - val_loss: 38.9805\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.8552 - val_loss: 39.5796\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 39.9467 - val_loss: 38.6156\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.7372 - val_loss: 37.2039\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.8992 - val_loss: 37.3796\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.9388 - val_loss: 35.8638\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.7426 - val_loss: 36.8541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.6225 - val_loss: 36.3496\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.1600 - val_loss: 34.4931\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.2603 - val_loss: 36.5497\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.0934 - val_loss: 35.4353\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.8600 - val_loss: 33.7679\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8078 - val_loss: 34.1773\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.9865 - val_loss: 34.7896\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.2416 - val_loss: 32.5788\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.3728 - val_loss: 34.6828\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.6384 - val_loss: 43.6248\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.1049 - val_loss: 32.9723\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.3838 - val_loss: 32.6742\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.7470 - val_loss: 37.7639\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 84.0953 - val_loss: 50.2300\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 50.2263 - val_loss: 46.8661\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 44.6055 - val_loss: 42.9021\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.4946 - val_loss: 40.2114\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.5205 - val_loss: 39.7448\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 41.0643 - val_loss: 40.1767\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.5088 - val_loss: 39.2911\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.4996 - val_loss: 43.0386\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.2871 - val_loss: 40.3391\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.1744 - val_loss: 37.3790\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.4197 - val_loss: 36.2920\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.6085 - val_loss: 35.4079\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.5904 - val_loss: 36.3232\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.6715 - val_loss: 37.2935\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.1094 - val_loss: 34.7793\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.7426 - val_loss: 34.0852\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.1725 - val_loss: 34.6625\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.0807 - val_loss: 34.2639\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.4936 - val_loss: 34.2139\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.8221 - val_loss: 34.2322\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.0280 - val_loss: 32.9471\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.1225 - val_loss: 34.3125\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.1542 - val_loss: 34.6649\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.3492 - val_loss: 32.8892\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 31.5844 - val_loss: 32.6623\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.5587 - val_loss: 32.7296\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.8882 - val_loss: 31.7162\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.7823 - val_loss: 35.2887\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.4801 - val_loss: 32.1370\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.6407 - val_loss: 31.1839\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.5649 - val_loss: 31.3687\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.0252 - val_loss: 30.9930\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.5627 - val_loss: 30.7906\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.1375 - val_loss: 30.8500\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.2346 - val_loss: 32.8715\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.6944 - val_loss: 29.7437\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.3264 - val_loss: 29.3138\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.6986 - val_loss: 31.2373\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.0656 - val_loss: 29.0695\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.2801 - val_loss: 28.5714\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.5418 - val_loss: 30.0807\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 27.2383 - val_loss: 28.9156\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.5867 - val_loss: 33.4180\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.4713 - val_loss: 28.2586\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.4268 - val_loss: 27.2010\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.9593 - val_loss: 26.5488\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.0583 - val_loss: 25.7159\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.4900 - val_loss: 25.8399\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.6350 - val_loss: 25.2123\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.1688 - val_loss: 25.4319\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 24.0340 - val_loss: 24.6389\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.5234 - val_loss: 24.4582\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.5472 - val_loss: 25.1757\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.1588 - val_loss: 24.0269\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.2438 - val_loss: 25.3910\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.4924 - val_loss: 23.8445\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.7766 - val_loss: 23.6185\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.3742 - val_loss: 23.3711\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1673 - val_loss: 23.3757\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.1383 - val_loss: 23.4673\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.0518 - val_loss: 23.1159\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.9754 - val_loss: 23.0801\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.3077 - val_loss: 23.8503\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.9361 - val_loss: 23.1639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.8081 - val_loss: 23.4467\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.6241 - val_loss: 23.1742\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 21.5057 - val_loss: 22.9529\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 21.3447 - val_loss: 22.6523\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3042 - val_loss: 23.2259\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2365 - val_loss: 22.5926\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.1154 - val_loss: 22.5208\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.0229 - val_loss: 22.4548\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.9647 - val_loss: 22.4724\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.9898 - val_loss: 22.3735\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.8557 - val_loss: 22.3556\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.7514 - val_loss: 22.5058\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.7781 - val_loss: 22.2754\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.8505 - val_loss: 22.3567\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.7986 - val_loss: 22.3274\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.5187 - val_loss: 22.2488\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.4906 - val_loss: 22.0653\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 20.5895 - val_loss: 22.1682\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.3192 - val_loss: 22.1785\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.2676 - val_loss: 22.1131\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.3436 - val_loss: 22.1022\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.3890 - val_loss: 22.1562\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.6156 - val_loss: 49.7638\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 46.7447 - val_loss: 45.6822\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 44.1387 - val_loss: 42.4935\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 41.9905 - val_loss: 42.8438\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 40.0550 - val_loss: 39.5852\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 38.6909 - val_loss: 39.9465\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 39.8645 - val_loss: 40.5212\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 38.0034 - val_loss: 38.4489\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 39.1917 - val_loss: 39.7912\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 38.9003 - val_loss: 39.9322\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 37.4483 - val_loss: 37.1338\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.6554 - val_loss: 36.5000\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 35.7790 - val_loss: 37.1103\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 35.7135 - val_loss: 36.3508\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.9477 - val_loss: 34.9864\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.4731 - val_loss: 35.5260\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 34.1425 - val_loss: 34.4318\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 34.0562 - val_loss: 34.8722\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 34.7121 - val_loss: 34.7367\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.8658 - val_loss: 34.5742\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 34.7344 - val_loss: 34.0665\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.3719 - val_loss: 33.4193\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.4668 - val_loss: 33.4640\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.5826 - val_loss: 32.8702\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 33.3363 - val_loss: 33.4952\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 32.3507 - val_loss: 35.1897\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 32.9333 - val_loss: 33.8892\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 32.9712 - val_loss: 34.1044\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 32.4725 - val_loss: 32.4509\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 31.3353 - val_loss: 34.3418\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 32.1448 - val_loss: 33.0334\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 31.6224 - val_loss: 31.7464\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 30.7264 - val_loss: 31.5891\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 30.0960 - val_loss: 31.4208\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 31.5866 - val_loss: 32.2703\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 30.2972 - val_loss: 30.9703\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 30.6632 - val_loss: 31.0231\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 30.4576 - val_loss: 31.0058\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 29.6927 - val_loss: 31.2643\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 29.8377 - val_loss: 30.3275\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 29.2408 - val_loss: 30.1598\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 29.4760 - val_loss: 30.5082\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.5618 - val_loss: 30.4592\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 28.9426 - val_loss: 30.0763\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 29.9009 - val_loss: 30.4862\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.0727 - val_loss: 29.9768\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 29.0083 - val_loss: 29.5163\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.3392 - val_loss: 31.4610\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 28.6387 - val_loss: 29.0753\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 28.3419 - val_loss: 29.1210\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 28.0887 - val_loss: 30.6359\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 29.3515 - val_loss: 28.9422\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 29.9662 - val_loss: 30.6005\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 28.8242 - val_loss: 28.8786\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.4923 - val_loss: 29.7566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.5224 - val_loss: 28.1614\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 27.3349 - val_loss: 27.7327\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.2998 - val_loss: 27.1320\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 26.4919 - val_loss: 27.7441\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.7770 - val_loss: 26.7841\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 25.9140 - val_loss: 27.0634\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.1838 - val_loss: 26.6984\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.4999 - val_loss: 26.1210\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.0155 - val_loss: 25.8676\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.8203 - val_loss: 25.4159\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.3244 - val_loss: 25.2227\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.1471 - val_loss: 26.0228\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 24.8343 - val_loss: 25.3554\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.8459 - val_loss: 25.6215\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.5576 - val_loss: 24.3279\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.6300 - val_loss: 24.8828\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.3234 - val_loss: 24.9630\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.5042 - val_loss: 24.0739\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.9912 - val_loss: 23.9501\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.8327 - val_loss: 23.9418\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.6932 - val_loss: 24.2754\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.7880 - val_loss: 24.4679\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6216 - val_loss: 23.6132\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.3348 - val_loss: 23.5141\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.3074 - val_loss: 23.5430\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.4876 - val_loss: 24.0720\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4813 - val_loss: 23.4946\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.0217 - val_loss: 23.3509\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.9454 - val_loss: 23.2691\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.9595 - val_loss: 23.2310\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7946 - val_loss: 23.3056\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.7700 - val_loss: 23.1650\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.8844 - val_loss: 23.3071\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.7009 - val_loss: 23.3007\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.1452 - val_loss: 24.1223\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.8385 - val_loss: 23.3661\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.6203 - val_loss: 23.1886\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.2548 - val_loss: 48.0263\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 45.6046 - val_loss: 42.5018\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 40.4418 - val_loss: 39.7694\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.8690 - val_loss: 41.3617\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.7499 - val_loss: 37.4025\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.0683 - val_loss: 37.1256\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.3758 - val_loss: 36.8445\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.4417 - val_loss: 35.8533\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 36.2903 - val_loss: 35.4781\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.9218 - val_loss: 35.4173\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 34.5119 - val_loss: 33.6163\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.5321 - val_loss: 34.6301\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.9594 - val_loss: 33.1605\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.4009 - val_loss: 35.7607\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.7615 - val_loss: 32.2489\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.7840 - val_loss: 32.7456\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.4147 - val_loss: 34.8733\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.8200 - val_loss: 33.5481\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.0107 - val_loss: 31.8057\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.1503 - val_loss: 31.4778\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.2306 - val_loss: 31.2893\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.8036 - val_loss: 32.5022\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.1743 - val_loss: 31.0689\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.1776 - val_loss: 31.6401\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.2562 - val_loss: 31.3490\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 30.8674 - val_loss: 33.5072\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.5396 - val_loss: 31.2136\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.0548 - val_loss: 34.2145\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.9538 - val_loss: 49.1762\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 44.6151 - val_loss: 41.7799\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 42.2567 - val_loss: 39.8508\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.6604 - val_loss: 39.2784\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.2235 - val_loss: 38.0956\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.1659 - val_loss: 38.0665\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.5715 - val_loss: 36.6180\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 39.3804 - val_loss: 38.3781\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.6067 - val_loss: 40.9343\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.0316 - val_loss: 36.9358\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.6436 - val_loss: 35.8930\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.7465 - val_loss: 35.1458\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.5297 - val_loss: 34.5542\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.0089 - val_loss: 34.7023\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.0101 - val_loss: 34.2045\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.6116 - val_loss: 38.5839\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.6474 - val_loss: 33.1300\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.8336 - val_loss: 33.2059\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.5885 - val_loss: 33.3696\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 36.3630 - val_loss: 36.0568\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 33.7009 - val_loss: 32.6183\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.9658 - val_loss: 35.9881\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 35.0459 - val_loss: 32.9848\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.2320 - val_loss: 31.9268\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.6850 - val_loss: 32.3754\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.1169 - val_loss: 31.4598\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.1428 - val_loss: 34.1327\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.2444 - val_loss: 30.7952\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.4654 - val_loss: 34.7494\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.1244 - val_loss: 31.3388\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 30.3810 - val_loss: 30.5136\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.5523 - val_loss: 31.2003\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.5771 - val_loss: 30.0179\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.0571 - val_loss: 29.8934\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 29.3770 - val_loss: 29.8833\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.0463 - val_loss: 29.5384\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.7957 - val_loss: 29.6669\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.8614 - val_loss: 29.1842\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.2402 - val_loss: 29.5888\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 28.2651 - val_loss: 31.9598\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.2697 - val_loss: 30.7305\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.2889 - val_loss: 28.8194\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 27.4841 - val_loss: 28.3450\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.5344 - val_loss: 28.7043\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.7356 - val_loss: 28.5605\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.6864 - val_loss: 27.8565\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 26.8291 - val_loss: 27.8798\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 26.5023 - val_loss: 27.5438\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.9152 - val_loss: 27.5276\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.8406 - val_loss: 26.7391\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.3484 - val_loss: 26.6386\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.9662 - val_loss: 26.7507\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.9040 - val_loss: 25.6895\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.6535 - val_loss: 25.4324\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.1403 - val_loss: 25.1648\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.1795 - val_loss: 27.6321\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.2631 - val_loss: 25.2551\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.9400 - val_loss: 24.8003\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.5037 - val_loss: 24.3706\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.2904 - val_loss: 24.8699\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.1825 - val_loss: 24.1349\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.9287 - val_loss: 23.9794\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.8016 - val_loss: 24.0251\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.7527 - val_loss: 24.1358\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.5983 - val_loss: 23.8082\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.5119 - val_loss: 24.2059\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.3799 - val_loss: 23.6597\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.3501 - val_loss: 23.7417\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.3287 - val_loss: 23.5699\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.2491 - val_loss: 23.5806\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.0942 - val_loss: 23.5355\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.9921 - val_loss: 23.3869\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.0212 - val_loss: 23.4434\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.0873 - val_loss: 23.9125\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.0247 - val_loss: 25.1143\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.4464 - val_loss: 23.4487\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7763 - val_loss: 23.3017\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.7166 - val_loss: 23.3611\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.6453 - val_loss: 23.3304\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.4732 - val_loss: 23.3199\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.5824 - val_loss: 24.0430\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.4874 - val_loss: 23.2578\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3947 - val_loss: 23.2208\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.3350 - val_loss: 23.2059\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.2847 - val_loss: 23.5035\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.2605 - val_loss: 23.3119\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2030 - val_loss: 23.0444\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0425 - val_loss: 23.2720\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 610us/step - loss: 21.0877 - val_loss: 23.1638\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0624 - val_loss: 23.1504\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.9997 - val_loss: 23.1317\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.8619 - val_loss: 23.0735\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 101.0208 - val_loss: 81.2121\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 57.6798 - val_loss: 46.0215\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 46.4448 - val_loss: 45.2500\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 44.1231 - val_loss: 40.2717\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.0967 - val_loss: 40.6361\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 39.6879 - val_loss: 39.6835\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 40.2707 - val_loss: 38.8090\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.0542 - val_loss: 37.9556\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 38.0336 - val_loss: 37.1326\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.1940 - val_loss: 37.3092\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.6015 - val_loss: 36.2300\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 36.0277 - val_loss: 36.3635\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.0300 - val_loss: 35.1631\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.2785 - val_loss: 39.6922\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.3958 - val_loss: 34.6521\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.1556 - val_loss: 35.6369\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.1242 - val_loss: 38.6455\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.1487 - val_loss: 35.2953\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.9787 - val_loss: 34.3164\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.9816 - val_loss: 33.4768\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.2780 - val_loss: 33.7614\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.5869 - val_loss: 35.3589\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.8149 - val_loss: 32.7668\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8288 - val_loss: 39.9720\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.9432 - val_loss: 32.7771\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.9033 - val_loss: 32.2865\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.5109 - val_loss: 33.9883\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.2709 - val_loss: 33.1833\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.7097 - val_loss: 34.7216\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.5125 - val_loss: 34.4636\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.7617 - val_loss: 32.0139\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.9536 - val_loss: 31.3171\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.6727 - val_loss: 34.3837\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.9500 - val_loss: 31.4248\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.5312 - val_loss: 30.4921\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.3672 - val_loss: 30.3135\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 30.0092 - val_loss: 30.1915\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.3137 - val_loss: 33.0204\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.8992 - val_loss: 29.8940\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.0116 - val_loss: 29.5477\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.4263 - val_loss: 29.2307\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.5748 - val_loss: 30.1985\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.6759 - val_loss: 28.8208\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.8114 - val_loss: 28.3044\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 27.1204 - val_loss: 28.2665\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.8392 - val_loss: 27.4215\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.4574 - val_loss: 26.7103\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.8567 - val_loss: 26.6371\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.2340 - val_loss: 25.8320\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.9570 - val_loss: 25.7371\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 24.4676 - val_loss: 25.2363\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 24.4166 - val_loss: 25.6203\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.9748 - val_loss: 24.7281\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.6947 - val_loss: 24.5473\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.5942 - val_loss: 24.6234\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.7675 - val_loss: 24.4906\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.4740 - val_loss: 24.6511\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 23.0819 - val_loss: 24.1833\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.9143 - val_loss: 24.2497\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.7438 - val_loss: 23.9559\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.6321 - val_loss: 24.0438\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.5571 - val_loss: 24.1883\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.5151 - val_loss: 23.8618\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.3477 - val_loss: 23.5362\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.2167 - val_loss: 23.9622\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.2088 - val_loss: 23.4290\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.0948 - val_loss: 23.4613\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9131 - val_loss: 23.3121\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.8822 - val_loss: 23.2834\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6813 - val_loss: 23.2876\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.7861 - val_loss: 23.9974\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.6634 - val_loss: 23.3032\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4706 - val_loss: 23.0853\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 599us/step - loss: 21.3998 - val_loss: 23.1010\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.3905 - val_loss: 23.4087\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3194 - val_loss: 23.1840\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.4249 - val_loss: 23.1737\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.2092 - val_loss: 22.9954\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.0461 - val_loss: 23.0245\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9162 - val_loss: 22.9504\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.9885 - val_loss: 23.0134\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 20.8408 - val_loss: 22.9921\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9312 - val_loss: 22.9466\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.0031 - val_loss: 24.0082\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 20.9632 - val_loss: 22.8626\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.6042 - val_loss: 23.0903\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.6328 - val_loss: 23.0919\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.6182 - val_loss: 22.7220\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.5637 - val_loss: 23.1823\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.4371 - val_loss: 22.7874\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.1679 - val_loss: 22.6723\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.1104 - val_loss: 22.8222\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 19.9763 - val_loss: 22.7130\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 19.9067 - val_loss: 22.8149\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 19.9524 - val_loss: 23.0867\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 19.9158 - val_loss: 22.7789\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.2803 - val_loss: 48.9914\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 44.7553 - val_loss: 45.5885\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.9221 - val_loss: 40.6725\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.8439 - val_loss: 39.7846\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.6049 - val_loss: 39.1276\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.1619 - val_loss: 40.7865\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.1518 - val_loss: 38.0476\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.2928 - val_loss: 36.7241\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.5286 - val_loss: 36.8221\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.3342 - val_loss: 36.2030\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.3351 - val_loss: 37.1766\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.1924 - val_loss: 35.0797\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 34.0314 - val_loss: 34.4607\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 784us/step - loss: 35.8667 - val_loss: 35.8276\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 704us/step - loss: 34.7514 - val_loss: 34.0603\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.6357 - val_loss: 33.8929\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.4425 - val_loss: 35.7035\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.3919 - val_loss: 35.1838\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.3166 - val_loss: 33.2303\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.2481 - val_loss: 32.5907\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.1475 - val_loss: 33.7482\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.8034 - val_loss: 32.4279\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.8136 - val_loss: 32.3085\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.5556 - val_loss: 32.7802\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.3185 - val_loss: 35.1387\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.7749 - val_loss: 32.9230\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.3339 - val_loss: 31.6208\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.5464 - val_loss: 31.9988\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.7251 - val_loss: 34.8031\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.7809 - val_loss: 31.4098\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.4224 - val_loss: 30.7224\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.2837 - val_loss: 34.1639\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.5656 - val_loss: 32.5142\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.8510 - val_loss: 30.9068\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.6862 - val_loss: 30.4357\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 29.1198 - val_loss: 30.2324\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.1619 - val_loss: 30.3670\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 782us/step - loss: 29.1283 - val_loss: 38.0556\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.3682 - val_loss: 29.8387\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 28.3681 - val_loss: 29.8534\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.3388 - val_loss: 32.6660\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.4993 - val_loss: 29.5139\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.2018 - val_loss: 28.8188\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.1419 - val_loss: 29.1107\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 27.7174 - val_loss: 28.9027\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.1151 - val_loss: 31.2008\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.0271 - val_loss: 28.7810\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.2427 - val_loss: 30.6146\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.7249 - val_loss: 28.3048\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 27.4046 - val_loss: 28.9300\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.2737 - val_loss: 27.3149\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 26.3154 - val_loss: 27.2096\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 26.4212 - val_loss: 29.1031\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.0077 - val_loss: 26.3064\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 689us/step - loss: 25.8347 - val_loss: 26.6563\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.3104 - val_loss: 27.0803\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.8786 - val_loss: 26.0854\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.3040 - val_loss: 25.4067\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 24.2236 - val_loss: 26.1520\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.0464 - val_loss: 25.0684\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.1124 - val_loss: 27.3491\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.7540 - val_loss: 25.3258\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.6101 - val_loss: 24.6119\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.3140 - val_loss: 24.1874\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.9508 - val_loss: 23.9441\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.8667 - val_loss: 24.2604\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.9340 - val_loss: 23.7560\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.6392 - val_loss: 23.6779\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.5804 - val_loss: 23.7583\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.6291 - val_loss: 24.6809\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.6221 - val_loss: 23.4944\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.2103 - val_loss: 23.7460\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.2887 - val_loss: 23.4714\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.3498 - val_loss: 24.3568\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3391 - val_loss: 23.2755\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.9819 - val_loss: 23.2174\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.1009 - val_loss: 24.4337\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.9588 - val_loss: 23.2060\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.7581 - val_loss: 23.2028\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7056 - val_loss: 23.2105\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.7835 - val_loss: 23.1154\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.6003 - val_loss: 23.2013\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.4801 - val_loss: 22.9818\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3874 - val_loss: 22.9270\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 695us/step - loss: 21.4212 - val_loss: 22.9285\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3717 - val_loss: 23.2403\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4167 - val_loss: 22.8378\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.1611 - val_loss: 23.0139\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.2583 - val_loss: 22.8313\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.2190 - val_loss: 22.9203\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1269 - val_loss: 22.8808\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0660 - val_loss: 22.7375\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1836 - val_loss: 22.8406\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.8672 - val_loss: 22.7482\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6277 - val_loss: 22.7121\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.1549 - val_loss: 22.7831\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.7803 - val_loss: 22.6740\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.7363 - val_loss: 22.7367\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.7382 - val_loss: 22.6449\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 20.6142 - val_loss: 22.6560\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 92.1967 - val_loss: 54.5843\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 46.2955 - val_loss: 42.4755\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 41.6975 - val_loss: 39.9565\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 42.5276 - val_loss: 41.7455\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.6994 - val_loss: 38.4588\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.3561 - val_loss: 36.7935\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 36.6784 - val_loss: 36.0265\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 36.9751 - val_loss: 39.4450\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 40.4120 - val_loss: 36.8875\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.3617 - val_loss: 36.4453\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.2162 - val_loss: 35.2654\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.4832 - val_loss: 34.8729\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.3070 - val_loss: 34.6206\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.7085 - val_loss: 34.0121\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.6551 - val_loss: 35.8644\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.2779 - val_loss: 34.1243\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.1668 - val_loss: 33.7084\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.3346 - val_loss: 33.0296\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 34.7774 - val_loss: 35.5458\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.0160 - val_loss: 32.7943\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.0893 - val_loss: 32.8568\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.7602 - val_loss: 34.0322\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.7851 - val_loss: 34.2936\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.7558 - val_loss: 31.5140\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.6531 - val_loss: 33.1018\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.5439 - val_loss: 31.7431\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.6940 - val_loss: 30.8848\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.6627 - val_loss: 32.2057\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.2667 - val_loss: 32.2055\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.4555 - val_loss: 30.9154\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.0798 - val_loss: 30.9851\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 637us/step - loss: 30.9111 - val_loss: 30.8269\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.2299 - val_loss: 30.4215\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.9237 - val_loss: 30.4061\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.5544 - val_loss: 33.1080\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.5406 - val_loss: 30.0857\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 29.9643 - val_loss: 30.6634\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.5886 - val_loss: 30.7914\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.2537 - val_loss: 32.8493\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.4035 - val_loss: 30.3263\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.1648 - val_loss: 29.3875\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.6619 - val_loss: 29.2751\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.4848 - val_loss: 30.3304\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 385us/step - loss: 29.2436 - val_loss: 35.6529\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 493us/step - loss: 28.6360 - val_loss: 29.0233\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.5962 - val_loss: 29.3282\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.9424 - val_loss: 29.0313\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.6751 - val_loss: 29.5772\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.1170 - val_loss: 28.7430\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 27.5283 - val_loss: 29.6462\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.9981 - val_loss: 28.5186\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.2041 - val_loss: 29.1833\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.8482 - val_loss: 28.0781\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 26.8604 - val_loss: 28.5537\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.8965 - val_loss: 28.2140\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 26.3419 - val_loss: 28.0976\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 26.4474 - val_loss: 27.4087\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 26.2715 - val_loss: 34.3617\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.4304 - val_loss: 27.4304\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 25.9473 - val_loss: 27.0931\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 25.6642 - val_loss: 27.2780\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 25.3824 - val_loss: 27.1674\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 25.2678 - val_loss: 27.0718\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 24.3597 - val_loss: 26.2008\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 24.6703 - val_loss: 26.6623\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 25.1372 - val_loss: 26.0919\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.2647 - val_loss: 27.0944\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 546us/step - loss: 24.2298 - val_loss: 25.8872\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 686us/step - loss: 23.8257 - val_loss: 24.9149\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.4337 - val_loss: 25.1914\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.8913 - val_loss: 24.6769\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 22.7008 - val_loss: 24.3754\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.9540 - val_loss: 24.5174\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.5848 - val_loss: 24.5924\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.2918 - val_loss: 24.3864\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 22.2604 - val_loss: 23.8593\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.9337 - val_loss: 23.8125\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 21.7569 - val_loss: 23.6765\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.5984 - val_loss: 23.6047\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.6566 - val_loss: 23.7030\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 21.5241 - val_loss: 23.4091\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.5381 - val_loss: 24.1658\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.6795 - val_loss: 23.2051\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.3905 - val_loss: 23.5641\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 21.3110 - val_loss: 23.1107\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.1372 - val_loss: 23.1661\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.1361 - val_loss: 23.2714\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.0767 - val_loss: 23.3575\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.9716 - val_loss: 23.0233\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 20.8228 - val_loss: 22.9148\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 20.7448 - val_loss: 22.8460\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 21.0121 - val_loss: 23.4774\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.8193 - val_loss: 22.8128\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.6042 - val_loss: 23.1548\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 20.7273 - val_loss: 22.6748\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.6231 - val_loss: 22.7613\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.7183 - val_loss: 22.8753\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 20.6173 - val_loss: 22.7908\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.5333 - val_loss: 22.7926\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.6858 - val_loss: 22.7218\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 83.1259 - val_loss: 48.2188\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 42.9486 - val_loss: 40.8777\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 41.1808 - val_loss: 38.9815\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.2980 - val_loss: 36.4648\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.0712 - val_loss: 37.7055\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.7296 - val_loss: 37.0546\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.0328 - val_loss: 35.5610\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 34.7449 - val_loss: 35.1049\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 610us/step - loss: 33.4537 - val_loss: 34.8319\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.2738 - val_loss: 33.3440\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.0712 - val_loss: 32.8155\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 541us/step - loss: 32.5255 - val_loss: 32.4719\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.9270 - val_loss: 34.2893\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.9350 - val_loss: 31.4745\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.7750 - val_loss: 33.0111\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 31.1007 - val_loss: 30.8242\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 30.8329 - val_loss: 30.9839\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.6021 - val_loss: 30.2425\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.0167 - val_loss: 30.6998\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.4653 - val_loss: 30.3886\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.0943 - val_loss: 30.6268\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.9114 - val_loss: 30.9567\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 29.6616 - val_loss: 29.6681\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.4776 - val_loss: 29.9314\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 29.9320 - val_loss: 30.7398\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.4243 - val_loss: 29.5050\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 28.9279 - val_loss: 29.5471\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.9190 - val_loss: 30.0042\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 28.5679 - val_loss: 29.0368\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.8967 - val_loss: 29.3815\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.2416 - val_loss: 28.3679\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.7732 - val_loss: 30.4796\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.0143 - val_loss: 28.8863\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.2683 - val_loss: 28.2132\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 27.7213 - val_loss: 28.3024\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.3305 - val_loss: 29.8323\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.8802 - val_loss: 28.8517\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 27.2042 - val_loss: 28.2009\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 27.1733 - val_loss: 28.0838\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 27.3668 - val_loss: 28.3178\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 27.8968 - val_loss: 27.5235\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.2380 - val_loss: 28.4137\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.2404 - val_loss: 28.4655\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 26.6639 - val_loss: 29.1569\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 27.3585 - val_loss: 27.6258\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 26.7763 - val_loss: 29.1398\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.4759 - val_loss: 47.2126\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 45.0574 - val_loss: 43.5692\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 43.1264 - val_loss: 40.7713\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 42.7996 - val_loss: 41.8503\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 42.6576 - val_loss: 42.4964\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.2355 - val_loss: 40.5593\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 40.4559 - val_loss: 38.8354\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.7110 - val_loss: 37.9759\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.4866 - val_loss: 39.9309\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.5135 - val_loss: 37.6568\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.5203 - val_loss: 36.7429\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.7389 - val_loss: 35.9874\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.6586 - val_loss: 36.3748\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 38.2619 - val_loss: 37.1675\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.6143 - val_loss: 36.5638\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.7844 - val_loss: 35.5624\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.8420 - val_loss: 35.9359\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.5458 - val_loss: 36.0284\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 35.6233 - val_loss: 35.4877\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 35.1319 - val_loss: 38.1124\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.6070 - val_loss: 35.1444\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.2957 - val_loss: 37.2262\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.1140 - val_loss: 33.9298\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 33.6220 - val_loss: 36.2865\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 33.6526 - val_loss: 34.6663\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.0016 - val_loss: 33.7066\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.8776 - val_loss: 34.1975\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.8868 - val_loss: 33.9421\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.1559 - val_loss: 33.5751\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.7655 - val_loss: 35.0902\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.5659 - val_loss: 32.7105\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 32.4279 - val_loss: 33.2561\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.8802 - val_loss: 32.0079\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.8674 - val_loss: 34.1722\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.5525 - val_loss: 34.0913\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.0916 - val_loss: 32.6047\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.4625 - val_loss: 32.1538\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 32.2218 - val_loss: 32.4863\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.6924 - val_loss: 54.6957\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 47.1247 - val_loss: 42.9446\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 44.0564 - val_loss: 40.9360\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.5217 - val_loss: 38.0428\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.5095 - val_loss: 44.4328\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.4497 - val_loss: 36.9114\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.0206 - val_loss: 36.4077\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.6331 - val_loss: 35.8051\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.3673 - val_loss: 36.1056\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.5249 - val_loss: 42.9722\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.6521 - val_loss: 34.5808\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.7536 - val_loss: 38.7086\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 36.6202 - val_loss: 36.7329\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.3865 - val_loss: 35.9323\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.6022 - val_loss: 34.9013\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.4948 - val_loss: 33.6001\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.6340 - val_loss: 38.6845\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.1271 - val_loss: 33.2493\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.7972 - val_loss: 34.3748\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.5916 - val_loss: 32.4442\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.4441 - val_loss: 32.0736\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 729us/step - loss: 32.4005 - val_loss: 31.7329\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 705us/step - loss: 31.5517 - val_loss: 31.9656\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 705us/step - loss: 33.3707 - val_loss: 33.8381\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 934us/step - loss: 31.7989 - val_loss: 31.6673\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 31.4031 - val_loss: 31.5631\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.3550 - val_loss: 31.5527\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.1393 - val_loss: 31.0799\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.8502 - val_loss: 31.0894\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.5225 - val_loss: 31.2830\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.7651 - val_loss: 31.4979\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 29.6389 - val_loss: 30.2770\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.9794 - val_loss: 33.5328\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 718us/step - loss: 30.6213 - val_loss: 30.3611\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 29.1421 - val_loss: 29.2745\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.5020 - val_loss: 29.0597\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.0983 - val_loss: 29.1098\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 28.1360 - val_loss: 28.3848\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 27.1131 - val_loss: 28.5383\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 26.7434 - val_loss: 28.6217\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.8337 - val_loss: 28.5404\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 26.5914 - val_loss: 26.9852\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 25.4955 - val_loss: 26.0895\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.1437 - val_loss: 25.5985\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 25.0800 - val_loss: 25.5530\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.2088 - val_loss: 25.4729\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.1197 - val_loss: 24.7625\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.8575 - val_loss: 24.5645\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.7348 - val_loss: 24.3485\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.8487 - val_loss: 25.4940\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.7382 - val_loss: 24.1679\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.2001 - val_loss: 24.0015\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.9555 - val_loss: 23.8681\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.8458 - val_loss: 24.2682\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 22.9440 - val_loss: 23.7913\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.6980 - val_loss: 23.5412\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.4922 - val_loss: 23.3749\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3665 - val_loss: 23.4783\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.3385 - val_loss: 23.3328\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.1575 - val_loss: 23.1603\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.1675 - val_loss: 23.1082\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0737 - val_loss: 23.5057\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.0624 - val_loss: 23.0282\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.8380 - val_loss: 22.9821\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.7507 - val_loss: 22.9400\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.7744 - val_loss: 22.7952\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8689 - val_loss: 22.7995\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7913 - val_loss: 22.8409\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.0105 - val_loss: 22.7996\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6349 - val_loss: 22.6772\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5108 - val_loss: 22.6750\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.6022 - val_loss: 22.6004\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3160 - val_loss: 22.5578\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.3164 - val_loss: 22.6002\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.2751 - val_loss: 22.9304\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.4359 - val_loss: 22.8755\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4037 - val_loss: 22.6453\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 640us/step - loss: 21.1649 - val_loss: 22.5824\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.8903 - val_loss: 45.5892\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 43.3569 - val_loss: 42.5646\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 40.0197 - val_loss: 41.1601\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 41.0149 - val_loss: 39.7756\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.5801 - val_loss: 39.4836\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.1670 - val_loss: 37.0654\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.4454 - val_loss: 35.4460\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.4645 - val_loss: 35.1697\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.5487 - val_loss: 35.1049\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.1116 - val_loss: 35.0901\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 34.3923 - val_loss: 35.7350\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.4696 - val_loss: 33.7236\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 33.5328 - val_loss: 32.5390\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.4451 - val_loss: 32.5256\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.1019 - val_loss: 32.0050\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.0584 - val_loss: 33.7206\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 31.7457 - val_loss: 33.5975\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.2290 - val_loss: 31.8026\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 30.6805 - val_loss: 30.8466\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.7350 - val_loss: 30.1158\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.0653 - val_loss: 34.0242\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 30.4749 - val_loss: 30.6074\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.7303 - val_loss: 30.1625\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.2951 - val_loss: 30.2871\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.5539 - val_loss: 29.3459\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.9625 - val_loss: 29.1922\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 29.3169 - val_loss: 29.1482\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.1971 - val_loss: 29.1900\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.0307 - val_loss: 28.7598\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.1834 - val_loss: 30.0290\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.7819 - val_loss: 29.0419\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 27.9072 - val_loss: 31.1054\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.2454 - val_loss: 29.4050\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.8635 - val_loss: 29.5353\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.2375 - val_loss: 54.2487\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 50.7708 - val_loss: 47.1501\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 46.2414 - val_loss: 45.3318\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 44.8175 - val_loss: 45.2209\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 44.1304 - val_loss: 44.6135\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 42.8546 - val_loss: 40.8021\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 40.0517 - val_loss: 39.8728\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.3634 - val_loss: 38.8684\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 38.6394 - val_loss: 38.1514\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.1952 - val_loss: 38.1612\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.5214 - val_loss: 37.2030\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.1559 - val_loss: 36.8859\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.5450 - val_loss: 38.0880\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.5882 - val_loss: 37.6860\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.4157 - val_loss: 34.8702\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.8824 - val_loss: 35.1973\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 714us/step - loss: 34.9862 - val_loss: 36.8265\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 36.4254 - val_loss: 35.2703\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 34.4547 - val_loss: 34.0210\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.8834 - val_loss: 35.2767\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.6729 - val_loss: 34.2494\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.3831 - val_loss: 32.0866\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.6931 - val_loss: 34.6199\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 32.3981 - val_loss: 32.2610\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 30.8074 - val_loss: 30.7175\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.3627 - val_loss: 29.9052\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 28.9864 - val_loss: 29.3884\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 27.9303 - val_loss: 27.5573\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 26.9517 - val_loss: 26.9807\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 26.1165 - val_loss: 26.8417\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 26.0429 - val_loss: 26.2311\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.5795 - val_loss: 25.8031\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.2513 - val_loss: 26.3499\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 24.8730 - val_loss: 25.2888\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.8539 - val_loss: 27.1518\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 25.2939 - val_loss: 24.8285\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.0714 - val_loss: 24.5082\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.7254 - val_loss: 24.3645\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.5487 - val_loss: 24.2563\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.6258 - val_loss: 25.4276\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.6482 - val_loss: 24.9550\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 23.4606 - val_loss: 23.8759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.9890 - val_loss: 23.6980\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.8231 - val_loss: 23.4888\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.6606 - val_loss: 23.4191\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.5352 - val_loss: 23.3539\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.5511 - val_loss: 23.4487\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4341 - val_loss: 23.2274\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.6369 - val_loss: 23.6262\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.9451 - val_loss: 23.8826\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.3786 - val_loss: 23.0146\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0329 - val_loss: 22.9883\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.0356 - val_loss: 22.9098\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.9397 - val_loss: 23.0950\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.9716 - val_loss: 22.9435\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0041 - val_loss: 22.8131\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.6902 - val_loss: 22.6461\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7099 - val_loss: 22.7630\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.5454 - val_loss: 22.7439\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5285 - val_loss: 22.8376\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.5045 - val_loss: 22.9917\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.4312 - val_loss: 22.8262\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 86.3425 - val_loss: 60.1757\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 47.7120 - val_loss: 48.6384\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 44.8939 - val_loss: 42.7942\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 44.7338 - val_loss: 42.7472\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 40.3839 - val_loss: 39.9459\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.3375 - val_loss: 40.3551\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.4804 - val_loss: 40.3193\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 38.3647 - val_loss: 37.7243\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 38.1702 - val_loss: 38.3527\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.2342 - val_loss: 36.5783\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.9899 - val_loss: 36.7705\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.7743 - val_loss: 36.0384\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 36.3690 - val_loss: 35.2068\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.9454 - val_loss: 35.9922\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.9018 - val_loss: 37.9682\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.0856 - val_loss: 34.2035\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.8460 - val_loss: 35.1048\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.6697 - val_loss: 34.5945\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 34.0944 - val_loss: 35.3034\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.8322 - val_loss: 33.8761\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.8902 - val_loss: 35.0521\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 33.3764 - val_loss: 33.0813\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.0717 - val_loss: 33.1221\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.9037 - val_loss: 32.9150\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.9501 - val_loss: 36.9309\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.1558 - val_loss: 35.1448\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.3029 - val_loss: 34.0102\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.8096 - val_loss: 32.2063\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.7986 - val_loss: 33.4990\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.4307 - val_loss: 32.2282\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.0975 - val_loss: 32.0234\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.2932 - val_loss: 34.1567\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.2422 - val_loss: 33.7357\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.9672 - val_loss: 31.8473\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 31.6286 - val_loss: 32.3182\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.3909 - val_loss: 32.9013\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.5693 - val_loss: 30.6108\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.9461 - val_loss: 30.2332\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.9309 - val_loss: 30.5088\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.0059 - val_loss: 30.8143\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.3985 - val_loss: 30.0595\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.9709 - val_loss: 30.0498\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.1353 - val_loss: 32.4399\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.7963 - val_loss: 29.5609\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.5532 - val_loss: 32.3110\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.3711 - val_loss: 32.7874\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.5726 - val_loss: 30.1194\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.8156 - val_loss: 29.7825\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 28.1091 - val_loss: 28.7651\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.3837 - val_loss: 28.8086\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.9527 - val_loss: 32.3864\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.1034 - val_loss: 29.5148\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.7582 - val_loss: 29.8698\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 27.6956 - val_loss: 32.1901\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.1955 - val_loss: 48.9929\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 47.5487 - val_loss: 49.0499\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 44.0744 - val_loss: 43.7544\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 42.6886 - val_loss: 42.7246\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 42.2128 - val_loss: 41.0335\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.1038 - val_loss: 39.2601\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.0171 - val_loss: 39.4683\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 39.6466 - val_loss: 39.3508\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.5726 - val_loss: 37.9701\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.8628 - val_loss: 37.2175\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.7204 - val_loss: 38.0720\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.1760 - val_loss: 36.6780\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 36.7116 - val_loss: 37.2728\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.3087 - val_loss: 37.5059\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.6187 - val_loss: 36.0501\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 36.0134 - val_loss: 37.1787\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.7111 - val_loss: 35.1610\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.3618 - val_loss: 35.2235\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.1523 - val_loss: 35.1065\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.2389 - val_loss: 36.7736\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.0445 - val_loss: 34.4435\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.2658 - val_loss: 34.2527\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.8881 - val_loss: 34.2665\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.5787 - val_loss: 36.6555\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.1375 - val_loss: 36.0344\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 33.6716 - val_loss: 36.1508\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.2344 - val_loss: 35.0170\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.0930 - val_loss: 54.4709\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 49.5518 - val_loss: 55.2403\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 48.9739 - val_loss: 45.9255\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 44.2613 - val_loss: 47.5641\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 45.5818 - val_loss: 43.6899\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 42.5224 - val_loss: 43.1137\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.6049 - val_loss: 41.6123\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 44.0848 - val_loss: 42.3724\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.6938 - val_loss: 41.7841\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 39.6669 - val_loss: 40.5210\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.0586 - val_loss: 41.2403\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.0301 - val_loss: 38.9497\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.0844 - val_loss: 38.6829\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.5533 - val_loss: 40.2469\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 37.5126 - val_loss: 38.3206\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.0162 - val_loss: 37.8212\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.5205 - val_loss: 42.7021\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.7350 - val_loss: 43.8512\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.1912 - val_loss: 38.6252\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.4443 - val_loss: 37.5332\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8346 - val_loss: 36.4310\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.9544 - val_loss: 38.3223\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.9530 - val_loss: 36.6126\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 33.5052 - val_loss: 34.9358\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.9666 - val_loss: 34.7916\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.6353 - val_loss: 35.2135\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.4741 - val_loss: 36.0846\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.1584 - val_loss: 33.7402\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.5649 - val_loss: 32.4737\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.2143 - val_loss: 31.5774\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.7387 - val_loss: 30.5069\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.2658 - val_loss: 31.4571\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.8311 - val_loss: 29.2685\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.6264 - val_loss: 28.2483\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 26.7161 - val_loss: 26.8799\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 26.2160 - val_loss: 26.5467\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.3564 - val_loss: 26.2262\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.9352 - val_loss: 25.4188\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 24.6933 - val_loss: 25.2818\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 24.8042 - val_loss: 25.2250\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.0912 - val_loss: 24.9575\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.8885 - val_loss: 24.5512\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.6838 - val_loss: 24.5278\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.5377 - val_loss: 24.1729\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.3495 - val_loss: 24.2784\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 23.2258 - val_loss: 23.9005\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.0643 - val_loss: 23.9229\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.9455 - val_loss: 23.6819\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.7710 - val_loss: 23.6390\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.6740 - val_loss: 23.6606\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.6812 - val_loss: 23.4833\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.4299 - val_loss: 23.4142\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 622us/step - loss: 22.3549 - val_loss: 23.4591\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.5030 - val_loss: 23.7203\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.3896 - val_loss: 23.1384\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.0379 - val_loss: 23.1115\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.0058 - val_loss: 23.6616\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.1943 - val_loss: 23.1424\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 21.8601 - val_loss: 22.9531\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.8143 - val_loss: 23.1621\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.0260 - val_loss: 23.5018\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7032 - val_loss: 23.0415\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6548 - val_loss: 22.8058\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.4912 - val_loss: 22.8027\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5397 - val_loss: 22.8219\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4178 - val_loss: 22.6273\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.3210 - val_loss: 22.6815\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.4311 - val_loss: 22.9492\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2416 - val_loss: 22.6552\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.3176 - val_loss: 22.5624\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.8231 - val_loss: 23.2469\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.3958 - val_loss: 22.5227\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.0385 - val_loss: 22.5585\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 20.9963 - val_loss: 22.4471\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.9074 - val_loss: 22.4639\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.8288 - val_loss: 22.4281\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 21.0430 - val_loss: 22.5385\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.1210 - val_loss: 22.6854\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.0021 - val_loss: 22.4733\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.7241 - val_loss: 22.9307\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.8974 - val_loss: 22.4964\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.5612 - val_loss: 44.4793\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 43.6720 - val_loss: 40.4796\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 41.2519 - val_loss: 41.4441\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.7509 - val_loss: 39.4436\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.3724 - val_loss: 37.6643\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.0897 - val_loss: 37.1273\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 37.1508 - val_loss: 36.2365\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.5215 - val_loss: 36.6143\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.0086 - val_loss: 37.2694\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.2627 - val_loss: 37.6234\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.3638 - val_loss: 37.1354\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.6229 - val_loss: 34.8170\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 35.0100 - val_loss: 34.7540\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.3393 - val_loss: 34.1128\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.5005 - val_loss: 37.3193\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 34.6972 - val_loss: 33.5516\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 34.3387 - val_loss: 34.9747\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.6856 - val_loss: 32.6430\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.3467 - val_loss: 32.4333\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.8832 - val_loss: 32.5893\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.6970 - val_loss: 32.1644\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.4404 - val_loss: 32.0214\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.0125 - val_loss: 33.6072\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 32.3999 - val_loss: 33.0453\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.9790 - val_loss: 33.4528\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.5106 - val_loss: 31.7861\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.7596 - val_loss: 32.8395\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.9838 - val_loss: 31.2275\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.0711 - val_loss: 32.1978\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.2554 - val_loss: 36.1638\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.2111 - val_loss: 31.1082\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 31.0999 - val_loss: 30.8600\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.5041 - val_loss: 31.6493\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.2755 - val_loss: 30.5078\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.9380 - val_loss: 31.2613\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.5194 - val_loss: 30.8407\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.1194 - val_loss: 29.9365\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.0675 - val_loss: 29.0107\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.6877 - val_loss: 29.7413\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.6578 - val_loss: 28.6069\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 28.1181 - val_loss: 29.6274\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.6653 - val_loss: 29.6511\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.4580 - val_loss: 28.3854\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.5752 - val_loss: 27.6299\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 27.1031 - val_loss: 27.2486\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 26.2428 - val_loss: 26.4427\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.2427 - val_loss: 26.1268\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.0737 - val_loss: 25.1279\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 24.7479 - val_loss: 24.7433\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 24.9238 - val_loss: 26.8501\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 25.0523 - val_loss: 24.1751\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.6417 - val_loss: 23.8369\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.3010 - val_loss: 23.7923\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.2907 - val_loss: 23.5023\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.9739 - val_loss: 23.3149\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.7716 - val_loss: 23.2724\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.7287 - val_loss: 23.1768\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.5352 - val_loss: 22.9372\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.4506 - val_loss: 23.0845\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4419 - val_loss: 22.8341\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.4706 - val_loss: 23.1241\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.3247 - val_loss: 22.7986\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.1620 - val_loss: 23.9400\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.1949 - val_loss: 22.6997\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.0481 - val_loss: 23.0078\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.9885 - val_loss: 22.6286\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8132 - val_loss: 22.5069\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.7588 - val_loss: 22.6522\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6346 - val_loss: 22.4088\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.6846 - val_loss: 23.2933\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7617 - val_loss: 22.8597\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.6963 - val_loss: 22.6017\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.6011 - val_loss: 22.3467\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.4830 - val_loss: 22.4146\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4195 - val_loss: 22.3130\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.4039 - val_loss: 22.3250\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 767us/step - loss: 21.2565 - val_loss: 22.4655\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 700us/step - loss: 21.2020 - val_loss: 22.2268\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 776us/step - loss: 21.1550 - val_loss: 22.1836\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 793us/step - loss: 21.1822 - val_loss: 22.4486\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.1257 - val_loss: 22.1564\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.0547 - val_loss: 22.1231\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.0534 - val_loss: 22.2564\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0908 - val_loss: 22.0822\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9228 - val_loss: 22.1857\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.8883 - val_loss: 22.2511\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.8338 - val_loss: 22.2409\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.9869 - val_loss: 22.5424\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 719us/step - loss: 20.8004 - val_loss: 22.1880\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.0662 - val_loss: 54.6288\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 48.0798 - val_loss: 44.8777\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.1509 - val_loss: 39.9564\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.2189 - val_loss: 40.1627\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.1172 - val_loss: 39.3542\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.7343 - val_loss: 36.9686\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 37.4031 - val_loss: 36.7597\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.3742 - val_loss: 35.9249\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.9284 - val_loss: 35.4688\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.2904 - val_loss: 38.0668\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.4652 - val_loss: 34.7191\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.0972 - val_loss: 34.5983\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.7674 - val_loss: 36.9615\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.3923 - val_loss: 33.9032\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.0350 - val_loss: 33.6355\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.3348 - val_loss: 35.4153\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8700 - val_loss: 33.1944\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.2818 - val_loss: 32.6734\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.0695 - val_loss: 32.8808\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.3251 - val_loss: 33.2996\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.7755 - val_loss: 32.3902\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.8334 - val_loss: 32.3590\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.7054 - val_loss: 33.8157\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.2367 - val_loss: 32.9387\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.0821 - val_loss: 32.8011\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.4800 - val_loss: 33.3869\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.1007 - val_loss: 32.3452\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.4702 - val_loss: 31.9400\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.4383 - val_loss: 30.9027\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.1087 - val_loss: 30.5555\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.5937 - val_loss: 41.3619\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.9661 - val_loss: 31.9358\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.5345 - val_loss: 31.2587\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.5540 - val_loss: 30.7913\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.6643 - val_loss: 30.4903\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.4430 - val_loss: 30.3155\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 632us/step - loss: 28.9228 - val_loss: 29.8757\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.0293 - val_loss: 30.1505\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.6960 - val_loss: 30.2404\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 28.9478 - val_loss: 30.0141\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.6762 - val_loss: 31.1430\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.9952 - val_loss: 29.6489\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.7585 - val_loss: 29.4182\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.6897 - val_loss: 29.3861\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.6180 - val_loss: 31.2264\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.8401 - val_loss: 28.8261\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.4343 - val_loss: 28.6397\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.7197 - val_loss: 28.7329\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.4437 - val_loss: 30.0073\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 27.6072 - val_loss: 29.4449\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.2402 - val_loss: 28.9975\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 27.3256 - val_loss: 28.3568\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.0728 - val_loss: 28.4243\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.8446 - val_loss: 28.3435\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.8017 - val_loss: 27.7536\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.5642 - val_loss: 28.3372\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.9992 - val_loss: 27.7277\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.9028 - val_loss: 27.3117\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.6508 - val_loss: 29.7649\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 27.2251 - val_loss: 27.6935\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 26.6502 - val_loss: 27.3183\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.2536 - val_loss: 28.1758\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.9794 - val_loss: 26.8580\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.2856 - val_loss: 26.6862\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 25.1827 - val_loss: 26.8064\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.6977 - val_loss: 26.1931\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.9708 - val_loss: 28.1293\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.4383 - val_loss: 25.9941\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 24.1542 - val_loss: 25.4503\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.0808 - val_loss: 25.3482\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.9493 - val_loss: 27.1771\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.5134 - val_loss: 24.8031\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 23.3223 - val_loss: 24.5964\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.1117 - val_loss: 24.3744\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.3536 - val_loss: 24.4353\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 22.6966 - val_loss: 24.2166\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.5226 - val_loss: 24.0772\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4538 - val_loss: 23.8740\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.9969 - val_loss: 24.0233\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7518 - val_loss: 23.9196\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4889 - val_loss: 23.5191\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.0776 - val_loss: 23.3647\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0052 - val_loss: 23.3417\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9050 - val_loss: 23.2101\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.7258 - val_loss: 23.1945\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.6495 - val_loss: 23.2712\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.6277 - val_loss: 23.2732\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.6215 - val_loss: 23.0837\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5998 - val_loss: 23.4577\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.6381 - val_loss: 23.0347\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3623 - val_loss: 22.9865\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.3142 - val_loss: 23.0071\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.1664 - val_loss: 22.8724\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.3060 - val_loss: 22.8655\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.1643 - val_loss: 23.1931\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2516 - val_loss: 22.8530\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0919 - val_loss: 22.8654\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.0965 - val_loss: 23.2848\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.3876 - val_loss: 23.2879\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.9427 - val_loss: 22.7485\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.2551 - val_loss: 46.8741\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 45.8019 - val_loss: 46.8346\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 43.3782 - val_loss: 38.3476\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.1340 - val_loss: 52.1285\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.2781 - val_loss: 38.8333\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.2514 - val_loss: 36.5800\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 39.8237 - val_loss: 37.2991\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.8453 - val_loss: 35.9456\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.0259 - val_loss: 35.3849\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.2865 - val_loss: 35.1721\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.5451 - val_loss: 35.0245\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.6929 - val_loss: 36.7164\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.7554 - val_loss: 34.9616\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 613us/step - loss: 39.4955 - val_loss: 35.2686\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.0730 - val_loss: 34.3447\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.4798 - val_loss: 34.8212\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 35.9955 - val_loss: 34.8872\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.8478 - val_loss: 34.0771\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.7400 - val_loss: 32.8039\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.2793 - val_loss: 34.1510\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.8724 - val_loss: 32.6786\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.2124 - val_loss: 33.6846\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.4582 - val_loss: 35.1968\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.3820 - val_loss: 31.9869\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.0772 - val_loss: 32.2258\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 32.7414 - val_loss: 34.2640\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.0646 - val_loss: 31.7991\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.0687 - val_loss: 30.7252\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.9613 - val_loss: 30.7477\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 31.9008 - val_loss: 30.9651\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.7086 - val_loss: 30.1849\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.1381 - val_loss: 30.5805\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.4391 - val_loss: 30.2859\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.5266 - val_loss: 29.7670\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 29.8877 - val_loss: 35.1309\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.6305 - val_loss: 32.1759\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.6725 - val_loss: 29.8358\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.9179 - val_loss: 29.2583\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.9016 - val_loss: 30.2007\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.4747 - val_loss: 29.6479\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 30.4487 - val_loss: 29.7938\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.0852 - val_loss: 29.2175\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 28.3848 - val_loss: 28.3278\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.0104 - val_loss: 29.9829\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.4627 - val_loss: 28.0205\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.0867 - val_loss: 28.1747\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.5402 - val_loss: 27.7346\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 27.4359 - val_loss: 30.7896\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.9656 - val_loss: 28.7827\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 26.2284 - val_loss: 26.3019\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.4225 - val_loss: 25.7599\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.1527 - val_loss: 26.2513\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.5648 - val_loss: 24.9898\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.0788 - val_loss: 24.7113\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.7244 - val_loss: 25.3911\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.1444 - val_loss: 24.2676\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.7184 - val_loss: 24.6455\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.1890 - val_loss: 23.6740\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.6529 - val_loss: 23.5523\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.5458 - val_loss: 23.4678\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.2895 - val_loss: 23.2756\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.2114 - val_loss: 23.1538\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.0519 - val_loss: 23.1209\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.2079 - val_loss: 23.4449\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.1421 - val_loss: 22.9871\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.7394 - val_loss: 23.0649\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.7518 - val_loss: 22.8343\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5496 - val_loss: 22.7818\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.4644 - val_loss: 23.1961\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.3624 - val_loss: 22.7077\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.2330 - val_loss: 22.5885\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.2401 - val_loss: 22.6996\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.1955 - val_loss: 22.4804\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.0637 - val_loss: 22.4940\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.0382 - val_loss: 22.5376\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 412us/step - loss: 20.9746 - val_loss: 22.3508\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 476us/step - loss: 20.8210 - val_loss: 22.2857\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 20.7493 - val_loss: 22.3424\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.6431 - val_loss: 22.5246\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.5439 - val_loss: 22.5206\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.6239 - val_loss: 22.3525\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.6085 - val_loss: 22.3758\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 94.6155 - val_loss: 85.1388\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 76.3456 - val_loss: 43.7173\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 45.0893 - val_loss: 60.3519\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 44.8958 - val_loss: 40.7630\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 41.4569 - val_loss: 51.8999\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 43.6277 - val_loss: 42.2763\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 40.1128 - val_loss: 38.6440\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 39.7982 - val_loss: 39.3438\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 679us/step - loss: 39.3088 - val_loss: 39.1347\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 38.7718 - val_loss: 37.3598\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.4672 - val_loss: 38.1383\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 38.6976 - val_loss: 37.0517\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 37.6608 - val_loss: 36.9233\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 37.6942 - val_loss: 37.0802\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 38.3688 - val_loss: 37.3576\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 37.3435 - val_loss: 37.7662\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 36.4175 - val_loss: 36.1249\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 36.7630 - val_loss: 35.9171\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 35.6301 - val_loss: 34.2720\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 36.6187 - val_loss: 35.8740\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 37.7425 - val_loss: 40.4220\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 36.9034 - val_loss: 38.5823\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.2431 - val_loss: 34.0365\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 34.6623 - val_loss: 34.7833\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 33.9862 - val_loss: 34.0246\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 33.2158 - val_loss: 33.5124\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 32.6534 - val_loss: 33.4252\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 32.9407 - val_loss: 37.0408\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.3374 - val_loss: 32.5824\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 31.8301 - val_loss: 31.4202\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.6162 - val_loss: 32.2864\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 767us/step - loss: 32.3493 - val_loss: 33.5265\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 971us/step - loss: 31.4687 - val_loss: 30.3127\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 913us/step - loss: 30.8351 - val_loss: 29.9427\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 884us/step - loss: 30.1892 - val_loss: 30.4206\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 889us/step - loss: 30.6855 - val_loss: 29.7369\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 29.8447 - val_loss: 30.2663\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9197 - val_loss: 30.5736\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.5204 - val_loss: 28.6677\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.2425 - val_loss: 29.5470\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.3442 - val_loss: 27.5269\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.0572 - val_loss: 27.9724\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.2762 - val_loss: 27.9434\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 26.4723 - val_loss: 26.3787\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.4307 - val_loss: 25.8933\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 26.1290 - val_loss: 25.6500\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 24.9986 - val_loss: 24.9808\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 24.8180 - val_loss: 25.0448\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.0531 - val_loss: 24.3468\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.6230 - val_loss: 23.9223\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.5999 - val_loss: 23.8292\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.1828 - val_loss: 23.6233\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.9731 - val_loss: 23.4376\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.9159 - val_loss: 23.3501\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.7765 - val_loss: 23.2076\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.5911 - val_loss: 23.1078\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.4338 - val_loss: 23.0272\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.3070 - val_loss: 22.9864\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2821 - val_loss: 23.0949\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 22.1953 - val_loss: 22.8343\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.1280 - val_loss: 23.0427\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.9904 - val_loss: 22.6698\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.8264 - val_loss: 22.7839\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.8207 - val_loss: 22.6467\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.6481 - val_loss: 22.5089\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.5590 - val_loss: 22.5269\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.6124 - val_loss: 22.5525\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.4921 - val_loss: 22.5172\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.4711 - val_loss: 22.2971\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2909 - val_loss: 22.3397\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.2161 - val_loss: 22.2672\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.0840 - val_loss: 22.1514\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.0415 - val_loss: 22.1188\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.0248 - val_loss: 22.1668\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.0390 - val_loss: 22.1633\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.9751 - val_loss: 22.0890\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.9147 - val_loss: 21.9799\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.7623 - val_loss: 21.9523\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.6818 - val_loss: 22.0768\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.6806 - val_loss: 22.2844\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.7771 - val_loss: 22.0840\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.6142 - val_loss: 22.0762\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.5458 - val_loss: 22.2218\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 82.3275 - val_loss: 69.2413\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 67.4378 - val_loss: 60.2293\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 606us/step - loss: 46.0597 - val_loss: 41.5064\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 40.5105 - val_loss: 39.9389\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 42.0490 - val_loss: 40.6971\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.7547 - val_loss: 39.3544\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 40.2367 - val_loss: 40.2833\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 39.9043 - val_loss: 38.1082\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.9272 - val_loss: 37.8885\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.5336 - val_loss: 37.2981\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 41.6954 - val_loss: 39.5926\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.7036 - val_loss: 39.4568\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.1195 - val_loss: 38.2775\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.3989 - val_loss: 37.5946\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.8199 - val_loss: 40.6213\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.0264 - val_loss: 51.1324\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 48.9309 - val_loss: 44.6365\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 45.3389 - val_loss: 43.0338\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 42.3856 - val_loss: 42.1289\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.8797 - val_loss: 40.2109\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 40.6096 - val_loss: 39.4149\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.6873 - val_loss: 42.5064\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.8088 - val_loss: 42.4427\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.4412 - val_loss: 39.6011\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.8668 - val_loss: 36.7452\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.9521 - val_loss: 37.0230\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.0096 - val_loss: 36.5521\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.9742 - val_loss: 37.0727\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.6971 - val_loss: 39.0914\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.9959 - val_loss: 35.4117\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.7528 - val_loss: 35.2744\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.1395 - val_loss: 34.4195\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.0278 - val_loss: 39.8528\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.6625 - val_loss: 33.8187\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 34.0916 - val_loss: 34.0023\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.0835 - val_loss: 35.0893\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.4908 - val_loss: 36.8475\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.2083 - val_loss: 34.0272\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.5532 - val_loss: 32.4849\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.9696 - val_loss: 34.1695\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.9854 - val_loss: 33.5789\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.6819 - val_loss: 34.1314\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.4981 - val_loss: 37.4288\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.4275 - val_loss: 32.4198\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.4838 - val_loss: 32.9830\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.4071 - val_loss: 32.1177\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.5625 - val_loss: 33.6631\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.6393 - val_loss: 32.0793\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.6440 - val_loss: 32.9728\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.6232 - val_loss: 31.3592\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.8785 - val_loss: 32.0685\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.9914 - val_loss: 31.1184\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.4638 - val_loss: 30.2666\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.8040 - val_loss: 30.4368\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.5259 - val_loss: 30.9807\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.6061 - val_loss: 31.2507\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.8955 - val_loss: 31.1054\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.9921 - val_loss: 30.1160\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.3528 - val_loss: 33.6765\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.5877 - val_loss: 30.1691\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 30.7517 - val_loss: 33.0900\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.3609 - val_loss: 29.9519\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.3081 - val_loss: 29.3630\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.4561 - val_loss: 33.0932\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.7491 - val_loss: 29.2326\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.9770 - val_loss: 28.9733\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.3855 - val_loss: 29.4779\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.1206 - val_loss: 30.3386\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 28.5069 - val_loss: 28.8666\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.0070 - val_loss: 28.4005\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 26.3560 - val_loss: 28.3003\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.3887 - val_loss: 26.8394\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 26.3357 - val_loss: 26.9307\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.2216 - val_loss: 28.6167\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.3982 - val_loss: 25.8318\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.4345 - val_loss: 25.5152\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.6099 - val_loss: 25.0194\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 24.2054 - val_loss: 24.8622\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.8501 - val_loss: 26.2119\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.3714 - val_loss: 24.6933\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.4286 - val_loss: 24.2267\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.2270 - val_loss: 24.0425\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 23.3149 - val_loss: 24.0413\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.0271 - val_loss: 24.1323\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 23.0058 - val_loss: 24.2330\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.0674 - val_loss: 24.1533\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.8889 - val_loss: 24.1301\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.6600 - val_loss: 23.4573\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.2606 - val_loss: 23.3760\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.3810 - val_loss: 24.3052\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.3530 - val_loss: 23.3594\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.0475 - val_loss: 23.3701\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.0973 - val_loss: 23.2822\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.0162 - val_loss: 23.0121\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7448 - val_loss: 23.1351\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.6363 - val_loss: 22.9585\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.6621 - val_loss: 22.8624\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.5059 - val_loss: 23.0245\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4430 - val_loss: 22.8051\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.4172 - val_loss: 22.6658\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.3088 - val_loss: 22.7570\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.2245 - val_loss: 22.5360\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.3177 - val_loss: 23.3341\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.2497 - val_loss: 22.6030\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.1580 - val_loss: 22.6562\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 20.9742 - val_loss: 22.4207\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 20.8554 - val_loss: 22.4503\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.8893 - val_loss: 22.4055\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 20.7687 - val_loss: 22.4507\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.8337 - val_loss: 22.6305\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.8540 - val_loss: 22.5552\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 564us/step - loss: 20.7262 - val_loss: 22.2826\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.5195 - val_loss: 22.2173\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.5702 - val_loss: 22.5202\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.3632 - val_loss: 22.2054\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.8603 - val_loss: 51.7437\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 47.1755 - val_loss: 44.1612\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 42.2937 - val_loss: 46.8683\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 42.1610 - val_loss: 40.5474\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.7845 - val_loss: 39.7838\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 40.1586 - val_loss: 39.4413\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.0247 - val_loss: 38.9797\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 694us/step - loss: 37.9774 - val_loss: 38.3943\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.9413 - val_loss: 40.4145\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.1229 - val_loss: 37.9241\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.7018 - val_loss: 36.7917\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 36.5966 - val_loss: 36.5650\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.6020 - val_loss: 37.9272\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.8630 - val_loss: 37.9025\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.1429 - val_loss: 35.4194\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.5963 - val_loss: 35.4974\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.7253 - val_loss: 34.9415\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.1257 - val_loss: 34.0282\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.2818 - val_loss: 34.2819\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.2216 - val_loss: 36.1345\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.8811 - val_loss: 33.5152\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.0588 - val_loss: 33.8421\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.1136 - val_loss: 34.3992\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.6930 - val_loss: 32.8941\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.1638 - val_loss: 33.1467\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.8286 - val_loss: 32.7392\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.1535 - val_loss: 33.0959\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.0737 - val_loss: 32.5080\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.9158 - val_loss: 33.8822\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.2828 - val_loss: 33.8564\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.4877 - val_loss: 32.4745\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.6572 - val_loss: 31.9084\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.8279 - val_loss: 31.6266\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.3959 - val_loss: 32.1015\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.5444 - val_loss: 30.8234\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.2736 - val_loss: 31.6209\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.2446 - val_loss: 30.9436\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.9876 - val_loss: 31.7617\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.7629 - val_loss: 31.7492\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.6728 - val_loss: 32.5623\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 1s 2ms/step - loss: 74.4800 - val_loss: 48.7002\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 45.9424 - val_loss: 43.6858\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.3769 - val_loss: 40.6273\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.6597 - val_loss: 38.1220\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 39.5341 - val_loss: 40.6085\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.0249 - val_loss: 37.8727\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.9491 - val_loss: 36.6804\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.8129 - val_loss: 36.8814\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.1834 - val_loss: 36.9039\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.0706 - val_loss: 35.9030\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.1494 - val_loss: 37.1365\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.8477 - val_loss: 35.0084\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.7030 - val_loss: 35.8971\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.9790 - val_loss: 35.3400\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.4722 - val_loss: 38.2883\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.5340 - val_loss: 34.1086\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.8904 - val_loss: 34.7121\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.4722 - val_loss: 33.1071\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.1555 - val_loss: 33.6382\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.1155 - val_loss: 33.1346\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.0249 - val_loss: 33.9687\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.1615 - val_loss: 32.7380\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.2130 - val_loss: 31.9537\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.9564 - val_loss: 31.7349\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.4639 - val_loss: 33.0134\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.1048 - val_loss: 33.3410\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.4425 - val_loss: 32.4304\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.1445 - val_loss: 32.1477\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.5794 - val_loss: 32.9169\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 83.5174 - val_loss: 54.2818\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 46.8022 - val_loss: 42.7194\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 42.5131 - val_loss: 40.5047\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.2544 - val_loss: 41.6777\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.4234 - val_loss: 39.7605\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.9690 - val_loss: 38.3353\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.6322 - val_loss: 37.7138\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.4474 - val_loss: 37.3071\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 38.3210 - val_loss: 36.6538\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 37.1192 - val_loss: 39.0956\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.1342 - val_loss: 38.8273\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 35.8384 - val_loss: 35.1649\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 35.3628 - val_loss: 39.7444\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.6988 - val_loss: 34.7056\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.2326 - val_loss: 33.7105\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.3276 - val_loss: 33.3549\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.1625 - val_loss: 34.2705\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 33.3746 - val_loss: 32.8348\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.2724 - val_loss: 32.6595\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.6590 - val_loss: 31.9768\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.3633 - val_loss: 31.7316\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.5753 - val_loss: 41.0739\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.5340 - val_loss: 33.0932\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.7195 - val_loss: 31.3141\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.1028 - val_loss: 30.9571\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.0691 - val_loss: 32.7470\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 29.6857 - val_loss: 30.3425\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 29.3621 - val_loss: 30.6303\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.8305 - val_loss: 30.2414\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.9835 - val_loss: 28.7631\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.1812 - val_loss: 29.0714\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.6026 - val_loss: 29.3327\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 27.3923 - val_loss: 28.1307\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 25.8752 - val_loss: 26.2595\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 25.3908 - val_loss: 25.8519\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.6874 - val_loss: 25.4018\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.2353 - val_loss: 25.3384\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 23.9681 - val_loss: 24.8524\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.3477 - val_loss: 25.8516\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 23.8714 - val_loss: 24.6951\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 23.4731 - val_loss: 24.9392\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 23.3125 - val_loss: 24.2853\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.9970 - val_loss: 24.1851\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.8182 - val_loss: 23.9901\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 22.7671 - val_loss: 24.0572\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.8332 - val_loss: 24.1909\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 22.6108 - val_loss: 23.7995\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.3516 - val_loss: 23.7566\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.3377 - val_loss: 23.5620\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.2041 - val_loss: 23.3889\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.0217 - val_loss: 23.3890\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.9380 - val_loss: 23.5016\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8363 - val_loss: 23.3910\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.8224 - val_loss: 23.2666\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6034 - val_loss: 23.2236\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.5586 - val_loss: 23.1660\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.4576 - val_loss: 23.2703\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5396 - val_loss: 23.1112\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3666 - val_loss: 23.2005\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.2918 - val_loss: 23.2382\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1844 - val_loss: 23.0868\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.2869 - val_loss: 23.0339\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.1681 - val_loss: 23.6361\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.2422 - val_loss: 23.1132\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.9954 - val_loss: 23.1445\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0371 - val_loss: 22.8230\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.0936 - val_loss: 22.8377\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.9786 - val_loss: 22.6785\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8231 - val_loss: 23.0053\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.8493 - val_loss: 22.8175\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.6217 - val_loss: 22.9308\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.5063 - val_loss: 22.7169\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.6179 - val_loss: 22.9273\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.1988 - val_loss: 47.6002\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 46.0173 - val_loss: 45.5748\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 44.9658 - val_loss: 42.3159\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 41.6399 - val_loss: 40.1879\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.4749 - val_loss: 41.7863\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 39.9734 - val_loss: 41.5689\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.7713 - val_loss: 38.4847\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.9582 - val_loss: 37.1511\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.2743 - val_loss: 39.4180\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.9871 - val_loss: 38.6376\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 37.6185 - val_loss: 36.8878\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.3347 - val_loss: 37.4585\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.2778 - val_loss: 36.5242\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.9666 - val_loss: 36.8276\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.2815 - val_loss: 34.9799\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.9209 - val_loss: 34.7686\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.3526 - val_loss: 37.1971\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.9196 - val_loss: 33.9985\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.5118 - val_loss: 37.8752\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.5254 - val_loss: 33.7944\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.9578 - val_loss: 33.3683\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.0165 - val_loss: 33.7231\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.9766 - val_loss: 32.8851\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.6942 - val_loss: 33.1939\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.4650 - val_loss: 36.0149\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.0367 - val_loss: 32.6702\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.5567 - val_loss: 35.1030\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.4886 - val_loss: 34.6152\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.8672 - val_loss: 31.9499\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.7369 - val_loss: 35.0420\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.2121 - val_loss: 32.3012\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.3797 - val_loss: 32.9607\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.1080 - val_loss: 31.4172\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.2523 - val_loss: 32.6909\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.9232 - val_loss: 32.9938\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.1825 - val_loss: 30.7988\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.4869 - val_loss: 32.9777\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.9215 - val_loss: 30.8373\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.2062 - val_loss: 30.6242\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.2633 - val_loss: 30.3956\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.7905 - val_loss: 30.6577\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 28.7475 - val_loss: 30.0852\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.5770 - val_loss: 29.4713\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.7657 - val_loss: 29.5487\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 28.9734 - val_loss: 29.3206\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 27.8535 - val_loss: 29.1676\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.5226 - val_loss: 28.8679\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 27.2852 - val_loss: 28.9668\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 26.7565 - val_loss: 27.9328\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 27.1916 - val_loss: 29.6805\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.7467 - val_loss: 27.3105\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.2705 - val_loss: 27.0469\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 26.0594 - val_loss: 27.0689\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.2654 - val_loss: 26.1278\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.8274 - val_loss: 26.3038\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.0226 - val_loss: 25.5643\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 24.1150 - val_loss: 25.1956\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.9118 - val_loss: 24.9128\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.6519 - val_loss: 24.5626\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.3635 - val_loss: 24.9938\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.5151 - val_loss: 24.4027\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.1952 - val_loss: 24.2640\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.9426 - val_loss: 24.4989\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.0260 - val_loss: 24.1594\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.8523 - val_loss: 23.9160\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.5880 - val_loss: 23.8804\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.4961 - val_loss: 24.0678\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.5182 - val_loss: 23.8056\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.5981 - val_loss: 23.9564\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.3339 - val_loss: 23.6937\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0821 - val_loss: 23.6016\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.0336 - val_loss: 23.5927\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.0019 - val_loss: 23.6731\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0480 - val_loss: 23.4417\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.0769 - val_loss: 23.7867\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.8857 - val_loss: 23.3247\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.7013 - val_loss: 23.2664\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.6460 - val_loss: 23.4070\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.7159 - val_loss: 23.4368\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.4982 - val_loss: 23.2735\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.4648 - val_loss: 23.3927\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4495 - val_loss: 23.8525\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.8152 - val_loss: 46.5381\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 45.2396 - val_loss: 42.8275\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 41.4278 - val_loss: 41.0958\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 40.2231 - val_loss: 40.2044\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 39.2452 - val_loss: 39.4311\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.1023 - val_loss: 40.4902\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.4240 - val_loss: 37.9340\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.2612 - val_loss: 37.3468\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.1727 - val_loss: 38.6726\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.4660 - val_loss: 38.5023\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.8160 - val_loss: 43.0736\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.5761 - val_loss: 38.6868\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.0462 - val_loss: 37.2635\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.1072 - val_loss: 36.1452\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.2485 - val_loss: 35.0348\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.9369 - val_loss: 34.4719\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.0288 - val_loss: 35.4679\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.8323 - val_loss: 35.5173\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.0694 - val_loss: 34.0126\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.8727 - val_loss: 33.4278\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.8393 - val_loss: 40.0796\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.3043 - val_loss: 33.7685\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.8068 - val_loss: 35.0833\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.8633 - val_loss: 33.9501\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.2669 - val_loss: 33.7763\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.7003 - val_loss: 47.2082\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 45.7825 - val_loss: 45.5857\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 42.3712 - val_loss: 40.3901\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.6085 - val_loss: 39.6970\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.9817 - val_loss: 39.8922\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.3267 - val_loss: 37.8665\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.9671 - val_loss: 36.9427\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.8018 - val_loss: 36.0828\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.1794 - val_loss: 35.7767\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.8624 - val_loss: 35.7162\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 36.6497 - val_loss: 36.1228\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.6201 - val_loss: 36.5057\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.9858 - val_loss: 34.4325\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.7039 - val_loss: 34.9963\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.6595 - val_loss: 35.0386\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.3061 - val_loss: 34.5154\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.8111 - val_loss: 35.8491\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.7234 - val_loss: 36.2153\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 73.6737 - val_loss: 47.1199\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 43.8596 - val_loss: 40.3779\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 38.9149 - val_loss: 37.4508\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.4632 - val_loss: 35.8018\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.7359 - val_loss: 34.4115\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.4532 - val_loss: 34.5546\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.7588 - val_loss: 35.0492\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.1029 - val_loss: 33.4295\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.7621 - val_loss: 32.8843\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.5443 - val_loss: 33.5427\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.5591 - val_loss: 32.1944\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.5879 - val_loss: 33.1474\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.2432 - val_loss: 31.8377\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.1788 - val_loss: 31.4101\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 31.9864 - val_loss: 35.5834\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.9804 - val_loss: 31.7997\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.2010 - val_loss: 31.0411\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.6878 - val_loss: 31.9082\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 31.1237 - val_loss: 31.1620\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.3330 - val_loss: 30.8890\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.6409 - val_loss: 30.2859\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.1727 - val_loss: 30.4373\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.3364 - val_loss: 31.3403\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.1561 - val_loss: 32.6363\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.4416 - val_loss: 29.4457\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.1710 - val_loss: 30.9509\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.1423 - val_loss: 31.1678\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.8499 - val_loss: 29.6044\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.6271 - val_loss: 29.4963\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.2984 - val_loss: 28.9957\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.8878 - val_loss: 30.1149\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.8216 - val_loss: 29.4068\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.3710 - val_loss: 30.3808\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.7991 - val_loss: 31.9341\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.6398 - val_loss: 30.0156\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.1217 - val_loss: 46.6737\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 45.9185 - val_loss: 47.5876\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 43.2884 - val_loss: 45.2983\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.0968 - val_loss: 40.6203\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 40.3196 - val_loss: 39.0856\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.8405 - val_loss: 39.7655\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.2419 - val_loss: 42.9341\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.8167 - val_loss: 39.8086\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.2768 - val_loss: 38.4543\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.1919 - val_loss: 37.5185\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 37.4859 - val_loss: 37.4709\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.1137 - val_loss: 36.9230\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.9444 - val_loss: 39.0705\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.6218 - val_loss: 36.7404\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.1187 - val_loss: 36.2966\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.0815 - val_loss: 36.4659\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.8560 - val_loss: 36.8309\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 37.5714 - val_loss: 37.1416\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.6243 - val_loss: 35.7683\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.3426 - val_loss: 38.4861\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 36.1205 - val_loss: 35.4845\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.5889 - val_loss: 34.6734\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.8962 - val_loss: 36.8981\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.3774 - val_loss: 35.1829\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.7340 - val_loss: 35.2273\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.2044 - val_loss: 35.9598\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.7457 - val_loss: 34.5118\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.8449 - val_loss: 35.2331\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.3155 - val_loss: 34.5256\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.4529 - val_loss: 33.9548\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.1771 - val_loss: 33.3320\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.6833 - val_loss: 33.7606\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.2531 - val_loss: 34.7705\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.3536 - val_loss: 34.7857\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.8884 - val_loss: 32.7451\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.3610 - val_loss: 33.1347\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.8001 - val_loss: 34.4471\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.3389 - val_loss: 32.5138\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.1281 - val_loss: 32.1877\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.4468 - val_loss: 32.4290\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.9169 - val_loss: 31.8212\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.2064 - val_loss: 31.1680\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.1557 - val_loss: 35.3320\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.3790 - val_loss: 31.8212\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.3411 - val_loss: 31.8119\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 596us/step - loss: 29.7929 - val_loss: 30.3007\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.6501 - val_loss: 29.2640\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 28.6142 - val_loss: 28.8503\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.6368 - val_loss: 31.4568\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.6531 - val_loss: 27.3660\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.5560 - val_loss: 26.7382\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 25.7229 - val_loss: 26.5056\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 25.6225 - val_loss: 25.5482\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 25.0379 - val_loss: 25.0073\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 771us/step - loss: 24.7567 - val_loss: 25.2252\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 24.2785 - val_loss: 24.6111\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 730us/step - loss: 24.1180 - val_loss: 24.6470\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 23.8693 - val_loss: 24.3866\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 776us/step - loss: 23.8053 - val_loss: 24.1082\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 23.5605 - val_loss: 24.4715\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.5309 - val_loss: 23.9141\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.2812 - val_loss: 23.7705\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.1994 - val_loss: 23.8219\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.0057 - val_loss: 23.6418\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.9240 - val_loss: 23.5841\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.9535 - val_loss: 23.5982\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.0843 - val_loss: 23.8626\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.9141 - val_loss: 23.6087\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.6649 - val_loss: 23.3228\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.5961 - val_loss: 23.2246\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.4799 - val_loss: 23.2159\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 22.4320 - val_loss: 23.1537\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.4046 - val_loss: 23.1923\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.4150 - val_loss: 23.1658\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.3726 - val_loss: 23.2081\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.3714 - val_loss: 23.0212\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.2244 - val_loss: 22.9272\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.0922 - val_loss: 23.1601\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.0934 - val_loss: 22.9465\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.9944 - val_loss: 23.0193\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.0693 - val_loss: 22.9961\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8637 - val_loss: 22.7691\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.8451 - val_loss: 22.8205\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8647 - val_loss: 22.9584\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.8487 - val_loss: 22.8057\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7217 - val_loss: 22.6825\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6041 - val_loss: 22.6802\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.6153 - val_loss: 22.9077\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.5769 - val_loss: 22.6236\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.5371 - val_loss: 22.6321\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.6517 - val_loss: 22.7668\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.4329 - val_loss: 22.7330\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.4530 - val_loss: 22.7234\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3553 - val_loss: 22.6678\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 82.0612 - val_loss: 46.9423\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 45.2521 - val_loss: 41.1199\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.0831 - val_loss: 38.6388\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.5504 - val_loss: 37.2652\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.1674 - val_loss: 37.4059\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.7762 - val_loss: 36.1003\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.3221 - val_loss: 35.3873\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.9949 - val_loss: 36.8746\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.8600 - val_loss: 34.5821\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.5186 - val_loss: 36.2872\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.2261 - val_loss: 40.4470\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 36.2323 - val_loss: 35.2037\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.9417 - val_loss: 33.6849\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.7631 - val_loss: 33.9173\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.1787 - val_loss: 33.6170\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.7625 - val_loss: 33.4059\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.3907 - val_loss: 33.1356\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.8903 - val_loss: 32.8619\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.6085 - val_loss: 32.7156\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.0259 - val_loss: 31.8482\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.7764 - val_loss: 33.8203\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.5128 - val_loss: 32.8129\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.7807 - val_loss: 32.2885\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.5368 - val_loss: 33.8472\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.8204 - val_loss: 32.0402\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 95.4098 - val_loss: 54.7143\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 46.3191 - val_loss: 42.6027\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.2554 - val_loss: 39.2956\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.3309 - val_loss: 37.8935\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.1023 - val_loss: 36.5854\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.6235 - val_loss: 36.3433\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.7439 - val_loss: 35.0161\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 34.1623 - val_loss: 34.4472\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.6749 - val_loss: 33.4938\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.3529 - val_loss: 33.8759\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.4476 - val_loss: 33.5767\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.2879 - val_loss: 32.8438\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7894 - val_loss: 32.4837\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.1204 - val_loss: 32.6382\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 31.5398 - val_loss: 31.9985\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 32.3178 - val_loss: 32.7582\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.3831 - val_loss: 32.4293\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.3894 - val_loss: 30.9206\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.9042 - val_loss: 30.3233\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.2940 - val_loss: 33.1717\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.7906 - val_loss: 30.9779\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.3254 - val_loss: 29.9002\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.9747 - val_loss: 29.5320\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 27.9042 - val_loss: 29.4576\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 28.2370 - val_loss: 29.0104\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.7658 - val_loss: 28.6346\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 28.2985 - val_loss: 32.5155\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.4652 - val_loss: 28.7129\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 27.4829 - val_loss: 28.4194\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.4595 - val_loss: 28.2378\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 27.2720 - val_loss: 28.7604\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.3303 - val_loss: 27.3188\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 563us/step - loss: 27.1132 - val_loss: 28.7846\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 26.7924 - val_loss: 27.0489\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.8144 - val_loss: 27.1441\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.3626 - val_loss: 26.7057\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.9873 - val_loss: 28.1460\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.9611 - val_loss: 26.0297\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 25.2111 - val_loss: 27.7751\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 24.3316 - val_loss: 25.5757\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.6859 - val_loss: 25.7046\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 24.1567 - val_loss: 25.5119\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.6530 - val_loss: 25.6856\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.6316 - val_loss: 25.4255\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 23.3634 - val_loss: 25.8157\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.3521 - val_loss: 24.6072\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.3498 - val_loss: 24.4692\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.9182 - val_loss: 24.5579\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.7670 - val_loss: 24.4909\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.6533 - val_loss: 24.2872\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.6719 - val_loss: 24.1481\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.4336 - val_loss: 24.5673\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.3654 - val_loss: 24.4520\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2837 - val_loss: 23.6915\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.5054 - val_loss: 23.5502\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.7967 - val_loss: 23.3171\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.7508 - val_loss: 23.2339\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 406us/step - loss: 21.4392 - val_loss: 23.1449\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2339 - val_loss: 23.2726\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.2741 - val_loss: 23.0214\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.1063 - val_loss: 23.1059\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.0555 - val_loss: 22.8205\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.8001 - val_loss: 22.7538\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.8205 - val_loss: 22.7365\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.0996 - val_loss: 23.2192\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2130 - val_loss: 22.6081\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.6578 - val_loss: 22.6761\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.5773 - val_loss: 22.3843\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.4998 - val_loss: 22.5904\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 20.4311 - val_loss: 22.6955\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.6443 - val_loss: 22.5856\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.4174 - val_loss: 22.6476\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.3130 - val_loss: 22.2657\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.0525 - val_loss: 22.2768\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.2291 - val_loss: 22.4368\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 20.0531 - val_loss: 22.2416\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.0207 - val_loss: 22.1362\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 19.8210 - val_loss: 22.0330\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 19.9134 - val_loss: 22.0475\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 651us/step - loss: 19.8118 - val_loss: 22.0342\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 19.7083 - val_loss: 21.9557\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 19.5556 - val_loss: 22.9333\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 20.1620 - val_loss: 21.9828\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 19.4599 - val_loss: 22.0626\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 19.5803 - val_loss: 22.3887\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 19.5067 - val_loss: 21.7695\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 19.2971 - val_loss: 21.8026\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 19.1026 - val_loss: 21.6563\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 19.1932 - val_loss: 21.6340\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 19.3776 - val_loss: 21.7971\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 19.1378 - val_loss: 21.6672\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 19.1689 - val_loss: 21.5270\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 18.8749 - val_loss: 21.6527\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 18.8388 - val_loss: 21.4921\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 18.8194 - val_loss: 21.5347\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 18.7790 - val_loss: 21.4275\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 18.9317 - val_loss: 21.6819\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 18.9338 - val_loss: 21.6468\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 18.8265 - val_loss: 21.5059\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 18.6913 - val_loss: 21.8403\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 83.7197 - val_loss: 61.9755\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 947us/step - loss: 54.1163 - val_loss: 50.4837\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 874us/step - loss: 47.3615 - val_loss: 44.6327\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 43.7847 - val_loss: 42.6337\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 42.6980 - val_loss: 41.1923\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.4798 - val_loss: 41.8438\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 40.7161 - val_loss: 41.0351\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 42.2870 - val_loss: 43.4176\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 41.1874 - val_loss: 41.8168\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.9463 - val_loss: 38.1599\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.8188 - val_loss: 40.2161\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.2640 - val_loss: 36.7769\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 37.4371 - val_loss: 36.9131\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.0870 - val_loss: 36.5731\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.5490 - val_loss: 37.1697\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.1902 - val_loss: 36.7495\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.0042 - val_loss: 35.5581\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.9542 - val_loss: 38.6612\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.8845 - val_loss: 34.7182\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.0171 - val_loss: 36.4160\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.1706 - val_loss: 35.3789\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.0903 - val_loss: 34.2820\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.1992 - val_loss: 33.7970\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.7283 - val_loss: 35.1399\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.5533 - val_loss: 34.0046\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.2994 - val_loss: 36.0419\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 33.2544 - val_loss: 33.4024\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.3860 - val_loss: 31.6612\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.3650 - val_loss: 31.3127\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.9023 - val_loss: 31.8056\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.0483 - val_loss: 30.6120\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.4152 - val_loss: 28.5661\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.7336 - val_loss: 30.6173\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.2792 - val_loss: 27.6802\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.8733 - val_loss: 27.6431\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 26.5945 - val_loss: 27.3490\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.8842 - val_loss: 25.9637\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.6128 - val_loss: 26.3204\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.2131 - val_loss: 25.4264\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.0412 - val_loss: 25.4271\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 24.8752 - val_loss: 24.8968\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.3055 - val_loss: 24.8808\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.0929 - val_loss: 24.7176\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.8562 - val_loss: 24.2857\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.7548 - val_loss: 24.1179\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.5889 - val_loss: 24.0255\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 23.3764 - val_loss: 23.8973\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.1736 - val_loss: 24.1401\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.0683 - val_loss: 23.6146\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.8501 - val_loss: 23.7098\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.8148 - val_loss: 23.3331\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.8261 - val_loss: 23.2995\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.6039 - val_loss: 23.2576\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.3914 - val_loss: 23.1999\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.3677 - val_loss: 22.9505\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.6226 - val_loss: 24.3749\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 616us/step - loss: 22.8813 - val_loss: 23.0815\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.1324 - val_loss: 22.8815\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.9382 - val_loss: 23.1264\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.7772 - val_loss: 22.8007\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.7383 - val_loss: 22.6590\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.7143 - val_loss: 22.9461\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 21.8011 - val_loss: 22.8057\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.0116 - val_loss: 22.8103\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 563us/step - loss: 21.5849 - val_loss: 22.9016\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 21.4775 - val_loss: 22.5274\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.3089 - val_loss: 22.4582\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 737us/step - loss: 21.2940 - val_loss: 22.2978\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5432 - val_loss: 22.3295\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3550 - val_loss: 22.2743\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.0255 - val_loss: 22.2007\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.0019 - val_loss: 22.3329\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.0264 - val_loss: 22.4890\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.2471 - val_loss: 22.3025\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.8926 - val_loss: 23.0759\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.1690 - val_loss: 22.2133\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.5464 - val_loss: 47.1022\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 46.0968 - val_loss: 43.5240\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 43.0917 - val_loss: 47.2900\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.9947 - val_loss: 45.1997\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.4000 - val_loss: 40.3140\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.1420 - val_loss: 38.5092\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.5199 - val_loss: 48.6780\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.0193 - val_loss: 38.4420\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.1549 - val_loss: 45.5360\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 39.8625 - val_loss: 38.3188\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 37.5032 - val_loss: 37.7230\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.9380 - val_loss: 38.7063\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.9987 - val_loss: 41.0399\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.9119 - val_loss: 41.6975\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.8672 - val_loss: 36.1279\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.9606 - val_loss: 34.7060\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.1388 - val_loss: 34.6504\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.2656 - val_loss: 35.7656\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.2666 - val_loss: 35.0250\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.7674 - val_loss: 34.3079\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 34.2757 - val_loss: 34.7022\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.2270 - val_loss: 34.6098\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.8187 - val_loss: 33.2571\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.5195 - val_loss: 33.0911\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.9158 - val_loss: 35.1366\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.5355 - val_loss: 34.4406\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.7339 - val_loss: 34.4951\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.3716 - val_loss: 32.6739\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.8426 - val_loss: 35.0297\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.0016 - val_loss: 32.4741\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.4490 - val_loss: 34.7128\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.2615 - val_loss: 35.5017\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.6807 - val_loss: 32.4654\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.4951 - val_loss: 31.6390\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.7894 - val_loss: 32.4189\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.8593 - val_loss: 31.2233\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 30.7757 - val_loss: 31.0349\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.1070 - val_loss: 33.2305\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.5423 - val_loss: 32.5787\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 30.9932 - val_loss: 32.0875\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.2087 - val_loss: 36.9038\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.5161 - val_loss: 30.5904\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.4560 - val_loss: 30.4704\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 29.0957 - val_loss: 30.1728\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 29.2180 - val_loss: 30.2862\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.0773 - val_loss: 29.7533\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 29.1872 - val_loss: 30.1580\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 29.8270 - val_loss: 30.2115\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.0136 - val_loss: 32.4895\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.3735 - val_loss: 30.8422\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.0590 - val_loss: 30.9079\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 83.7893 - val_loss: 48.7325\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 47.5122 - val_loss: 47.4203\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 44.9686 - val_loss: 43.6548\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 42.7911 - val_loss: 42.6819\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 43.0384 - val_loss: 42.0246\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 41.5214 - val_loss: 41.6188\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.5934 - val_loss: 39.0584\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.0086 - val_loss: 40.7372\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.8260 - val_loss: 37.8797\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.5211 - val_loss: 39.7635\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.4505 - val_loss: 39.4555\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.6248 - val_loss: 36.5774\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.8572 - val_loss: 37.0614\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.7455 - val_loss: 36.1830\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.7163 - val_loss: 35.9776\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 35.5270 - val_loss: 36.5726\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.9451 - val_loss: 35.0415\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.5300 - val_loss: 35.4804\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.0556 - val_loss: 34.3399\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.1391 - val_loss: 37.4228\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.9812 - val_loss: 34.9071\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.8541 - val_loss: 34.1382\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.8804 - val_loss: 33.2349\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.2528 - val_loss: 32.8293\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.2750 - val_loss: 35.1824\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.6310 - val_loss: 32.5374\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.3022 - val_loss: 31.6212\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.6240 - val_loss: 32.1052\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.5275 - val_loss: 33.9753\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.8051 - val_loss: 29.9858\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.7861 - val_loss: 30.2326\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.7675 - val_loss: 29.1477\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 28.4628 - val_loss: 29.0427\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.4302 - val_loss: 27.3186\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.3554 - val_loss: 26.4353\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.8394 - val_loss: 25.8728\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.0786 - val_loss: 25.3156\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.5303 - val_loss: 24.8869\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 24.2301 - val_loss: 24.6541\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.1918 - val_loss: 24.3330\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.7664 - val_loss: 24.6619\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.6995 - val_loss: 24.0337\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.3337 - val_loss: 24.1112\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.2172 - val_loss: 23.7042\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.9299 - val_loss: 23.5452\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.9491 - val_loss: 23.4398\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.8496 - val_loss: 23.4108\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6875 - val_loss: 23.5128\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.5758 - val_loss: 23.2569\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.7061 - val_loss: 23.2952\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.3360 - val_loss: 23.1689\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.2461 - val_loss: 23.1744\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.1643 - val_loss: 23.1951\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.2146 - val_loss: 22.9421\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9280 - val_loss: 22.9694\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.7978 - val_loss: 22.8385\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.6117 - val_loss: 22.8203\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7338 - val_loss: 22.8180\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.5345 - val_loss: 22.8787\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5822 - val_loss: 22.6418\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3934 - val_loss: 22.6100\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3933 - val_loss: 22.7225\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3361 - val_loss: 22.8047\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.2998 - val_loss: 22.7537\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2892 - val_loss: 23.1410\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1538 - val_loss: 22.5895\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.1423 - val_loss: 22.5155\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 21.0586 - val_loss: 22.6082\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.9339 - val_loss: 22.7246\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.7811 - val_loss: 22.5264\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.7976 - val_loss: 22.5394\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.6458 - val_loss: 22.4488\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.6701 - val_loss: 22.7519\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.5572 - val_loss: 22.6392\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.5920 - val_loss: 22.5305\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.5080 - val_loss: 22.5569\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.4405 - val_loss: 22.4924\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 96.3815 - val_loss: 83.2035\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 56.3740 - val_loss: 49.4926\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 46.0761 - val_loss: 45.8335\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 43.9230 - val_loss: 45.7135\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 42.7225 - val_loss: 43.4402\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 603us/step - loss: 42.8534 - val_loss: 42.6060\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 42.0560 - val_loss: 42.0141\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.9872 - val_loss: 40.8575\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.0268 - val_loss: 42.2342\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.3805 - val_loss: 39.6731\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.6290 - val_loss: 43.9465\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 41.3146 - val_loss: 38.8524\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 39.0011 - val_loss: 42.9963\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.4367 - val_loss: 40.3508\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.1240 - val_loss: 37.5240\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.5560 - val_loss: 37.1935\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.9019 - val_loss: 37.0083\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.6107 - val_loss: 36.1971\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 835us/step - loss: 36.0163 - val_loss: 39.5850\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 705us/step - loss: 35.3735 - val_loss: 35.2507\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 738us/step - loss: 33.6386 - val_loss: 36.4997\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 893us/step - loss: 33.6682 - val_loss: 35.9023\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 32.5046 - val_loss: 33.8992\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.4169 - val_loss: 33.6188\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 31.8620 - val_loss: 32.3101\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.8978 - val_loss: 31.5498\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.0928 - val_loss: 30.3227\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.9004 - val_loss: 30.0283\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 27.9792 - val_loss: 28.5184\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 27.4261 - val_loss: 27.8063\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.6710 - val_loss: 27.2646\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 26.4658 - val_loss: 26.5100\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 25.6759 - val_loss: 26.9020\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 25.5559 - val_loss: 26.2709\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.2385 - val_loss: 25.6824\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 24.8202 - val_loss: 25.4238\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.6875 - val_loss: 25.2431\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.3748 - val_loss: 25.0834\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.2712 - val_loss: 24.8790\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.1019 - val_loss: 25.3437\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.9187 - val_loss: 24.5342\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.6746 - val_loss: 24.5342\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.5924 - val_loss: 24.5078\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.3040 - val_loss: 24.2549\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 23.2181 - val_loss: 24.4461\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.0116 - val_loss: 24.0101\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.1160 - val_loss: 23.9525\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.1068 - val_loss: 24.3820\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.7465 - val_loss: 23.7686\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.8181 - val_loss: 23.7728\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.6945 - val_loss: 23.6884\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.7699 - val_loss: 23.8459\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.6034 - val_loss: 23.5828\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.2360 - val_loss: 23.5039\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.1755 - val_loss: 23.6540\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2691 - val_loss: 23.6712\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.1451 - val_loss: 23.5069\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.0565 - val_loss: 23.3772\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.8393 - val_loss: 23.3165\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.7911 - val_loss: 23.4918\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.7775 - val_loss: 23.3863\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.8576 - val_loss: 23.2595\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6303 - val_loss: 23.1982\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.7051 - val_loss: 23.3741\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4888 - val_loss: 23.4288\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.4806 - val_loss: 23.9203\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.6072 - val_loss: 24.3420\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0692 - val_loss: 24.4270\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.7046 - val_loss: 48.4389\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 45.3462 - val_loss: 44.3141\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 42.4856 - val_loss: 42.8648\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 42.1244 - val_loss: 41.6575\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 40.3586 - val_loss: 38.4824\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 39.5698 - val_loss: 40.5492\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 39.6745 - val_loss: 38.4943\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 39.0467 - val_loss: 41.0596\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.6544 - val_loss: 37.7409\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.5183 - val_loss: 37.3989\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.9544 - val_loss: 36.4777\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 36.8786 - val_loss: 46.9454\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 37.6758 - val_loss: 38.8695\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 36.2087 - val_loss: 39.3721\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 656us/step - loss: 36.2516 - val_loss: 36.3102\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.6975 - val_loss: 34.1543\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 35.0865 - val_loss: 34.2618\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.2246 - val_loss: 34.6831\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 33.8855 - val_loss: 33.5879\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.6315 - val_loss: 34.9214\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.1678 - val_loss: 33.0295\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.0841 - val_loss: 41.7210\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.8218 - val_loss: 32.8446\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.0969 - val_loss: 34.2460\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.7197 - val_loss: 34.3177\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.5413 - val_loss: 34.8866\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 33.0574 - val_loss: 32.0304\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.1971 - val_loss: 31.9359\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.1240 - val_loss: 31.4974\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.8843 - val_loss: 33.0553\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.8138 - val_loss: 31.2270\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 32.4700 - val_loss: 31.2022\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.3869 - val_loss: 31.9576\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 30.7566 - val_loss: 30.1549\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 31.1373 - val_loss: 30.9925\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 31.5612 - val_loss: 31.7588\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 31.6582 - val_loss: 30.9686\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 30.4688 - val_loss: 30.7704\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.3644 - val_loss: 30.1014\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 29.9334 - val_loss: 30.1732\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 31.1886 - val_loss: 29.7983\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.9377 - val_loss: 29.5154\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.2789 - val_loss: 31.6266\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 29.0702 - val_loss: 28.6761\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 28.7240 - val_loss: 30.0856\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.6047 - val_loss: 31.7323\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 29.2783 - val_loss: 28.4035\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 27.9778 - val_loss: 29.0501\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.5220 - val_loss: 27.5479\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 28.4320 - val_loss: 28.4116\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 28.0792 - val_loss: 27.4243\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 27.6898 - val_loss: 27.5044\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 26.8120 - val_loss: 26.5489\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 25.5684 - val_loss: 25.6372\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 25.1820 - val_loss: 25.7753\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 24.6542 - val_loss: 24.9424\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.4462 - val_loss: 25.9265\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.8648 - val_loss: 24.5406\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 23.6558 - val_loss: 23.9862\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 23.3155 - val_loss: 24.2099\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.2056 - val_loss: 23.6666\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 22.9081 - val_loss: 23.4714\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.7770 - val_loss: 23.4104\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.7084 - val_loss: 23.3256\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.5747 - val_loss: 23.6189\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 22.5174 - val_loss: 23.1699\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 22.3088 - val_loss: 23.0393\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 22.2753 - val_loss: 23.3784\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 750us/step - loss: 22.1555 - val_loss: 22.8786\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.9911 - val_loss: 23.0847\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.9264 - val_loss: 22.7631\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9152 - val_loss: 22.9667\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.9286 - val_loss: 22.6797\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.7445 - val_loss: 22.8016\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 751us/step - loss: 21.6429 - val_loss: 22.6296\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.6371 - val_loss: 22.5817\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5301 - val_loss: 22.5613\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.4956 - val_loss: 22.4582\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.4636 - val_loss: 22.4709\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.3912 - val_loss: 22.3797\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.5263 - val_loss: 22.5732\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3371 - val_loss: 22.2878\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.1960 - val_loss: 22.2628\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.4529 - val_loss: 22.5723\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.2175 - val_loss: 22.3307\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.1593 - val_loss: 22.1747\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.1113 - val_loss: 22.6834\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.0938 - val_loss: 22.1840\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.9673 - val_loss: 22.2223\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.1346 - val_loss: 22.3613\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.8946 - val_loss: 22.2854\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 1s 2ms/step - loss: 63.7456 - val_loss: 48.3798\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 45.6639 - val_loss: 42.7795\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 43.4483 - val_loss: 43.9560\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 41.1924 - val_loss: 40.4508\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.2519 - val_loss: 38.2911\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.5012 - val_loss: 41.5370\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.4244 - val_loss: 37.8351\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.5948 - val_loss: 36.5285\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.1063 - val_loss: 36.0212\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.2817 - val_loss: 35.6563\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.6008 - val_loss: 35.0673\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.1661 - val_loss: 35.3188\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.3863 - val_loss: 35.5890\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.7651 - val_loss: 34.8753\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.8014 - val_loss: 34.4796\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.6477 - val_loss: 34.9538\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.7513 - val_loss: 34.3527\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 33.1227 - val_loss: 32.6913\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.4956 - val_loss: 34.0312\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.1431 - val_loss: 32.2110\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 31.9763 - val_loss: 33.9263\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.2115 - val_loss: 32.4598\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 31.8860 - val_loss: 33.0237\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.5731 - val_loss: 33.8135\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.7377 - val_loss: 31.7055\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.9654 - val_loss: 31.5003\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.3876 - val_loss: 31.7105\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.9329 - val_loss: 32.0282\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.4614 - val_loss: 32.0745\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.9917 - val_loss: 32.2506\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.9515 - val_loss: 32.6336\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.0023 - val_loss: 44.8259\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 45.1830 - val_loss: 41.9050\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.3272 - val_loss: 39.3610\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 42.2010 - val_loss: 43.3781\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.5770 - val_loss: 39.9810\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 39.3230 - val_loss: 42.0987\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.0559 - val_loss: 37.0212\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.9069 - val_loss: 37.4428\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.6265 - val_loss: 38.9146\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 38.2988 - val_loss: 36.2462\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.6411 - val_loss: 37.6913\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.3065 - val_loss: 35.4298\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.0098 - val_loss: 37.4770\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.0586 - val_loss: 36.8670\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.3672 - val_loss: 35.3652\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.7410 - val_loss: 35.5443\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.4951 - val_loss: 34.5078\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.0627 - val_loss: 36.4056\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.7728 - val_loss: 35.2402\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.8272 - val_loss: 36.8427\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.1648 - val_loss: 33.9485\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 36.5313 - val_loss: 35.3060\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.2823 - val_loss: 33.5545\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 677us/step - loss: 34.5380 - val_loss: 32.9949\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.9794 - val_loss: 34.4933\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.3890 - val_loss: 32.7296\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 34.4240 - val_loss: 36.6405\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.1036 - val_loss: 33.0742\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.5906 - val_loss: 32.6005\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 33.9877 - val_loss: 36.4255\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.6360 - val_loss: 33.6704\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.4501 - val_loss: 34.3843\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.3794 - val_loss: 39.7633\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.9662 - val_loss: 32.7658\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.3474 - val_loss: 51.5760\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 47.8279 - val_loss: 44.6200\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 43.9004 - val_loss: 41.3248\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 42.6717 - val_loss: 42.1913\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 42.0696 - val_loss: 41.0230\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.2258 - val_loss: 39.1452\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 41.0328 - val_loss: 38.9698\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.7094 - val_loss: 38.1977\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.1317 - val_loss: 39.0531\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.7373 - val_loss: 38.1225\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.8282 - val_loss: 38.7241\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.5329 - val_loss: 37.8131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 39.4152 - val_loss: 36.8604\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 43.2931 - val_loss: 39.9426\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.0670 - val_loss: 37.0655\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 38.0303 - val_loss: 37.9644\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.3715 - val_loss: 35.2816\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.9740 - val_loss: 34.8074\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 557us/step - loss: 36.2994 - val_loss: 34.5456\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.0430 - val_loss: 34.6256\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 35.0193 - val_loss: 34.4690\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 34.8182 - val_loss: 33.0589\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 34.2011 - val_loss: 36.4065\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 37.6260 - val_loss: 40.3823\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.6693 - val_loss: 33.7451\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.8440 - val_loss: 32.6530\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.2219 - val_loss: 32.9975\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.0302 - val_loss: 34.1852\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.3301 - val_loss: 32.4017\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.7442 - val_loss: 32.2367\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.2526 - val_loss: 31.1731\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.1773 - val_loss: 32.0280\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.9920 - val_loss: 30.6257\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.7694 - val_loss: 30.7543\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 31.4589 - val_loss: 36.7103\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 31.3000 - val_loss: 29.6036\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.8289 - val_loss: 29.3312\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.2621 - val_loss: 28.9822\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.0946 - val_loss: 28.8745\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 29.3987 - val_loss: 28.9778\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 28.0824 - val_loss: 27.6861\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 27.2167 - val_loss: 26.8585\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 26.9342 - val_loss: 26.6209\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 26.8612 - val_loss: 25.9672\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.2774 - val_loss: 25.3378\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 24.6398 - val_loss: 24.9025\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 24.1860 - val_loss: 24.4554\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.9501 - val_loss: 25.2276\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.0859 - val_loss: 24.5056\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.5464 - val_loss: 23.8624\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.2166 - val_loss: 23.6391\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.2473 - val_loss: 23.5523\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.9855 - val_loss: 23.5757\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 22.7902 - val_loss: 23.3710\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.6909 - val_loss: 23.4084\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.6657 - val_loss: 23.2361\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.5764 - val_loss: 23.0757\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.5161 - val_loss: 23.4599\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 22.3255 - val_loss: 22.9336\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.3248 - val_loss: 23.1570\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.2610 - val_loss: 22.7847\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.1108 - val_loss: 22.6501\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.8639 - val_loss: 22.5832\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.7549 - val_loss: 22.6034\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.7393 - val_loss: 22.4051\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7316 - val_loss: 22.3618\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.6044 - val_loss: 22.3426\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.5039 - val_loss: 22.2779\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.7034 - val_loss: 22.4780\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.6350 - val_loss: 22.3824\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.3720 - val_loss: 22.1725\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2424 - val_loss: 22.3642\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.3852 - val_loss: 22.3696\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3448 - val_loss: 22.0535\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.1511 - val_loss: 22.0632\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.0691 - val_loss: 22.5003\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1306 - val_loss: 22.1527\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.9039 - val_loss: 21.9454\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.8378 - val_loss: 21.9487\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9317 - val_loss: 21.9451\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.8348 - val_loss: 21.8737\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.7561 - val_loss: 21.8208\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.6823 - val_loss: 22.0160\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.7560 - val_loss: 22.1912\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.5919 - val_loss: 21.8144\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.4508 - val_loss: 21.9414\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.5045 - val_loss: 21.9007\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.4073 - val_loss: 22.0678\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.3559 - val_loss: 22.0561\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.5052 - val_loss: 21.8602\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 94.1952 - val_loss: 57.5522\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 47.2161 - val_loss: 48.4463\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 43.1088 - val_loss: 42.4744\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 40.6387 - val_loss: 41.8227\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 40.1116 - val_loss: 40.6595\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.1840 - val_loss: 40.4604\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.0651 - val_loss: 39.0993\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.0776 - val_loss: 42.4869\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.6563 - val_loss: 39.6759\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.8091 - val_loss: 37.8583\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.8852 - val_loss: 37.2079\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.3803 - val_loss: 37.8163\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.8528 - val_loss: 36.4822\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 36.1256 - val_loss: 36.5058\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.6384 - val_loss: 36.8825\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.3049 - val_loss: 38.9786\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.6843 - val_loss: 38.8212\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.1613 - val_loss: 36.8768\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 89.6356 - val_loss: 68.8161\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 53.6818 - val_loss: 49.5350\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 46.0749 - val_loss: 46.0472\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 43.0015 - val_loss: 40.9564\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.2472 - val_loss: 42.1366\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.9534 - val_loss: 41.8030\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 40.1595 - val_loss: 38.7461\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.3484 - val_loss: 37.4297\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.3393 - val_loss: 38.4913\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 37.8761 - val_loss: 43.3744\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.0761 - val_loss: 38.1234\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.5943 - val_loss: 36.9460\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.3373 - val_loss: 36.7758\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.2727 - val_loss: 35.1019\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.0509 - val_loss: 36.8013\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.2519 - val_loss: 34.1406\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.3310 - val_loss: 33.9888\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.7367 - val_loss: 34.2978\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.2608 - val_loss: 34.6948\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.8286 - val_loss: 33.4635\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.1375 - val_loss: 34.3309\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.2105 - val_loss: 34.2036\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.5450 - val_loss: 33.6375\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.6496 - val_loss: 33.1781\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.4972 - val_loss: 32.5281\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.4944 - val_loss: 33.0847\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.0525 - val_loss: 32.4345\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.7060 - val_loss: 31.9975\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.7430 - val_loss: 33.0308\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.3838 - val_loss: 33.2137\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 31.4148 - val_loss: 31.6217\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 32.3254 - val_loss: 31.5985\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 30.8146 - val_loss: 31.4665\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 30.0858 - val_loss: 30.7279\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 32.1639 - val_loss: 31.2977\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.1475 - val_loss: 30.9703\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.1382 - val_loss: 30.2157\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.8604 - val_loss: 30.5360\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.7965 - val_loss: 30.0415\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.1023 - val_loss: 29.6189\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 29.2141 - val_loss: 29.3201\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.9105 - val_loss: 29.9951\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 29.3047 - val_loss: 30.8461\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.7014 - val_loss: 33.5130\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.0741 - val_loss: 31.9697\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.3395 - val_loss: 30.5845\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.2977 - val_loss: 48.6290\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 46.0238 - val_loss: 46.2446\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 43.2240 - val_loss: 42.2887\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.4164 - val_loss: 40.8961\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 721us/step - loss: 40.6816 - val_loss: 43.2104\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 40.4770 - val_loss: 39.4433\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 718us/step - loss: 38.3351 - val_loss: 38.1829\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 715us/step - loss: 37.2964 - val_loss: 37.1757\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 798us/step - loss: 38.1659 - val_loss: 43.2035\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.6097 - val_loss: 37.4836\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.4573 - val_loss: 39.5146\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 612us/step - loss: 36.7434 - val_loss: 35.6857\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.6855 - val_loss: 40.2675\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 36.5769 - val_loss: 37.7241\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.9581 - val_loss: 34.7896\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 561us/step - loss: 34.1248 - val_loss: 34.3771\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 35.2267 - val_loss: 36.4448\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 711us/step - loss: 36.0015 - val_loss: 34.5568\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.7959 - val_loss: 36.7859\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.8777 - val_loss: 34.1918\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.0176 - val_loss: 33.3308\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.5253 - val_loss: 32.7661\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.2339 - val_loss: 33.1285\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.0950 - val_loss: 33.1086\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.9680 - val_loss: 32.2483\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.7528 - val_loss: 35.7035\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.2088 - val_loss: 31.7440\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.0654 - val_loss: 34.3068\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.3669 - val_loss: 31.3455\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.2023 - val_loss: 31.5072\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.3783 - val_loss: 31.4727\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.1496 - val_loss: 32.5696\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.2323 - val_loss: 30.7281\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.8200 - val_loss: 30.3430\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.5616 - val_loss: 29.9967\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.1591 - val_loss: 29.9592\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.1680 - val_loss: 30.6585\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 29.4968 - val_loss: 30.4855\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.6856 - val_loss: 29.4196\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.0042 - val_loss: 28.8003\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.3014 - val_loss: 28.4577\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.2405 - val_loss: 30.7965\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.7929 - val_loss: 28.9291\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.8353 - val_loss: 29.1202\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.6516 - val_loss: 27.6269\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 27.0556 - val_loss: 28.3233\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.7816 - val_loss: 28.3523\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 26.1791 - val_loss: 27.1891\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 26.9626 - val_loss: 28.6406\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.4126 - val_loss: 28.6027\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.0970 - val_loss: 26.5239\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.2680 - val_loss: 26.9785\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.1687 - val_loss: 25.6393\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 24.3750 - val_loss: 25.3530\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.8015 - val_loss: 25.7226\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.3988 - val_loss: 25.0279\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.7774 - val_loss: 24.9596\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.7597 - val_loss: 24.7308\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.6751 - val_loss: 24.7247\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 24.4022 - val_loss: 25.5675\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.5820 - val_loss: 24.4261\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.9704 - val_loss: 24.1413\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2625 - val_loss: 24.1163\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.7478 - val_loss: 23.9049\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.7670 - val_loss: 24.4209\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.6187 - val_loss: 24.4660\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.7346 - val_loss: 23.7809\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.3371 - val_loss: 23.6505\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.1814 - val_loss: 23.5266\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.1729 - val_loss: 23.4245\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.9974 - val_loss: 23.3504\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.2893 - val_loss: 23.5305\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.8219 - val_loss: 23.3276\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.7538 - val_loss: 23.5019\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.7465 - val_loss: 23.1436\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.7588 - val_loss: 23.7372\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.7107 - val_loss: 23.1119\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.3980 - val_loss: 23.4543\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7518 - val_loss: 23.0453\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.2127 - val_loss: 22.9954\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.1669 - val_loss: 22.8290\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.0003 - val_loss: 22.9196\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9963 - val_loss: 23.0038\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 21.1946 - val_loss: 22.8781\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.9438 - val_loss: 22.8291\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.7793 - val_loss: 23.1417\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.8967 - val_loss: 48.3421\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 46.5300 - val_loss: 42.3873\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 628us/step - loss: 44.5587 - val_loss: 41.7187\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 41.5120 - val_loss: 42.3090\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 296us/step - loss: 40.0262 - val_loss: 40.9036\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 40.0812 - val_loss: 38.2217\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.1913 - val_loss: 37.4397\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.9887 - val_loss: 36.2955\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.4070 - val_loss: 37.6930\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.9173 - val_loss: 36.7385\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.9025 - val_loss: 38.7574\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.1143 - val_loss: 36.7193\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.2431 - val_loss: 35.6426\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.4503 - val_loss: 35.2329\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 36.6432 - val_loss: 34.8840\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.3979 - val_loss: 34.3781\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.9897 - val_loss: 36.1754\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 33.6748 - val_loss: 33.9334\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 33.4240 - val_loss: 34.4050\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.4560 - val_loss: 33.7824\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 33.9206 - val_loss: 33.4726\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.5848 - val_loss: 32.7993\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 31.9766 - val_loss: 32.5767\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 32.1879 - val_loss: 35.3596\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.8884 - val_loss: 34.3591\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 32.9605 - val_loss: 33.5618\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 32.7678 - val_loss: 31.7790\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 31.1866 - val_loss: 33.9842\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 31.6263 - val_loss: 32.6848\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 31.2269 - val_loss: 31.4670\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.1453 - val_loss: 32.0989\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 30.6358 - val_loss: 32.4153\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 31.4096 - val_loss: 30.8864\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 30.4975 - val_loss: 30.9429\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 30.9181 - val_loss: 31.4440\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 30.2880 - val_loss: 31.0170\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 28.7831 - val_loss: 29.3736\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 29.1202 - val_loss: 30.3629\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 29.5399 - val_loss: 29.2418\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 28.7128 - val_loss: 30.3028\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 29.0749 - val_loss: 31.2137\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 28.7262 - val_loss: 31.0088\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 27.2643 - val_loss: 26.8124\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 26.5871 - val_loss: 26.2845\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 25.6936 - val_loss: 27.0050\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 25.5401 - val_loss: 25.5708\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 696us/step - loss: 24.6546 - val_loss: 25.1255\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 24.3373 - val_loss: 24.8340\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 24.0790 - val_loss: 24.5411\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 820us/step - loss: 23.8155 - val_loss: 24.7306\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 687us/step - loss: 23.8240 - val_loss: 24.3246\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 23.7405 - val_loss: 24.2792\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.7357 - val_loss: 24.4444\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 23.3214 - val_loss: 23.9145\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 23.0527 - val_loss: 23.7548\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.9422 - val_loss: 23.7159\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.7894 - val_loss: 23.5043\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.6190 - val_loss: 23.4097\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.7460 - val_loss: 23.8330\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 22.7209 - val_loss: 23.2931\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 22.4067 - val_loss: 23.3163\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.3446 - val_loss: 23.1325\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 22.2866 - val_loss: 23.6805\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 22.4895 - val_loss: 23.1641\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 22.1367 - val_loss: 22.8640\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 688us/step - loss: 22.0237 - val_loss: 22.9240\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.9140 - val_loss: 22.8044\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 21.8319 - val_loss: 22.8344\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 21.7104 - val_loss: 22.9182\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.8556 - val_loss: 22.6641\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 21.5425 - val_loss: 22.6403\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 21.4676 - val_loss: 22.7961\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.5621 - val_loss: 22.8907\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.5513 - val_loss: 22.6442\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.3962 - val_loss: 22.4874\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 21.3865 - val_loss: 23.1664\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.4253 - val_loss: 22.5070\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 955us/step - loss: 21.2219 - val_loss: 22.5707\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 21.3638 - val_loss: 22.5366\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 890us/step - loss: 21.3039 - val_loss: 22.6650\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.8926 - val_loss: 49.2480\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 48.1727 - val_loss: 46.2216\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 43.6888 - val_loss: 42.2114\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 41.0730 - val_loss: 41.6143\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 40.2400 - val_loss: 40.7751\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 40.8800 - val_loss: 40.0705\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 533us/step - loss: 40.5276 - val_loss: 43.4599\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 39.3707 - val_loss: 39.9829\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.0460 - val_loss: 37.5419\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 37.4770 - val_loss: 36.9199\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 36.7656 - val_loss: 38.2888\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 37.4520 - val_loss: 36.6236\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.9400 - val_loss: 40.8018\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 36.9598 - val_loss: 36.2964\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 35.7681 - val_loss: 35.5706\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.2782 - val_loss: 38.1519\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.8034 - val_loss: 36.5524\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.4730 - val_loss: 34.2183\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 33.8745 - val_loss: 34.0800\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.9193 - val_loss: 35.9367\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 33.9041 - val_loss: 34.1786\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 32.7516 - val_loss: 32.8177\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.4068 - val_loss: 34.0718\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.6054 - val_loss: 33.9995\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.1586 - val_loss: 33.3749\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.1953 - val_loss: 32.0999\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.2630 - val_loss: 31.6590\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 32.0821 - val_loss: 35.0963\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.5166 - val_loss: 32.3742\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.9410 - val_loss: 32.2593\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.7730 - val_loss: 32.9617\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.4699 - val_loss: 31.8343\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 84.3437 - val_loss: 48.9175\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 47.1234 - val_loss: 43.0365\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 41.9266 - val_loss: 40.0405\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.4383 - val_loss: 45.0208\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.1494 - val_loss: 39.5880\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.6543 - val_loss: 38.4645\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.6872 - val_loss: 38.0763\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.7950 - val_loss: 37.0733\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.8129 - val_loss: 39.4324\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.5340 - val_loss: 38.3949\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.0981 - val_loss: 39.8159\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.2493 - val_loss: 38.0372\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.1287 - val_loss: 35.6993\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 37.0661 - val_loss: 38.5201\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.7387 - val_loss: 35.0939\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.3117 - val_loss: 34.6983\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.1715 - val_loss: 34.8839\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 34.4733 - val_loss: 34.8132\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.9671 - val_loss: 33.5181\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.7439 - val_loss: 35.9938\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.4842 - val_loss: 33.3929\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.7716 - val_loss: 33.9377\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.4819 - val_loss: 32.8177\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.8701 - val_loss: 33.7765\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.6823 - val_loss: 32.4314\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.2050 - val_loss: 32.5954\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.8863 - val_loss: 32.7416\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 31.1915 - val_loss: 32.8100\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 31.7732 - val_loss: 31.9001\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.4554 - val_loss: 33.9028\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.3931 - val_loss: 31.6010\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 30.6922 - val_loss: 30.7533\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.1214 - val_loss: 31.4797\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.1631 - val_loss: 31.4962\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.4718 - val_loss: 30.7167\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.7501 - val_loss: 30.5849\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.4697 - val_loss: 29.6878\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.9859 - val_loss: 29.3771\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.3568 - val_loss: 29.3034\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 27.7075 - val_loss: 28.4884\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.5566 - val_loss: 29.4126\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.3726 - val_loss: 27.9055\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 26.6490 - val_loss: 27.5079\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.0709 - val_loss: 27.4821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.1281 - val_loss: 27.1105\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.6408 - val_loss: 27.7299\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.8641 - val_loss: 25.1249\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.1433 - val_loss: 24.9877\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.0808 - val_loss: 24.7580\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.7797 - val_loss: 24.5225\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 23.4619 - val_loss: 24.2353\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 23.3873 - val_loss: 24.4910\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.3316 - val_loss: 24.0473\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.9702 - val_loss: 23.9754\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.8273 - val_loss: 23.8315\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.8320 - val_loss: 23.7322\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.7136 - val_loss: 23.9649\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.6884 - val_loss: 24.3402\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.5695 - val_loss: 23.7868\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.4436 - val_loss: 23.4392\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.2746 - val_loss: 23.6147\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.1903 - val_loss: 23.5153\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.1102 - val_loss: 23.2323\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.0469 - val_loss: 23.1465\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0429 - val_loss: 23.3666\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8323 - val_loss: 23.1770\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8695 - val_loss: 23.0226\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.6455 - val_loss: 22.9857\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.5167 - val_loss: 22.9702\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.4730 - val_loss: 22.8767\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.4338 - val_loss: 22.8598\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.3362 - val_loss: 23.0345\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.4239 - val_loss: 22.8318\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.4860 - val_loss: 23.2517\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.2896 - val_loss: 23.3479\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2022 - val_loss: 23.0896\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.4264 - val_loss: 22.8008\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.9898 - val_loss: 22.9878\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.1234 - val_loss: 22.8227\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.0458 - val_loss: 22.7237\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.9474 - val_loss: 22.6274\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.8442 - val_loss: 22.6205\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.8326 - val_loss: 22.6788\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.8577 - val_loss: 22.5374\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.6041 - val_loss: 22.7193\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.5722 - val_loss: 22.6719\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.4703 - val_loss: 22.6767\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.8003 - val_loss: 22.7232\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.4580 - val_loss: 22.7085\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.5746 - val_loss: 45.1545\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 44.2393 - val_loss: 46.9133\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 41.7160 - val_loss: 41.8334\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 40.4237 - val_loss: 40.8667\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.5522 - val_loss: 38.4803\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.5582 - val_loss: 37.7386\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.5028 - val_loss: 39.1834\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.0325 - val_loss: 38.0103\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.5770 - val_loss: 38.0870\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 35.6195 - val_loss: 35.7195\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.7944 - val_loss: 38.1605\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.1739 - val_loss: 36.1502\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.2361 - val_loss: 37.2228\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.6449 - val_loss: 35.4284\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.2599 - val_loss: 38.1552\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.3265 - val_loss: 35.8126\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.2842 - val_loss: 35.2801\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.3633 - val_loss: 37.5930\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.7240 - val_loss: 33.8174\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.5145 - val_loss: 33.8789\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.7131 - val_loss: 33.2779\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.9026 - val_loss: 36.7328\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.9623 - val_loss: 33.1930\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.0480 - val_loss: 32.6441\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.0826 - val_loss: 33.3923\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 32.6036 - val_loss: 32.2352\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.9579 - val_loss: 32.2990\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.6927 - val_loss: 32.0405\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.3152 - val_loss: 31.4559\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.3799 - val_loss: 31.2342\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.5794 - val_loss: 31.0813\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.9589 - val_loss: 30.9449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 29.8869 - val_loss: 31.6581\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.5242 - val_loss: 32.7314\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.9689 - val_loss: 30.3560\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.0435 - val_loss: 30.5704\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 29.3405 - val_loss: 31.7829\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.0159 - val_loss: 33.2106\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 28.7798 - val_loss: 29.3311\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.4448 - val_loss: 28.9253\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.2604 - val_loss: 31.1070\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 28.3836 - val_loss: 30.3739\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.6627 - val_loss: 29.1251\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 556us/step - loss: 28.9423 - val_loss: 28.9041\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.2046 - val_loss: 28.2938\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 26.5987 - val_loss: 27.3089\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 26.3596 - val_loss: 27.3746\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.3901 - val_loss: 26.6676\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 25.8357 - val_loss: 26.6831\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.5719 - val_loss: 25.8549\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 24.6410 - val_loss: 25.1575\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.8034 - val_loss: 24.8580\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.8216 - val_loss: 24.8645\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 23.5470 - val_loss: 24.9577\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.6769 - val_loss: 25.1295\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.5202 - val_loss: 23.9665\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.9803 - val_loss: 23.7168\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.8370 - val_loss: 24.5745\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.1085 - val_loss: 23.7752\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.6819 - val_loss: 23.2922\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 22.3918 - val_loss: 23.2444\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.2896 - val_loss: 23.2077\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3346 - val_loss: 23.4504\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.2109 - val_loss: 22.8762\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.0497 - val_loss: 22.9408\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.2875 - val_loss: 22.9889\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.1491 - val_loss: 22.7361\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.7752 - val_loss: 22.6464\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7669 - val_loss: 22.5641\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6459 - val_loss: 22.5248\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.5361 - val_loss: 22.6382\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.7044 - val_loss: 22.5301\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.4325 - val_loss: 22.4183\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.4709 - val_loss: 22.7747\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.4575 - val_loss: 22.4505\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.3269 - val_loss: 22.4370\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.4105 - val_loss: 22.3266\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.2647 - val_loss: 22.2994\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.2758 - val_loss: 22.2129\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.1991 - val_loss: 22.2995\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.0755 - val_loss: 22.2388\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.0283 - val_loss: 22.2280\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1140 - val_loss: 22.3591\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.1411 - val_loss: 22.1163\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9789 - val_loss: 22.1161\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.9375 - val_loss: 22.1018\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.8697 - val_loss: 22.1403\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9260 - val_loss: 22.6308\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.8778 - val_loss: 22.4707\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1040 - val_loss: 22.1583\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.9217 - val_loss: 22.2182\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.8109 - val_loss: 45.8059\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 43.3975 - val_loss: 41.2119\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.8251 - val_loss: 40.2913\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.2105 - val_loss: 38.6906\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 40.3185 - val_loss: 40.1477\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.3598 - val_loss: 36.7527\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.1326 - val_loss: 36.2647\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.4931 - val_loss: 38.8440\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.8896 - val_loss: 36.5667\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.7587 - val_loss: 35.7355\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.0953 - val_loss: 34.8098\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.5305 - val_loss: 34.3793\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.7663 - val_loss: 34.0429\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.5387 - val_loss: 34.4247\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.8551 - val_loss: 33.8327\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.2642 - val_loss: 34.2981\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.7392 - val_loss: 33.0490\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.2188 - val_loss: 33.3322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.3092 - val_loss: 33.7172\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.0678 - val_loss: 32.9875\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.3977 - val_loss: 32.6244\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 33.1324 - val_loss: 32.8807\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.1135 - val_loss: 33.4487\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.4207 - val_loss: 31.7648\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.8645 - val_loss: 32.4659\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 32.5057 - val_loss: 32.4836\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 31.9575 - val_loss: 31.9341\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.7505 - val_loss: 31.7563\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.8904 - val_loss: 34.4494\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.3802 - val_loss: 31.4312\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 30.8870 - val_loss: 32.0167\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 30.9079 - val_loss: 30.5878\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.6841 - val_loss: 35.7434\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.7544 - val_loss: 35.3616\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.6151 - val_loss: 35.8824\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.9227 - val_loss: 32.2108\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.3426 - val_loss: 30.9325\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.1668 - val_loss: 47.4838\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 46.0658 - val_loss: 45.0605\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 42.2567 - val_loss: 45.8439\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 42.1287 - val_loss: 41.3929\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.1377 - val_loss: 38.7120\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.2911 - val_loss: 37.3109\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.9098 - val_loss: 36.5657\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 36.8392 - val_loss: 36.9748\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.9145 - val_loss: 35.4915\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 36.1664 - val_loss: 36.5188\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.5777 - val_loss: 34.5356\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.7415 - val_loss: 34.9954\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.3693 - val_loss: 33.7083\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 33.8645 - val_loss: 33.1326\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 32.9564 - val_loss: 34.3428\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 33.2798 - val_loss: 32.7170\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.7164 - val_loss: 35.8149\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.9137 - val_loss: 32.9106\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.5533 - val_loss: 32.1954\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.5403 - val_loss: 32.1625\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.5735 - val_loss: 33.1020\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.6606 - val_loss: 32.5058\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.4742 - val_loss: 32.2659\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.3758 - val_loss: 31.4037\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 32.5244 - val_loss: 33.8062\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.9750 - val_loss: 33.0522\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 32.1843 - val_loss: 32.5852\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.7232 - val_loss: 30.7173\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 30.7340 - val_loss: 33.7520\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 30.8885 - val_loss: 30.5708\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 29.9315 - val_loss: 30.4028\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 30.1327 - val_loss: 32.7231\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.5116 - val_loss: 30.8286\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 29.7477 - val_loss: 30.0165\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 29.3106 - val_loss: 29.8563\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 29.1951 - val_loss: 29.3848\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 28.9413 - val_loss: 29.3361\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 30.2725 - val_loss: 29.9155\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.1485 - val_loss: 29.2973\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.2102 - val_loss: 28.6417\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.2588 - val_loss: 30.5718\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 29.5756 - val_loss: 28.8402\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 28.7220 - val_loss: 29.7517\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 28.7353 - val_loss: 28.1565\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 27.7581 - val_loss: 27.8873\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 27.7139 - val_loss: 28.4115\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 26.7252 - val_loss: 27.1191\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 25.9552 - val_loss: 26.6979\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 26.2477 - val_loss: 32.5115\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.8671 - val_loss: 26.5006\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 25.7759 - val_loss: 25.4865\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 24.4642 - val_loss: 25.1163\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 24.4386 - val_loss: 24.2785\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.6263 - val_loss: 23.9253\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 23.2753 - val_loss: 24.1481\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.1164 - val_loss: 23.2680\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.8541 - val_loss: 23.2804\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 22.7932 - val_loss: 23.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.4511 - val_loss: 22.7965\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.4157 - val_loss: 23.6779\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 22.4053 - val_loss: 22.5715\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.1680 - val_loss: 22.5011\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.9012 - val_loss: 22.2654\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.7233 - val_loss: 22.2463\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.6417 - val_loss: 22.2650\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.7945 - val_loss: 22.5729\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8164 - val_loss: 21.9612\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5244 - val_loss: 22.0644\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.3833 - val_loss: 21.8517\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.6211 - val_loss: 21.8496\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.4025 - val_loss: 21.8766\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.2414 - val_loss: 21.7447\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.1362 - val_loss: 21.7762\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.1896 - val_loss: 21.7964\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.2829 - val_loss: 21.8428\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9282 - val_loss: 21.8666\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.0289 - val_loss: 21.5787\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.8518 - val_loss: 22.1208\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.0605 - val_loss: 21.6711\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.7479 - val_loss: 21.3725\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.7012 - val_loss: 21.4108\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.7232 - val_loss: 21.7561\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.9355 - val_loss: 21.4833\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.7058 - val_loss: 21.2840\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.5871 - val_loss: 21.3514\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.5623 - val_loss: 21.2291\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.4908 - val_loss: 21.2764\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.4823 - val_loss: 21.6828\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.5583 - val_loss: 21.4861\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.5301 - val_loss: 21.2212\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.3334 - val_loss: 21.2575\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.4566 - val_loss: 21.3325\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.4010 - val_loss: 22.1029\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.5155 - val_loss: 21.2076\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.3025 - val_loss: 21.3244\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.2673 - val_loss: 21.1682\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.2333 - val_loss: 21.1094\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.1153 - val_loss: 21.0036\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.0796 - val_loss: 21.0133\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.0108 - val_loss: 21.3973\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.8041 - val_loss: 45.6096\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 44.6096 - val_loss: 43.8024\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 42.1976 - val_loss: 42.2826\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 41.3343 - val_loss: 40.6648\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 41.0444 - val_loss: 41.8092\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.1851 - val_loss: 38.8506\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.5020 - val_loss: 41.6418\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.6630 - val_loss: 40.6527\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.7526 - val_loss: 38.2835\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.9441 - val_loss: 37.5661\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.4302 - val_loss: 36.8135\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.7524 - val_loss: 38.8631\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.8628 - val_loss: 36.6679\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.8495 - val_loss: 39.0676\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.5787 - val_loss: 36.7199\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.0820 - val_loss: 36.1120\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.4918 - val_loss: 38.3773\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.8736 - val_loss: 36.7273\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.9616 - val_loss: 35.1597\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.2274 - val_loss: 35.0150\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.1554 - val_loss: 34.6718\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.3301 - val_loss: 36.3313\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.6953 - val_loss: 34.4566\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.5883 - val_loss: 36.5866\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.7575 - val_loss: 35.5258\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.7946 - val_loss: 34.0361\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.2837 - val_loss: 34.5647\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.7063 - val_loss: 33.6945\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 33.0834 - val_loss: 33.8780\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.7995 - val_loss: 33.7366\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.9867 - val_loss: 34.6353\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.0914 - val_loss: 32.7010\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.4429 - val_loss: 32.4821\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.6942 - val_loss: 32.2323\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.7268 - val_loss: 33.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.3820 - val_loss: 30.6439\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.1152 - val_loss: 31.4931\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.0110 - val_loss: 29.7059\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.3432 - val_loss: 28.5331\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 27.6895 - val_loss: 27.9141\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 26.7315 - val_loss: 26.5923\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.0138 - val_loss: 26.3516\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 25.5803 - val_loss: 25.9076\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.1583 - val_loss: 25.1042\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.6588 - val_loss: 25.0281\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.2958 - val_loss: 24.6911\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.1644 - val_loss: 24.4443\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.0499 - val_loss: 24.3298\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.8685 - val_loss: 24.7495\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.5739 - val_loss: 24.0107\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.3798 - val_loss: 23.8977\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.2176 - val_loss: 23.7905\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.2704 - val_loss: 24.0601\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.0213 - val_loss: 23.6885\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.0072 - val_loss: 23.5204\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.8502 - val_loss: 23.6361\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.7813 - val_loss: 23.3283\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.6331 - val_loss: 23.2911\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.6229 - val_loss: 23.2045\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.4918 - val_loss: 23.1383\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.5128 - val_loss: 23.4528\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.4021 - val_loss: 23.1349\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3408 - val_loss: 23.0386\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1446 - val_loss: 23.0061\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.1501 - val_loss: 22.8970\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.0260 - val_loss: 22.9457\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.9491 - val_loss: 22.8430\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.9272 - val_loss: 22.7678\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8655 - val_loss: 22.8445\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8155 - val_loss: 22.7954\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.8385 - val_loss: 22.9495\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 21.7775 - val_loss: 22.8802\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.7872 - val_loss: 22.8998\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.5283 - val_loss: 51.1187\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 46.8258 - val_loss: 42.3392\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.4103 - val_loss: 45.9611\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.6494 - val_loss: 40.0205\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.5185 - val_loss: 38.8134\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 40.0498 - val_loss: 40.4371\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 38.7390 - val_loss: 37.1505\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.4710 - val_loss: 37.7630\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.0585 - val_loss: 36.8202\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.2605 - val_loss: 37.0232\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.5935 - val_loss: 36.4288\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.7493 - val_loss: 37.4020\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.6543 - val_loss: 38.5416\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.4971 - val_loss: 36.8817\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.5449 - val_loss: 34.5830\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.7202 - val_loss: 33.7900\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.6680 - val_loss: 33.7868\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.8984 - val_loss: 35.8723\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.6645 - val_loss: 33.6241\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.0191 - val_loss: 33.4523\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.7348 - val_loss: 38.1532\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 34.4931 - val_loss: 36.3794\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.8950 - val_loss: 36.4873\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.4884 - val_loss: 32.1991\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.0111 - val_loss: 31.8835\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 32.5591 - val_loss: 31.3465\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.5339 - val_loss: 32.9651\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.5718 - val_loss: 31.9835\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.5413 - val_loss: 31.6119\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.8379 - val_loss: 30.8771\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.4291 - val_loss: 31.0586\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.6518 - val_loss: 35.1749\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.1127 - val_loss: 31.0515\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.8515 - val_loss: 30.3053\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.2694 - val_loss: 32.0453\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.1054 - val_loss: 31.9609\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.2956 - val_loss: 30.7195\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.5503 - val_loss: 30.7909\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.9723 - val_loss: 29.3950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 30.0603 - val_loss: 32.3066\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.0100 - val_loss: 29.4863\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 29.1541 - val_loss: 31.4207\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.4812 - val_loss: 32.0076\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.3266 - val_loss: 30.1310\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.9428 - val_loss: 49.0805\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 46.9386 - val_loss: 44.3215\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 41.0836 - val_loss: 42.2785\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.7206 - val_loss: 37.4652\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.4019 - val_loss: 39.6493\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 39.1335 - val_loss: 36.5237\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.5440 - val_loss: 35.2357\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.9035 - val_loss: 40.8050\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.7825 - val_loss: 34.5022\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.7075 - val_loss: 40.5855\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.0201 - val_loss: 33.9985\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.1620 - val_loss: 33.5549\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.0395 - val_loss: 33.1406\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.7196 - val_loss: 32.4064\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.8534 - val_loss: 33.2363\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.8379 - val_loss: 32.2971\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.6709 - val_loss: 31.5947\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.6125 - val_loss: 32.8426\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.4672 - val_loss: 31.6675\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.1403 - val_loss: 33.6581\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 30.9747 - val_loss: 30.8540\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 30.1242 - val_loss: 31.8620\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.6200 - val_loss: 30.9513\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.4811 - val_loss: 34.2747\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 29.4974 - val_loss: 29.7526\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.1200 - val_loss: 30.0173\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.4022 - val_loss: 29.4155\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 29.2603 - val_loss: 29.3171\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.9509 - val_loss: 28.9683\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.4168 - val_loss: 29.2789\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 31.5663 - val_loss: 31.1507\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.2305 - val_loss: 30.7931\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 29.0426 - val_loss: 29.9135\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.9789 - val_loss: 28.3531\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 27.6203 - val_loss: 28.9522\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.5877 - val_loss: 29.1260\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.9672 - val_loss: 31.3672\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.1781 - val_loss: 28.3039\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.9152 - val_loss: 28.8449\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 26.8878 - val_loss: 28.1208\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 26.2441 - val_loss: 30.0722\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.2252 - val_loss: 27.6215\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.3164 - val_loss: 27.4014\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.4700 - val_loss: 27.8698\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.2742 - val_loss: 27.5390\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.8571 - val_loss: 27.1840\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.5790 - val_loss: 27.2492\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.3158 - val_loss: 27.2861\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 25.4532 - val_loss: 27.6998\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 25.3609 - val_loss: 29.8379\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 26.2018 - val_loss: 27.0624\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 25.8784 - val_loss: 27.5466\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 25.3318 - val_loss: 29.0562\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.4227 - val_loss: 27.5598\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 26.6219 - val_loss: 28.1255\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.7670 - val_loss: 27.5181\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.7744 - val_loss: 55.7150\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 52.5280 - val_loss: 49.0342\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 46.3784 - val_loss: 46.2383\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 44.1677 - val_loss: 42.4570\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.6823 - val_loss: 41.1526\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 42.9588 - val_loss: 42.3923\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.5627 - val_loss: 41.6954\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.6471 - val_loss: 39.0658\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 39.1186 - val_loss: 37.7623\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.8893 - val_loss: 37.1240\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.2015 - val_loss: 38.0171\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.6307 - val_loss: 36.9713\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.5341 - val_loss: 36.7901\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.6809 - val_loss: 36.6408\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.4541 - val_loss: 35.2971\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.2339 - val_loss: 39.1544\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.0566 - val_loss: 35.6795\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.8035 - val_loss: 35.2107\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.5311 - val_loss: 35.6954\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.7979 - val_loss: 36.1849\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.0452 - val_loss: 32.8803\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.8093 - val_loss: 33.2824\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.7615 - val_loss: 32.0062\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.4234 - val_loss: 31.4163\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.8917 - val_loss: 32.5788\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.2131 - val_loss: 29.7884\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 28.8401 - val_loss: 30.4695\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.1093 - val_loss: 28.6908\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 27.6647 - val_loss: 29.1165\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.9888 - val_loss: 29.7769\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.1203 - val_loss: 26.9928\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.8089 - val_loss: 26.7788\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.6474 - val_loss: 27.4747\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.9606 - val_loss: 25.9953\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.2297 - val_loss: 26.1329\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.8870 - val_loss: 25.4396\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.9848 - val_loss: 25.3243\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 24.8106 - val_loss: 25.2918\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 24.5916 - val_loss: 27.1358\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 24.5206 - val_loss: 24.9179\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.9957 - val_loss: 24.5904\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.9832 - val_loss: 25.2362\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.9210 - val_loss: 24.2902\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.5263 - val_loss: 24.1998\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.6430 - val_loss: 24.2530\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.3476 - val_loss: 23.9616\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.3086 - val_loss: 24.7372\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.2766 - val_loss: 24.6704\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.1476 - val_loss: 23.6991\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.0540 - val_loss: 24.1563\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.8352 - val_loss: 23.9208\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.9379 - val_loss: 23.7619\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.6530 - val_loss: 23.7513\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.6732 - val_loss: 23.5805\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.6279 - val_loss: 23.2278\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2982 - val_loss: 23.2175\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.2012 - val_loss: 23.0913\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0613 - val_loss: 23.1479\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.0916 - val_loss: 22.9436\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.2473 - val_loss: 23.0144\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3483 - val_loss: 23.0937\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.8216 - val_loss: 22.9389\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7945 - val_loss: 22.7710\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.5759 - val_loss: 22.7504\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.5334 - val_loss: 22.7492\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6678 - val_loss: 23.1991\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.6425 - val_loss: 22.5988\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.4530 - val_loss: 22.4893\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.4155 - val_loss: 22.5352\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3181 - val_loss: 22.4530\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2128 - val_loss: 22.8099\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.1854 - val_loss: 22.5113\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.1193 - val_loss: 22.5086\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.0265 - val_loss: 22.6591\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0184 - val_loss: 22.9019\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.7355 - val_loss: 46.9945\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 43.9886 - val_loss: 41.2582\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 42.5821 - val_loss: 45.8494\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.3365 - val_loss: 40.9138\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.0465 - val_loss: 38.9395\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.8439 - val_loss: 40.4548\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.1300 - val_loss: 40.6833\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.5646 - val_loss: 39.8533\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.8050 - val_loss: 39.5050\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.0527 - val_loss: 36.7284\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.3757 - val_loss: 36.5309\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.2211 - val_loss: 37.7703\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.3012 - val_loss: 37.0139\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.8198 - val_loss: 37.1183\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 36.5596 - val_loss: 38.3162\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.9629 - val_loss: 35.0471\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.9747 - val_loss: 35.1122\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 622us/step - loss: 33.9065 - val_loss: 35.2813\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.0973 - val_loss: 36.9993\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.2440 - val_loss: 36.7154\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.5217 - val_loss: 34.3793\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.7613 - val_loss: 33.8816\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 32.3752 - val_loss: 34.1974\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.9555 - val_loss: 36.2587\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.6641 - val_loss: 32.5784\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.7083 - val_loss: 33.1554\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.7779 - val_loss: 32.0874\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.3382 - val_loss: 32.2317\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.9229 - val_loss: 31.9674\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.7737 - val_loss: 34.5713\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 31.7368 - val_loss: 32.3016\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 30.6935 - val_loss: 31.3379\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.4049 - val_loss: 31.4604\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.7962 - val_loss: 31.0043\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.0124 - val_loss: 31.4289\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.3987 - val_loss: 31.2790\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.5394 - val_loss: 31.0520\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.5726 - val_loss: 33.0297\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.1440 - val_loss: 30.3819\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.0645 - val_loss: 29.8791\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 28.5817 - val_loss: 29.4848\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 28.3712 - val_loss: 31.1353\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 28.3017 - val_loss: 29.9850\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.1031 - val_loss: 29.1068\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 29.0450 - val_loss: 31.0523\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 30.0888 - val_loss: 30.9932\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 743us/step - loss: 28.8793 - val_loss: 29.1729\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 713us/step - loss: 28.3515 - val_loss: 29.3887\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 744us/step - loss: 28.2983 - val_loss: 31.7734\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.2007 - val_loss: 51.7844\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 49.5339 - val_loss: 49.4273\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 44.2738 - val_loss: 46.4608\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 42.4915 - val_loss: 43.9926\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 41.3251 - val_loss: 40.9453\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.6943 - val_loss: 43.0762\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 40.9949 - val_loss: 40.4547\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.9047 - val_loss: 40.5730\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.5987 - val_loss: 39.3810\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 40.0335 - val_loss: 38.6094\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 38.0917 - val_loss: 37.8912\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.8296 - val_loss: 38.2528\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.6222 - val_loss: 37.4077\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.9356 - val_loss: 37.8526\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.4092 - val_loss: 36.3370\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.8814 - val_loss: 37.5048\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.7257 - val_loss: 35.6410\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.4629 - val_loss: 34.9796\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.6306 - val_loss: 37.8186\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.0679 - val_loss: 35.1626\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.8429 - val_loss: 34.1747\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.1990 - val_loss: 34.5063\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 33.8025 - val_loss: 37.6423\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.6026 - val_loss: 34.8879\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 33.3391 - val_loss: 33.5253\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 316us/step - loss: 32.7769 - val_loss: 34.0577\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 304us/step - loss: 33.8539 - val_loss: 33.6423\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 298us/step - loss: 32.8225 - val_loss: 35.1421\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 263us/step - loss: 32.4106 - val_loss: 32.4231\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 284us/step - loss: 31.7651 - val_loss: 32.4407\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 281us/step - loss: 33.3099 - val_loss: 35.2983\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 276us/step - loss: 32.9356 - val_loss: 32.8199\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 270us/step - loss: 31.3424 - val_loss: 35.9152\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 307us/step - loss: 33.1795 - val_loss: 32.5355\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.5537 - val_loss: 55.3142\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 49.3368 - val_loss: 46.0173\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 44.9442 - val_loss: 44.3979\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 44.3276 - val_loss: 44.0156\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 44.1720 - val_loss: 44.2293\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 42.1107 - val_loss: 41.9069\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 43.3926 - val_loss: 44.6908\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 41.9439 - val_loss: 41.9126\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 41.6118 - val_loss: 41.5626\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 40.2314 - val_loss: 39.3863\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 38.9940 - val_loss: 39.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 39.6577 - val_loss: 40.1102\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.6695 - val_loss: 45.7284\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 38.1682 - val_loss: 39.0394\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.4102 - val_loss: 38.0813\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 37.3324 - val_loss: 40.4669\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.8640 - val_loss: 39.4362\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 37.3583 - val_loss: 38.1793\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.4030 - val_loss: 38.4289\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.8011 - val_loss: 42.6149\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 84.3428 - val_loss: 48.6426\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 46.9231 - val_loss: 42.6221\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 42.0610 - val_loss: 39.1468\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 40.8805 - val_loss: 37.7331\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 39.8683 - val_loss: 37.7197\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.6953 - val_loss: 36.9946\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.8489 - val_loss: 36.2154\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 37.4233 - val_loss: 35.4448\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.4953 - val_loss: 38.4388\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.7322 - val_loss: 34.5293\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.0769 - val_loss: 35.2323\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 35.5913 - val_loss: 36.9195\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.0698 - val_loss: 36.5291\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.3122 - val_loss: 33.5115\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 35.2612 - val_loss: 33.7428\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 35.1145 - val_loss: 34.1116\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.8409 - val_loss: 34.0193\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.1654 - val_loss: 32.1350\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.4920 - val_loss: 32.7926\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.3577 - val_loss: 32.4592\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.3609 - val_loss: 33.1425\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 32.5443 - val_loss: 32.0526\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 32.3758 - val_loss: 31.5343\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 555us/step - loss: 32.5013 - val_loss: 31.1544\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 32.0130 - val_loss: 31.5392\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.8444 - val_loss: 31.1903\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.8708 - val_loss: 37.1879\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 34.1983 - val_loss: 32.4514\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.3747 - val_loss: 31.7776\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 90.8871 - val_loss: 49.0972\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 47.1605 - val_loss: 45.6323\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 43.0409 - val_loss: 40.9138\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.7480 - val_loss: 40.1432\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 40.2620 - val_loss: 38.9557\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.9739 - val_loss: 37.5030\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.7934 - val_loss: 37.8001\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.5562 - val_loss: 39.4269\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.2097 - val_loss: 37.3508\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 36.5122 - val_loss: 36.5048\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 36.5261 - val_loss: 38.9842\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.6500 - val_loss: 36.4099\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.6132 - val_loss: 34.7729\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.7025 - val_loss: 34.3767\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.6309 - val_loss: 35.2496\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 34.5244 - val_loss: 33.8446\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.3996 - val_loss: 34.4466\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.5332 - val_loss: 34.2301\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.9182 - val_loss: 33.4895\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.0358 - val_loss: 34.7543\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.6861 - val_loss: 38.7520\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.5524 - val_loss: 33.3859\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.8527 - val_loss: 33.2687\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.8906 - val_loss: 31.9706\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.7063 - val_loss: 33.7727\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.2447 - val_loss: 32.8136\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.9504 - val_loss: 31.9805\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.1043 - val_loss: 31.7733\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.2281 - val_loss: 31.7145\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.4273 - val_loss: 33.8391\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.6348 - val_loss: 31.8954\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.8665 - val_loss: 31.9216\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.4578 - val_loss: 30.9970\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.0722 - val_loss: 30.6097\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.1448 - val_loss: 31.1375\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.5963 - val_loss: 30.1634\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.9916 - val_loss: 31.0418\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.6153 - val_loss: 30.0306\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 29.1545 - val_loss: 30.5853\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 29.0850 - val_loss: 32.8882\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.4552 - val_loss: 29.4363\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.8758 - val_loss: 29.5670\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.7369 - val_loss: 30.8136\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.6264 - val_loss: 30.0563\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 28.1138 - val_loss: 29.2338\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 27.8541 - val_loss: 29.1022\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.7977 - val_loss: 28.5616\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.4538 - val_loss: 29.0852\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.4044 - val_loss: 28.2400\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.0336 - val_loss: 28.0798\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.3118 - val_loss: 28.5563\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.8428 - val_loss: 28.0128\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.1584 - val_loss: 28.5234\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.6218 - val_loss: 28.9426\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.2314 - val_loss: 27.3320\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 26.3466 - val_loss: 27.1262\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 25.6963 - val_loss: 26.7759\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.5559 - val_loss: 26.9519\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.3964 - val_loss: 26.2922\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.9690 - val_loss: 26.3623\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.6769 - val_loss: 25.6959\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.2391 - val_loss: 25.5411\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.5881 - val_loss: 25.7860\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 24.3525 - val_loss: 25.0239\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 23.9207 - val_loss: 24.7708\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.4378 - val_loss: 24.5176\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.3150 - val_loss: 24.9263\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.1158 - val_loss: 24.9134\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.6526 - val_loss: 24.3212\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.9571 - val_loss: 24.0751\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.9694 - val_loss: 24.5470\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.7514 - val_loss: 24.0567\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.6675 - val_loss: 24.5695\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.6993 - val_loss: 23.7654\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.9587 - val_loss: 24.2523\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.8910 - val_loss: 23.9358\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.1821 - val_loss: 23.3459\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.9986 - val_loss: 23.3115\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.9092 - val_loss: 23.5565\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.9983 - val_loss: 23.2103\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.9232 - val_loss: 23.2427\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.8619 - val_loss: 23.9200\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8077 - val_loss: 23.6076\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6519 - val_loss: 23.1262\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.4325 - val_loss: 23.0580\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.3013 - val_loss: 22.9885\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3833 - val_loss: 23.0819\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.1875 - val_loss: 22.9656\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.1890 - val_loss: 23.0053\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.0419 - val_loss: 23.0787\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.0285 - val_loss: 23.0024\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.0171 - val_loss: 22.8901\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9523 - val_loss: 22.8720\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.8866 - val_loss: 22.9572\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.9081 - val_loss: 23.0937\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7589 - val_loss: 22.8807\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.7561 - val_loss: 22.9159\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.6340 - val_loss: 22.9554\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.3712 - val_loss: 46.3284\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 44.0658 - val_loss: 41.6223\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 41.7056 - val_loss: 38.4309\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 40.9666 - val_loss: 41.5779\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 43.0603 - val_loss: 45.9215\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.1711 - val_loss: 38.2142\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 38.7322 - val_loss: 36.7884\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.4298 - val_loss: 36.3196\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 38.7515 - val_loss: 35.8012\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 38.5588 - val_loss: 39.9183\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.4599 - val_loss: 38.6368\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.5865 - val_loss: 35.4829\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 37.1120 - val_loss: 38.5333\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 37.8511 - val_loss: 35.9910\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 37.7120 - val_loss: 37.1390\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.4392 - val_loss: 33.7597\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 34.9614 - val_loss: 33.0713\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 635us/step - loss: 35.8537 - val_loss: 37.2569\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.0796 - val_loss: 34.7358\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 35.6001 - val_loss: 33.3170\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.4600 - val_loss: 33.5812\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.1877 - val_loss: 32.5543\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.1561 - val_loss: 33.2809\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8407 - val_loss: 32.4987\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 34.2194 - val_loss: 37.0753\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.1927 - val_loss: 33.3938\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 34.6193 - val_loss: 34.7610\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.2722 - val_loss: 32.8756\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.1056 - val_loss: 35.5951\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.8021 - val_loss: 48.0109\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 45.7336 - val_loss: 42.8731\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 45.8782 - val_loss: 47.3010\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 43.2938 - val_loss: 40.4670\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 42.5642 - val_loss: 42.0835\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.2628 - val_loss: 39.9638\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 40.3696 - val_loss: 38.3887\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 39.4698 - val_loss: 37.8748\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.4851 - val_loss: 40.0105\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 41.1188 - val_loss: 39.3009\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.7919 - val_loss: 36.9495\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.0949 - val_loss: 36.8266\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.8913 - val_loss: 39.1015\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.0317 - val_loss: 34.8010\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.2412 - val_loss: 35.2239\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.1034 - val_loss: 37.1985\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.4859 - val_loss: 34.2271\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.4866 - val_loss: 40.6966\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.3672 - val_loss: 33.1065\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.9187 - val_loss: 33.0037\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.5191 - val_loss: 35.4800\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.2833 - val_loss: 33.0484\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.5007 - val_loss: 33.8366\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.9039 - val_loss: 37.6889\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.9115 - val_loss: 34.6931\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.3037 - val_loss: 53.4792\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 44.4930 - val_loss: 43.2090\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 41.0864 - val_loss: 40.5669\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.9731 - val_loss: 41.4945\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 40.8666 - val_loss: 40.1944\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.8465 - val_loss: 41.1062\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.6423 - val_loss: 38.6600\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.1116 - val_loss: 38.0932\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.2242 - val_loss: 37.6771\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.3929 - val_loss: 38.2488\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 753us/step - loss: 37.2382 - val_loss: 36.7482\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.0128 - val_loss: 37.7763\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.8403 - val_loss: 35.9016\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.2891 - val_loss: 36.5183\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.1852 - val_loss: 39.0235\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.5244 - val_loss: 37.1010\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 34.7697 - val_loss: 38.0820\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.4544 - val_loss: 35.7952\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.2349 - val_loss: 35.1690\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.9781 - val_loss: 33.9861\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.7975 - val_loss: 33.9245\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.8664 - val_loss: 34.6424\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 33.6943 - val_loss: 34.6671\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 32.8405 - val_loss: 34.0417\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.8932 - val_loss: 34.9931\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.1313 - val_loss: 32.9421\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.4750 - val_loss: 33.4985\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.6481 - val_loss: 32.1321\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.8322 - val_loss: 32.7466\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 31.0004 - val_loss: 35.2423\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.2865 - val_loss: 34.6456\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.3091 - val_loss: 38.6685\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.2652 - val_loss: 33.3705\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 98.2751 - val_loss: 86.8531\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 59.0560 - val_loss: 48.2878\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 46.3636 - val_loss: 45.0611\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 42.3977 - val_loss: 40.0667\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 42.4941 - val_loss: 41.0953\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 40.0252 - val_loss: 38.7705\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.6311 - val_loss: 38.7298\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 37.2970 - val_loss: 36.8691\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 37.8920 - val_loss: 36.8201\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.8705 - val_loss: 35.2419\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.8234 - val_loss: 35.0904\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.7439 - val_loss: 40.2868\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.7370 - val_loss: 35.2628\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.9180 - val_loss: 35.0540\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.3560 - val_loss: 34.6471\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.5096 - val_loss: 33.2905\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 33.8477 - val_loss: 33.7141\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.0175 - val_loss: 34.5926\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.8236 - val_loss: 35.3068\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.2290 - val_loss: 40.7506\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.5633 - val_loss: 33.7627\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.1340 - val_loss: 48.4378\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 46.1556 - val_loss: 45.3884\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 44.4551 - val_loss: 44.5880\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 42.3883 - val_loss: 40.8715\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 40.5971 - val_loss: 40.4526\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 40.1123 - val_loss: 39.8714\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.8781 - val_loss: 39.0887\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 38.6108 - val_loss: 43.6066\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 39.4015 - val_loss: 39.2078\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 37.3155 - val_loss: 37.3805\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.0455 - val_loss: 36.6329\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 36.1943 - val_loss: 38.1465\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.9823 - val_loss: 36.2012\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 34.4499 - val_loss: 37.0335\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.1624 - val_loss: 36.3682\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.0840 - val_loss: 35.4775\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.3391 - val_loss: 35.6580\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.5699 - val_loss: 36.3801\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 789us/step - loss: 34.6032 - val_loss: 34.9909\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 729us/step - loss: 32.8566 - val_loss: 33.8956\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 859us/step - loss: 32.5835 - val_loss: 33.9027\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 875us/step - loss: 33.5040 - val_loss: 35.6855\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 674us/step - loss: 33.0632 - val_loss: 33.6572\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.9087 - val_loss: 32.6677\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 31.2596 - val_loss: 32.4964\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.1102 - val_loss: 32.3538\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 30.9479 - val_loss: 32.4816\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 31.9757 - val_loss: 34.0208\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.2404 - val_loss: 31.9099\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.5254 - val_loss: 31.5063\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 691us/step - loss: 30.0810 - val_loss: 31.2355\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 31.7217 - val_loss: 31.7478\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.2766 - val_loss: 32.1244\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 30.6976 - val_loss: 36.3142\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 705us/step - loss: 31.3503 - val_loss: 31.3967\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.6929 - val_loss: 32.2264\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.3286 - val_loss: 50.8990\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 49.0793 - val_loss: 44.4748\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.6747 - val_loss: 42.4679\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 42.3871 - val_loss: 45.4664\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 41.1499 - val_loss: 38.9381\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.3313 - val_loss: 39.9901\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.6029 - val_loss: 37.0682\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.3892 - val_loss: 38.6308\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.2856 - val_loss: 36.8139\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.5617 - val_loss: 36.9117\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 36.2556 - val_loss: 35.8315\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.0091 - val_loss: 38.0118\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.0014 - val_loss: 35.1172\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.6769 - val_loss: 34.9412\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.2332 - val_loss: 35.7687\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.4539 - val_loss: 36.3290\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.0898 - val_loss: 35.1330\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.2109 - val_loss: 33.9296\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 33.8805 - val_loss: 36.4290\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.3175 - val_loss: 35.3855\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.3536 - val_loss: 33.7460\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.9855 - val_loss: 32.8705\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.8034 - val_loss: 32.5945\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.8051 - val_loss: 33.0040\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.0010 - val_loss: 32.6716\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.5254 - val_loss: 33.4994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.1298 - val_loss: 35.9286\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.0858 - val_loss: 31.7790\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.4340 - val_loss: 32.8117\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.6319 - val_loss: 31.7480\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.8078 - val_loss: 31.3145\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.8257 - val_loss: 31.0390\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 30.0577 - val_loss: 30.7626\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 29.6851 - val_loss: 32.6291\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.8456 - val_loss: 30.5646\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 29.9948 - val_loss: 32.7334\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.3774 - val_loss: 30.8865\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.4975 - val_loss: 31.0984\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.6222 - val_loss: 30.0803\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 29.2339 - val_loss: 30.8747\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.3602 - val_loss: 29.3659\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.3040 - val_loss: 32.2883\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.0385 - val_loss: 29.0551\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 28.3351 - val_loss: 29.0820\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 27.6598 - val_loss: 28.2592\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 27.4373 - val_loss: 27.4254\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.5107 - val_loss: 28.2332\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.8791 - val_loss: 27.8402\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 25.3074 - val_loss: 26.6326\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.8271 - val_loss: 25.2772\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.7575 - val_loss: 25.3658\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.8454 - val_loss: 24.4593\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.3424 - val_loss: 24.3893\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.3030 - val_loss: 24.0698\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.8483 - val_loss: 23.7014\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.6709 - val_loss: 23.5615\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.6390 - val_loss: 24.5464\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.1886 - val_loss: 23.4435\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.0366 - val_loss: 23.8678\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.3094 - val_loss: 23.3159\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0540 - val_loss: 23.1714\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.0426 - val_loss: 23.0392\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.9775 - val_loss: 23.4122\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.8737 - val_loss: 22.8352\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7083 - val_loss: 22.8172\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.7032 - val_loss: 23.1318\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.7370 - val_loss: 23.1392\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6338 - val_loss: 22.8805\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.4220 - val_loss: 22.6748\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5457 - val_loss: 22.8018\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.7164 - val_loss: 22.7912\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.3841 - val_loss: 23.0015\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.2782 - val_loss: 22.7125\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2150 - val_loss: 22.4765\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.0521 - val_loss: 22.4591\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.0990 - val_loss: 22.5118\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.3230 - val_loss: 23.1194\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.3682 - val_loss: 22.4741\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.0415 - val_loss: 22.6550\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.9684 - val_loss: 22.3987\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9561 - val_loss: 22.3954\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.1447 - val_loss: 22.3822\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.7938 - val_loss: 22.3592\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.7107 - val_loss: 22.2946\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.6418 - val_loss: 22.4021\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.6150 - val_loss: 22.4492\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.5902 - val_loss: 22.3153\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 20.5775 - val_loss: 23.0910\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.6345 - val_loss: 22.3814\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 80.9205 - val_loss: 70.3544\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 69.0489 - val_loss: 69.3996\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 67.3449 - val_loss: 66.0658\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 66.2433 - val_loss: 67.0016\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 65.5481 - val_loss: 66.3358\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 65.5605 - val_loss: 64.2646\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 65.2886 - val_loss: 64.5902\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 63.6304 - val_loss: 63.6111\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 62.7528 - val_loss: 63.2072\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 62.2635 - val_loss: 62.5780\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 62.3388 - val_loss: 61.8368\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 60.7665 - val_loss: 43.2056\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.5289 - val_loss: 36.7766\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.4983 - val_loss: 43.2124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.0838 - val_loss: 35.7156\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 34.2773 - val_loss: 33.9728\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.1408 - val_loss: 34.3069\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.7206 - val_loss: 33.7791\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 32.6192 - val_loss: 34.6784\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.0404 - val_loss: 32.6494\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.5130 - val_loss: 34.4517\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.2797 - val_loss: 32.4518\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.8893 - val_loss: 32.3301\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.6145 - val_loss: 32.4035\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.7710 - val_loss: 32.0385\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.6859 - val_loss: 32.7079\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.9694 - val_loss: 30.9639\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 30.3782 - val_loss: 30.8650\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.8177 - val_loss: 32.1579\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.2910 - val_loss: 30.4241\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 29.6913 - val_loss: 31.9761\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.2446 - val_loss: 30.8396\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.6366 - val_loss: 37.0736\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 29.9457 - val_loss: 29.5589\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 28.2425 - val_loss: 29.5650\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 27.5799 - val_loss: 28.5599\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 26.9804 - val_loss: 27.4095\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 26.1819 - val_loss: 26.9551\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 26.9967 - val_loss: 26.5530\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 25.7807 - val_loss: 27.6315\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.4110 - val_loss: 25.3053\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.3395 - val_loss: 24.8582\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.9188 - val_loss: 24.5929\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.9198 - val_loss: 25.0659\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 23.7508 - val_loss: 24.9884\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.2776 - val_loss: 24.0509\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.9655 - val_loss: 23.9147\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.8211 - val_loss: 23.8062\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.7071 - val_loss: 23.6583\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.8313 - val_loss: 23.8422\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.5640 - val_loss: 23.5721\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.2512 - val_loss: 23.4261\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.1797 - val_loss: 23.3562\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0158 - val_loss: 23.2649\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.0449 - val_loss: 23.3190\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.1870 - val_loss: 23.6098\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.9550 - val_loss: 23.2837\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.8530 - val_loss: 23.2307\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.7466 - val_loss: 23.0819\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 21.8082 - val_loss: 23.2171\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6798 - val_loss: 22.9819\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.3599 - val_loss: 22.9248\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.4721 - val_loss: 23.2050\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3037 - val_loss: 22.8780\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2585 - val_loss: 23.3036\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0841 - val_loss: 23.0292\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.3548 - val_loss: 22.9125\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.0957 - val_loss: 22.7078\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.8989 - val_loss: 22.7099\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.8252 - val_loss: 22.6921\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 20.6902 - val_loss: 22.8386\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9454 - val_loss: 23.9914\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1340 - val_loss: 22.6166\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.6802 - val_loss: 22.7538\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.9912 - val_loss: 23.0649\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.7475 - val_loss: 22.5492\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.3576 - val_loss: 22.5110\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.4350 - val_loss: 22.7199\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.4054 - val_loss: 22.7868\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.4166 - val_loss: 22.6482\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.2918 - val_loss: 22.5860\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 20.1104 - val_loss: 22.6672\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.3470 - val_loss: 51.3788\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 48.1511 - val_loss: 44.4282\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 560us/step - loss: 44.6194 - val_loss: 43.0465\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.5361 - val_loss: 43.2593\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.6349 - val_loss: 39.8169\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 39.8509 - val_loss: 40.9081\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.2873 - val_loss: 38.2177\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 38.1316 - val_loss: 41.9347\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 39.2851 - val_loss: 38.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.8791 - val_loss: 37.9969\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 37.9173 - val_loss: 37.2223\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.4841 - val_loss: 35.4660\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.6104 - val_loss: 39.3279\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.6357 - val_loss: 35.9503\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.4390 - val_loss: 35.7852\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.7488 - val_loss: 37.0022\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.0122 - val_loss: 39.9386\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.7154 - val_loss: 49.3069\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 44.6761 - val_loss: 43.2073\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 41.9649 - val_loss: 40.4345\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.1335 - val_loss: 39.1532\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.1575 - val_loss: 40.9796\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 39.8017 - val_loss: 39.3409\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.7162 - val_loss: 37.1883\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 37.0640 - val_loss: 37.5386\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 37.2875 - val_loss: 38.1341\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.8880 - val_loss: 36.7981\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.1454 - val_loss: 37.7743\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.7941 - val_loss: 39.2338\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.3336 - val_loss: 35.5214\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.5900 - val_loss: 38.2834\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.4882 - val_loss: 34.9239\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.2702 - val_loss: 34.0116\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.2897 - val_loss: 34.8530\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 33.2554 - val_loss: 33.3315\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.4029 - val_loss: 33.5490\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 33.8769 - val_loss: 33.3952\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.9921 - val_loss: 35.2505\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.9960 - val_loss: 33.0083\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.5188 - val_loss: 32.3614\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.1226 - val_loss: 31.8918\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.2123 - val_loss: 45.7076\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.5042 - val_loss: 33.7840\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 550us/step - loss: 33.0541 - val_loss: 36.5440\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.5727 - val_loss: 33.3702\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.7062 - val_loss: 31.6636\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.2747 - val_loss: 31.7552\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.8684 - val_loss: 30.9542\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.2450 - val_loss: 32.9575\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.7512 - val_loss: 31.8524\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.4118 - val_loss: 31.8648\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.8545 - val_loss: 31.5801\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.0075 - val_loss: 33.2068\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 80.4561 - val_loss: 55.8662\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 48.7822 - val_loss: 45.2716\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 43.2407 - val_loss: 41.2427\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.6087 - val_loss: 39.2741\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.4080 - val_loss: 39.0442\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.4067 - val_loss: 37.7026\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.1197 - val_loss: 37.7964\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.3598 - val_loss: 36.0246\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.2818 - val_loss: 35.4648\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.7646 - val_loss: 35.0376\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.5085 - val_loss: 36.0684\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.6676 - val_loss: 34.9297\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.3535 - val_loss: 36.1437\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.6156 - val_loss: 34.7585\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.7551 - val_loss: 34.6000\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.3941 - val_loss: 34.6484\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.4454 - val_loss: 33.8746\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.1968 - val_loss: 35.2764\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.1198 - val_loss: 34.7655\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.0045 - val_loss: 32.9315\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.6908 - val_loss: 34.3689\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.4886 - val_loss: 33.6681\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.0280 - val_loss: 34.6840\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.0458 - val_loss: 32.2830\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.6348 - val_loss: 32.1771\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 33.2393 - val_loss: 33.1522\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.7261 - val_loss: 31.6178\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.7827 - val_loss: 31.1761\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.9046 - val_loss: 32.5186\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.2788 - val_loss: 32.2412\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.7065 - val_loss: 32.5542\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.9108 - val_loss: 32.5775\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.1855 - val_loss: 34.0453\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 69.8412 - val_loss: 47.9660\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 47.0089 - val_loss: 50.5547\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 44.4687 - val_loss: 41.7314\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 40.9854 - val_loss: 40.4575\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.1940 - val_loss: 42.5410\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 40.2215 - val_loss: 40.4056\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.7489 - val_loss: 37.3047\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.1074 - val_loss: 35.2171\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.0656 - val_loss: 37.0692\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.8877 - val_loss: 34.6290\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.3181 - val_loss: 34.8733\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.6928 - val_loss: 34.0757\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.2761 - val_loss: 37.0242\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 33.5856 - val_loss: 32.8258\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.6406 - val_loss: 32.0587\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.1892 - val_loss: 32.2570\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.4847 - val_loss: 32.3368\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.1138 - val_loss: 32.3980\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.4309 - val_loss: 33.7791\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 33.6728 - val_loss: 31.6380\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.7648 - val_loss: 30.8505\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.7140 - val_loss: 30.6882\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.8211 - val_loss: 33.8154\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.5048 - val_loss: 30.1845\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.2600 - val_loss: 31.8530\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.7324 - val_loss: 30.4146\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.6718 - val_loss: 30.0389\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.7293 - val_loss: 29.1721\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.2935 - val_loss: 30.4331\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.1218 - val_loss: 31.1186\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.4354 - val_loss: 29.3143\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.4497 - val_loss: 28.5454\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 28.2850 - val_loss: 28.5676\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.9267 - val_loss: 28.9070\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.7960 - val_loss: 28.2800\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.0317 - val_loss: 29.8498\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 27.5932 - val_loss: 27.1228\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.1111 - val_loss: 27.5477\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.5303 - val_loss: 27.8351\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.4120 - val_loss: 26.4780\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.5731 - val_loss: 29.6768\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.0669 - val_loss: 27.1071\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.5858 - val_loss: 26.3879\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.7447 - val_loss: 25.6426\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 25.0204 - val_loss: 25.2585\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.3657 - val_loss: 24.6259\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.8976 - val_loss: 24.2301\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.8955 - val_loss: 24.5066\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.7679 - val_loss: 24.3986\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.1914 - val_loss: 23.5301\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.9349 - val_loss: 23.5413\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.2432 - val_loss: 23.5037\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.7386 - val_loss: 23.0682\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.5679 - val_loss: 23.2669\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.4003 - val_loss: 22.9209\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.5462 - val_loss: 22.9986\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.3076 - val_loss: 22.6170\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.2111 - val_loss: 23.1651\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0807 - val_loss: 22.6399\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.8734 - val_loss: 24.0577\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.8026 - val_loss: 22.4538\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6404 - val_loss: 22.4207\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.7190 - val_loss: 22.2202\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5176 - val_loss: 22.3174\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.4126 - val_loss: 22.1486\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3868 - val_loss: 23.1779\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3256 - val_loss: 21.9880\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.0541 - val_loss: 22.0887\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.2318 - val_loss: 21.9081\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.8815 - val_loss: 21.8309\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.9117 - val_loss: 22.2456\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.0373 - val_loss: 22.2127\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.8563 - val_loss: 22.6336\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.8060 - val_loss: 21.7038\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.7299 - val_loss: 21.7252\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.8099 - val_loss: 21.7506\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 607us/step - loss: 20.6477 - val_loss: 22.0259\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.6584 - val_loss: 21.6762\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.6422 - val_loss: 21.9054\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.5514 - val_loss: 21.5887\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.5063 - val_loss: 21.5591\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.3228 - val_loss: 21.6280\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.3418 - val_loss: 21.4927\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.2747 - val_loss: 21.5897\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 567us/step - loss: 20.6004 - val_loss: 21.7845\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.3182 - val_loss: 21.4556\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.2246 - val_loss: 21.8233\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.3673 - val_loss: 21.5234\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.0999 - val_loss: 21.5631\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.1618 - val_loss: 21.5155\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.1530 - val_loss: 21.7382\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.4015 - val_loss: 47.9701\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 821us/step - loss: 46.4491 - val_loss: 42.8823\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 741us/step - loss: 42.9417 - val_loss: 40.9129\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 41.3225 - val_loss: 40.4898\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 40.9756 - val_loss: 40.0612\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 40.1690 - val_loss: 39.2166\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.6788 - val_loss: 41.2590\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 41.4739 - val_loss: 40.5737\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 40.4110 - val_loss: 40.3363\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 38.3700 - val_loss: 37.7524\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 740us/step - loss: 38.1273 - val_loss: 38.6967\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 39.2019 - val_loss: 38.4834\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 38.5347 - val_loss: 38.0567\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 37.4974 - val_loss: 37.1904\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 36.8342 - val_loss: 37.2216\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 36.6280 - val_loss: 37.1044\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 36.1799 - val_loss: 41.0200\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 37.2618 - val_loss: 40.2491\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.9885 - val_loss: 36.3800\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 36.2783 - val_loss: 38.5611\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 35.5101 - val_loss: 36.6708\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 35.2718 - val_loss: 35.0360\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 35.5626 - val_loss: 42.8008\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 35.9216 - val_loss: 34.7767\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 34.5464 - val_loss: 34.2132\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 33.9536 - val_loss: 37.7707\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 34.2092 - val_loss: 34.1038\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.7902 - val_loss: 35.5513\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 35.6657 - val_loss: 33.8492\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 35.1316 - val_loss: 37.8783\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 35.3526 - val_loss: 36.8150\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.9386 - val_loss: 33.4800\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 34.1035 - val_loss: 33.8314\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 32.7908 - val_loss: 33.1830\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 33.2299 - val_loss: 34.0637\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.5876 - val_loss: 32.5876\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 32.2712 - val_loss: 32.6996\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.0394 - val_loss: 33.1533\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 32.8407 - val_loss: 32.7721\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 33.8854 - val_loss: 36.4241\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.9167 - val_loss: 36.5070\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.9212 - val_loss: 52.3729\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 50.1621 - val_loss: 45.1837\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 43.9403 - val_loss: 43.6011\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 42.0192 - val_loss: 40.1955\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.2599 - val_loss: 38.8580\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 39.6326 - val_loss: 38.7147\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.5407 - val_loss: 37.7260\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.2589 - val_loss: 37.8177\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.1518 - val_loss: 38.3855\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.9958 - val_loss: 36.4285\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.5696 - val_loss: 41.2108\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.7085 - val_loss: 36.3347\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.3954 - val_loss: 36.2058\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.1404 - val_loss: 36.2251\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.2132 - val_loss: 34.9426\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.1306 - val_loss: 34.6677\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.1030 - val_loss: 34.4947\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.8873 - val_loss: 33.7241\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.5709 - val_loss: 32.9494\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.2223 - val_loss: 34.9264\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.6820 - val_loss: 33.9260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 33.7051 - val_loss: 35.9691\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 34.7287 - val_loss: 34.0999\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.2027 - val_loss: 32.7719\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 32.5374 - val_loss: 33.0652\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 32.2044 - val_loss: 31.7048\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 32.8118 - val_loss: 31.7999\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 31.6548 - val_loss: 31.3564\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.4750 - val_loss: 31.3076\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.7614 - val_loss: 30.7849\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.5770 - val_loss: 31.0944\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.3373 - val_loss: 30.8682\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.4256 - val_loss: 30.2085\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 30.4639 - val_loss: 31.1236\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 30.4813 - val_loss: 29.9309\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.1201 - val_loss: 30.5605\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 29.6351 - val_loss: 30.0680\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 29.2615 - val_loss: 29.5411\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.4471 - val_loss: 28.7985\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.2930 - val_loss: 28.7965\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 27.6139 - val_loss: 28.0754\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.9193 - val_loss: 27.7723\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.8998 - val_loss: 27.4413\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.2532 - val_loss: 27.3598\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 26.2775 - val_loss: 26.1566\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 25.1543 - val_loss: 25.5779\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.0983 - val_loss: 25.1738\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 752us/step - loss: 24.9613 - val_loss: 25.7300\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.2998 - val_loss: 24.8944\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.1000 - val_loss: 25.1124\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.7808 - val_loss: 24.2452\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.5789 - val_loss: 24.3540\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.1983 - val_loss: 23.9247\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.0401 - val_loss: 23.7794\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.9773 - val_loss: 24.3895\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 23.3055 - val_loss: 23.6739\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 23.0936 - val_loss: 23.4547\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.6393 - val_loss: 23.3804\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.8102 - val_loss: 23.4387\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.4208 - val_loss: 23.6323\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.5801 - val_loss: 23.8788\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.3754 - val_loss: 23.3571\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.1414 - val_loss: 23.1960\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.2190 - val_loss: 22.9677\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.0053 - val_loss: 23.5569\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.1486 - val_loss: 23.1474\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.9275 - val_loss: 22.7615\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.8985 - val_loss: 22.9519\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.8100 - val_loss: 22.6845\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.9777 - val_loss: 22.8590\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.9378 - val_loss: 22.9790\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6686 - val_loss: 22.7392\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.4533 - val_loss: 22.5664\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 773us/step - loss: 21.4353 - val_loss: 22.8360\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 769us/step - loss: 21.3683 - val_loss: 22.5518\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 21.2613 - val_loss: 22.5113\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.2480 - val_loss: 22.6940\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.3291 - val_loss: 22.6191\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.2360 - val_loss: 22.5525\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.2884 - val_loss: 22.4386\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1460 - val_loss: 22.5667\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.3353 - val_loss: 23.1869\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4180 - val_loss: 22.4614\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.3135 - val_loss: 22.5669\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.9926 - val_loss: 22.3953\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.9920 - val_loss: 23.9608\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.1029 - val_loss: 22.4054\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.8981 - val_loss: 22.3763\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.8051 - val_loss: 22.6275\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.9191 - val_loss: 22.5905\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.8196 - val_loss: 22.5780\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 20.6826 - val_loss: 22.2088\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.8788 - val_loss: 22.8594\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.8986 - val_loss: 22.3864\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.5906 - val_loss: 22.3280\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.7694 - val_loss: 22.1783\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.5659 - val_loss: 22.2631\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.6066 - val_loss: 22.5581\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.6158 - val_loss: 22.2000\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.3905 - val_loss: 22.3630\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 78.5843 - val_loss: 47.3922\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 46.5603 - val_loss: 42.1827\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.2213 - val_loss: 38.9465\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.1054 - val_loss: 43.0683\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.4135 - val_loss: 37.5510\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.2568 - val_loss: 39.0472\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.2191 - val_loss: 36.6279\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.3151 - val_loss: 35.3277\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.9739 - val_loss: 36.0358\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.2910 - val_loss: 34.2344\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.2750 - val_loss: 33.6279\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.6291 - val_loss: 36.2118\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.7694 - val_loss: 34.0585\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.4675 - val_loss: 32.6147\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.8406 - val_loss: 32.0670\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.2386 - val_loss: 31.3329\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.7090 - val_loss: 32.0210\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.5144 - val_loss: 30.9477\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.8274 - val_loss: 30.7200\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.9640 - val_loss: 32.7490\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.7508 - val_loss: 33.2953\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 30.6601 - val_loss: 30.1295\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.6152 - val_loss: 30.0064\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.7244 - val_loss: 30.6250\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.6025 - val_loss: 29.5775\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.0881 - val_loss: 29.1113\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.2510 - val_loss: 30.7257\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.8493 - val_loss: 30.0919\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.3248 - val_loss: 29.0743\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.7393 - val_loss: 28.6117\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 27.8945 - val_loss: 29.7125\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 27.7782 - val_loss: 27.8643\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.7016 - val_loss: 29.5117\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.3651 - val_loss: 28.4534\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 28.5707 - val_loss: 28.4239\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.4913 - val_loss: 29.3989\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 27.3005 - val_loss: 27.8043\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.0300 - val_loss: 28.6056\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.2238 - val_loss: 29.0256\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.8181 - val_loss: 27.1577\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 27.5028 - val_loss: 28.4379\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 26.4684 - val_loss: 27.6225\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.9818 - val_loss: 26.6280\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 26.3650 - val_loss: 27.0580\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 26.1270 - val_loss: 27.3206\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 26.8766 - val_loss: 26.6807\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 27.0583 - val_loss: 27.0704\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 25.9202 - val_loss: 27.4842\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.0783 - val_loss: 50.7460\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 49.0646 - val_loss: 45.8753\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 47.5736 - val_loss: 52.7413\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 46.5251 - val_loss: 41.8369\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 42.4064 - val_loss: 43.8119\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.4224 - val_loss: 39.9517\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 39.6016 - val_loss: 40.8725\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.8782 - val_loss: 39.1513\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 39.8817 - val_loss: 38.1200\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 38.9417 - val_loss: 39.4130\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.8122 - val_loss: 40.6037\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.4408 - val_loss: 38.7014\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.7486 - val_loss: 36.8786\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 36.1856 - val_loss: 37.1028\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.4071 - val_loss: 37.7423\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 37.6845 - val_loss: 36.3973\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.8574 - val_loss: 36.4404\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.6077 - val_loss: 36.1591\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.3815 - val_loss: 35.1076\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.0697 - val_loss: 35.9657\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.9529 - val_loss: 36.6539\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.2364 - val_loss: 36.1234\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.1577 - val_loss: 34.8439\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.0108 - val_loss: 36.7280\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 33.4150 - val_loss: 32.8565\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.0663 - val_loss: 33.8272\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 635us/step - loss: 30.4825 - val_loss: 31.4576\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.2204 - val_loss: 31.2259\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 29.9846 - val_loss: 29.2371\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 28.1669 - val_loss: 28.2570\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 27.6747 - val_loss: 27.6959\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.0083 - val_loss: 27.4973\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 26.7789 - val_loss: 27.2636\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.3557 - val_loss: 26.7649\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.8829 - val_loss: 26.7836\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.9319 - val_loss: 26.2936\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 25.4484 - val_loss: 25.8569\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 25.2267 - val_loss: 26.2057\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.0278 - val_loss: 25.4390\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.8043 - val_loss: 25.2801\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 24.4508 - val_loss: 25.2379\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.4258 - val_loss: 25.2400\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 24.2031 - val_loss: 24.8808\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 23.9471 - val_loss: 24.9702\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 23.8889 - val_loss: 24.7627\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.7309 - val_loss: 24.4746\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.6431 - val_loss: 24.4778\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.3627 - val_loss: 24.5177\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.4448 - val_loss: 24.2767\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 23.3994 - val_loss: 24.2272\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.1777 - val_loss: 24.9111\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.2620 - val_loss: 24.0518\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.9213 - val_loss: 23.9302\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.1861 - val_loss: 24.3922\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.9013 - val_loss: 23.8832\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.7152 - val_loss: 23.7359\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.5374 - val_loss: 23.7234\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.4742 - val_loss: 23.6310\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.5906 - val_loss: 24.0645\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.5881 - val_loss: 23.6115\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.3094 - val_loss: 23.9472\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.5387 - val_loss: 23.6458\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.3906 - val_loss: 23.7928\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3286 - val_loss: 23.7216\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.0209 - val_loss: 23.3419\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.0351 - val_loss: 23.3706\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.8238 - val_loss: 23.3090\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.7425 - val_loss: 23.2479\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.6973 - val_loss: 23.3697\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.8880 - val_loss: 23.2669\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.6574 - val_loss: 23.1549\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.5658 - val_loss: 23.3659\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.4711 - val_loss: 23.1938\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.4991 - val_loss: 23.4535\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.5227 - val_loss: 23.0317\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.3636 - val_loss: 23.0033\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.2674 - val_loss: 23.0489\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.1784 - val_loss: 23.1277\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.4440 - val_loss: 23.4522\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.5023 - val_loss: 23.2038\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 21.1436 - val_loss: 23.0374\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 94.7861 - val_loss: 78.3490\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 50.5345 - val_loss: 45.5662\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 43.3009 - val_loss: 45.6998\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 41.0930 - val_loss: 41.8395\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.1678 - val_loss: 40.0227\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.1889 - val_loss: 43.2893\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.5915 - val_loss: 40.6822\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.3243 - val_loss: 37.9415\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.2222 - val_loss: 38.7940\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.1373 - val_loss: 37.0328\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.2344 - val_loss: 37.7790\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.8368 - val_loss: 37.4345\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.0187 - val_loss: 36.1913\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.3938 - val_loss: 36.9035\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.2608 - val_loss: 35.8343\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.0130 - val_loss: 36.3664\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.7157 - val_loss: 36.3654\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.3413 - val_loss: 36.5085\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 33.9006 - val_loss: 34.7534\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.7165 - val_loss: 34.2033\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.6858 - val_loss: 34.6011\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.2695 - val_loss: 34.4778\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 641us/step - loss: 33.1515 - val_loss: 34.8082\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 31.8191 - val_loss: 33.2071\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 31.8947 - val_loss: 33.1337\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.4459 - val_loss: 33.4530\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.3565 - val_loss: 34.9608\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.9403 - val_loss: 32.7729\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.7492 - val_loss: 32.2571\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 30.8415 - val_loss: 33.6588\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 30.6159 - val_loss: 31.6606\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 30.7025 - val_loss: 31.4989\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.6254 - val_loss: 33.1179\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.1185 - val_loss: 31.1777\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.3164 - val_loss: 30.6464\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.4402 - val_loss: 31.0160\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 29.9057 - val_loss: 32.1930\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 29.1147 - val_loss: 29.9733\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 28.2745 - val_loss: 30.3713\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 29.3804 - val_loss: 29.2723\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.6486 - val_loss: 29.2896\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.6389 - val_loss: 29.8570\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.4691 - val_loss: 27.7807\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 26.3759 - val_loss: 26.8015\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 25.6861 - val_loss: 27.3092\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 25.6696 - val_loss: 25.7886\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.7092 - val_loss: 25.2943\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 24.2974 - val_loss: 25.0946\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.5658 - val_loss: 25.0472\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.1328 - val_loss: 24.7826\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.9100 - val_loss: 25.0665\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.3813 - val_loss: 25.1717\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.2245 - val_loss: 24.8049\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 23.8244 - val_loss: 24.3351\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.2028 - val_loss: 23.9415\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 22.9678 - val_loss: 23.9192\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.8908 - val_loss: 23.7056\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.7771 - val_loss: 23.7822\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.1868 - val_loss: 24.3552\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.7527 - val_loss: 23.3538\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.4057 - val_loss: 23.3751\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3775 - val_loss: 23.7756\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 22.6008 - val_loss: 23.2463\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.3091 - val_loss: 23.0901\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 22.0692 - val_loss: 23.0736\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.1054 - val_loss: 23.0418\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.9379 - val_loss: 22.8710\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.2291 - val_loss: 22.8365\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.9895 - val_loss: 22.8453\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.7853 - val_loss: 22.7994\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.5885 - val_loss: 22.7579\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.6098 - val_loss: 22.8083\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.7054 - val_loss: 22.7037\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5333 - val_loss: 23.0988\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.4663 - val_loss: 22.7004\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.3725 - val_loss: 22.6264\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.3216 - val_loss: 22.5122\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.2583 - val_loss: 22.4211\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.1872 - val_loss: 22.5367\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.2932 - val_loss: 22.5670\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.5209 - val_loss: 22.7754\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.2514 - val_loss: 22.4741\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.0822 - val_loss: 22.4744\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.7934 - val_loss: 55.4789\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 50.8068 - val_loss: 47.2226\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 45.7690 - val_loss: 43.8823\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 42.9891 - val_loss: 43.4585\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 42.0537 - val_loss: 42.6740\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 41.7137 - val_loss: 41.0334\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 40.2920 - val_loss: 42.3559\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.2392 - val_loss: 41.2848\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 39.7380 - val_loss: 39.7103\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.3619 - val_loss: 42.2672\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.9824 - val_loss: 38.6028\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.0973 - val_loss: 37.4221\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.8553 - val_loss: 38.8375\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.2991 - val_loss: 37.6175\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.9652 - val_loss: 36.4700\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.0660 - val_loss: 36.8523\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 629us/step - loss: 34.9294 - val_loss: 35.9216\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.9218 - val_loss: 35.4173\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.9966 - val_loss: 34.9659\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.6262 - val_loss: 35.3405\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.8248 - val_loss: 35.3532\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.6854 - val_loss: 35.0526\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.3798 - val_loss: 36.7722\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.9231 - val_loss: 36.4905\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 77.3856 - val_loss: 60.2728\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 52.0981 - val_loss: 47.0110\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 46.4182 - val_loss: 48.0151\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 728us/step - loss: 46.8106 - val_loss: 43.5807\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 701us/step - loss: 42.4353 - val_loss: 42.5029\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 736us/step - loss: 41.3311 - val_loss: 41.5607\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 836us/step - loss: 44.0046 - val_loss: 41.8665\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 45.5855 - val_loss: 47.3953\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 42.1287 - val_loss: 45.3062\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.8653 - val_loss: 40.0419\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 39.4926 - val_loss: 39.1570\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.6993 - val_loss: 38.9511\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.8953 - val_loss: 38.3635\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.9707 - val_loss: 38.0917\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 556us/step - loss: 39.4129 - val_loss: 37.9514\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.5266 - val_loss: 38.4795\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 37.4388 - val_loss: 42.3861\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.0912 - val_loss: 36.4785\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.1083 - val_loss: 37.1228\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 36.4451 - val_loss: 37.4077\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 37.4365 - val_loss: 36.9805\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.1990 - val_loss: 35.1120\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.0577 - val_loss: 34.9762\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.5501 - val_loss: 34.6044\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.0448 - val_loss: 34.8532\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 34.9203 - val_loss: 34.5712\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.0847 - val_loss: 33.5062\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.5319 - val_loss: 33.7855\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.5715 - val_loss: 34.0232\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.5502 - val_loss: 35.3892\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.5832 - val_loss: 32.1654\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.3237 - val_loss: 34.4784\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.1476 - val_loss: 31.6553\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 31.0957 - val_loss: 31.0176\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.5520 - val_loss: 30.1272\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.1415 - val_loss: 29.0683\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.9254 - val_loss: 28.1862\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 26.8623 - val_loss: 27.3342\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 26.3445 - val_loss: 26.7120\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.6664 - val_loss: 27.0020\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.3008 - val_loss: 25.3012\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.6314 - val_loss: 25.1557\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 24.3980 - val_loss: 24.9412\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.1109 - val_loss: 24.9427\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.1717 - val_loss: 24.3986\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.0443 - val_loss: 24.3467\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.5860 - val_loss: 24.1503\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.4200 - val_loss: 24.0067\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.2327 - val_loss: 23.9995\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.1439 - val_loss: 23.7098\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.9756 - val_loss: 23.7553\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.8428 - val_loss: 23.6148\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.7638 - val_loss: 23.5495\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.8700 - val_loss: 23.5456\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.6306 - val_loss: 23.4407\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4470 - val_loss: 23.4441\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.4825 - val_loss: 23.3148\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.5333 - val_loss: 23.3316\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.3532 - val_loss: 23.0986\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.1791 - val_loss: 23.1254\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.0604 - val_loss: 23.1399\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 22.0112 - val_loss: 23.5051\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.9698 - val_loss: 23.0920\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.0184 - val_loss: 22.9997\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8045 - val_loss: 22.8835\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.7683 - val_loss: 22.9706\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.9055 - val_loss: 23.8630\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.8164 - val_loss: 22.8800\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.5107 - val_loss: 22.7835\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 612us/step - loss: 21.4215 - val_loss: 22.8048\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.4495 - val_loss: 22.9229\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.4218 - val_loss: 22.7673\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.3739 - val_loss: 22.7118\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2053 - val_loss: 22.9135\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 21.1984 - val_loss: 22.8023\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.1404 - val_loss: 22.6368\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.0923 - val_loss: 22.7822\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.0397 - val_loss: 22.7988\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.9446 - val_loss: 22.7237\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2164 - val_loss: 22.8057\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9027 - val_loss: 22.7809\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.3755 - val_loss: 47.2554\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 46.7155 - val_loss: 51.7571\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 44.1340 - val_loss: 42.5554\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 41.3549 - val_loss: 40.4488\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 40.6719 - val_loss: 43.2906\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.3793 - val_loss: 40.3555\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.2777 - val_loss: 37.7433\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 38.4685 - val_loss: 41.5897\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.8162 - val_loss: 39.9096\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.4626 - val_loss: 37.6371\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.0041 - val_loss: 36.6234\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.3658 - val_loss: 39.4475\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.5015 - val_loss: 38.0424\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.8456 - val_loss: 37.1678\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 35.7600 - val_loss: 38.2129\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.1481 - val_loss: 35.0591\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.6872 - val_loss: 34.6373\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.3091 - val_loss: 34.0850\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.5655 - val_loss: 34.4001\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.2899 - val_loss: 35.7690\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.8475 - val_loss: 33.4912\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.6698 - val_loss: 33.9712\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 35.2664 - val_loss: 35.4089\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.4965 - val_loss: 33.6080\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.4666 - val_loss: 33.7910\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.1338 - val_loss: 33.3648\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.9580 - val_loss: 33.7199\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.2161 - val_loss: 33.9465\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.9121 - val_loss: 32.5831\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.0963 - val_loss: 32.8042\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7799 - val_loss: 33.4609\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.6571 - val_loss: 32.1866\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.3321 - val_loss: 31.8386\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.7309 - val_loss: 32.0570\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.7798 - val_loss: 31.6834\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.4889 - val_loss: 32.2167\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.4149 - val_loss: 32.4619\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 30.6360 - val_loss: 31.6340\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.2618 - val_loss: 31.6429\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.9221 - val_loss: 31.0473\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.7722 - val_loss: 33.6119\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 30.4932 - val_loss: 35.2052\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.0139 - val_loss: 31.3336\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.5655 - val_loss: 30.6500\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.4771 - val_loss: 32.1681\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.6224 - val_loss: 30.2385\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.5147 - val_loss: 30.1939\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.6446 - val_loss: 29.4141\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.4809 - val_loss: 29.6774\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.8112 - val_loss: 29.2241\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.5623 - val_loss: 29.9132\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 27.9940 - val_loss: 29.9887\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 28.5605 - val_loss: 29.7088\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.0952 - val_loss: 29.5248\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 27.1924 - val_loss: 27.8638\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 25.9776 - val_loss: 26.6701\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 759us/step - loss: 25.3142 - val_loss: 26.1271\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.7454 - val_loss: 25.4596\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 24.3718 - val_loss: 26.8493\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 24.3801 - val_loss: 24.7688\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 23.8425 - val_loss: 24.4556\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 23.3047 - val_loss: 24.2077\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.1521 - val_loss: 23.9793\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.1545 - val_loss: 23.8693\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.9551 - val_loss: 24.3014\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 615us/step - loss: 22.8907 - val_loss: 23.6165\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.5409 - val_loss: 23.4628\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.4341 - val_loss: 23.3344\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.3206 - val_loss: 23.4363\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 22.1797 - val_loss: 23.1709\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.1756 - val_loss: 23.1672\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.0322 - val_loss: 23.0696\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0988 - val_loss: 23.0309\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.8756 - val_loss: 22.9134\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.8248 - val_loss: 23.1136\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.8347 - val_loss: 22.8438\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 21.7194 - val_loss: 22.7737\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.6709 - val_loss: 22.7831\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.6717 - val_loss: 22.9378\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.6345 - val_loss: 22.8328\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.5980 - val_loss: 22.7990\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.5870 - val_loss: 22.6278\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.3341 - val_loss: 22.6161\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3830 - val_loss: 22.6031\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.3432 - val_loss: 22.5780\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.2509 - val_loss: 22.5712\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2302 - val_loss: 22.6381\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.1279 - val_loss: 22.5301\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.2495 - val_loss: 22.8974\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.2308 - val_loss: 22.4763\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 21.0378 - val_loss: 22.4827\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.0840 - val_loss: 22.7101\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.0266 - val_loss: 22.4888\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9659 - val_loss: 22.5255\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.8528 - val_loss: 22.4069\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.8212 - val_loss: 22.4545\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.8153 - val_loss: 22.4158\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.7341 - val_loss: 22.3556\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.7688 - val_loss: 22.5293\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.8289 - val_loss: 22.6867\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.0531 - val_loss: 49.8602\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 44.7892 - val_loss: 43.5039\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.5729 - val_loss: 40.7034\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.1005 - val_loss: 38.7574\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 39.7563 - val_loss: 38.7260\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.2878 - val_loss: 38.9778\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.8952 - val_loss: 37.3494\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 36.7005 - val_loss: 36.3075\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.9772 - val_loss: 35.6675\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.8799 - val_loss: 35.4200\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.6601 - val_loss: 40.9482\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.1505 - val_loss: 34.9726\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.0934 - val_loss: 35.6477\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.3251 - val_loss: 36.2187\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.8628 - val_loss: 38.4923\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 33.6070 - val_loss: 33.5932\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.3220 - val_loss: 34.4847\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.6423 - val_loss: 34.1644\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.4700 - val_loss: 32.7499\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.8099 - val_loss: 32.3670\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.9713 - val_loss: 31.8827\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.5120 - val_loss: 32.5984\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.2096 - val_loss: 32.1019\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 31.7738 - val_loss: 38.5474\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.8685 - val_loss: 33.9932\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.0058 - val_loss: 31.5884\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.6470 - val_loss: 31.3609\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.2175 - val_loss: 34.6224\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.3210 - val_loss: 31.8984\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9654 - val_loss: 32.6340\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.1834 - val_loss: 36.2201\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.0983 - val_loss: 30.7172\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.5355 - val_loss: 31.5911\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.0133 - val_loss: 30.0388\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.7185 - val_loss: 30.2486\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.8985 - val_loss: 30.6092\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.3298 - val_loss: 29.5984\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.6338 - val_loss: 30.7781\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.5557 - val_loss: 31.2959\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.7508 - val_loss: 29.5780\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.8849 - val_loss: 29.1639\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.9716 - val_loss: 38.1331\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 609us/step - loss: 29.7753 - val_loss: 29.1784\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.6794 - val_loss: 29.7409\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.5365 - val_loss: 28.8105\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 28.5059 - val_loss: 29.1233\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.3883 - val_loss: 29.0130\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 27.9609 - val_loss: 28.9217\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 28.2850 - val_loss: 30.7476\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.9554 - val_loss: 28.3843\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.1059 - val_loss: 29.5342\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 28.1403 - val_loss: 28.7090\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 28.8078 - val_loss: 29.6555\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 27.4865 - val_loss: 28.3237\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.3289 - val_loss: 31.4964\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 28.4935 - val_loss: 28.4251\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 27.2730 - val_loss: 27.9150\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 26.8648 - val_loss: 28.3600\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 26.8888 - val_loss: 27.6828\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 28.1448 - val_loss: 28.2045\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.6599 - val_loss: 28.2875\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.4684 - val_loss: 27.6731\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.1125 - val_loss: 27.2908\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 26.4486 - val_loss: 27.6073\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.0080 - val_loss: 29.0618\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 565us/step - loss: 26.7674 - val_loss: 28.1489\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 26.3592 - val_loss: 27.1682\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.6307 - val_loss: 27.2671\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.4820 - val_loss: 27.6962\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.1191 - val_loss: 26.1524\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.0941 - val_loss: 26.6110\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.0489 - val_loss: 26.3680\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.0338 - val_loss: 26.2654\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.5936 - val_loss: 26.0067\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.3922 - val_loss: 25.8956\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.3050 - val_loss: 25.2703\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.3875 - val_loss: 25.4588\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.2140 - val_loss: 25.2276\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.5180 - val_loss: 25.3460\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.3215 - val_loss: 24.6349\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2390 - val_loss: 26.4984\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.1873 - val_loss: 24.2377\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.9757 - val_loss: 25.3584\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.2355 - val_loss: 25.4814\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.2643 - val_loss: 24.1617\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.7251 - val_loss: 23.9515\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4517 - val_loss: 23.8030\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.6655 - val_loss: 23.4988\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.2890 - val_loss: 23.5863\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.1222 - val_loss: 23.5250\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.0108 - val_loss: 23.4055\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1772 - val_loss: 24.3204\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.1348 - val_loss: 23.3405\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.8098 - val_loss: 23.8027\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.7865 - val_loss: 23.8468\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.9052 - val_loss: 23.2206\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.6084 - val_loss: 23.0776\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.5549 - val_loss: 23.0965\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5264 - val_loss: 23.0032\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.3740 - val_loss: 23.0520\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 80.9653 - val_loss: 66.8404\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 52.2215 - val_loss: 43.6097\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 43.9672 - val_loss: 41.0111\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 40.6751 - val_loss: 39.6875\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.5509 - val_loss: 41.7915\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 38.4007 - val_loss: 38.3021\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.0306 - val_loss: 37.8348\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.6878 - val_loss: 37.3618\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.2249 - val_loss: 37.0701\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.4209 - val_loss: 36.5927\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.4046 - val_loss: 37.1555\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.2689 - val_loss: 41.1682\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.2565 - val_loss: 36.9839\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.9246 - val_loss: 36.4022\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.1842 - val_loss: 35.0087\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.0823 - val_loss: 37.0374\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 37.0388 - val_loss: 35.3374\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.2578 - val_loss: 36.2639\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.2635 - val_loss: 35.1887\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 624us/step - loss: 33.3361 - val_loss: 34.4065\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.8890 - val_loss: 35.0342\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.8339 - val_loss: 34.1218\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.6744 - val_loss: 34.3706\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.7543 - val_loss: 33.6335\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.9304 - val_loss: 34.3127\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 31.9734 - val_loss: 34.2259\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 31.9062 - val_loss: 33.9078\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.6893 - val_loss: 32.4932\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 31.3834 - val_loss: 32.4468\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.6642 - val_loss: 32.2401\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 32.9881 - val_loss: 33.7864\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 31.9865 - val_loss: 32.5868\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 30.1966 - val_loss: 31.3692\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.0323 - val_loss: 31.8785\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 30.5028 - val_loss: 31.5317\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.0098 - val_loss: 34.4580\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.7983 - val_loss: 31.0151\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 29.2901 - val_loss: 31.2349\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.6542 - val_loss: 30.6858\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 28.8203 - val_loss: 31.1009\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.7791 - val_loss: 30.3175\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.3207 - val_loss: 29.7510\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.6136 - val_loss: 30.0882\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.6676 - val_loss: 29.8865\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.9151 - val_loss: 30.3205\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.4458 - val_loss: 29.7594\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.5051 - val_loss: 29.1124\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 26.6766 - val_loss: 27.9116\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.8994 - val_loss: 27.8634\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.0195 - val_loss: 29.5652\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 25.2736 - val_loss: 25.7050\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.4626 - val_loss: 25.5597\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.5013 - val_loss: 24.5906\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.4833 - val_loss: 24.2811\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0967 - val_loss: 23.8632\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.3613 - val_loss: 24.4377\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.2431 - val_loss: 23.7899\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7502 - val_loss: 23.3623\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.4806 - val_loss: 23.8104\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.4646 - val_loss: 23.2051\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.2645 - val_loss: 23.7973\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2846 - val_loss: 23.0035\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.1099 - val_loss: 22.8706\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.3728 - val_loss: 22.8025\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.9748 - val_loss: 22.7136\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.8095 - val_loss: 22.6116\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.6361 - val_loss: 22.6309\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.6507 - val_loss: 22.5510\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.5251 - val_loss: 22.4199\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.5557 - val_loss: 22.3390\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.3449 - val_loss: 22.4008\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.4966 - val_loss: 22.9638\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.3202 - val_loss: 22.2011\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1807 - val_loss: 22.4816\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.1316 - val_loss: 22.1289\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.1586 - val_loss: 23.0461\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.1380 - val_loss: 22.3696\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.1270 - val_loss: 22.0510\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.0413 - val_loss: 22.1914\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.2168 - val_loss: 22.0181\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.8778 - val_loss: 22.2757\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.8287 - val_loss: 21.9008\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.6974 - val_loss: 21.8701\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.5704 - val_loss: 21.8775\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 20.5477 - val_loss: 21.8775\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.4656 - val_loss: 21.9015\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.5168 - val_loss: 21.9127\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.4650 - val_loss: 22.2727\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.9238 - val_loss: 48.7167\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 46.8859 - val_loss: 47.5552\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 43.1341 - val_loss: 41.0134\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 42.6989 - val_loss: 42.7132\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 41.0776 - val_loss: 39.2587\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 40.8854 - val_loss: 43.5313\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.7577 - val_loss: 39.8568\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.4922 - val_loss: 38.3267\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 603us/step - loss: 39.1292 - val_loss: 38.3905\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.5860 - val_loss: 37.6590\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.8095 - val_loss: 36.8511\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.5166 - val_loss: 37.7786\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.8163 - val_loss: 36.9382\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.5797 - val_loss: 35.9461\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.5653 - val_loss: 38.5266\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.5484 - val_loss: 36.7255\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.7711 - val_loss: 36.2851\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.2114 - val_loss: 35.0442\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.0401 - val_loss: 35.2972\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.3554 - val_loss: 36.2748\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.9510 - val_loss: 34.9846\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.4697 - val_loss: 34.2445\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 35.8771 - val_loss: 36.9330\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 35.7128 - val_loss: 34.1572\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 34.3906 - val_loss: 37.3716\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.1998 - val_loss: 34.2661\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 35.1758 - val_loss: 34.0327\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.3500 - val_loss: 34.7209\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 33.9106 - val_loss: 34.7609\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 34.9194 - val_loss: 34.7272\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 33.6136 - val_loss: 32.7702\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 33.2305 - val_loss: 32.6889\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 32.2699 - val_loss: 33.5054\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.1485 - val_loss: 32.6025\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 31.9344 - val_loss: 31.9166\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 32.0597 - val_loss: 32.2267\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 32.1603 - val_loss: 31.5284\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 32.4306 - val_loss: 33.8747\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.2542 - val_loss: 31.6796\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 31.8909 - val_loss: 30.9668\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 30.7735 - val_loss: 30.8528\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 32.1870 - val_loss: 31.5573\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 30.9833 - val_loss: 32.3280\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 30.3361 - val_loss: 30.3100\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 31.2717 - val_loss: 30.5573\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.1872 - val_loss: 31.3476\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 30.7662 - val_loss: 32.0109\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 30.5967 - val_loss: 30.1000\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 29.2166 - val_loss: 29.4188\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.4849 - val_loss: 29.6699\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.8438 - val_loss: 29.6807\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 29.9841 - val_loss: 31.7664\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 30.1184 - val_loss: 29.2262\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 29.1871 - val_loss: 29.1522\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 29.8007 - val_loss: 29.4208\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 29.3991 - val_loss: 29.3392\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 29.0532 - val_loss: 28.3163\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 29.0232 - val_loss: 32.3396\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 710us/step - loss: 29.9273 - val_loss: 28.3238\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 28.2439 - val_loss: 32.1110\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 28.5004 - val_loss: 27.8804\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 27.3278 - val_loss: 27.2597\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 28.0401 - val_loss: 28.0758\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 27.3680 - val_loss: 27.3428\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 26.7831 - val_loss: 26.6571\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 25.6682 - val_loss: 26.1215\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 25.0089 - val_loss: 25.3169\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 24.8776 - val_loss: 26.5448\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 24.3973 - val_loss: 25.4776\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 23.7107 - val_loss: 23.9628\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 23.2868 - val_loss: 23.7560\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 23.2342 - val_loss: 23.4514\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 22.9772 - val_loss: 23.3489\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 22.8042 - val_loss: 23.0530\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.3146 - val_loss: 22.9238\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.2819 - val_loss: 22.7532\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.0984 - val_loss: 22.8880\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 22.3404 - val_loss: 22.6685\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 811us/step - loss: 22.2967 - val_loss: 22.5123\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 699us/step - loss: 21.7716 - val_loss: 22.4299\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 752us/step - loss: 21.6568 - val_loss: 22.3131\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 779us/step - loss: 21.5841 - val_loss: 22.2106\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 873us/step - loss: 21.5203 - val_loss: 22.2627\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.3225 - val_loss: 22.1247\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 890us/step - loss: 21.2437 - val_loss: 22.1017\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 21.3006 - val_loss: 21.9329\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 854us/step - loss: 21.1738 - val_loss: 22.4993\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 889us/step - loss: 21.1754 - val_loss: 21.8530\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 813us/step - loss: 20.9571 - val_loss: 21.8224\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.8600 - val_loss: 21.7346\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.8412 - val_loss: 21.8198\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 20.7659 - val_loss: 21.7259\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 20.8391 - val_loss: 21.6829\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.8408 - val_loss: 21.6781\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7483 - val_loss: 21.7696\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 20.5277 - val_loss: 21.6833\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.6291 - val_loss: 21.5587\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.4240 - val_loss: 21.5761\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.4462 - val_loss: 21.5146\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.2459 - val_loss: 21.6279\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 91.1053 - val_loss: 56.2326\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 46.9126 - val_loss: 44.1617\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 42.6468 - val_loss: 54.2398\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.5194 - val_loss: 42.5262\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 41.8963 - val_loss: 40.8631\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.9556 - val_loss: 45.2494\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 41.1200 - val_loss: 41.2023\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.0748 - val_loss: 39.1450\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 39.5741 - val_loss: 39.7884\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.0342 - val_loss: 38.4032\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.4700 - val_loss: 41.3560\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 36.9791 - val_loss: 38.9897\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.6939 - val_loss: 37.3272\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 36.4250 - val_loss: 37.1922\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.8277 - val_loss: 35.6625\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.6593 - val_loss: 36.9133\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.1079 - val_loss: 35.2434\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.8171 - val_loss: 34.3448\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.4218 - val_loss: 35.4399\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.1099 - val_loss: 36.7961\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.9479 - val_loss: 34.4037\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.6539 - val_loss: 35.1917\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 33.6940 - val_loss: 33.8194\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 788us/step - loss: 33.3739 - val_loss: 33.7817\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.4034 - val_loss: 34.3054\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.2451 - val_loss: 32.9685\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 32.5393 - val_loss: 35.6488\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.2591 - val_loss: 34.5655\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.0829 - val_loss: 34.7945\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 33.6650 - val_loss: 36.3741\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 31.8529 - val_loss: 31.6101\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 31.3963 - val_loss: 31.9201\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 30.4746 - val_loss: 34.7916\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.6643 - val_loss: 31.9023\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.2686 - val_loss: 31.2634\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 29.9356 - val_loss: 30.7111\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 29.9067 - val_loss: 29.6831\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.6888 - val_loss: 29.4897\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.9580 - val_loss: 29.9629\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 28.6550 - val_loss: 28.1320\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 28.2758 - val_loss: 29.2583\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 27.3743 - val_loss: 28.7927\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 26.8548 - val_loss: 27.4504\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 25.8697 - val_loss: 26.1182\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 25.1065 - val_loss: 26.6164\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 25.2976 - val_loss: 25.3022\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 24.3244 - val_loss: 24.9131\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 24.2450 - val_loss: 25.0824\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 24.1733 - val_loss: 24.7674\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 23.4627 - val_loss: 24.4495\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 23.1717 - val_loss: 24.2921\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 23.1029 - val_loss: 23.9671\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 23.1274 - val_loss: 23.9845\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 23.3428 - val_loss: 25.6934\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 23.8810 - val_loss: 24.1453\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.8393 - val_loss: 23.7618\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.5036 - val_loss: 23.5768\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.2574 - val_loss: 23.3678\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.0181 - val_loss: 23.3370\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.1461 - val_loss: 23.4106\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.9353 - val_loss: 23.3445\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.7694 - val_loss: 23.1586\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 640us/step - loss: 21.6444 - val_loss: 22.9791\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.4759 - val_loss: 22.9492\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.3515 - val_loss: 22.8513\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.3607 - val_loss: 22.8651\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.2154 - val_loss: 23.0173\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.1608 - val_loss: 23.1340\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.0286 - val_loss: 22.7423\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.0293 - val_loss: 22.6304\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.0004 - val_loss: 22.7573\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9410 - val_loss: 22.5613\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.8853 - val_loss: 22.7457\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 20.7319 - val_loss: 22.8158\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 20.6901 - val_loss: 22.6088\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.5683 - val_loss: 22.5146\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.6860 - val_loss: 22.5495\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.5411 - val_loss: 22.4220\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 20.3599 - val_loss: 22.6917\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.3753 - val_loss: 22.3822\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 20.3369 - val_loss: 22.4335\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.2012 - val_loss: 22.4941\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.7398 - val_loss: 23.1114\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.3694 - val_loss: 22.3826\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.0884 - val_loss: 22.2473\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 20.0389 - val_loss: 22.4972\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.0114 - val_loss: 22.2484\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 19.8855 - val_loss: 22.3270\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 19.8042 - val_loss: 22.2953\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 19.7582 - val_loss: 22.4565\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.2847 - val_loss: 47.4404\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 47.3476 - val_loss: 45.0356\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 43.1980 - val_loss: 42.3246\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 40.7700 - val_loss: 41.4392\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.6026 - val_loss: 39.9033\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.5740 - val_loss: 39.0198\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 38.7499 - val_loss: 40.3213\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.4391 - val_loss: 40.2586\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 39.2565 - val_loss: 38.0846\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.8263 - val_loss: 38.8751\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.1046 - val_loss: 36.9534\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.7858 - val_loss: 37.3951\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.9842 - val_loss: 37.0196\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.4317 - val_loss: 37.0473\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.8664 - val_loss: 35.2555\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.0140 - val_loss: 36.9421\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.9263 - val_loss: 36.8654\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 35.5903 - val_loss: 36.0075\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 34.4460 - val_loss: 34.7174\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.5365 - val_loss: 34.7537\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.9210 - val_loss: 35.2214\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.6065 - val_loss: 37.6417\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.1501 - val_loss: 35.4473\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 34.3184 - val_loss: 35.0296\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.8154 - val_loss: 53.0187\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 47.0996 - val_loss: 44.7596\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 42.9681 - val_loss: 42.6469\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 40.8607 - val_loss: 41.0427\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.2576 - val_loss: 40.4696\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.5184 - val_loss: 40.6336\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 38.2560 - val_loss: 38.7927\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 37.1447 - val_loss: 37.4052\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 36.2927 - val_loss: 37.0407\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.4147 - val_loss: 37.0659\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.1889 - val_loss: 36.7394\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 36.3837 - val_loss: 37.1563\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.5228 - val_loss: 35.6534\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 34.3851 - val_loss: 35.1803\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.9284 - val_loss: 35.6590\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.4665 - val_loss: 34.4717\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.4875 - val_loss: 39.0329\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.7984 - val_loss: 36.3903\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.6046 - val_loss: 37.9507\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.9989 - val_loss: 34.3998\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.0153 - val_loss: 35.1291\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.8977 - val_loss: 34.4906\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.8920 - val_loss: 34.6835\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.5165 - val_loss: 33.8100\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.6279 - val_loss: 33.3541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7185 - val_loss: 32.5321\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.0716 - val_loss: 32.6833\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.9085 - val_loss: 32.6162\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.8956 - val_loss: 32.3083\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.7504 - val_loss: 34.8908\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.0259 - val_loss: 31.2305\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.9721 - val_loss: 30.7140\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.7480 - val_loss: 30.4463\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 29.1755 - val_loss: 30.6249\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 30.3336 - val_loss: 31.2098\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.6596 - val_loss: 31.0395\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.1300 - val_loss: 31.1163\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.8536 - val_loss: 31.0067\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.3867 - val_loss: 46.7702\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 44.8108 - val_loss: 42.1108\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 41.9855 - val_loss: 39.8948\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.1243 - val_loss: 39.3870\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 38.5035 - val_loss: 37.0556\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 37.6427 - val_loss: 38.1804\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.4266 - val_loss: 36.0893\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.3873 - val_loss: 35.3101\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 35.3135 - val_loss: 34.1290\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.9682 - val_loss: 35.2613\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.5728 - val_loss: 33.8512\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.9870 - val_loss: 34.0767\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.8085 - val_loss: 33.3316\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 35.1666 - val_loss: 32.9921\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.6372 - val_loss: 33.2909\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 33.3372 - val_loss: 35.3043\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.9500 - val_loss: 31.7125\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.4178 - val_loss: 32.5284\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.6007 - val_loss: 31.9447\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.8784 - val_loss: 33.2648\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.6431 - val_loss: 32.0590\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.6617 - val_loss: 31.5981\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.4218 - val_loss: 30.9220\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.0884 - val_loss: 31.8190\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.4592 - val_loss: 34.5513\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.0344 - val_loss: 32.4981\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.0929 - val_loss: 31.3038\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.5723 - val_loss: 30.2467\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.9345 - val_loss: 32.1223\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.1818 - val_loss: 31.9718\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.0449 - val_loss: 30.1857\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 29.5604 - val_loss: 29.6788\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.1257 - val_loss: 34.5062\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.7362 - val_loss: 29.7708\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.1778 - val_loss: 30.0660\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.1790 - val_loss: 29.4862\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 29.0921 - val_loss: 29.8851\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.7087 - val_loss: 29.7990\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.4824 - val_loss: 29.0098\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.3204 - val_loss: 29.1398\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 28.1079 - val_loss: 28.5164\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.6783 - val_loss: 28.5327\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 28.2259 - val_loss: 29.5725\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.3200 - val_loss: 28.6505\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 27.9452 - val_loss: 28.1093\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 28.2176 - val_loss: 32.9554\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.9860 - val_loss: 27.9939\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.4286 - val_loss: 27.3075\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 26.1876 - val_loss: 26.5719\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 26.4819 - val_loss: 26.3916\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 25.6368 - val_loss: 26.5902\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.1585 - val_loss: 25.5233\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.8608 - val_loss: 25.6124\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.6729 - val_loss: 24.6292\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 24.3976 - val_loss: 24.7106\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 24.9215 - val_loss: 24.9378\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.9580 - val_loss: 24.0635\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.5004 - val_loss: 23.7435\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.3048 - val_loss: 23.7147\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.2688 - val_loss: 23.5654\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 23.0912 - val_loss: 23.6712\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.9615 - val_loss: 23.3846\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6331 - val_loss: 23.2613\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.5453 - val_loss: 23.1555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.4524 - val_loss: 23.2058\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.6060 - val_loss: 22.9663\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.3180 - val_loss: 23.4535\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.3937 - val_loss: 22.9032\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.1192 - val_loss: 23.1050\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.9631 - val_loss: 22.8533\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.3058 - val_loss: 22.9152\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.9674 - val_loss: 22.6258\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.8499 - val_loss: 22.5997\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7669 - val_loss: 22.8627\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.7066 - val_loss: 22.4539\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.6139 - val_loss: 22.4861\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5547 - val_loss: 22.7794\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.6025 - val_loss: 22.3558\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.3765 - val_loss: 22.3079\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.3450 - val_loss: 22.3782\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.3102 - val_loss: 22.4390\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4092 - val_loss: 22.3779\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.3008 - val_loss: 22.5453\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.5381 - val_loss: 22.4379\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 57.8821 - val_loss: 43.5737\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 43.8986 - val_loss: 42.0408\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.6893 - val_loss: 39.2419\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.1860 - val_loss: 38.9968\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.6096 - val_loss: 37.8907\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.9960 - val_loss: 38.5270\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.6037 - val_loss: 37.8636\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.4538 - val_loss: 41.1695\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.5019 - val_loss: 38.2762\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.2471 - val_loss: 38.3148\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 35.5119 - val_loss: 34.4101\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.7995 - val_loss: 35.3506\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 34.5418 - val_loss: 33.7992\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.2614 - val_loss: 33.4684\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 33.7251 - val_loss: 33.6541\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.6365 - val_loss: 32.9375\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.5814 - val_loss: 32.9836\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.2574 - val_loss: 32.5059\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 33.4983 - val_loss: 33.0385\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.3309 - val_loss: 32.1809\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 33.1834 - val_loss: 32.7989\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 32.2674 - val_loss: 31.9711\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.2523 - val_loss: 32.7463\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 32.3412 - val_loss: 31.7344\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.8505 - val_loss: 33.7174\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 31.6469 - val_loss: 31.7200\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 33.9861 - val_loss: 33.7241\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.0304 - val_loss: 31.2258\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 30.4936 - val_loss: 31.5563\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 30.6186 - val_loss: 30.8508\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.7768 - val_loss: 34.0920\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 30.6702 - val_loss: 30.4652\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.9287 - val_loss: 30.9657\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 694us/step - loss: 29.7321 - val_loss: 30.2034\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.5424 - val_loss: 30.6931\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 29.7530 - val_loss: 30.3354\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.2190 - val_loss: 31.0017\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.7696 - val_loss: 30.3678\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 29.0164 - val_loss: 29.3303\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 29.5063 - val_loss: 29.6024\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.1075 - val_loss: 29.9148\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 29.5592 - val_loss: 32.6034\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 29.3866 - val_loss: 32.3730\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 29.2432 - val_loss: 29.0198\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 28.0110 - val_loss: 28.6289\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.0159 - val_loss: 30.0278\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 27.8080 - val_loss: 28.6792\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 27.3579 - val_loss: 27.9446\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 27.7192 - val_loss: 28.3791\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 27.3656 - val_loss: 27.8244\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 27.8796 - val_loss: 28.3723\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 27.8774 - val_loss: 28.4192\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 26.4010 - val_loss: 27.0833\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 26.0865 - val_loss: 26.9357\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 26.1663 - val_loss: 26.5603\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 26.2587 - val_loss: 26.4568\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.2506 - val_loss: 27.4862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 25.4134 - val_loss: 26.0101\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 24.7682 - val_loss: 25.5414\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 24.3683 - val_loss: 25.3993\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.3283 - val_loss: 25.0858\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.0753 - val_loss: 25.3286\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.2046 - val_loss: 24.6384\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 23.7229 - val_loss: 25.6315\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.1982 - val_loss: 24.4972\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.2520 - val_loss: 24.0746\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.1949 - val_loss: 26.1103\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.6581 - val_loss: 25.0941\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.1418 - val_loss: 23.7538\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.7202 - val_loss: 24.0532\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.9884 - val_loss: 24.0588\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.5735 - val_loss: 23.5219\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.4297 - val_loss: 23.7989\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.2760 - val_loss: 23.4711\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.3289 - val_loss: 23.3950\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.3302 - val_loss: 24.0873\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.1325 - val_loss: 23.8965\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.9281 - val_loss: 23.1270\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.8067 - val_loss: 23.0769\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.7473 - val_loss: 23.0808\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.6473 - val_loss: 23.1346\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.6171 - val_loss: 22.9861\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.5581 - val_loss: 23.1791\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.6080 - val_loss: 23.0349\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.5344 - val_loss: 22.8011\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.3070 - val_loss: 22.8622\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.6429 - val_loss: 23.8402\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.7010 - val_loss: 22.8064\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1760 - val_loss: 22.8360\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.1148 - val_loss: 22.8405\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.2864 - val_loss: 48.7950\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 49.5321 - val_loss: 45.2359\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 44.2573 - val_loss: 42.5179\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 41.8497 - val_loss: 41.2655\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 40.2828 - val_loss: 41.5756\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.8706 - val_loss: 40.3586\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.8404 - val_loss: 39.3080\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.8921 - val_loss: 37.6335\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.5964 - val_loss: 37.0315\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.1617 - val_loss: 36.8595\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.7466 - val_loss: 37.5333\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.7029 - val_loss: 36.7010\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.0350 - val_loss: 35.8650\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.6965 - val_loss: 37.8878\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.5667 - val_loss: 35.2473\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.0439 - val_loss: 37.6426\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.6486 - val_loss: 34.3801\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.6913 - val_loss: 34.4833\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 33.0416 - val_loss: 33.3304\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.4554 - val_loss: 36.1188\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.7493 - val_loss: 33.0937\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.5745 - val_loss: 34.0774\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.0091 - val_loss: 32.5335\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.4932 - val_loss: 31.8363\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.6073 - val_loss: 31.4055\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.3861 - val_loss: 30.8659\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.7473 - val_loss: 30.4221\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.7782 - val_loss: 30.8034\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.8015 - val_loss: 29.6082\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.0682 - val_loss: 28.8584\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 27.1991 - val_loss: 27.9414\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 26.9221 - val_loss: 27.8437\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.1119 - val_loss: 27.3868\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.9281 - val_loss: 26.7370\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.4403 - val_loss: 26.3265\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 25.5020 - val_loss: 27.3448\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 700us/step - loss: 24.9769 - val_loss: 26.0496\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 725us/step - loss: 24.4665 - val_loss: 25.6999\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 781us/step - loss: 24.1909 - val_loss: 25.4214\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 881us/step - loss: 23.9423 - val_loss: 25.1978\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 23.8690 - val_loss: 25.1622\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.6100 - val_loss: 24.9456\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.4553 - val_loss: 24.7211\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2554 - val_loss: 24.6458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 23.1334 - val_loss: 24.5040\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.0028 - val_loss: 24.5151\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.9474 - val_loss: 24.8094\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.9159 - val_loss: 24.4368\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 22.5973 - val_loss: 24.4397\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.5839 - val_loss: 24.0502\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.4655 - val_loss: 24.2482\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4059 - val_loss: 24.0574\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4066 - val_loss: 24.2002\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.8503 - val_loss: 23.6964\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3113 - val_loss: 23.7079\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.9164 - val_loss: 23.5613\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.8117 - val_loss: 23.5903\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.8537 - val_loss: 23.5291\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.5388 - val_loss: 23.4203\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.5476 - val_loss: 23.3627\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.3274 - val_loss: 23.3457\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 21.3800 - val_loss: 23.3607\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.3664 - val_loss: 23.5624\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.3126 - val_loss: 23.3561\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.1909 - val_loss: 23.6857\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.1662 - val_loss: 23.3170\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.2570 - val_loss: 23.2193\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.2575 - val_loss: 23.1510\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.8360 - val_loss: 23.1769\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.8596 - val_loss: 23.5221\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.9407 - val_loss: 24.1897\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.3448 - val_loss: 23.2331\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.0044 - val_loss: 23.0780\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.5941 - val_loss: 23.1070\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.5869 - val_loss: 23.1128\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.6579 - val_loss: 23.1477\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.0235 - val_loss: 23.1096\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6130 - val_loss: 23.0708\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.3913 - val_loss: 23.2477\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.6719 - val_loss: 23.5020\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.4705 - val_loss: 22.9987\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.1490 - val_loss: 23.0883\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.3405 - val_loss: 23.4562\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.2538 - val_loss: 22.9504\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.1917 - val_loss: 23.1176\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.1439 - val_loss: 23.3507\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.1766 - val_loss: 22.9657\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 19.9441 - val_loss: 23.4363\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 19.8994 - val_loss: 22.9332\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 19.8086 - val_loss: 22.9873\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 19.7649 - val_loss: 23.2935\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 19.8623 - val_loss: 23.1125\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 19.6412 - val_loss: 22.9654\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 19.6135 - val_loss: 23.0877\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.2726 - val_loss: 48.1204\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 44.4710 - val_loss: 39.7620\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 41.9774 - val_loss: 39.9792\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.7453 - val_loss: 41.5779\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 40.9840 - val_loss: 39.5461\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 38.7183 - val_loss: 36.6268\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.9554 - val_loss: 35.6625\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.5960 - val_loss: 40.5891\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.6066 - val_loss: 36.0043\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 37.7419 - val_loss: 35.8385\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.0815 - val_loss: 34.3258\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.2763 - val_loss: 35.1377\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.9552 - val_loss: 33.8342\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 35.3762 - val_loss: 33.3799\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.6589 - val_loss: 33.7553\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.2619 - val_loss: 32.5290\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.3953 - val_loss: 33.3073\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.0690 - val_loss: 32.8642\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.6174 - val_loss: 33.3870\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 36.2608 - val_loss: 37.1383\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.7729 - val_loss: 33.2283\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.6380 - val_loss: 46.5574\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 43.3490 - val_loss: 41.7759\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 40.4372 - val_loss: 39.3667\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.9220 - val_loss: 40.3548\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.0963 - val_loss: 38.6517\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.5441 - val_loss: 40.7991\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.4370 - val_loss: 36.1548\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 37.2626 - val_loss: 35.9373\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 35.8471 - val_loss: 35.2775\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.2133 - val_loss: 37.1416\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.4771 - val_loss: 35.2776\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.3850 - val_loss: 34.0299\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.0648 - val_loss: 34.9473\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.1787 - val_loss: 34.2758\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.8660 - val_loss: 33.6490\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.6286 - val_loss: 33.2667\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.6701 - val_loss: 34.8860\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.7255 - val_loss: 32.9778\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.7030 - val_loss: 38.4843\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.1855 - val_loss: 34.4432\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.3264 - val_loss: 32.2176\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 31.4483 - val_loss: 32.0268\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.4174 - val_loss: 32.3388\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.6672 - val_loss: 35.6194\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.3265 - val_loss: 32.1307\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.5171 - val_loss: 31.3429\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.0093 - val_loss: 32.3883\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.8543 - val_loss: 37.5725\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.0914 - val_loss: 33.7197\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.9320 - val_loss: 32.0682\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.5299 - val_loss: 30.6995\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.4994 - val_loss: 30.6836\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.5807 - val_loss: 30.2724\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 30.8298 - val_loss: 32.7040\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 30.1456 - val_loss: 30.4663\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.8840 - val_loss: 30.3269\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 28.9021 - val_loss: 30.4227\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.8719 - val_loss: 32.6621\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 90.6159 - val_loss: 49.4860\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 46.6929 - val_loss: 41.7833\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.5390 - val_loss: 41.6595\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 38.9500 - val_loss: 36.8971\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.4949 - val_loss: 35.4041\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.1940 - val_loss: 34.6812\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.7588 - val_loss: 34.9577\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.8832 - val_loss: 33.6334\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.8848 - val_loss: 33.0495\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 32.8916 - val_loss: 32.3998\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.7072 - val_loss: 32.0240\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 568us/step - loss: 32.0899 - val_loss: 32.3374\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 31.6446 - val_loss: 30.8978\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.0246 - val_loss: 31.2467\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.4322 - val_loss: 30.5524\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.8277 - val_loss: 30.4609\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.7494 - val_loss: 30.2341\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.5048 - val_loss: 29.9488\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.7238 - val_loss: 32.7588\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.4383 - val_loss: 31.7662\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.3920 - val_loss: 29.6217\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 29.4429 - val_loss: 29.4402\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 29.3168 - val_loss: 29.0755\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.9526 - val_loss: 30.3797\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.9953 - val_loss: 29.5825\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 28.6954 - val_loss: 28.8437\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.2883 - val_loss: 28.4873\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.5280 - val_loss: 28.5875\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 29.6989 - val_loss: 28.7405\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.4430 - val_loss: 31.9902\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 29.6783 - val_loss: 30.6068\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.3932 - val_loss: 28.3111\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.9346 - val_loss: 28.8841\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.5237 - val_loss: 27.8290\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 27.5938 - val_loss: 28.2583\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.9834 - val_loss: 29.3105\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 28.5390 - val_loss: 28.5543\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.2564 - val_loss: 28.4282\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.9785 - val_loss: 27.2233\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 27.2404 - val_loss: 27.5475\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.6580 - val_loss: 26.9108\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.4428 - val_loss: 26.6449\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.3451 - val_loss: 26.5921\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.2999 - val_loss: 27.4008\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 610us/step - loss: 26.1299 - val_loss: 26.2095\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 26.0717 - val_loss: 26.5692\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 26.4908 - val_loss: 26.2903\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.5603 - val_loss: 25.8192\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.2122 - val_loss: 25.7381\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 25.0337 - val_loss: 25.2579\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 24.5485 - val_loss: 25.5425\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.4222 - val_loss: 24.6651\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.3010 - val_loss: 24.6982\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.7440 - val_loss: 25.0419\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.7957 - val_loss: 23.9910\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.0545 - val_loss: 26.4346\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.5416 - val_loss: 24.3683\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.2384 - val_loss: 23.3153\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.9876 - val_loss: 24.0377\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 23.3866 - val_loss: 23.2003\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.5519 - val_loss: 23.0999\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.4058 - val_loss: 23.5181\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.7787 - val_loss: 22.7988\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.8319 - val_loss: 23.5469\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.8682 - val_loss: 22.7877\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.2224 - val_loss: 22.4116\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.7841 - val_loss: 22.4894\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.7090 - val_loss: 22.3363\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7803 - val_loss: 22.2074\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.6827 - val_loss: 22.1876\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.7171 - val_loss: 22.1355\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5098 - val_loss: 22.6546\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5052 - val_loss: 21.9077\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.2393 - val_loss: 22.8066\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.3530 - val_loss: 22.0549\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5550 - val_loss: 22.5470\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.3835 - val_loss: 21.6885\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.8606 - val_loss: 21.6512\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 20.9494 - val_loss: 21.6161\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.7441 - val_loss: 21.7417\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.7695 - val_loss: 21.5054\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.6335 - val_loss: 21.6862\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.6766 - val_loss: 21.6255\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.6392 - val_loss: 21.4746\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.5438 - val_loss: 21.4397\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.5149 - val_loss: 21.4368\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.4282 - val_loss: 21.3107\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.4493 - val_loss: 21.3388\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.7126 - val_loss: 21.8153\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.4761 - val_loss: 21.3571\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.4230 - val_loss: 21.2972\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.3917 - val_loss: 21.9741\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.5127 - val_loss: 21.7369\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.4014 - val_loss: 21.5144\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.2507 - val_loss: 21.2278\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.0902 - val_loss: 21.1707\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.0705 - val_loss: 21.2485\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.0028 - val_loss: 21.2162\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.1603 - val_loss: 21.2206\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.1096 - val_loss: 21.3716\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 83.5518 - val_loss: 51.0456\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 48.9722 - val_loss: 44.0868\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 45.6231 - val_loss: 42.8584\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 43.0341 - val_loss: 43.4912\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 42.6800 - val_loss: 43.2686\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 42.8218 - val_loss: 42.2667\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 41.1199 - val_loss: 42.9438\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.9966 - val_loss: 38.4139\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.8230 - val_loss: 38.1956\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 39.5329 - val_loss: 39.1477\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.7829 - val_loss: 38.3977\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 41.2452 - val_loss: 37.8272\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.7692 - val_loss: 37.2479\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.7815 - val_loss: 36.8456\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.1947 - val_loss: 36.2747\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.8717 - val_loss: 35.8226\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.1452 - val_loss: 36.1042\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.6103 - val_loss: 37.4955\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.9654 - val_loss: 38.7495\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.1963 - val_loss: 35.4554\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.4344 - val_loss: 36.0202\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 620us/step - loss: 37.3396 - val_loss: 36.8851\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.2683 - val_loss: 35.1969\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.4987 - val_loss: 34.1386\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.2681 - val_loss: 36.2659\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.6985 - val_loss: 35.0630\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.9367 - val_loss: 34.0919\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.7446 - val_loss: 33.9083\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.9881 - val_loss: 33.3166\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 33.2582 - val_loss: 34.2498\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.3757 - val_loss: 33.8856\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 33.3745 - val_loss: 32.2766\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.6744 - val_loss: 34.7250\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 34.2788 - val_loss: 33.0256\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.8745 - val_loss: 34.6020\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.4351 - val_loss: 32.5251\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.6398 - val_loss: 33.3498\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.1036 - val_loss: 47.2290\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 45.0942 - val_loss: 41.0891\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 43.5691 - val_loss: 39.9913\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 40.3191 - val_loss: 38.4909\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.8615 - val_loss: 39.6662\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.5346 - val_loss: 37.0783\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 37.9344 - val_loss: 36.0876\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 37.5246 - val_loss: 36.0755\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 37.1927 - val_loss: 35.5501\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 36.6668 - val_loss: 34.8807\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.6071 - val_loss: 35.7279\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.3277 - val_loss: 36.1203\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.3140 - val_loss: 35.7304\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.4655 - val_loss: 34.3170\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.6611 - val_loss: 37.6550\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.7852 - val_loss: 33.4160\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.6612 - val_loss: 33.4631\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.4670 - val_loss: 32.9816\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 33.6451 - val_loss: 32.8343\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.2716 - val_loss: 32.8630\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.8251 - val_loss: 32.6363\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.7338 - val_loss: 33.2436\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.0812 - val_loss: 32.2882\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.1843 - val_loss: 31.6360\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.6256 - val_loss: 32.5575\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.3211 - val_loss: 32.9061\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.2763 - val_loss: 34.6795\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.5937 - val_loss: 30.9743\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.7361 - val_loss: 31.7853\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.2482 - val_loss: 31.0031\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.8699 - val_loss: 32.5187\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.9314 - val_loss: 30.9420\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 30.3464 - val_loss: 30.3889\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.7086 - val_loss: 30.7083\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.7056 - val_loss: 31.4876\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.0333 - val_loss: 29.9030\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.9721 - val_loss: 30.5143\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.2879 - val_loss: 29.7225\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 29.2623 - val_loss: 30.4960\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 420us/step - loss: 30.6249 - val_loss: 30.4656\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 447us/step - loss: 28.7726 - val_loss: 30.5224\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 29.0387 - val_loss: 30.8284\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 521us/step - loss: 28.6015 - val_loss: 29.0605\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 549us/step - loss: 28.3314 - val_loss: 29.3580\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 28.1736 - val_loss: 29.0778\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 532us/step - loss: 27.5245 - val_loss: 28.2700\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.3634 - val_loss: 29.8145\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 26.9768 - val_loss: 28.5350\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 565us/step - loss: 26.6318 - val_loss: 27.0400\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 535us/step - loss: 25.9780 - val_loss: 27.8239\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 751us/step - loss: 25.5200 - val_loss: 26.2894\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 759us/step - loss: 25.2137 - val_loss: 26.3528\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 25.0828 - val_loss: 27.9316\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 25.6858 - val_loss: 25.8205\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 24.7823 - val_loss: 25.0231\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 23.8850 - val_loss: 24.3702\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 23.6580 - val_loss: 24.2127\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 23.5625 - val_loss: 24.3694\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.4855 - val_loss: 24.0333\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 23.3551 - val_loss: 24.1104\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 23.3697 - val_loss: 23.6788\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 667us/step - loss: 22.9651 - val_loss: 23.6391\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.8426 - val_loss: 23.5060\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.7763 - val_loss: 23.4870\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.7987 - val_loss: 23.4941\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.6732 - val_loss: 23.2136\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 22.4418 - val_loss: 23.3002\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.3902 - val_loss: 23.1068\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.2579 - val_loss: 23.1752\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 22.1816 - val_loss: 22.9673\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.1950 - val_loss: 22.9183\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.1185 - val_loss: 23.1189\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.0919 - val_loss: 23.3893\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.0683 - val_loss: 22.8378\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.2697 - val_loss: 22.8664\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 22.1764 - val_loss: 22.8711\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.9889 - val_loss: 22.6948\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.8188 - val_loss: 22.7236\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.6866 - val_loss: 22.5947\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.7634 - val_loss: 22.7362\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.7083 - val_loss: 22.5771\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 21.6549 - val_loss: 22.6633\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.5841 - val_loss: 22.6870\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.4921 - val_loss: 22.6275\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.5446 - val_loss: 22.5729\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.2870 - val_loss: 22.4081\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.2314 - val_loss: 22.4215\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.3910 - val_loss: 22.6029\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 21.2166 - val_loss: 22.3765\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.1729 - val_loss: 22.5355\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.1310 - val_loss: 22.3970\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.1367 - val_loss: 22.5035\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 21.0767 - val_loss: 22.3486\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.9930 - val_loss: 22.5463\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.0247 - val_loss: 22.3102\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.9167 - val_loss: 22.3346\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.8511 - val_loss: 22.3997\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.7767 - val_loss: 22.2762\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 20.7329 - val_loss: 22.2875\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.6177 - val_loss: 22.2726\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.4182 - val_loss: 52.0021\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 45.9031 - val_loss: 43.7043\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 42.0454 - val_loss: 39.3914\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 38.9550 - val_loss: 39.0564\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.7699 - val_loss: 37.0217\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.5439 - val_loss: 35.8943\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.9374 - val_loss: 35.7671\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 35.9901 - val_loss: 36.4948\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.7966 - val_loss: 34.7929\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 34.2750 - val_loss: 34.4007\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.8667 - val_loss: 33.4387\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.1380 - val_loss: 33.6191\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.4667 - val_loss: 35.5636\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.3374 - val_loss: 32.1418\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.4666 - val_loss: 31.6379\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.1149 - val_loss: 36.2989\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.5588 - val_loss: 31.4471\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 34.4810 - val_loss: 33.8472\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.6035 - val_loss: 31.2313\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.5879 - val_loss: 30.2711\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.7390 - val_loss: 30.9952\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.0636 - val_loss: 30.0545\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.4443 - val_loss: 31.6919\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.7190 - val_loss: 31.6129\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.1636 - val_loss: 30.1892\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.3970 - val_loss: 29.3600\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.8965 - val_loss: 30.8995\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.6783 - val_loss: 29.2862\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.1289 - val_loss: 29.7852\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.4116 - val_loss: 29.7465\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.9107 - val_loss: 28.9235\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.8094 - val_loss: 28.7475\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 28.2603 - val_loss: 28.9904\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 28.5057 - val_loss: 29.9814\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 794us/step - loss: 28.6327 - val_loss: 28.0791\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 27.9609 - val_loss: 28.1203\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 717us/step - loss: 27.8830 - val_loss: 28.1369\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 905us/step - loss: 28.8971 - val_loss: 29.6311\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 1ms/step - loss: 29.0155 - val_loss: 29.0023\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 880us/step - loss: 28.0114 - val_loss: 28.6710\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.4628 - val_loss: 51.4901\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 50.7873 - val_loss: 46.1274\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 46.0305 - val_loss: 44.7253\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 44.3301 - val_loss: 42.2752\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 42.6564 - val_loss: 40.8789\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.6818 - val_loss: 40.9057\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 40.8435 - val_loss: 40.0967\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.8715 - val_loss: 38.6849\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 38.9753 - val_loss: 38.0103\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 38.0935 - val_loss: 37.3368\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 38.1313 - val_loss: 37.7011\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.5646 - val_loss: 36.9766\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.4637 - val_loss: 37.8476\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.2651 - val_loss: 36.7842\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 35.8794 - val_loss: 35.2079\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.3848 - val_loss: 35.5922\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.7639 - val_loss: 36.1504\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.2748 - val_loss: 36.3207\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.1414 - val_loss: 34.6927\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.3405 - val_loss: 37.3494\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.1380 - val_loss: 34.9181\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.0142 - val_loss: 34.0405\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.4650 - val_loss: 34.1736\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.3082 - val_loss: 32.3272\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.3532 - val_loss: 32.5602\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.3091 - val_loss: 32.4042\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 32.0444 - val_loss: 34.4049\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.7914 - val_loss: 30.4517\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.8122 - val_loss: 30.7131\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 28.6888 - val_loss: 28.5623\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.2983 - val_loss: 27.1704\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 26.7430 - val_loss: 28.6995\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.2143 - val_loss: 27.2618\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 26.7365 - val_loss: 27.0497\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.1109 - val_loss: 26.9237\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 25.4476 - val_loss: 25.6204\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.8465 - val_loss: 25.2537\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 24.4671 - val_loss: 25.0146\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.1973 - val_loss: 24.9261\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.0799 - val_loss: 24.7609\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.8145 - val_loss: 24.4311\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.6536 - val_loss: 24.6478\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.5124 - val_loss: 24.1584\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.3042 - val_loss: 23.9943\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.1630 - val_loss: 23.8197\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.0334 - val_loss: 23.7316\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.8888 - val_loss: 23.6432\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.7588 - val_loss: 23.6116\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.6700 - val_loss: 23.7065\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.6708 - val_loss: 23.4627\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.4532 - val_loss: 23.3957\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.3876 - val_loss: 23.1796\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.5442 - val_loss: 23.4363\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.2940 - val_loss: 23.1040\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.1195 - val_loss: 22.9617\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.0657 - val_loss: 23.0579\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.9627 - val_loss: 23.0134\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.8292 - val_loss: 22.9030\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.7616 - val_loss: 22.6703\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.8223 - val_loss: 22.7512\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.8062 - val_loss: 22.6974\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.4831 - val_loss: 22.5616\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3985 - val_loss: 22.6018\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3048 - val_loss: 22.7432\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.3477 - val_loss: 22.6686\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.5457 - val_loss: 22.5365\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5296 - val_loss: 22.5083\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.2783 - val_loss: 22.4737\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.1473 - val_loss: 22.5737\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.0112 - val_loss: 22.2603\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.9297 - val_loss: 22.2506\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.9857 - val_loss: 22.7450\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1178 - val_loss: 22.5927\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.9628 - val_loss: 22.2049\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.7200 - val_loss: 22.2697\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 620us/step - loss: 20.6887 - val_loss: 22.2450\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.6604 - val_loss: 22.2968\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.6187 - val_loss: 22.0984\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.5779 - val_loss: 22.0713\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.5421 - val_loss: 21.9958\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.3856 - val_loss: 22.4005\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.7282 - val_loss: 22.5406\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.6497 - val_loss: 22.6961\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.7532 - val_loss: 21.8657\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.4192 - val_loss: 21.9029\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.2193 - val_loss: 21.9757\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.1131 - val_loss: 22.1268\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.4288 - val_loss: 21.9993\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.3421 - val_loss: 22.0103\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.5693 - val_loss: 59.7736\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 46.7140 - val_loss: 46.2109\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 43.5514 - val_loss: 42.3865\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 40.2475 - val_loss: 43.4682\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.0416 - val_loss: 40.6421\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 39.9188 - val_loss: 40.4589\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.3785 - val_loss: 41.5036\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 38.7532 - val_loss: 40.2592\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.9627 - val_loss: 40.4232\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.9580 - val_loss: 39.0083\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.4891 - val_loss: 38.2904\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.7634 - val_loss: 40.7693\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 36.8285 - val_loss: 41.9139\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.9406 - val_loss: 37.3541\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.4261 - val_loss: 37.5273\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.1511 - val_loss: 36.5386\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.9791 - val_loss: 36.1332\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.9185 - val_loss: 36.8114\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.8953 - val_loss: 38.0195\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.9007 - val_loss: 38.0119\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.9853 - val_loss: 35.8520\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.8709 - val_loss: 35.6529\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.8310 - val_loss: 35.3667\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 33.6270 - val_loss: 34.7140\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.2765 - val_loss: 34.6828\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.8011 - val_loss: 34.8401\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.5930 - val_loss: 34.9624\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.4361 - val_loss: 34.2424\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.0556 - val_loss: 34.5181\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.4838 - val_loss: 33.8547\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.1485 - val_loss: 33.9186\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.7559 - val_loss: 33.6889\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.0199 - val_loss: 34.5026\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.6708 - val_loss: 36.3542\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.2925 - val_loss: 33.4535\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.8190 - val_loss: 32.9887\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.0907 - val_loss: 33.8706\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.8520 - val_loss: 32.5447\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.7486 - val_loss: 32.8142\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.7096 - val_loss: 32.1099\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.3229 - val_loss: 35.4195\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.6348 - val_loss: 32.9145\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.6600 - val_loss: 33.6349\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.2448 - val_loss: 32.1798\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.9882 - val_loss: 32.4951\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 92.6821 - val_loss: 57.9303\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 49.6232 - val_loss: 46.0856\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 44.4082 - val_loss: 42.8881\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.6337 - val_loss: 45.4473\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 41.1520 - val_loss: 40.6056\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.1344 - val_loss: 40.9305\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.7791 - val_loss: 40.5699\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.3493 - val_loss: 39.7202\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.4816 - val_loss: 42.3438\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.9974 - val_loss: 37.7091\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 38.0300 - val_loss: 37.7383\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.5042 - val_loss: 38.5387\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.6917 - val_loss: 38.8451\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.0265 - val_loss: 37.4246\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.2543 - val_loss: 36.0111\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.9166 - val_loss: 35.6659\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.7664 - val_loss: 35.1213\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.6763 - val_loss: 35.0593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.7380 - val_loss: 33.9557\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 32.7002 - val_loss: 33.5112\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.5224 - val_loss: 32.8735\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.6009 - val_loss: 32.7482\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.6838 - val_loss: 31.7457\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 29.8897 - val_loss: 31.1872\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 28.9193 - val_loss: 29.5129\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.2533 - val_loss: 30.4514\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.5683 - val_loss: 27.0007\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.8630 - val_loss: 26.2800\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.2287 - val_loss: 25.7858\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 24.9307 - val_loss: 25.6230\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 24.4890 - val_loss: 24.9432\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 24.5488 - val_loss: 25.3442\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.2779 - val_loss: 24.6461\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.8811 - val_loss: 24.4035\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.6085 - val_loss: 24.2664\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.4489 - val_loss: 24.0961\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.3231 - val_loss: 23.9651\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.2452 - val_loss: 23.9562\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 23.0996 - val_loss: 23.9669\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.1677 - val_loss: 24.0648\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.9974 - val_loss: 24.0727\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.8217 - val_loss: 23.6149\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 22.7145 - val_loss: 23.4591\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.6937 - val_loss: 23.4577\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 22.6184 - val_loss: 23.4832\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.4785 - val_loss: 23.3373\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.5220 - val_loss: 24.1671\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.5399 - val_loss: 23.3628\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.3546 - val_loss: 23.1702\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.3455 - val_loss: 23.4293\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 22.2640 - val_loss: 23.1471\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.0556 - val_loss: 23.0239\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.9180 - val_loss: 23.0328\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.9909 - val_loss: 22.9538\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.8307 - val_loss: 22.8881\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.7547 - val_loss: 22.8696\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.7668 - val_loss: 22.8423\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.7619 - val_loss: 22.7590\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.9631 - val_loss: 23.3939\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.6968 - val_loss: 22.7630\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.4831 - val_loss: 22.8353\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.5027 - val_loss: 22.8174\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.6925 - val_loss: 23.6163\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.7975 - val_loss: 49.0160\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 50.1804 - val_loss: 49.7513\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 45.9107 - val_loss: 43.4265\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 45.4919 - val_loss: 42.5801\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 42.8343 - val_loss: 41.0584\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 41.2463 - val_loss: 40.0584\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.0304 - val_loss: 41.7568\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.7246 - val_loss: 40.7420\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 39.6208 - val_loss: 38.5840\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.2348 - val_loss: 37.3267\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 38.3852 - val_loss: 38.5516\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 38.4635 - val_loss: 39.1916\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 38.4216 - val_loss: 36.1814\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 37.5612 - val_loss: 41.0604\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.6188 - val_loss: 35.1091\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 37.2350 - val_loss: 40.9106\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.7802 - val_loss: 34.2673\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 34.4453 - val_loss: 34.1294\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.0422 - val_loss: 36.6614\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 34.4278 - val_loss: 33.9992\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 33.2499 - val_loss: 33.2925\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 33.5812 - val_loss: 32.7078\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 32.5154 - val_loss: 35.8997\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.8874 - val_loss: 32.4679\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 31.8398 - val_loss: 31.1998\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 30.2805 - val_loss: 30.1645\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 29.5537 - val_loss: 29.0370\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 27.8326 - val_loss: 27.9718\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 26.8413 - val_loss: 26.9857\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 26.0392 - val_loss: 26.0259\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 25.1276 - val_loss: 25.5664\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 24.8185 - val_loss: 25.7989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 24.4759 - val_loss: 25.0218\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 24.0671 - val_loss: 24.6075\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 23.7546 - val_loss: 24.5305\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.6161 - val_loss: 24.1679\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.5094 - val_loss: 24.0005\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.6139 - val_loss: 23.9507\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 23.0948 - val_loss: 23.7940\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.9987 - val_loss: 23.6175\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.9023 - val_loss: 23.7197\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.8175 - val_loss: 23.4677\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.5759 - val_loss: 23.3333\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.4329 - val_loss: 23.5667\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.4799 - val_loss: 23.1611\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 22.3371 - val_loss: 23.1907\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.3013 - val_loss: 23.4815\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.1125 - val_loss: 23.0569\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.3400 - val_loss: 22.9045\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.9251 - val_loss: 22.8501\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8285 - val_loss: 22.7807\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.7941 - val_loss: 22.7258\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.7139 - val_loss: 22.7032\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.5872 - val_loss: 22.7854\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.6045 - val_loss: 22.6784\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.5716 - val_loss: 22.7932\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.4585 - val_loss: 22.5173\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 21.3742 - val_loss: 22.8616\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.5695 - val_loss: 22.4115\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.4184 - val_loss: 22.4574\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 21.3835 - val_loss: 22.4497\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.2901 - val_loss: 22.8183\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.3666 - val_loss: 22.3236\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.2176 - val_loss: 23.0351\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0738 - val_loss: 22.2413\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.8862 - val_loss: 22.4321\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.0079 - val_loss: 22.3032\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.8260 - val_loss: 22.1688\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.9608 - val_loss: 22.3878\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.7796 - val_loss: 22.3298\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 20.7651 - val_loss: 22.1534\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.7873 - val_loss: 22.1259\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.8413 - val_loss: 22.3256\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 20.5785 - val_loss: 22.1122\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.7578 - val_loss: 22.0278\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.5460 - val_loss: 22.0665\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.5983 - val_loss: 22.5336\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.5129 - val_loss: 22.0826\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.5043 - val_loss: 22.2260\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.4786 - val_loss: 22.1307\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 78.4977 - val_loss: 63.8259\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 51.7239 - val_loss: 43.1109\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 43.0943 - val_loss: 41.2774\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 41.2491 - val_loss: 40.6483\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.6870 - val_loss: 38.8074\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.4762 - val_loss: 38.2680\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 37.5711 - val_loss: 37.3686\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.8628 - val_loss: 40.4040\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 37.4354 - val_loss: 37.3550\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 36.1064 - val_loss: 36.8923\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.2584 - val_loss: 36.0528\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.4705 - val_loss: 36.7048\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.5833 - val_loss: 36.5265\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.1223 - val_loss: 34.3665\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.5411 - val_loss: 36.7793\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.5201 - val_loss: 38.2445\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.6044 - val_loss: 34.4527\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.7992 - val_loss: 33.6061\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.5081 - val_loss: 35.7106\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.3859 - val_loss: 37.2369\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.0820 - val_loss: 33.9631\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.4203 - val_loss: 33.1099\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.4348 - val_loss: 32.5982\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.9045 - val_loss: 33.1341\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.8758 - val_loss: 33.4150\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.7126 - val_loss: 31.7882\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.5911 - val_loss: 32.4431\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.7009 - val_loss: 31.9251\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.5312 - val_loss: 30.9739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.8746 - val_loss: 33.5987\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.4569 - val_loss: 30.4972\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.7139 - val_loss: 31.0035\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.5242 - val_loss: 31.7205\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 30.8411 - val_loss: 30.3997\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.9934 - val_loss: 29.6581\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 29.8393 - val_loss: 29.7897\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 28.4316 - val_loss: 29.6699\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.9721 - val_loss: 28.4921\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 27.8266 - val_loss: 30.4132\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.4742 - val_loss: 28.3745\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.4984 - val_loss: 29.8123\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 26.3648 - val_loss: 26.7291\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.8624 - val_loss: 26.7091\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.0366 - val_loss: 25.4671\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.3392 - val_loss: 25.1319\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 24.0735 - val_loss: 25.5643\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.0548 - val_loss: 24.6008\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.7586 - val_loss: 24.4672\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.4587 - val_loss: 24.2012\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.1900 - val_loss: 25.2161\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.6139 - val_loss: 23.8001\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.8787 - val_loss: 23.6490\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.0971 - val_loss: 24.1435\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.1248 - val_loss: 24.4311\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.7078 - val_loss: 23.4197\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.4934 - val_loss: 23.3347\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.3017 - val_loss: 23.2020\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.1962 - val_loss: 23.1459\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.1135 - val_loss: 23.1056\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.1155 - val_loss: 23.0641\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0151 - val_loss: 23.2784\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.9517 - val_loss: 22.9957\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 21.8648 - val_loss: 22.9056\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.8206 - val_loss: 23.1976\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.7530 - val_loss: 22.7646\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6371 - val_loss: 22.8598\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 563us/step - loss: 21.5519 - val_loss: 22.6716\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.5622 - val_loss: 22.7766\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5779 - val_loss: 22.8012\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.4743 - val_loss: 22.6239\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.3268 - val_loss: 22.5687\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.4122 - val_loss: 22.4769\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2910 - val_loss: 22.5910\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2063 - val_loss: 22.5725\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.2356 - val_loss: 22.5727\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.4772 - val_loss: 22.3700\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.2696 - val_loss: 22.3623\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.9981 - val_loss: 22.4383\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.9583 - val_loss: 22.3477\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.9579 - val_loss: 22.2680\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.9466 - val_loss: 22.8305\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.9858 - val_loss: 22.3469\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.8100 - val_loss: 22.3684\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.7455 - val_loss: 22.2929\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7836 - val_loss: 22.3434\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.6791 - val_loss: 48.8311\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 45.0499 - val_loss: 42.9677\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.2135 - val_loss: 39.5579\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.0563 - val_loss: 37.6467\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.3809 - val_loss: 37.7493\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.4876 - val_loss: 36.4854\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.3652 - val_loss: 36.4487\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.6309 - val_loss: 36.3040\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.5902 - val_loss: 35.1358\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.1200 - val_loss: 35.1537\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.2713 - val_loss: 34.4363\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.5094 - val_loss: 36.0308\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.4887 - val_loss: 35.0327\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.3131 - val_loss: 34.1399\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.9620 - val_loss: 34.6461\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.5071 - val_loss: 35.0018\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.5785 - val_loss: 34.9905\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.0588 - val_loss: 34.4336\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 34.7956 - val_loss: 36.5990\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 70.8522 - val_loss: 50.6033\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 45.5062 - val_loss: 44.0672\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.8391 - val_loss: 42.3540\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.5161 - val_loss: 40.5597\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.7155 - val_loss: 39.9119\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.4806 - val_loss: 42.1180\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.7019 - val_loss: 40.1059\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 38.1074 - val_loss: 38.6934\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.0756 - val_loss: 38.3262\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.8368 - val_loss: 40.9877\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 37.2084 - val_loss: 37.7671\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.2714 - val_loss: 37.0449\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.7815 - val_loss: 37.0218\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 35.7301 - val_loss: 36.6446\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.7132 - val_loss: 43.4138\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.8162 - val_loss: 38.5265\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 36.1436 - val_loss: 39.8088\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.5212 - val_loss: 35.8253\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.1577 - val_loss: 36.5394\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.3663 - val_loss: 35.4420\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.7082 - val_loss: 38.5303\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.5351 - val_loss: 35.9674\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.8107 - val_loss: 34.0368\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 32.7775 - val_loss: 33.9359\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.0939 - val_loss: 36.2391\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.3853 - val_loss: 34.9466\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.7833 - val_loss: 33.4580\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.4053 - val_loss: 33.8234\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.1750 - val_loss: 33.0343\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.4130 - val_loss: 33.1089\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.1186 - val_loss: 32.6415\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.0872 - val_loss: 32.8937\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.2977 - val_loss: 32.4337\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.4634 - val_loss: 35.1015\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.0391 - val_loss: 32.8991\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.4351 - val_loss: 34.0607\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.7707 - val_loss: 31.8589\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.0171 - val_loss: 31.0770\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.7613 - val_loss: 31.5247\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.4091 - val_loss: 31.7857\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.8079 - val_loss: 31.8330\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.4517 - val_loss: 31.4648\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.5088 - val_loss: 32.0840\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 94.3429 - val_loss: 85.1454\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 79.5121 - val_loss: 45.3182\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 46.5667 - val_loss: 43.9494\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 43.4912 - val_loss: 42.2323\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 41.1648 - val_loss: 43.4086\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 42.9176 - val_loss: 41.4444\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 40.1687 - val_loss: 38.3311\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 38.9097 - val_loss: 38.4957\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.5269 - val_loss: 37.5070\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.8255 - val_loss: 37.9651\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 38.3047 - val_loss: 37.8074\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.3364 - val_loss: 36.0350\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.6817 - val_loss: 35.6251\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.1991 - val_loss: 35.0996\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 35.7827 - val_loss: 38.0706\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.4599 - val_loss: 38.9907\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.7189 - val_loss: 34.6966\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 34.8250 - val_loss: 34.6234\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.0611 - val_loss: 34.0611\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.0966 - val_loss: 33.5427\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.7148 - val_loss: 33.2416\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.1158 - val_loss: 35.6177\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.0828 - val_loss: 33.7009\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.8464 - val_loss: 32.8041\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.2219 - val_loss: 35.7560\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.1447 - val_loss: 31.6452\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.2157 - val_loss: 31.7057\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.0888 - val_loss: 31.4137\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.8016 - val_loss: 29.6121\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.6133 - val_loss: 29.3628\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 28.3625 - val_loss: 28.4169\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 27.4439 - val_loss: 27.0601\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.1463 - val_loss: 26.3142\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.7093 - val_loss: 25.7533\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.1750 - val_loss: 25.5391\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 641us/step - loss: 24.9096 - val_loss: 25.6015\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.4484 - val_loss: 24.8481\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 24.0268 - val_loss: 24.5586\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.7947 - val_loss: 24.4291\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 23.5906 - val_loss: 24.5566\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 560us/step - loss: 23.3656 - val_loss: 24.1140\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 23.2861 - val_loss: 24.1266\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.0353 - val_loss: 23.7945\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.7614 - val_loss: 23.6979\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.7436 - val_loss: 23.5982\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.6180 - val_loss: 23.7304\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.7060 - val_loss: 23.6471\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.4806 - val_loss: 23.3712\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.2562 - val_loss: 23.4546\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 826us/step - loss: 22.2084 - val_loss: 23.1933\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 771us/step - loss: 22.0364 - val_loss: 23.4070\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 572us/step - loss: 21.9049 - val_loss: 23.1326\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.8296 - val_loss: 23.3391\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.7326 - val_loss: 23.0866\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.6361 - val_loss: 22.8593\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.4695 - val_loss: 22.8942\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3782 - val_loss: 22.7871\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 21.2417 - val_loss: 22.6927\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.2152 - val_loss: 22.7238\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 21.3537 - val_loss: 22.8235\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.2946 - val_loss: 22.8932\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.2736 - val_loss: 22.5926\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.9173 - val_loss: 22.6186\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.0032 - val_loss: 22.6715\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.9755 - val_loss: 22.6618\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 20.8388 - val_loss: 22.5167\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.7177 - val_loss: 22.6076\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.8686 - val_loss: 22.5003\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.6846 - val_loss: 22.3303\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.5027 - val_loss: 22.4463\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.9140 - val_loss: 22.7088\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.6515 - val_loss: 22.4585\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.3327 - val_loss: 22.3938\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.2101 - val_loss: 22.4407\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 80.5868 - val_loss: 59.4375\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 47.3102 - val_loss: 45.0017\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 42.7122 - val_loss: 43.5912\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 42.8515 - val_loss: 44.6033\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 41.7744 - val_loss: 41.0342\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 41.4653 - val_loss: 40.5260\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 43.9190 - val_loss: 42.0094\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.5317 - val_loss: 40.5592\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.6801 - val_loss: 40.4265\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.9095 - val_loss: 39.2884\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 37.8351 - val_loss: 38.2427\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.4286 - val_loss: 39.8933\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.7528 - val_loss: 39.8498\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.7574 - val_loss: 36.9498\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.7144 - val_loss: 36.1901\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 36.7594 - val_loss: 36.6356\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.3259 - val_loss: 38.2669\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.3958 - val_loss: 37.8036\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.1419 - val_loss: 36.0872\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.7630 - val_loss: 36.6884\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.7740 - val_loss: 36.7083\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.8509 - val_loss: 35.2877\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 34.3352 - val_loss: 35.7722\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.7777 - val_loss: 35.4951\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.6653 - val_loss: 35.1420\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 34.1902 - val_loss: 34.4570\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.3506 - val_loss: 35.3837\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 33.7125 - val_loss: 37.8563\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.1783 - val_loss: 34.4515\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.9131 - val_loss: 36.0485\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.9423 - val_loss: 36.3358\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 35.0650 - val_loss: 34.8188\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.0209 - val_loss: 32.7751\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.4589 - val_loss: 35.5221\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.6207 - val_loss: 33.0059\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 32.4462 - val_loss: 34.5357\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.2102 - val_loss: 33.2866\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.5417 - val_loss: 32.3266\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 641us/step - loss: 31.3291 - val_loss: 33.9630\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.6110 - val_loss: 32.9749\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.0013 - val_loss: 35.0829\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.2628 - val_loss: 33.0967\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.1876 - val_loss: 32.5895\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 84.9292 - val_loss: 52.4554\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 48.6023 - val_loss: 46.2306\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 43.3088 - val_loss: 41.7786\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 40.6685 - val_loss: 39.9940\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.8640 - val_loss: 41.7664\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 39.4199 - val_loss: 41.4993\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.4224 - val_loss: 38.6941\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.1286 - val_loss: 37.3543\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 37.6005 - val_loss: 37.9266\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 40.1167 - val_loss: 37.5117\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.4693 - val_loss: 36.7098\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.4128 - val_loss: 37.6702\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.7862 - val_loss: 37.6810\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.6449 - val_loss: 39.0178\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.6160 - val_loss: 38.5370\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.1177 - val_loss: 37.1395\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.3302 - val_loss: 51.0526\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 47.7655 - val_loss: 44.2971\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 43.3149 - val_loss: 44.1947\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 43.0090 - val_loss: 48.2461\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.0164 - val_loss: 42.5838\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.9497 - val_loss: 39.7914\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.5281 - val_loss: 40.8044\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.4522 - val_loss: 38.8340\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 38.3264 - val_loss: 40.2778\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.5464 - val_loss: 39.7862\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 38.5741 - val_loss: 37.8785\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.2311 - val_loss: 38.0712\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.7905 - val_loss: 39.8564\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.8502 - val_loss: 36.4201\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.7284 - val_loss: 36.1566\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.0921 - val_loss: 34.9181\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.5351 - val_loss: 34.8607\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.1137 - val_loss: 35.3476\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.8680 - val_loss: 36.3238\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.0480 - val_loss: 37.2924\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.7854 - val_loss: 36.5212\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.6214 - val_loss: 36.5949\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.5099 - val_loss: 46.3036\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 45.0544 - val_loss: 43.0149\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 41.3078 - val_loss: 38.2309\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 683us/step - loss: 39.3441 - val_loss: 38.2053\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 692us/step - loss: 39.0093 - val_loss: 36.6751\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 37.8322 - val_loss: 35.9091\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 37.0037 - val_loss: 37.0373\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 37.9132 - val_loss: 35.8990\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 675us/step - loss: 37.6912 - val_loss: 35.0056\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 37.1570 - val_loss: 35.3508\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 36.3948 - val_loss: 34.7251\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 35.0907 - val_loss: 34.5092\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 681us/step - loss: 35.3684 - val_loss: 34.0474\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 34.9347 - val_loss: 35.1094\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 34.7036 - val_loss: 33.5665\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 34.4543 - val_loss: 33.5938\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 35.8346 - val_loss: 33.7109\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 34.6812 - val_loss: 33.1188\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 684us/step - loss: 34.8370 - val_loss: 33.8776\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 33.8049 - val_loss: 33.1157\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 33.3426 - val_loss: 38.8377\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 34.3740 - val_loss: 34.2356\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 691us/step - loss: 33.4731 - val_loss: 32.3952\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 32.9639 - val_loss: 36.4557\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 33.8355 - val_loss: 32.4781\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 32.4369 - val_loss: 31.8607\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 32.8144 - val_loss: 31.9830\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 31.8951 - val_loss: 33.2843\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 671us/step - loss: 33.9395 - val_loss: 32.0697\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 686us/step - loss: 32.3421 - val_loss: 34.4849\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 32.7230 - val_loss: 33.1676\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.9598 - val_loss: 51.6385\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 46.9632 - val_loss: 42.3515\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 952us/step - loss: 41.5315 - val_loss: 39.3759\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 40.7322 - val_loss: 38.6204\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 845us/step - loss: 39.1487 - val_loss: 37.2166\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 917us/step - loss: 38.0722 - val_loss: 36.6044\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 821us/step - loss: 37.4205 - val_loss: 38.1755\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.5836 - val_loss: 36.8734\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.7573 - val_loss: 34.9729\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.9110 - val_loss: 35.7726\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.2476 - val_loss: 35.7290\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.4655 - val_loss: 35.5241\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.8923 - val_loss: 34.4243\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 34.1681 - val_loss: 35.1989\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.8537 - val_loss: 33.9602\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.9540 - val_loss: 34.1499\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 34.0371 - val_loss: 35.4538\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.4427 - val_loss: 34.0075\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 33.2610 - val_loss: 32.5098\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.8696 - val_loss: 32.2875\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.1956 - val_loss: 33.2736\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.1760 - val_loss: 32.8980\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.6327 - val_loss: 32.5021\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.1147 - val_loss: 32.5016\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.1383 - val_loss: 32.6133\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 86.5996 - val_loss: 48.0815\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 47.3436 - val_loss: 49.0344\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 44.0756 - val_loss: 41.8106\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 40.5928 - val_loss: 38.8533\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 39.2473 - val_loss: 38.2097\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.2775 - val_loss: 40.4068\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.6924 - val_loss: 37.2954\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.4768 - val_loss: 37.2451\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.5890 - val_loss: 36.3831\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.7319 - val_loss: 38.0309\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.7377 - val_loss: 36.4114\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.5849 - val_loss: 36.1579\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.4755 - val_loss: 35.1290\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.6111 - val_loss: 33.9169\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 34.5603 - val_loss: 34.0612\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.6560 - val_loss: 35.3773\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 35.5637 - val_loss: 35.6042\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 709us/step - loss: 34.0056 - val_loss: 33.3044\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.4887 - val_loss: 33.4269\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 32.4786 - val_loss: 32.3389\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 32.1968 - val_loss: 34.7554\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.1349 - val_loss: 33.1262\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 32.5633 - val_loss: 33.8129\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.7937 - val_loss: 34.5510\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.0264 - val_loss: 31.6491\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.5835 - val_loss: 31.6576\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.1680 - val_loss: 31.3632\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.4499 - val_loss: 31.1180\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.4931 - val_loss: 30.7274\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.0804 - val_loss: 30.5874\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.1574 - val_loss: 31.1400\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 29.7873 - val_loss: 30.4529\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 28.9243 - val_loss: 30.2341\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 28.2495 - val_loss: 30.7978\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.1528 - val_loss: 31.2797\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 28.6116 - val_loss: 29.0126\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.8319 - val_loss: 27.7880\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 26.4170 - val_loss: 27.9960\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 26.6543 - val_loss: 27.5353\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.5903 - val_loss: 26.0420\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 25.1399 - val_loss: 26.5255\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.0684 - val_loss: 26.0422\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.2939 - val_loss: 25.5701\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.1074 - val_loss: 25.3819\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.6598 - val_loss: 24.6892\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.5595 - val_loss: 24.4452\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.3264 - val_loss: 24.1764\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.0593 - val_loss: 24.0270\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.9477 - val_loss: 23.9085\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.8197 - val_loss: 23.8387\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.9825 - val_loss: 23.9405\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.6825 - val_loss: 23.8837\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.5829 - val_loss: 23.9663\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.4625 - val_loss: 23.6739\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.2800 - val_loss: 23.4304\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.1215 - val_loss: 23.3444\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 22.0738 - val_loss: 23.6091\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.9706 - val_loss: 23.2515\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8926 - val_loss: 23.1996\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.0806 - val_loss: 23.6401\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.9690 - val_loss: 23.4386\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7575 - val_loss: 23.1044\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.5391 - val_loss: 23.3241\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.5681 - val_loss: 23.6868\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.5090 - val_loss: 23.3454\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.4335 - val_loss: 23.2349\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.3014 - val_loss: 23.3080\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.3143 - val_loss: 47.9976\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 45.1349 - val_loss: 41.1623\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 42.5582 - val_loss: 42.3319\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.6515 - val_loss: 37.8134\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.7785 - val_loss: 38.5164\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.6173 - val_loss: 39.5485\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 38.3813 - val_loss: 36.7508\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.6106 - val_loss: 35.2695\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 36.4860 - val_loss: 34.9191\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.8295 - val_loss: 35.4328\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 36.7043 - val_loss: 35.4868\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.7228 - val_loss: 34.1441\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.0810 - val_loss: 39.2212\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.4453 - val_loss: 33.9841\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.5659 - val_loss: 33.3214\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.0123 - val_loss: 34.6249\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.3009 - val_loss: 32.9257\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.7346 - val_loss: 37.3480\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.4474 - val_loss: 32.4058\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.7796 - val_loss: 31.9498\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.6901 - val_loss: 32.0525\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.0117 - val_loss: 33.2201\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.1418 - val_loss: 31.9386\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.9985 - val_loss: 32.4022\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 32.2784 - val_loss: 32.3774\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 32.1418 - val_loss: 34.6763\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.0448 - val_loss: 32.2786\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 31.9436 - val_loss: 31.8031\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.2221 - val_loss: 31.8800\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.7793 - val_loss: 32.7237\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 30.8402 - val_loss: 30.2022\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.3216 - val_loss: 30.8566\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 30.5750 - val_loss: 29.4766\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.8065 - val_loss: 29.3982\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.9700 - val_loss: 29.5133\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 29.4672 - val_loss: 32.2923\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.4557 - val_loss: 29.5054\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.3751 - val_loss: 29.4310\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.6767 - val_loss: 28.8375\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.4084 - val_loss: 28.7648\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 30.0629 - val_loss: 32.2142\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.0658 - val_loss: 28.5072\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 28.7052 - val_loss: 28.6735\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.3057 - val_loss: 28.2698\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.9829 - val_loss: 29.0179\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.1461 - val_loss: 29.1529\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.4399 - val_loss: 28.3003\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.1007 - val_loss: 28.1699\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 27.9989 - val_loss: 28.4717\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.4488 - val_loss: 31.0936\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.7043 - val_loss: 28.1087\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.5832 - val_loss: 28.7184\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 28.9921 - val_loss: 28.7932\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 28.0819 - val_loss: 27.6206\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.0570 - val_loss: 26.9806\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 26.4460 - val_loss: 26.4447\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 25.8021 - val_loss: 26.4698\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 26.6416 - val_loss: 29.2312\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 26.1036 - val_loss: 26.2447\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 25.1895 - val_loss: 25.2450\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 25.1208 - val_loss: 25.3404\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.1887 - val_loss: 24.8293\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.2220 - val_loss: 24.2876\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.6865 - val_loss: 24.0768\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 615us/step - loss: 23.6758 - val_loss: 23.8809\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.3043 - val_loss: 23.6577\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.0367 - val_loss: 23.8508\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.1465 - val_loss: 23.3657\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 22.7143 - val_loss: 23.1832\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 22.4904 - val_loss: 23.0912\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.4458 - val_loss: 23.2328\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.3195 - val_loss: 22.9998\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.1786 - val_loss: 22.7857\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.3330 - val_loss: 22.8353\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.0345 - val_loss: 22.6157\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.9046 - val_loss: 22.8720\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.1401 - val_loss: 22.6568\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.7795 - val_loss: 22.4412\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.8233 - val_loss: 22.7177\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.7180 - val_loss: 22.7392\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6959 - val_loss: 22.4128\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.6023 - val_loss: 22.4898\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6456 - val_loss: 22.2707\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.4323 - val_loss: 22.2192\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.6543 - val_loss: 22.2377\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.3954 - val_loss: 22.3916\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.3408 - val_loss: 22.1855\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.3505 - val_loss: 22.1462\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.2530 - val_loss: 22.2696\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2783 - val_loss: 22.2135\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.3075 - val_loss: 22.2814\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1618 - val_loss: 22.0553\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.1332 - val_loss: 22.4436\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.1911 - val_loss: 22.2493\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.2061 - val_loss: 22.0543\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1440 - val_loss: 22.0551\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1131 - val_loss: 21.9975\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.8739 - val_loss: 22.0075\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 20.8937 - val_loss: 22.1985\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 20.8928 - val_loss: 22.0410\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.4957 - val_loss: 45.3312\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 45.6676 - val_loss: 41.1041\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 41.4134 - val_loss: 39.6227\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.6868 - val_loss: 41.4240\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.7342 - val_loss: 42.6997\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.9597 - val_loss: 40.0702\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 39.0073 - val_loss: 38.3515\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.7112 - val_loss: 37.8174\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 37.1563 - val_loss: 37.0522\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 38.7818 - val_loss: 37.4452\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.8278 - val_loss: 36.3181\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.6145 - val_loss: 35.6121\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.0926 - val_loss: 35.0591\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 757us/step - loss: 36.4991 - val_loss: 36.3696\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 37.2234 - val_loss: 35.8649\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.3597 - val_loss: 36.3440\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 34.5056 - val_loss: 33.9308\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.6803 - val_loss: 34.2535\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.3750 - val_loss: 33.6711\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.7132 - val_loss: 33.1223\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.4320 - val_loss: 32.7083\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.0239 - val_loss: 33.1594\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.9635 - val_loss: 36.7884\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.8001 - val_loss: 33.5988\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.5088 - val_loss: 33.5361\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.4502 - val_loss: 34.2584\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.9650 - val_loss: 45.9716\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.1554 - val_loss: 39.6806\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 38.8624 - val_loss: 36.7732\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 38.2683 - val_loss: 38.1214\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.9229 - val_loss: 35.9143\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 34.8463 - val_loss: 35.3165\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.6742 - val_loss: 33.5719\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.3372 - val_loss: 38.0481\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.6369 - val_loss: 33.5237\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 33.3859 - val_loss: 33.4250\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.7188 - val_loss: 32.0264\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.9894 - val_loss: 31.8108\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.8770 - val_loss: 31.2703\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.5414 - val_loss: 32.6555\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.5144 - val_loss: 32.8735\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 31.7960 - val_loss: 30.6748\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 32.0560 - val_loss: 31.1710\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.1935 - val_loss: 30.8348\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.6116 - val_loss: 31.3671\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.7189 - val_loss: 31.1292\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.5954 - val_loss: 32.6475\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.6052 - val_loss: 46.2788\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 45.9639 - val_loss: 43.1838\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 42.6288 - val_loss: 39.8784\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 41.2937 - val_loss: 39.3709\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.9943 - val_loss: 41.7361\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 41.5410 - val_loss: 41.0100\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.8456 - val_loss: 37.7599\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.3707 - val_loss: 41.0022\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.8435 - val_loss: 38.7530\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.8968 - val_loss: 39.2309\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.1603 - val_loss: 36.5472\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 37.3832 - val_loss: 36.5289\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 36.4918 - val_loss: 36.3492\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 38.7203 - val_loss: 37.8425\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 37.6578 - val_loss: 35.1075\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 37.5545 - val_loss: 41.8684\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.7096 - val_loss: 35.8261\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 36.4750 - val_loss: 35.1333\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.2786 - val_loss: 37.0351\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.9145 - val_loss: 35.6125\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.6454 - val_loss: 47.4542\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 45.6422 - val_loss: 41.4117\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 42.6237 - val_loss: 39.2765\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 40.3070 - val_loss: 44.9529\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 40.5113 - val_loss: 37.8030\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 38.4302 - val_loss: 38.5510\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 39.0892 - val_loss: 37.1410\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.5434 - val_loss: 36.9104\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 37.0614 - val_loss: 35.9402\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 35.7362 - val_loss: 35.4968\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.4297 - val_loss: 35.2354\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 36.1913 - val_loss: 34.9163\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.9852 - val_loss: 34.4969\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.2855 - val_loss: 39.2277\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 34.7910 - val_loss: 33.3354\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.9749 - val_loss: 34.9946\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 35.2443 - val_loss: 34.9203\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 34.1983 - val_loss: 38.7104\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 33.9297 - val_loss: 33.8524\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.6579 - val_loss: 32.8085\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.9690 - val_loss: 32.7806\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.8833 - val_loss: 34.4573\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 32.4597 - val_loss: 32.6565\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.6575 - val_loss: 31.9806\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.6292 - val_loss: 31.2260\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.7478 - val_loss: 32.6621\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.0100 - val_loss: 30.9491\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.4473 - val_loss: 31.0278\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.3677 - val_loss: 31.1011\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 29.9269 - val_loss: 30.3923\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.9890 - val_loss: 30.1110\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.7039 - val_loss: 30.0522\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.3112 - val_loss: 31.8215\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.4474 - val_loss: 29.6636\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.0282 - val_loss: 29.1770\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.0076 - val_loss: 32.5030\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.7900 - val_loss: 28.7122\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.6640 - val_loss: 28.2069\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 27.3170 - val_loss: 28.0358\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.8501 - val_loss: 27.7519\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 27.6271 - val_loss: 27.2221\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.1263 - val_loss: 26.5542\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.4428 - val_loss: 25.8946\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 25.9117 - val_loss: 25.8566\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.7359 - val_loss: 25.3706\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.9155 - val_loss: 27.9167\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.6339 - val_loss: 24.8556\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.1969 - val_loss: 24.8912\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 24.2924 - val_loss: 24.6191\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.7566 - val_loss: 24.2505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 23.5950 - val_loss: 24.3165\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 23.2715 - val_loss: 24.4428\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 23.3291 - val_loss: 24.0298\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.1313 - val_loss: 23.9099\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 22.9414 - val_loss: 23.7009\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.1749 - val_loss: 23.6491\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.9112 - val_loss: 23.6725\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.7069 - val_loss: 23.4007\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.7020 - val_loss: 24.5150\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 23.0809 - val_loss: 23.7757\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 22.5892 - val_loss: 23.2132\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.2884 - val_loss: 23.2007\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.3104 - val_loss: 23.7517\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 22.3882 - val_loss: 23.4909\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.1997 - val_loss: 22.9595\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.0272 - val_loss: 22.9742\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.9563 - val_loss: 23.1577\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.9885 - val_loss: 22.9439\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.8929 - val_loss: 22.7900\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.7517 - val_loss: 22.9791\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.8048 - val_loss: 22.9964\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7993 - val_loss: 22.7258\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.7108 - val_loss: 22.8211\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.6492 - val_loss: 22.6766\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.5572 - val_loss: 22.5827\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4554 - val_loss: 22.6701\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.6210 - val_loss: 22.6239\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.5208 - val_loss: 22.7216\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4038 - val_loss: 22.6212\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.5249 - val_loss: 23.1005\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.7130 - val_loss: 47.8539\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 45.4534 - val_loss: 43.1413\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 43.3439 - val_loss: 40.8849\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 40.0802 - val_loss: 38.6395\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.0852 - val_loss: 37.9852\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 37.1765 - val_loss: 36.4215\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 37.9436 - val_loss: 36.4662\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.6980 - val_loss: 36.6443\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.3664 - val_loss: 35.1645\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.0536 - val_loss: 34.4083\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.3899 - val_loss: 33.6451\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 33.8718 - val_loss: 32.6939\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8626 - val_loss: 33.6538\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.6880 - val_loss: 33.1519\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.2748 - val_loss: 31.8711\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.9520 - val_loss: 32.0056\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 31.5518 - val_loss: 31.0977\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.0630 - val_loss: 30.8124\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.8258 - val_loss: 32.2087\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.8618 - val_loss: 32.0251\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 31.5737 - val_loss: 32.4633\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9581 - val_loss: 31.3383\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.1985 - val_loss: 32.1765\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.2061 - val_loss: 54.7847\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 51.6171 - val_loss: 48.6430\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 47.5317 - val_loss: 43.9903\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 43.6652 - val_loss: 41.9396\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.9376 - val_loss: 44.0046\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.9945 - val_loss: 41.4168\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 40.6830 - val_loss: 40.1347\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.6725 - val_loss: 39.0377\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.9569 - val_loss: 40.2058\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 39.1593 - val_loss: 40.3032\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.4882 - val_loss: 40.4738\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 38.7225 - val_loss: 37.4014\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 36.9680 - val_loss: 36.8228\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 36.1623 - val_loss: 36.5314\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.3713 - val_loss: 37.7463\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.3893 - val_loss: 36.1147\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.6030 - val_loss: 35.7626\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.3807 - val_loss: 35.6621\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.5955 - val_loss: 35.5198\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.8164 - val_loss: 34.9842\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.8058 - val_loss: 35.1293\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.9645 - val_loss: 34.8450\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.7742 - val_loss: 36.6687\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.7160 - val_loss: 36.8179\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.9611 - val_loss: 34.9838\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.5788 - val_loss: 33.0342\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.2422 - val_loss: 34.8306\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.9385 - val_loss: 31.8283\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.3306 - val_loss: 32.5830\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.8828 - val_loss: 31.1105\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 28.7649 - val_loss: 30.4992\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.0011 - val_loss: 29.5804\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.1353 - val_loss: 27.9619\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.7532 - val_loss: 27.0653\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 26.0791 - val_loss: 27.6511\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 26.3972 - val_loss: 26.4782\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 25.6494 - val_loss: 26.4092\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.0159 - val_loss: 25.5934\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.7241 - val_loss: 26.1535\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 24.5540 - val_loss: 25.5572\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.2702 - val_loss: 24.8883\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.9844 - val_loss: 24.7797\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.7728 - val_loss: 24.5348\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.8448 - val_loss: 24.3326\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.6043 - val_loss: 24.1656\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.3528 - val_loss: 23.9774\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.1068 - val_loss: 23.9033\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 23.0850 - val_loss: 23.8125\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 22.8934 - val_loss: 23.8837\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.8514 - val_loss: 24.3840\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.8394 - val_loss: 23.5041\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.6818 - val_loss: 23.4773\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.5706 - val_loss: 23.3274\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.3585 - val_loss: 23.4756\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.2987 - val_loss: 23.2589\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.2755 - val_loss: 23.2265\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.1597 - val_loss: 23.1694\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.1011 - val_loss: 23.0843\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.9468 - val_loss: 23.0126\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 21.9355 - val_loss: 23.0987\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.0254 - val_loss: 23.0115\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.1523 - val_loss: 23.3368\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.9008 - val_loss: 23.3319\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.7720 - val_loss: 22.8836\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.5496 - val_loss: 22.9253\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.5475 - val_loss: 22.7985\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.5477 - val_loss: 22.8923\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.3719 - val_loss: 22.6055\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2630 - val_loss: 22.6792\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2134 - val_loss: 22.5516\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.1942 - val_loss: 22.4839\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.1565 - val_loss: 23.1827\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.2817 - val_loss: 22.6404\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.1825 - val_loss: 22.4968\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.0365 - val_loss: 22.6210\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.9666 - val_loss: 22.4310\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.8560 - val_loss: 22.3338\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 20.8973 - val_loss: 22.3438\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.8995 - val_loss: 22.3739\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.8405 - val_loss: 22.7945\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 20.7958 - val_loss: 22.7091\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.7057 - val_loss: 22.6109\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.7595 - val_loss: 46.8739\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.2529 - val_loss: 43.8940\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 45.0035 - val_loss: 42.8417\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 41.3013 - val_loss: 42.4836\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 711us/step - loss: 40.0924 - val_loss: 40.8296\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 39.1561 - val_loss: 40.2625\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 37.9400 - val_loss: 45.0427\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.7552 - val_loss: 39.3458\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.5199 - val_loss: 42.0852\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 37.3925 - val_loss: 37.2549\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.1724 - val_loss: 36.6974\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 37.5591 - val_loss: 36.9187\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.0745 - val_loss: 36.3117\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.6983 - val_loss: 35.9146\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 36.5846 - val_loss: 37.1380\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.9932 - val_loss: 36.0714\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.4070 - val_loss: 35.7931\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 35.5413 - val_loss: 36.6838\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 629us/step - loss: 34.0864 - val_loss: 35.1599\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 34.5434 - val_loss: 35.8063\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.4098 - val_loss: 36.5727\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.1003 - val_loss: 35.6742\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.8414 - val_loss: 33.7954\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.8198 - val_loss: 35.5986\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.9089 - val_loss: 32.9890\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.0548 - val_loss: 32.7424\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.6759 - val_loss: 34.6067\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.9852 - val_loss: 32.2781\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 31.2366 - val_loss: 34.7219\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.8271 - val_loss: 32.5773\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.5156 - val_loss: 32.9120\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.1949 - val_loss: 32.0655\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.4614 - val_loss: 32.9018\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.8464 - val_loss: 32.0065\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.0778 - val_loss: 31.0190\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.8044 - val_loss: 30.8639\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.2500 - val_loss: 30.5278\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 29.6328 - val_loss: 33.4249\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.4816 - val_loss: 30.4079\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.5842 - val_loss: 29.8241\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 28.1991 - val_loss: 29.8761\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.3325 - val_loss: 29.7465\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.0533 - val_loss: 28.8648\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 27.8632 - val_loss: 30.0979\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 27.7079 - val_loss: 29.7276\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 26.4277 - val_loss: 26.8827\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.8755 - val_loss: 27.4115\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.6084 - val_loss: 26.5492\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.0639 - val_loss: 25.2892\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.4154 - val_loss: 24.8702\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 24.1891 - val_loss: 25.0664\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 24.2688 - val_loss: 24.3924\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.7445 - val_loss: 24.6520\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 23.4169 - val_loss: 24.0531\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 23.2846 - val_loss: 24.3401\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 23.5011 - val_loss: 23.8169\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.0680 - val_loss: 23.6048\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.9211 - val_loss: 23.5504\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.8047 - val_loss: 23.4230\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.6286 - val_loss: 23.3968\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 22.6280 - val_loss: 23.2396\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 22.8389 - val_loss: 24.3936\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 22.4446 - val_loss: 23.1267\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.2190 - val_loss: 23.0961\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.1822 - val_loss: 23.1892\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.1193 - val_loss: 23.3804\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.1920 - val_loss: 22.9515\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.0526 - val_loss: 23.4158\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.0017 - val_loss: 22.7994\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8135 - val_loss: 22.7740\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.7284 - val_loss: 22.6696\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.6748 - val_loss: 22.8928\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7804 - val_loss: 23.4585\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.7457 - val_loss: 22.5734\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.5155 - val_loss: 22.9058\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5598 - val_loss: 22.5409\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.3312 - val_loss: 22.5393\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.2544 - val_loss: 22.5011\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.2785 - val_loss: 22.4189\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.1887 - val_loss: 22.5275\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.1586 - val_loss: 22.6728\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.7198 - val_loss: 22.6981\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3739 - val_loss: 22.4004\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.1592 - val_loss: 23.2419\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.2691 - val_loss: 22.3243\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.8945 - val_loss: 22.3154\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 20.8534 - val_loss: 22.2823\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.8195 - val_loss: 22.2373\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.8659 - val_loss: 22.2791\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.7833 - val_loss: 22.3575\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.6507 - val_loss: 22.3271\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.6343 - val_loss: 22.4898\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.6408 - val_loss: 22.1719\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.5193 - val_loss: 22.5847\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.5512 - val_loss: 22.1981\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.5201 - val_loss: 22.3559\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.3998 - val_loss: 22.3815\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 20.4361 - val_loss: 22.2127\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 65.0130 - val_loss: 48.8555\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 46.2522 - val_loss: 44.8300\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 43.5262 - val_loss: 44.3910\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 41.6070 - val_loss: 43.5371\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.5029 - val_loss: 40.3242\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 39.0566 - val_loss: 40.8707\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 39.5151 - val_loss: 42.2423\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.7102 - val_loss: 39.0852\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.6566 - val_loss: 40.0767\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.6495 - val_loss: 37.7910\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.5789 - val_loss: 39.2216\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.8414 - val_loss: 37.1589\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.8763 - val_loss: 38.4944\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.0427 - val_loss: 37.3888\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.3548 - val_loss: 38.3060\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.2133 - val_loss: 40.2036\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.5645 - val_loss: 35.9924\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.7069 - val_loss: 35.5373\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.0892 - val_loss: 34.8376\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.7341 - val_loss: 35.3507\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.8871 - val_loss: 35.7205\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.8319 - val_loss: 35.0689\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.4684 - val_loss: 36.4041\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.4095 - val_loss: 34.4993\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.7320 - val_loss: 33.9258\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.8471 - val_loss: 34.8755\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 32.8694 - val_loss: 33.3551\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.6131 - val_loss: 35.2440\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.6987 - val_loss: 33.4981\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.2762 - val_loss: 32.8681\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.2745 - val_loss: 32.5506\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.5855 - val_loss: 32.4935\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.2844 - val_loss: 33.0660\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.2584 - val_loss: 34.9628\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.1154 - val_loss: 32.2529\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.0791 - val_loss: 31.2761\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 29.5101 - val_loss: 30.7349\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.6967 - val_loss: 30.5513\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.7142 - val_loss: 30.6017\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.2770 - val_loss: 29.9464\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.4606 - val_loss: 29.0061\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 27.8369 - val_loss: 28.2228\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.6109 - val_loss: 27.7024\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.0026 - val_loss: 26.7986\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 25.5798 - val_loss: 26.2119\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.8195 - val_loss: 25.8312\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 24.2609 - val_loss: 25.0530\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.2938 - val_loss: 25.6728\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.9006 - val_loss: 24.8207\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 23.9288 - val_loss: 25.5926\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.6276 - val_loss: 24.1992\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.1873 - val_loss: 24.3483\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.2237 - val_loss: 24.2804\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.9340 - val_loss: 23.7029\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.7326 - val_loss: 23.5865\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.6632 - val_loss: 23.4668\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.4399 - val_loss: 23.5968\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.3002 - val_loss: 23.2744\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.2531 - val_loss: 23.6076\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.2085 - val_loss: 23.1191\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0215 - val_loss: 23.0137\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 21.9044 - val_loss: 22.9173\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.8993 - val_loss: 22.9115\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8659 - val_loss: 22.8880\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.7751 - val_loss: 22.7711\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.7893 - val_loss: 22.9968\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.8687 - val_loss: 22.8409\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6366 - val_loss: 22.6699\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.3868 - val_loss: 22.9085\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.3730 - val_loss: 22.6352\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.3068 - val_loss: 22.7027\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.3681 - val_loss: 22.5023\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.1204 - val_loss: 22.5091\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.2217 - val_loss: 22.6058\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 608us/step - loss: 21.2437 - val_loss: 22.4754\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 20.9595 - val_loss: 22.4452\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.0023 - val_loss: 22.3479\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 20.9373 - val_loss: 22.3455\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.7767 - val_loss: 22.3914\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.7060 - val_loss: 22.2812\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.8867 - val_loss: 22.4794\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.6212 - val_loss: 22.3314\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.7777 - val_loss: 23.3035\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.8629 - val_loss: 22.5654\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.5056 - val_loss: 22.2123\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 20.4310 - val_loss: 22.2336\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 20.3404 - val_loss: 22.3195\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.3036 - val_loss: 22.2470\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.3383 - val_loss: 22.2703\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.3362 - val_loss: 22.2969\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.3568 - val_loss: 49.5007\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 49.4783 - val_loss: 47.0611\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 45.4796 - val_loss: 43.3488\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 43.5235 - val_loss: 43.2708\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 42.5304 - val_loss: 42.8844\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 42.2200 - val_loss: 42.6411\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 41.1646 - val_loss: 43.2002\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 40.5218 - val_loss: 39.2202\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 39.0827 - val_loss: 41.4887\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.3393 - val_loss: 39.2040\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 39.5669 - val_loss: 38.6222\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 39.1673 - val_loss: 43.5055\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 38.3890 - val_loss: 36.8548\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.9755 - val_loss: 39.0990\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.7808 - val_loss: 35.8011\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 35.7849 - val_loss: 35.6101\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 35.4702 - val_loss: 37.4491\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.2066 - val_loss: 34.0735\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.6925 - val_loss: 33.9490\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.6692 - val_loss: 34.3956\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 34.8784 - val_loss: 36.1560\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.7237 - val_loss: 35.9849\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.7013 - val_loss: 33.7533\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 32.5651 - val_loss: 33.1790\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.1661 - val_loss: 31.8819\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 31.0697 - val_loss: 31.2351\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.5909 - val_loss: 30.4985\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.7648 - val_loss: 29.7626\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.6748 - val_loss: 28.9418\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 27.8618 - val_loss: 28.3348\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.8991 - val_loss: 26.9642\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.0072 - val_loss: 26.4129\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.5673 - val_loss: 26.1082\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 25.0971 - val_loss: 25.8932\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 24.9063 - val_loss: 25.9411\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 24.8771 - val_loss: 25.3464\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 24.4586 - val_loss: 25.0484\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.1889 - val_loss: 24.8927\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.9120 - val_loss: 24.7743\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 23.8288 - val_loss: 24.6301\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.5780 - val_loss: 24.4700\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.4426 - val_loss: 24.3079\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.2795 - val_loss: 24.1922\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.1772 - val_loss: 24.4181\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.0533 - val_loss: 24.1422\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 442us/step - loss: 23.1270 - val_loss: 23.9076\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 363us/step - loss: 22.7768 - val_loss: 23.8771\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 22.5849 - val_loss: 23.7255\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 22.4955 - val_loss: 23.8171\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 545us/step - loss: 22.3399 - val_loss: 23.5733\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.3112 - val_loss: 23.5993\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 544us/step - loss: 22.2239 - val_loss: 23.6553\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 22.0725 - val_loss: 23.3150\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 539us/step - loss: 22.0922 - val_loss: 23.4420\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 549us/step - loss: 21.8675 - val_loss: 23.2508\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 566us/step - loss: 21.7941 - val_loss: 23.3197\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.8624 - val_loss: 23.3579\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 21.8900 - val_loss: 23.2728\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 21.6675 - val_loss: 23.1055\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.3630 - val_loss: 23.0864\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 21.2928 - val_loss: 23.0626\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 658us/step - loss: 21.3433 - val_loss: 23.0278\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.2616 - val_loss: 23.0009\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.2784 - val_loss: 23.2422\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.1972 - val_loss: 22.8147\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 20.9625 - val_loss: 22.8446\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.8990 - val_loss: 22.9761\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.7889 - val_loss: 22.7818\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.7973 - val_loss: 22.8210\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 21.1643 - val_loss: 23.7986\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 20.9383 - val_loss: 22.9406\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 20.6828 - val_loss: 22.8701\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 20.5095 - val_loss: 22.9977\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.1016 - val_loss: 48.7974\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 44.9681 - val_loss: 42.5836\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 41.6853 - val_loss: 41.3861\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 41.9588 - val_loss: 40.3447\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 41.3117 - val_loss: 39.7140\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 39.8792 - val_loss: 44.0725\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 40.2054 - val_loss: 39.6800\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 39.9399 - val_loss: 42.4713\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 39.7762 - val_loss: 40.0042\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 39.3923 - val_loss: 37.8261\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 38.4040 - val_loss: 37.7986\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.4609 - val_loss: 37.2220\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 37.5864 - val_loss: 37.0872\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 36.8915 - val_loss: 40.0231\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 903us/step - loss: 38.2665 - val_loss: 38.1933\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 36.6291 - val_loss: 35.8054\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 846us/step - loss: 35.5623 - val_loss: 35.2758\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 905us/step - loss: 36.9720 - val_loss: 36.2794\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 796us/step - loss: 38.1645 - val_loss: 42.3437\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.3093 - val_loss: 39.8516\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.1510 - val_loss: 34.6755\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.7069 - val_loss: 35.9095\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 562us/step - loss: 34.5747 - val_loss: 34.0382\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 33.3798 - val_loss: 33.2901\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 33.9597 - val_loss: 35.9729\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.0782 - val_loss: 36.3202\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.8240 - val_loss: 34.1318\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.2660 - val_loss: 35.5900\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 32.8866 - val_loss: 32.9947\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.0935 - val_loss: 32.3664\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.7464 - val_loss: 32.3304\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.4980 - val_loss: 31.6337\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.6245 - val_loss: 31.5559\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 31.8013 - val_loss: 32.0910\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.6816 - val_loss: 32.8792\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.9988 - val_loss: 32.6000\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.1847 - val_loss: 31.2930\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 30.8792 - val_loss: 31.2120\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.2397 - val_loss: 30.5005\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.3053 - val_loss: 30.5512\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 30.6619 - val_loss: 32.3614\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.1835 - val_loss: 30.1044\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 30.3191 - val_loss: 32.9717\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.6983 - val_loss: 31.3339\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 30.3615 - val_loss: 30.3469\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 29.3490 - val_loss: 29.2548\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 28.4334 - val_loss: 29.4358\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.6093 - val_loss: 28.7543\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 28.6551 - val_loss: 30.0738\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 28.3119 - val_loss: 28.3821\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 27.1840 - val_loss: 28.5690\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.3606 - val_loss: 27.8798\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 26.6535 - val_loss: 27.2604\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 26.5915 - val_loss: 26.8453\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 25.8204 - val_loss: 26.3535\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.0992 - val_loss: 25.6576\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 24.5961 - val_loss: 25.9038\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 24.8615 - val_loss: 25.1832\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.6931 - val_loss: 24.8763\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.8158 - val_loss: 24.4182\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 23.7242 - val_loss: 24.5889\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.4790 - val_loss: 24.0257\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.2690 - val_loss: 23.8665\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.1687 - val_loss: 23.8803\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 23.1175 - val_loss: 23.6964\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 613us/step - loss: 22.9360 - val_loss: 23.8217\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 22.8569 - val_loss: 23.7730\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.7342 - val_loss: 23.7542\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.5241 - val_loss: 23.3168\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.4992 - val_loss: 23.3388\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.4161 - val_loss: 23.2246\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 22.3099 - val_loss: 23.3452\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 22.1984 - val_loss: 23.1282\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 22.1510 - val_loss: 23.2770\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.1020 - val_loss: 23.0070\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.9426 - val_loss: 22.9112\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 21.8463 - val_loss: 22.8660\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 21.8628 - val_loss: 22.9387\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 21.7732 - val_loss: 22.7841\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 21.6860 - val_loss: 22.7697\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 21.7472 - val_loss: 22.7047\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 711us/step - loss: 21.5948 - val_loss: 22.7102\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.5620 - val_loss: 22.6098\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 21.4612 - val_loss: 22.6450\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.5056 - val_loss: 22.6373\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.4924 - val_loss: 22.8045\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.4079 - val_loss: 22.6422\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.6192 - val_loss: 22.8552\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 76.4163 - val_loss: 53.0009\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 583us/step - loss: 48.8873 - val_loss: 44.2159\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 42.9800 - val_loss: 42.7487\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 41.6669 - val_loss: 40.3319\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.2894 - val_loss: 39.1593\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 39.4515 - val_loss: 39.2253\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.6006 - val_loss: 37.5422\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 36.9747 - val_loss: 37.4438\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.1486 - val_loss: 36.4490\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.9221 - val_loss: 35.8715\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.1987 - val_loss: 37.1019\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.7845 - val_loss: 40.5963\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.9166 - val_loss: 35.3874\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 36.2348 - val_loss: 36.5374\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.1288 - val_loss: 35.2890\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.5971 - val_loss: 35.1823\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.8371 - val_loss: 34.0761\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.2363 - val_loss: 34.9408\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.1540 - val_loss: 33.9101\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.1124 - val_loss: 35.6347\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.6393 - val_loss: 35.3300\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 34.3682 - val_loss: 34.2998\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.3980 - val_loss: 33.3320\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.9511 - val_loss: 33.5749\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.5578 - val_loss: 33.0056\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 32.5641 - val_loss: 32.3165\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.9415 - val_loss: 33.8482\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.2000 - val_loss: 32.1996\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 31.7487 - val_loss: 32.3501\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 31.4032 - val_loss: 32.1087\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 30.4664 - val_loss: 34.3086\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.8650 - val_loss: 31.5626\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.8928 - val_loss: 30.4818\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.7173 - val_loss: 30.6977\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 29.5848 - val_loss: 30.5226\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.1101 - val_loss: 30.7454\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 30.3180 - val_loss: 31.7574\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.3985 - val_loss: 32.9230\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.6798 - val_loss: 47.9176\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 44.3146 - val_loss: 42.0251\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 41.2919 - val_loss: 42.5336\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.1424 - val_loss: 39.9068\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.5304 - val_loss: 40.5076\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 38.9211 - val_loss: 38.8013\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.8403 - val_loss: 38.0066\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.8022 - val_loss: 41.6193\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.7406 - val_loss: 38.3316\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 36.5109 - val_loss: 38.7372\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 37.9702 - val_loss: 42.9885\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 37.1575 - val_loss: 36.9183\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.6774 - val_loss: 37.9774\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 38.7535 - val_loss: 37.7451\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.8962 - val_loss: 37.3129\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.6309 - val_loss: 40.7202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.0061 - val_loss: 36.4848\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.6179 - val_loss: 35.2504\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 34.2472 - val_loss: 38.1017\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.8573 - val_loss: 36.6947\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.9387 - val_loss: 35.6423\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 758us/step - loss: 33.4549 - val_loss: 34.1787\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 744us/step - loss: 33.6224 - val_loss: 34.8515\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 749us/step - loss: 35.8404 - val_loss: 35.7695\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 889us/step - loss: 35.2148 - val_loss: 35.0315\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.1704 - val_loss: 33.9948\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.4091 - val_loss: 35.8112\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.5280 - val_loss: 35.2701\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.6477 - val_loss: 33.6475\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.0724 - val_loss: 33.2580\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.6969 - val_loss: 33.9265\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.2354 - val_loss: 33.1785\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.6154 - val_loss: 33.3042\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.4654 - val_loss: 33.2967\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 33.2437 - val_loss: 35.6695\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.4037 - val_loss: 32.9937\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.6167 - val_loss: 32.3033\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.4324 - val_loss: 33.0676\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 30.8746 - val_loss: 31.7045\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.1210 - val_loss: 32.3893\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 30.0581 - val_loss: 31.1430\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.4490 - val_loss: 32.5292\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.1142 - val_loss: 31.3773\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.7278 - val_loss: 31.6312\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 29.0254 - val_loss: 30.2862\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.1506 - val_loss: 30.4976\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 29.8078 - val_loss: 31.1493\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.5343 - val_loss: 33.0154\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.0069 - val_loss: 30.3205\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 29.2997 - val_loss: 30.8471\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.0228 - val_loss: 53.4982\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 46.4682 - val_loss: 44.2447\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 43.6016 - val_loss: 42.7373\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 43.0623 - val_loss: 45.2545\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 45.0324 - val_loss: 42.7279\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 43.2609 - val_loss: 42.8172\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 42.0721 - val_loss: 40.5433\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 40.6041 - val_loss: 42.3355\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 41.0878 - val_loss: 38.9218\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 39.5829 - val_loss: 38.2773\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.9109 - val_loss: 37.9686\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 38.0975 - val_loss: 41.5475\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 38.8617 - val_loss: 37.7810\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 38.6036 - val_loss: 36.6184\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.7896 - val_loss: 36.7489\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.0019 - val_loss: 35.8715\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.2765 - val_loss: 36.0118\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.0433 - val_loss: 36.3015\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.9276 - val_loss: 38.2499\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.1211 - val_loss: 35.9496\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 36.2851 - val_loss: 35.0106\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.9080 - val_loss: 35.2260\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.7400 - val_loss: 36.6708\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.7002 - val_loss: 32.9711\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.2564 - val_loss: 32.2238\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.6787 - val_loss: 31.6583\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.4436 - val_loss: 31.1968\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.3529 - val_loss: 34.2056\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 33.3955 - val_loss: 33.1567\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.5691 - val_loss: 30.6673\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.8785 - val_loss: 30.0144\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 28.8956 - val_loss: 28.8135\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.1842 - val_loss: 29.1848\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 27.6404 - val_loss: 27.7034\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.9633 - val_loss: 26.6599\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 25.9537 - val_loss: 26.0999\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.6084 - val_loss: 27.1942\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.0154 - val_loss: 25.1478\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 24.6927 - val_loss: 24.7565\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.2092 - val_loss: 24.2858\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.9652 - val_loss: 24.3018\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.9448 - val_loss: 23.9751\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.3632 - val_loss: 24.2174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.2740 - val_loss: 23.6429\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 23.1256 - val_loss: 23.6134\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.8937 - val_loss: 23.3491\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 22.8063 - val_loss: 23.9530\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.8225 - val_loss: 23.4304\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.5447 - val_loss: 23.1067\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.4154 - val_loss: 23.0216\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 22.3354 - val_loss: 22.8739\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.1876 - val_loss: 22.8848\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.0682 - val_loss: 22.8740\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.0116 - val_loss: 22.8284\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.0383 - val_loss: 22.6844\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.8529 - val_loss: 23.0280\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.0573 - val_loss: 22.7879\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8214 - val_loss: 22.5917\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6048 - val_loss: 22.5522\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.5944 - val_loss: 22.4435\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.4327 - val_loss: 22.3452\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.4785 - val_loss: 23.0872\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.7887 - val_loss: 22.4990\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.4286 - val_loss: 22.4577\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.1373 - val_loss: 22.3190\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.1339 - val_loss: 22.2454\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.0656 - val_loss: 22.3009\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 20.9893 - val_loss: 22.2538\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 21.0693 - val_loss: 22.2468\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.8994 - val_loss: 22.1139\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 21.0240 - val_loss: 22.4780\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 20.8949 - val_loss: 22.1623\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.8061 - val_loss: 22.1271\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.3031 - val_loss: 22.9463\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.0749 - val_loss: 22.1457\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.0503 - val_loss: 50.1950\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 47.0214 - val_loss: 44.6416\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 42.3981 - val_loss: 42.0456\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 41.1240 - val_loss: 43.0138\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.6176 - val_loss: 40.1779\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.4176 - val_loss: 40.0874\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 41.2863 - val_loss: 40.1344\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 41.0677 - val_loss: 41.6680\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 38.6767 - val_loss: 38.4105\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 39.0551 - val_loss: 40.5370\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 37.6115 - val_loss: 37.2625\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.0452 - val_loss: 37.2344\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.5912 - val_loss: 38.2504\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.5593 - val_loss: 37.2213\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.9668 - val_loss: 40.2023\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.6187 - val_loss: 37.5016\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.0760 - val_loss: 35.1416\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.2314 - val_loss: 37.8505\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.1730 - val_loss: 36.5130\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 36.0706 - val_loss: 38.3062\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 34.8930 - val_loss: 35.0896\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 34.6233 - val_loss: 34.2084\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.9312 - val_loss: 36.6167\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 33.1404 - val_loss: 34.4232\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.2665 - val_loss: 33.8861\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.9325 - val_loss: 32.7738\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 32.1792 - val_loss: 32.8386\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.9377 - val_loss: 33.6925\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.4531 - val_loss: 35.9549\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.0187 - val_loss: 31.7259\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.2448 - val_loss: 32.6145\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.4104 - val_loss: 34.2023\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.7277 - val_loss: 37.3218\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.3110 - val_loss: 31.5939\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.3708 - val_loss: 30.9249\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.7669 - val_loss: 30.7889\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.0863 - val_loss: 31.5990\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 29.6447 - val_loss: 32.5060\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 30.2700 - val_loss: 31.0104\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 29.7890 - val_loss: 30.1832\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 28.6047 - val_loss: 29.3658\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 28.4415 - val_loss: 31.5909\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 29.2218 - val_loss: 31.7691\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 29.0376 - val_loss: 30.3517\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 29.6177 - val_loss: 32.0893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 28.2860 - val_loss: 29.8948\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.4294 - val_loss: 46.7097\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 46.4554 - val_loss: 43.1681\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 43.9810 - val_loss: 42.0794\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 41.1425 - val_loss: 40.7964\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 41.4617 - val_loss: 41.6870\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 40.4502 - val_loss: 41.2390\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 38.5513 - val_loss: 38.5211\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 39.0354 - val_loss: 38.7315\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 38.3829 - val_loss: 41.9578\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.4753 - val_loss: 39.2970\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 38.9035 - val_loss: 41.7612\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.1831 - val_loss: 38.8764\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.1639 - val_loss: 58.6007\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 49.2279 - val_loss: 46.8174\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 43.2361 - val_loss: 43.1639\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 41.0952 - val_loss: 41.9120\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 39.9492 - val_loss: 40.3909\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.2411 - val_loss: 39.3982\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 39.7186 - val_loss: 43.4372\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 40.3061 - val_loss: 40.2427\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.7742 - val_loss: 39.4518\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.2856 - val_loss: 36.6723\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 36.2244 - val_loss: 37.4228\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.0358 - val_loss: 36.7516\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.7480 - val_loss: 35.7080\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.0270 - val_loss: 34.3294\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 33.6470 - val_loss: 34.7288\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.1790 - val_loss: 34.9244\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 34.5160 - val_loss: 38.2406\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.5503 - val_loss: 33.8137\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 32.4556 - val_loss: 33.1138\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.5273 - val_loss: 33.7871\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.9615 - val_loss: 33.0001\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.9136 - val_loss: 34.8893\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.4529 - val_loss: 32.9398\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.0295 - val_loss: 32.4754\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 30.6184 - val_loss: 32.0045\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.2328 - val_loss: 32.2457\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.3480 - val_loss: 37.1380\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 31.6673 - val_loss: 32.7518\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.5893 - val_loss: 31.0101\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 29.8266 - val_loss: 31.1188\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.5086 - val_loss: 32.2970\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 29.9559 - val_loss: 30.8029\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.1637 - val_loss: 30.7318\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 29.1045 - val_loss: 30.6985\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 28.3297 - val_loss: 30.3289\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 29.6898 - val_loss: 30.0844\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.2273 - val_loss: 30.0752\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.1953 - val_loss: 30.7331\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 27.8675 - val_loss: 31.3881\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.0443 - val_loss: 28.6800\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.7191 - val_loss: 28.0377\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 26.2440 - val_loss: 27.4543\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.9102 - val_loss: 29.0071\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.1337 - val_loss: 29.8254\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 26.1424 - val_loss: 26.7867\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.8604 - val_loss: 27.5750\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 25.2002 - val_loss: 25.8862\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 24.6386 - val_loss: 26.1565\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 25.0466 - val_loss: 26.0123\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 24.4341 - val_loss: 25.1353\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 23.7469 - val_loss: 24.9121\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.5300 - val_loss: 24.6312\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.7412 - val_loss: 24.8882\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.4275 - val_loss: 24.4210\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.1761 - val_loss: 24.6613\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 663us/step - loss: 23.2482 - val_loss: 24.5540\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.3793 - val_loss: 24.5418\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.7922 - val_loss: 23.9277\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.6267 - val_loss: 24.4598\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.5515 - val_loss: 23.6472\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.4985 - val_loss: 24.4706\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.4088 - val_loss: 24.0281\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.2984 - val_loss: 23.5350\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.1603 - val_loss: 23.5902\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.1799 - val_loss: 23.7376\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.0461 - val_loss: 23.7203\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.1294 - val_loss: 23.3082\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.1201 - val_loss: 23.2494\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 22.0395 - val_loss: 23.4477\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.7486 - val_loss: 23.1698\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.6895 - val_loss: 23.0980\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.5413 - val_loss: 23.1428\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5595 - val_loss: 23.0577\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.6298 - val_loss: 23.7388\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.4845 - val_loss: 23.2682\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5937 - val_loss: 23.1207\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.2529 - val_loss: 23.0415\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.2409 - val_loss: 22.8904\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.4431 - val_loss: 23.0672\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.5834 - val_loss: 23.1524\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.1812 - val_loss: 22.8557\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.1731 - val_loss: 22.9641\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.1164 - val_loss: 22.8034\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.1566 - val_loss: 23.2988\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 21.0806 - val_loss: 22.8916\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.8700 - val_loss: 22.7838\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.8951 - val_loss: 22.8991\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.7516 - val_loss: 22.7357\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.6844 - val_loss: 23.0093\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.7037 - val_loss: 23.3503\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.9553 - val_loss: 22.7529\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.8967 - val_loss: 23.1521\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.6196 - val_loss: 22.7672\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 63.1857 - val_loss: 54.7324\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 48.6365 - val_loss: 43.1780\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 42.4660 - val_loss: 41.0127\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 40.8326 - val_loss: 38.8618\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 39.4669 - val_loss: 38.8724\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 41.2046 - val_loss: 38.2257\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.9741 - val_loss: 37.4477\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.4538 - val_loss: 37.6518\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.4397 - val_loss: 36.8708\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 37.3883 - val_loss: 36.2506\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 37.3136 - val_loss: 35.5692\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.0724 - val_loss: 35.0383\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.5418 - val_loss: 34.7150\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.9850 - val_loss: 36.6771\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.7711 - val_loss: 36.5815\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.5702 - val_loss: 34.7017\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.2655 - val_loss: 34.2889\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.3742 - val_loss: 33.9173\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.0452 - val_loss: 34.0734\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.5521 - val_loss: 34.1167\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.8441 - val_loss: 33.4719\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 33.8412 - val_loss: 34.3673\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 34.0617 - val_loss: 33.6174\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.5981 - val_loss: 33.3976\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.0923 - val_loss: 32.5418\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.7003 - val_loss: 33.6832\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.6406 - val_loss: 35.8095\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.8708 - val_loss: 32.6072\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.0489 - val_loss: 32.5279\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.8242 - val_loss: 32.0239\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 32.5205 - val_loss: 35.3378\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.3994 - val_loss: 32.4742\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.0403 - val_loss: 31.7785\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.3262 - val_loss: 32.3966\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.9926 - val_loss: 31.2266\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.5975 - val_loss: 32.8875\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.5914 - val_loss: 33.4120\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.3947 - val_loss: 31.4156\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 31.8363 - val_loss: 31.3747\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.3893 - val_loss: 31.0038\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.0224 - val_loss: 31.8303\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.5452 - val_loss: 32.6331\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 763us/step - loss: 31.6989 - val_loss: 31.7704\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 30.8404 - val_loss: 30.2189\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.1703 - val_loss: 30.1553\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.0540 - val_loss: 30.6941\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 29.3492 - val_loss: 29.8303\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 612us/step - loss: 30.5929 - val_loss: 31.5853\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 29.7437 - val_loss: 30.4983\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.9410 - val_loss: 29.2594\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 27.9855 - val_loss: 29.1652\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 29.2231 - val_loss: 29.0780\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.9248 - val_loss: 28.6169\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.2638 - val_loss: 28.5417\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.9037 - val_loss: 29.1881\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.0829 - val_loss: 27.4358\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 26.4184 - val_loss: 27.7476\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.9777 - val_loss: 26.1482\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.7529 - val_loss: 25.6432\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.5716 - val_loss: 25.3920\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 24.9198 - val_loss: 24.6909\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 23.9948 - val_loss: 24.1913\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.6105 - val_loss: 24.1586\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.3526 - val_loss: 23.6652\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.0643 - val_loss: 23.3971\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.8308 - val_loss: 23.5885\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.1423 - val_loss: 23.9285\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.8207 - val_loss: 23.1516\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.4709 - val_loss: 23.0745\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.5831 - val_loss: 22.9142\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.3321 - val_loss: 22.8888\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.2040 - val_loss: 22.7659\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 22.1984 - val_loss: 22.7018\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.0561 - val_loss: 22.5596\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.9224 - val_loss: 22.4985\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.8656 - val_loss: 22.5364\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.9066 - val_loss: 22.4073\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 21.7111 - val_loss: 22.3247\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.6480 - val_loss: 22.3611\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.5940 - val_loss: 22.2380\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.5497 - val_loss: 22.1854\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4540 - val_loss: 22.0955\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.4309 - val_loss: 22.3678\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.5160 - val_loss: 22.1437\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.3351 - val_loss: 22.2155\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.3891 - val_loss: 22.0760\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.2860 - val_loss: 22.1498\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.2548 - val_loss: 21.9988\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.6421 - val_loss: 21.9594\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.1236 - val_loss: 22.0924\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.2245 - val_loss: 21.9474\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.0649 - val_loss: 21.8814\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0340 - val_loss: 23.4941\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5372 - val_loss: 21.8656\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.1011 - val_loss: 21.8365\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 20.8797 - val_loss: 21.8460\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 20.8029 - val_loss: 21.8513\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.7653 - val_loss: 21.8219\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.8205 - val_loss: 22.1530\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9108 - val_loss: 21.8714\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 94.9335 - val_loss: 56.3110\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 48.6846 - val_loss: 45.2138\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 44.2904 - val_loss: 42.8445\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 42.1865 - val_loss: 41.3684\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 41.4131 - val_loss: 39.9961\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 40.6146 - val_loss: 38.5894\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 41.2988 - val_loss: 42.1134\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 39.0129 - val_loss: 38.7470\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.9208 - val_loss: 36.8716\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 38.6068 - val_loss: 37.3069\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 36.3020 - val_loss: 35.7620\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.5758 - val_loss: 36.6293\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.3015 - val_loss: 38.1964\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 36.9483 - val_loss: 38.8371\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 36.8132 - val_loss: 38.7982\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.1235 - val_loss: 35.1158\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.9113 - val_loss: 33.5290\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 33.5832 - val_loss: 37.2807\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.6939 - val_loss: 33.6865\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 33.2860 - val_loss: 34.2979\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.6964 - val_loss: 33.2759\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.1207 - val_loss: 31.9489\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.7245 - val_loss: 32.4093\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 33.0129 - val_loss: 33.6048\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 633us/step - loss: 32.7540 - val_loss: 33.2577\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.2881 - val_loss: 32.9361\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.3794 - val_loss: 31.4579\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.9408 - val_loss: 31.9478\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.6480 - val_loss: 30.4160\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.0909 - val_loss: 31.1424\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 756us/step - loss: 29.8847 - val_loss: 29.8704\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 694us/step - loss: 29.4236 - val_loss: 30.2657\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 730us/step - loss: 29.6463 - val_loss: 30.1976\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 764us/step - loss: 28.8646 - val_loss: 28.7117\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 840us/step - loss: 28.1590 - val_loss: 28.8812\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.9107 - val_loss: 29.1687\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.5504 - val_loss: 30.0051\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 27.8068 - val_loss: 27.6303\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.0998 - val_loss: 27.6203\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.7783 - val_loss: 26.7022\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 26.1373 - val_loss: 26.7395\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 25.5703 - val_loss: 25.6599\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.9252 - val_loss: 24.9830\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 713us/step - loss: 24.2431 - val_loss: 24.7758\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 24.1542 - val_loss: 24.6039\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 23.8922 - val_loss: 24.3414\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.7353 - val_loss: 24.4998\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 23.5576 - val_loss: 24.2970\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 23.4152 - val_loss: 23.9278\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.2671 - val_loss: 24.1924\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 23.2166 - val_loss: 23.7260\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0084 - val_loss: 23.6858\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0405 - val_loss: 23.7240\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.8937 - val_loss: 23.5072\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.7360 - val_loss: 23.4864\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.7605 - val_loss: 23.3962\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.1334 - val_loss: 23.9866\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 22.8787 - val_loss: 23.3326\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 22.3884 - val_loss: 23.2040\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.3326 - val_loss: 23.3525\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.2109 - val_loss: 23.1498\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.1811 - val_loss: 23.4635\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 22.0647 - val_loss: 23.0431\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.1110 - val_loss: 23.5864\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.1077 - val_loss: 23.0885\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.0312 - val_loss: 23.0049\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.8336 - val_loss: 22.8730\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.9174 - val_loss: 22.7901\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.6816 - val_loss: 22.9100\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.6356 - val_loss: 22.8673\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.6488 - val_loss: 22.9862\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.8585 - val_loss: 22.7434\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.5362 - val_loss: 22.7076\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.3948 - val_loss: 22.6570\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.3597 - val_loss: 22.5762\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.2580 - val_loss: 22.6009\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.1961 - val_loss: 22.6269\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.1847 - val_loss: 22.6592\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.1909 - val_loss: 22.6655\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.0804 - val_loss: 22.6068\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.9651 - val_loss: 50.9058\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 47.5102 - val_loss: 44.3223\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 42.4755 - val_loss: 40.8991\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.3614 - val_loss: 39.9934\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.7623 - val_loss: 39.4122\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.4939 - val_loss: 40.3162\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 38.4482 - val_loss: 37.8205\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.7543 - val_loss: 36.6159\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.2289 - val_loss: 39.9511\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.4289 - val_loss: 35.5047\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.9857 - val_loss: 36.6502\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 580us/step - loss: 35.8359 - val_loss: 35.2064\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.9358 - val_loss: 36.8428\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 36.3352 - val_loss: 36.3479\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.2686 - val_loss: 38.3829\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.7341 - val_loss: 35.6039\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.0171 - val_loss: 35.1203\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.9626 - val_loss: 35.9046\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 36.4282 - val_loss: 35.0062\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.3834 - val_loss: 36.3531\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 34.1457 - val_loss: 34.4253\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 622us/step - loss: 33.8062 - val_loss: 34.4844\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.7941 - val_loss: 34.5466\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 33.1458 - val_loss: 33.2122\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 32.7311 - val_loss: 34.6716\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.1184 - val_loss: 38.9587\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 36.1454 - val_loss: 34.1531\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.3811 - val_loss: 34.0168\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 33.6619 - val_loss: 34.8907\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.1340 - val_loss: 53.5569\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 47.7088 - val_loss: 43.0353\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 44.6740 - val_loss: 40.3969\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 41.9588 - val_loss: 39.5833\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 40.4537 - val_loss: 38.0066\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.1113 - val_loss: 37.3757\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.9502 - val_loss: 37.5066\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.9042 - val_loss: 36.3351\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.7993 - val_loss: 35.2057\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.9269 - val_loss: 38.4873\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 37.3965 - val_loss: 38.6792\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 36.8350 - val_loss: 36.2670\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 35.9772 - val_loss: 34.3695\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 36.1971 - val_loss: 37.3149\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 35.7370 - val_loss: 33.7976\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.8095 - val_loss: 37.5171\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.6966 - val_loss: 33.4381\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.3962 - val_loss: 35.1469\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.4044 - val_loss: 33.0013\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.5650 - val_loss: 33.6452\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.3916 - val_loss: 33.9057\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 32.8170 - val_loss: 34.0406\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 33.8295 - val_loss: 34.5845\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 33.2424 - val_loss: 32.9765\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 32.5803 - val_loss: 31.1119\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.6885 - val_loss: 31.7252\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 32.2575 - val_loss: 31.9600\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 31.5385 - val_loss: 30.5570\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.2204 - val_loss: 30.5612\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 30.8490 - val_loss: 34.4971\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.4947 - val_loss: 30.9937\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.3522 - val_loss: 30.2838\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 30.8013 - val_loss: 32.1908\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 31.1064 - val_loss: 30.9352\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.2746 - val_loss: 30.1933\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 30.0434 - val_loss: 31.9287\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 29.6329 - val_loss: 29.3758\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 29.3608 - val_loss: 29.1122\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 29.6744 - val_loss: 29.5257\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 28.7745 - val_loss: 28.8365\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 28.2840 - val_loss: 29.0194\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 29.8638 - val_loss: 33.8506\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.3016 - val_loss: 28.8461\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 28.7662 - val_loss: 28.3977\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.3463 - val_loss: 27.6015\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 28.4414 - val_loss: 28.1677\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 28.0540 - val_loss: 28.0695\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 27.3934 - val_loss: 26.9452\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 26.1283 - val_loss: 26.5418\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 26.0012 - val_loss: 26.3169\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 25.3942 - val_loss: 25.7417\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 26.1247 - val_loss: 25.8324\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 24.8234 - val_loss: 25.4778\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 24.7299 - val_loss: 25.1443\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.3001 - val_loss: 24.7501\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.7436 - val_loss: 25.3810\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.5138 - val_loss: 25.1064\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 23.8288 - val_loss: 24.5033\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.6995 - val_loss: 24.0895\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 23.5691 - val_loss: 24.1884\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.2853 - val_loss: 24.1507\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 23.3616 - val_loss: 24.0146\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.2021 - val_loss: 23.7458\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.8067 - val_loss: 23.5660\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.6627 - val_loss: 23.3592\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.9173 - val_loss: 23.9609\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.7835 - val_loss: 23.2926\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 22.4084 - val_loss: 23.3864\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 22.4983 - val_loss: 23.1124\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 625us/step - loss: 22.3333 - val_loss: 23.0239\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.1317 - val_loss: 23.0465\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.1629 - val_loss: 23.0788\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.1834 - val_loss: 22.9208\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.1067 - val_loss: 22.7898\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.9669 - val_loss: 22.7881\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.9162 - val_loss: 23.3982\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 21.8995 - val_loss: 22.9539\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 21.8404 - val_loss: 22.7953\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 21.6807 - val_loss: 22.6126\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.6107 - val_loss: 22.7001\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.5982 - val_loss: 22.7893\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.6046 - val_loss: 22.6093\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.4376 - val_loss: 22.6398\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.3786 - val_loss: 22.6318\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.6161 - val_loss: 22.8689\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.4162 - val_loss: 22.5277\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.3337 - val_loss: 22.6431\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.2124 - val_loss: 22.4408\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.2116 - val_loss: 22.5119\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.2517 - val_loss: 22.4202\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.1333 - val_loss: 22.4943\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 21.1019 - val_loss: 22.4165\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 20.9806 - val_loss: 22.6995\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.0481 - val_loss: 22.3997\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.9365 - val_loss: 22.5279\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 21.0855 - val_loss: 22.6116\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 20.9120 - val_loss: 22.4861\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.7582 - val_loss: 22.7017\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.7563 - val_loss: 22.6423\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 66.1641 - val_loss: 47.5428\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 45.3351 - val_loss: 42.3558\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 673us/step - loss: 41.9833 - val_loss: 45.1726\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 42.2359 - val_loss: 39.6047\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 41.7520 - val_loss: 39.4562\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 40.6951 - val_loss: 39.0227\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 38.8838 - val_loss: 37.1667\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 37.7146 - val_loss: 37.2735\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 37.4635 - val_loss: 36.5345\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 37.0436 - val_loss: 35.7087\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 36.3318 - val_loss: 37.0918\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 37.4855 - val_loss: 35.4798\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 35.4254 - val_loss: 35.0072\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 35.1465 - val_loss: 34.4486\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 37.8197 - val_loss: 39.7413\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.8136 - val_loss: 34.0568\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.1748 - val_loss: 34.2353\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 33.8353 - val_loss: 34.8746\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 34.4527 - val_loss: 33.6808\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 34.1917 - val_loss: 34.7651\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 33.9253 - val_loss: 32.9684\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 32.6637 - val_loss: 32.8657\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 33.5280 - val_loss: 32.8062\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 33.1248 - val_loss: 32.5836\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 679us/step - loss: 32.5035 - val_loss: 32.7403\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 31.8592 - val_loss: 31.9425\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 32.2854 - val_loss: 33.7056\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 32.1869 - val_loss: 31.5454\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 31.5984 - val_loss: 33.2622\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 32.1718 - val_loss: 32.4564\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 32.3888 - val_loss: 31.4267\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 31.5110 - val_loss: 31.9058\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 668us/step - loss: 31.3959 - val_loss: 30.5601\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 30.4140 - val_loss: 30.4370\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 30.1562 - val_loss: 30.1847\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 30.0288 - val_loss: 36.3546\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.7554 - val_loss: 29.7242\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 30.0217 - val_loss: 30.4584\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 678us/step - loss: 29.7055 - val_loss: 29.4003\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 30.2863 - val_loss: 29.6319\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 29.9424 - val_loss: 31.1377\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 29.2351 - val_loss: 29.0702\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 29.3089 - val_loss: 29.5542\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 29.1725 - val_loss: 31.3163\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 790us/step - loss: 29.1548 - val_loss: 30.4731\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 29.1656 - val_loss: 31.8424\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 995us/step - loss: 29.5727 - val_loss: 31.1504\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 1s 2ms/step - loss: 74.2942 - val_loss: 47.5102\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 46.7140 - val_loss: 43.0791\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 42.0313 - val_loss: 41.1273\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 41.0260 - val_loss: 41.6564\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 39.3072 - val_loss: 38.4604\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 37.7642 - val_loss: 38.8305\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.1443 - val_loss: 39.2885\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 36.2341 - val_loss: 36.1172\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 35.7363 - val_loss: 36.9295\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.9557 - val_loss: 35.3874\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.0430 - val_loss: 34.6612\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 34.8331 - val_loss: 35.5239\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.0844 - val_loss: 34.9104\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 34.2011 - val_loss: 35.7332\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.9998 - val_loss: 33.4132\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.7312 - val_loss: 33.6675\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.0620 - val_loss: 32.9141\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.2817 - val_loss: 32.5479\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.6109 - val_loss: 32.4053\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 32.5497 - val_loss: 33.8368\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.6966 - val_loss: 33.5021\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.8055 - val_loss: 31.7707\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.6447 - val_loss: 34.8023\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 32.0349 - val_loss: 31.3030\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.2954 - val_loss: 31.5005\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.9474 - val_loss: 31.7047\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 30.7046 - val_loss: 30.5799\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 31.8349 - val_loss: 30.9307\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.1810 - val_loss: 31.4246\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 31.1499 - val_loss: 31.2512\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 30.7491 - val_loss: 30.2505\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 29.9221 - val_loss: 31.3791\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 29.5574 - val_loss: 30.3608\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 28.7770 - val_loss: 29.3405\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 29.0882 - val_loss: 30.4898\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 727us/step - loss: 29.4781 - val_loss: 29.0090\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 29.8668 - val_loss: 29.1616\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.5428 - val_loss: 28.2568\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 27.4323 - val_loss: 27.9108\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 27.3918 - val_loss: 29.7767\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 28.3448 - val_loss: 28.2550\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 26.8444 - val_loss: 26.5892\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 26.6426 - val_loss: 26.6971\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 25.6447 - val_loss: 25.7231\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 25.3627 - val_loss: 26.2225\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.4577 - val_loss: 25.1618\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.1173 - val_loss: 24.2739\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.7752 - val_loss: 24.2502\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 23.7158 - val_loss: 23.8763\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.2356 - val_loss: 23.6511\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 22.9437 - val_loss: 23.4231\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.9687 - val_loss: 23.2214\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.7668 - val_loss: 23.3791\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 22.7143 - val_loss: 23.0890\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.5324 - val_loss: 22.9837\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.3363 - val_loss: 22.7913\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.1256 - val_loss: 22.7242\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.0941 - val_loss: 22.5812\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 21.9498 - val_loss: 22.5698\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 22.2602 - val_loss: 25.6532\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.0324 - val_loss: 22.7181\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.9034 - val_loss: 22.4516\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.8229 - val_loss: 22.3557\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 21.6455 - val_loss: 22.2966\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.7353 - val_loss: 22.3138\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.6233 - val_loss: 22.1275\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.8542 - val_loss: 22.6944\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.5874 - val_loss: 22.2980\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 21.3737 - val_loss: 21.9877\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.2435 - val_loss: 22.0101\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.1916 - val_loss: 21.9362\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 21.3026 - val_loss: 21.9460\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.0958 - val_loss: 21.7949\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.9746 - val_loss: 21.8572\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.0308 - val_loss: 21.9074\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.1076 - val_loss: 21.8174\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.8644 - val_loss: 21.6647\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.8654 - val_loss: 22.0820\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.8320 - val_loss: 22.0434\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.8129 - val_loss: 21.6179\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9318 - val_loss: 21.6217\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.8508 - val_loss: 22.0869\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.6701 - val_loss: 21.4703\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.4990 - val_loss: 21.4373\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.5009 - val_loss: 21.3808\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 20.4168 - val_loss: 21.4999\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.3694 - val_loss: 21.5417\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 20.3776 - val_loss: 21.4651\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 20.7159 - val_loss: 21.5508\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 20.8059 - val_loss: 21.3912\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 81.5022 - val_loss: 69.1220\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 65.3282 - val_loss: 48.3760\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 45.6748 - val_loss: 41.9360\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 44.1865 - val_loss: 40.2427\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 41.8029 - val_loss: 44.0231\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 42.0886 - val_loss: 42.4776\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 41.2478 - val_loss: 38.8344\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.4361 - val_loss: 37.7362\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.7512 - val_loss: 37.6319\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 39.5813 - val_loss: 38.2671\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.8743 - val_loss: 39.2183\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 40.3239 - val_loss: 36.7081\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.7697 - val_loss: 36.0760\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.1111 - val_loss: 36.0186\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.3648 - val_loss: 34.6570\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 36.3790 - val_loss: 36.2506\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 35.9614 - val_loss: 34.5982\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.5515 - val_loss: 35.9535\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 35.4759 - val_loss: 34.2488\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.6855 - val_loss: 33.9304\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.6957 - val_loss: 33.4427\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.8306 - val_loss: 33.0953\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.6044 - val_loss: 33.8046\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 35.2898 - val_loss: 38.9726\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 35.2781 - val_loss: 34.0154\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.8069 - val_loss: 33.3979\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 34.0020 - val_loss: 34.2063\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 64.6966 - val_loss: 47.8095\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 46.3317 - val_loss: 43.0990\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 43.3444 - val_loss: 40.3113\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 40.9804 - val_loss: 42.0315\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.6729 - val_loss: 39.7133\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.9385 - val_loss: 39.1407\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 40.9622 - val_loss: 38.1964\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 39.4580 - val_loss: 37.9297\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 38.4694 - val_loss: 37.1911\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 734us/step - loss: 39.6506 - val_loss: 38.3914\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 38.3046 - val_loss: 36.6198\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 38.2068 - val_loss: 36.2949\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.4261 - val_loss: 35.3832\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.9339 - val_loss: 35.4555\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 35.9356 - val_loss: 35.1980\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 36.4209 - val_loss: 35.2633\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.0759 - val_loss: 35.4111\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.3931 - val_loss: 37.8362\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 36.2568 - val_loss: 34.3169\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 34.5848 - val_loss: 33.9237\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 34.1390 - val_loss: 33.8452\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.4697 - val_loss: 33.6747\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.7643 - val_loss: 36.7321\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.7459 - val_loss: 35.5059\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.8636 - val_loss: 33.3993\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 34.2916 - val_loss: 32.6626\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 32.4963 - val_loss: 33.1015\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.6239 - val_loss: 32.1965\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 33.0472 - val_loss: 34.4014\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.2414 - val_loss: 32.5359\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 32.5221 - val_loss: 33.5954\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 33.1386 - val_loss: 31.5310\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 32.9875 - val_loss: 31.6433\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.0270 - val_loss: 31.1299\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 31.2926 - val_loss: 31.7333\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.1965 - val_loss: 31.6469\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 30.8021 - val_loss: 30.5925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.1096 - val_loss: 31.5624\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.7986 - val_loss: 30.4956\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.9487 - val_loss: 31.6328\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.5313 - val_loss: 30.0677\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.0600 - val_loss: 30.2988\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 721us/step - loss: 30.1686 - val_loss: 32.2209\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 756us/step - loss: 31.3325 - val_loss: 30.1021\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 737us/step - loss: 30.1341 - val_loss: 30.7970\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 839us/step - loss: 30.2197 - val_loss: 29.4579\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 688us/step - loss: 29.6147 - val_loss: 30.8170\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.4687 - val_loss: 31.4719\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.1669 - val_loss: 28.8556\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.4608 - val_loss: 32.4050\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 30.3395 - val_loss: 31.6095\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.7749 - val_loss: 28.9433\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.3427 - val_loss: 28.6402\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 27.1520 - val_loss: 27.6377\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 26.2372 - val_loss: 28.4943\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 680us/step - loss: 25.9790 - val_loss: 27.1645\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.5288 - val_loss: 25.5970\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 25.6611 - val_loss: 26.0727\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 25.3861 - val_loss: 25.5260\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 24.2830 - val_loss: 24.7412\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.7805 - val_loss: 24.1930\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.4209 - val_loss: 24.0690\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.3229 - val_loss: 23.8107\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 23.2420 - val_loss: 23.6463\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.9355 - val_loss: 23.8057\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.7994 - val_loss: 23.3818\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.6556 - val_loss: 23.4316\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.8914 - val_loss: 23.4470\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 22.7480 - val_loss: 23.4648\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.4294 - val_loss: 23.1390\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.2709 - val_loss: 22.9815\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 22.3028 - val_loss: 23.4025\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.2232 - val_loss: 23.0742\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.0375 - val_loss: 22.8152\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.9477 - val_loss: 22.8677\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.9961 - val_loss: 22.8508\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.8839 - val_loss: 22.8437\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.8196 - val_loss: 22.7415\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.7345 - val_loss: 22.7542\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.8037 - val_loss: 22.6998\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.8353 - val_loss: 22.7499\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.6881 - val_loss: 22.5453\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.5055 - val_loss: 22.5850\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.5288 - val_loss: 22.6664\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.4644 - val_loss: 22.5246\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 21.4275 - val_loss: 22.8062\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.5161 - val_loss: 22.4877\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.2815 - val_loss: 22.4699\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.3250 - val_loss: 22.4227\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.3068 - val_loss: 22.4551\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.3516 - val_loss: 22.6866\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.2077 - val_loss: 22.3650\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 21.1093 - val_loss: 22.3744\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.0829 - val_loss: 22.4565\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 21.1688 - val_loss: 22.3210\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 20.9923 - val_loss: 22.3316\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.9835 - val_loss: 22.2935\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 20.9837 - val_loss: 22.3597\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.8324 - val_loss: 22.3299\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.8273 - val_loss: 22.3156\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 68.4238 - val_loss: 45.9506\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 44.7348 - val_loss: 41.7092\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 42.7604 - val_loss: 41.2737\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.0839 - val_loss: 38.7950\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.3529 - val_loss: 37.3764\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.9348 - val_loss: 35.6720\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 36.1201 - val_loss: 36.9364\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 35.6632 - val_loss: 35.7945\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.4796 - val_loss: 33.5806\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 33.6765 - val_loss: 33.7558\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.5215 - val_loss: 34.7817\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.9690 - val_loss: 32.3702\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.6594 - val_loss: 31.9092\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.4941 - val_loss: 31.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.3753 - val_loss: 30.8939\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 31.2955 - val_loss: 30.8534\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 31.3504 - val_loss: 32.1436\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 30.1012 - val_loss: 29.8345\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.0635 - val_loss: 35.9462\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.2356 - val_loss: 30.0031\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 569us/step - loss: 29.6463 - val_loss: 30.9631\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.4646 - val_loss: 30.8037\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 30.2927 - val_loss: 29.5387\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 29.3315 - val_loss: 36.0377\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 31.1381 - val_loss: 29.5028\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 29.0161 - val_loss: 30.0468\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 28.9050 - val_loss: 28.8820\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.6436 - val_loss: 28.5484\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.0624 - val_loss: 28.6612\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 28.0388 - val_loss: 28.5388\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 27.8203 - val_loss: 28.3291\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.4146 - val_loss: 27.5489\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 27.3466 - val_loss: 30.6513\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.5181 - val_loss: 28.6112\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 27.3802 - val_loss: 27.8799\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.9142 - val_loss: 27.2953\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.9547 - val_loss: 28.7559\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 26.6950 - val_loss: 27.0576\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 26.7629 - val_loss: 31.2888\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 27.2173 - val_loss: 27.5514\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 26.0208 - val_loss: 26.7098\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.7453 - val_loss: 27.7691\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 26.6578 - val_loss: 26.6950\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 25.5537 - val_loss: 27.3255\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 25.8581 - val_loss: 26.6915\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.1117 - val_loss: 26.0981\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.0262 - val_loss: 25.9665\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 25.2582 - val_loss: 25.8912\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 25.3270 - val_loss: 27.8119\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 26.4793 - val_loss: 26.4053\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 25.2954 - val_loss: 25.9541\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 24.5393 - val_loss: 25.7796\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 25.1375 - val_loss: 26.4400\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 25.7466 - val_loss: 25.5948\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.4731 - val_loss: 25.1054\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 24.1397 - val_loss: 25.0817\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.5681 - val_loss: 24.8997\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 23.9274 - val_loss: 24.9175\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 23.7734 - val_loss: 27.1217\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 24.8265 - val_loss: 25.0463\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 23.5982 - val_loss: 24.5123\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 22.8214 - val_loss: 25.1152\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 759us/step - loss: 23.1505 - val_loss: 24.3996\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 804us/step - loss: 23.4125 - val_loss: 24.4697\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 700us/step - loss: 23.1135 - val_loss: 24.2308\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 22.5362 - val_loss: 24.1788\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.3142 - val_loss: 24.3840\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 22.4615 - val_loss: 23.7326\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 22.0141 - val_loss: 23.5790\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 21.8791 - val_loss: 23.4767\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 22.2071 - val_loss: 23.8141\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.6878 - val_loss: 23.6223\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.3667 - val_loss: 23.2105\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 669us/step - loss: 21.5137 - val_loss: 23.5734\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.1188 - val_loss: 23.1205\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.9089 - val_loss: 23.7932\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.3122 - val_loss: 22.7590\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.0423 - val_loss: 22.7381\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.7839 - val_loss: 22.5973\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 20.7202 - val_loss: 22.8154\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.5423 - val_loss: 23.0316\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.0451 - val_loss: 23.2287\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 21.3404 - val_loss: 23.5004\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.5544 - val_loss: 22.3657\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.1594 - val_loss: 22.2910\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.1092 - val_loss: 22.1447\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 20.2514 - val_loss: 22.1360\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 20.2684 - val_loss: 22.0710\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 19.8850 - val_loss: 22.0295\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 19.8572 - val_loss: 22.0773\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 19.7509 - val_loss: 21.7869\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 19.5643 - val_loss: 22.1303\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 19.5933 - val_loss: 21.7326\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 19.6637 - val_loss: 21.7430\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 19.7171 - val_loss: 22.1297\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 19.9106 - val_loss: 21.7060\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 19.5428 - val_loss: 21.6329\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 19.4652 - val_loss: 21.6974\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 19.5566 - val_loss: 21.6230\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 19.2611 - val_loss: 22.8086\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 71.0959 - val_loss: 50.7562\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 48.5072 - val_loss: 44.6827\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 46.6001 - val_loss: 43.9384\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 43.2931 - val_loss: 41.6692\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 42.9416 - val_loss: 41.0769\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 40.8351 - val_loss: 39.4535\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 40.3486 - val_loss: 39.9559\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 39.8804 - val_loss: 38.5590\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 38.2219 - val_loss: 38.1713\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 38.0135 - val_loss: 40.7983\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 37.9112 - val_loss: 37.6714\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 37.2670 - val_loss: 42.4166\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 38.4145 - val_loss: 41.7389\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.4784 - val_loss: 37.5430\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 38.5576 - val_loss: 37.6564\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.3988 - val_loss: 36.8923\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.3369 - val_loss: 35.4342\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.1602 - val_loss: 38.8111\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 34.9476 - val_loss: 34.8159\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.1065 - val_loss: 34.4801\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.0630 - val_loss: 36.4091\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.2346 - val_loss: 34.6107\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.6983 - val_loss: 33.9691\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.1463 - val_loss: 34.9431\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.1547 - val_loss: 35.5947\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.5353 - val_loss: 33.3786\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.6753 - val_loss: 33.1772\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.2691 - val_loss: 33.7705\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.7136 - val_loss: 30.5777\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.1332 - val_loss: 29.9434\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 682us/step - loss: 29.9922 - val_loss: 29.9040\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.1737 - val_loss: 29.2813\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 27.9834 - val_loss: 28.2881\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 27.3936 - val_loss: 27.8280\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 27.1858 - val_loss: 28.1884\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.7456 - val_loss: 26.7173\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 25.5919 - val_loss: 26.2031\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 25.4668 - val_loss: 25.8453\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 24.9352 - val_loss: 25.6342\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 24.7581 - val_loss: 25.3519\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 24.8881 - val_loss: 25.0370\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 24.0576 - val_loss: 24.8032\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 23.7513 - val_loss: 24.5436\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 23.6560 - val_loss: 24.2953\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 23.3315 - val_loss: 24.1455\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 23.2479 - val_loss: 23.9865\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.9965 - val_loss: 23.7916\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.9182 - val_loss: 24.1232\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 23.0106 - val_loss: 23.9031\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.8088 - val_loss: 23.3826\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.8937 - val_loss: 23.7454\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 22.8668 - val_loss: 23.7226\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.5619 - val_loss: 23.1052\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 22.2327 - val_loss: 23.2034\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 584us/step - loss: 22.1420 - val_loss: 22.9551\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 22.0737 - val_loss: 23.1504\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.8448 - val_loss: 22.8408\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.8229 - val_loss: 22.7247\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.8376 - val_loss: 23.1733\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.7980 - val_loss: 22.7278\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 21.6110 - val_loss: 22.6038\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.3926 - val_loss: 22.5432\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.4628 - val_loss: 22.7162\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 21.3498 - val_loss: 22.4322\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.2254 - val_loss: 22.4649\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.1231 - val_loss: 22.4260\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 21.2599 - val_loss: 22.4135\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.1706 - val_loss: 22.8514\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 639us/step - loss: 21.4192 - val_loss: 22.5087\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.9912 - val_loss: 22.2370\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 20.8477 - val_loss: 22.1308\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 20.8082 - val_loss: 22.1213\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.7393 - val_loss: 22.1869\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 20.8694 - val_loss: 22.1795\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 20.6870 - val_loss: 22.0696\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.7743 - val_loss: 22.0788\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0058 - val_loss: 22.5482\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 575us/step - loss: 20.7988 - val_loss: 22.2883\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 20.5207 - val_loss: 22.1787\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.3583 - val_loss: 21.9612\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 20.3425 - val_loss: 21.9615\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 20.2399 - val_loss: 21.9324\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.5921 - val_loss: 22.1719\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 20.5069 - val_loss: 23.1166\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.5751 - val_loss: 22.3640\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 20.1425 - val_loss: 21.9478\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.0184 - val_loss: 21.9276\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 19.9983 - val_loss: 21.9131\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.0023 - val_loss: 21.9322\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.0663 - val_loss: 22.4688\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.0795 - val_loss: 21.9457\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 19.8435 - val_loss: 21.9213\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 19.8660 - val_loss: 21.9912\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 86.6424 - val_loss: 49.6623\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 45.7143 - val_loss: 43.2916\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 41.4262 - val_loss: 43.1047\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.8908 - val_loss: 40.9194\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.6148 - val_loss: 39.5727\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.5819 - val_loss: 39.4753\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.6956 - val_loss: 40.6736\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 37.5246 - val_loss: 38.6703\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.7574 - val_loss: 37.6851\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 35.9044 - val_loss: 38.2831\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.2074 - val_loss: 40.5324\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.1083 - val_loss: 36.7696\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.3571 - val_loss: 36.9119\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 34.6386 - val_loss: 34.9719\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.0688 - val_loss: 36.8560\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.1263 - val_loss: 37.2506\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 34.6359 - val_loss: 35.4036\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.1185 - val_loss: 34.7086\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 33.0063 - val_loss: 34.0929\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 32.2875 - val_loss: 33.9802\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 31.8721 - val_loss: 35.2884\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 32.4102 - val_loss: 36.4374\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 32.5789 - val_loss: 33.6833\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 31.5964 - val_loss: 34.2928\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 31.6738 - val_loss: 34.9458\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.3032 - val_loss: 32.1838\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 30.7564 - val_loss: 31.9972\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 30.0703 - val_loss: 31.7810\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.1278 - val_loss: 33.6299\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.9391 - val_loss: 31.8417\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.7347 - val_loss: 31.1881\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.8540 - val_loss: 32.2875\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.2891 - val_loss: 31.8786\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 30.5085 - val_loss: 35.0988\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 30.9509 - val_loss: 31.7623\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.0819 - val_loss: 32.6991\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.6092 - val_loss: 51.2742\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 47.3188 - val_loss: 46.4517\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 44.1373 - val_loss: 47.6688\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 42.8273 - val_loss: 45.9838\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 42.1259 - val_loss: 41.7671\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 40.2617 - val_loss: 42.5999\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 40.0633 - val_loss: 41.7120\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 40.2549 - val_loss: 41.0142\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 38.5312 - val_loss: 39.0639\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 37.4871 - val_loss: 38.3925\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 37.1741 - val_loss: 39.0485\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 37.2573 - val_loss: 39.1406\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.0911 - val_loss: 37.4450\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.5738 - val_loss: 37.2206\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 35.5217 - val_loss: 39.6792\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 36.0259 - val_loss: 36.5787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 36.2434 - val_loss: 36.2248\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.5799 - val_loss: 35.6089\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.2918 - val_loss: 36.1787\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 33.9962 - val_loss: 35.8993\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.4957 - val_loss: 36.9149\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.3950 - val_loss: 34.6160\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 33.7095 - val_loss: 35.4811\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 32.4582 - val_loss: 35.8571\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.6897 - val_loss: 34.8128\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.4783 - val_loss: 33.8536\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.7133 - val_loss: 34.2480\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 31.7004 - val_loss: 34.8698\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.3930 - val_loss: 33.4360\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 31.6254 - val_loss: 32.4848\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 31.9297 - val_loss: 32.7684\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 30.6938 - val_loss: 33.1931\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 30.2257 - val_loss: 32.2840\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 30.6324 - val_loss: 32.0366\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 29.6181 - val_loss: 30.8934\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 29.8988 - val_loss: 34.3421\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.5358 - val_loss: 30.6342\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 30.7459 - val_loss: 30.4183\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.0883 - val_loss: 30.4334\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 28.0726 - val_loss: 28.2779\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 26.6054 - val_loss: 27.1639\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.6212 - val_loss: 26.4979\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 25.1756 - val_loss: 25.8126\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 24.9262 - val_loss: 25.3791\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 24.3261 - val_loss: 25.4243\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.3318 - val_loss: 24.9085\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 24.2537 - val_loss: 25.2315\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.7749 - val_loss: 24.4649\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 23.7896 - val_loss: 24.4284\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.2999 - val_loss: 24.0572\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 23.1399 - val_loss: 23.8783\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 22.9695 - val_loss: 23.7765\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.8992 - val_loss: 23.7159\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 22.7324 - val_loss: 24.0936\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.6609 - val_loss: 23.4805\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.4755 - val_loss: 23.4753\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.3859 - val_loss: 23.5895\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.2542 - val_loss: 23.2772\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 22.3332 - val_loss: 23.3018\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 22.2448 - val_loss: 23.1589\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 22.0808 - val_loss: 23.2851\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.0105 - val_loss: 23.1518\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.8460 - val_loss: 23.1365\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.0215 - val_loss: 23.1274\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.8269 - val_loss: 22.9527\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.6600 - val_loss: 22.9873\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.5647 - val_loss: 22.8667\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.5505 - val_loss: 22.8176\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.5142 - val_loss: 22.8571\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.3469 - val_loss: 22.7284\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.4339 - val_loss: 22.8170\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.4291 - val_loss: 22.7948\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.2623 - val_loss: 22.8789\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.1049 - val_loss: 23.1053\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.2116 - val_loss: 22.8667\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.0158 - val_loss: 49.0218\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 49.0446 - val_loss: 45.4167\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 45.8151 - val_loss: 44.4109\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 43.6718 - val_loss: 45.8562\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 43.6955 - val_loss: 42.1925\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 41.4775 - val_loss: 40.9946\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 40.2304 - val_loss: 39.7016\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 41.1418 - val_loss: 40.1707\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 39.5013 - val_loss: 39.8304\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 41.2375 - val_loss: 40.2841\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.6177 - val_loss: 38.6008\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 39.0757 - val_loss: 38.1474\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 38.0733 - val_loss: 44.5214\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 37.3684 - val_loss: 37.0412\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.9637 - val_loss: 36.9599\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 37.0613 - val_loss: 38.6430\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 37.6612 - val_loss: 36.7611\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 36.2553 - val_loss: 37.3651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.3668 - val_loss: 35.1115\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.3331 - val_loss: 35.2042\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.2192 - val_loss: 34.1876\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 34.8448 - val_loss: 34.2151\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.5378 - val_loss: 37.1926\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.4774 - val_loss: 33.4915\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 36.2229 - val_loss: 34.2199\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 33.1667 - val_loss: 33.1523\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 32.7846 - val_loss: 36.4974\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.3432 - val_loss: 39.0495\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.1510 - val_loss: 33.4333\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 34.5274 - val_loss: 33.5838\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 31.6510 - val_loss: 31.5770\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 30.9080 - val_loss: 31.3150\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.7786 - val_loss: 31.3272\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 29.5831 - val_loss: 32.5557\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 29.1417 - val_loss: 29.5790\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 29.2925 - val_loss: 31.0631\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 28.1693 - val_loss: 28.0048\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 26.7710 - val_loss: 28.1577\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 26.0894 - val_loss: 26.1487\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.2403 - val_loss: 25.5581\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 25.1283 - val_loss: 25.0613\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 24.3395 - val_loss: 24.6715\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.1629 - val_loss: 24.4927\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 23.9612 - val_loss: 24.8950\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.8929 - val_loss: 24.4321\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.6572 - val_loss: 24.0048\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 23.3458 - val_loss: 23.9406\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.2564 - val_loss: 23.8224\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 23.1791 - val_loss: 23.6670\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 23.0252 - val_loss: 23.6020\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.9767 - val_loss: 24.1588\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.8768 - val_loss: 23.5683\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 768us/step - loss: 22.9350 - val_loss: 23.4219\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 665us/step - loss: 22.7365 - val_loss: 23.3906\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 702us/step - loss: 22.7321 - val_loss: 23.2973\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 735us/step - loss: 22.4806 - val_loss: 23.1593\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 806us/step - loss: 22.4215 - val_loss: 23.1717\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.3627 - val_loss: 23.2886\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 22.4508 - val_loss: 24.6607\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.4735 - val_loss: 23.1229\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 22.2541 - val_loss: 22.9900\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 22.1597 - val_loss: 22.9504\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 22.2936 - val_loss: 23.1223\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.1629 - val_loss: 22.8565\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.0206 - val_loss: 22.9665\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 672us/step - loss: 21.9419 - val_loss: 22.7868\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.8505 - val_loss: 22.9872\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 21.8961 - val_loss: 22.7955\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.9926 - val_loss: 22.9319\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 21.8372 - val_loss: 22.8653\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.8735 - val_loss: 22.5970\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 21.6828 - val_loss: 22.6521\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.6189 - val_loss: 22.6805\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.5969 - val_loss: 22.7267\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.6393 - val_loss: 22.6818\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.7856 - val_loss: 22.8666\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.1690 - val_loss: 50.5547\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 44.8824 - val_loss: 41.6325\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 41.7159 - val_loss: 40.1457\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 40.8267 - val_loss: 40.1833\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.7321 - val_loss: 40.6046\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 38.7003 - val_loss: 37.4861\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 39.3440 - val_loss: 43.2859\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.2016 - val_loss: 36.6029\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.0476 - val_loss: 38.0637\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.4462 - val_loss: 35.5780\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.9804 - val_loss: 36.0999\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 36.4980 - val_loss: 38.1590\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.4957 - val_loss: 35.4038\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 35.6318 - val_loss: 35.4237\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.9509 - val_loss: 35.7703\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.3309 - val_loss: 34.4996\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.8470 - val_loss: 36.5065\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 34.8518 - val_loss: 34.3204\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 33.8976 - val_loss: 35.9038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 35.4416 - val_loss: 35.9581\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.4744 - val_loss: 33.1660\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 586us/step - loss: 33.1718 - val_loss: 35.5560\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.6743 - val_loss: 33.7461\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 34.0922 - val_loss: 33.4271\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.2475 - val_loss: 33.7396\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 576us/step - loss: 32.7901 - val_loss: 32.4221\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 31.7610 - val_loss: 33.1150\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 33.1222 - val_loss: 33.2058\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.6377 - val_loss: 32.6360\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.0941 - val_loss: 31.8736\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.3240 - val_loss: 31.7024\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.2208 - val_loss: 31.5257\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 31.7311 - val_loss: 33.4374\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.4975 - val_loss: 31.3213\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 30.5049 - val_loss: 31.1861\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.4308 - val_loss: 31.0416\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 30.9610 - val_loss: 31.5012\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 31.2320 - val_loss: 30.9276\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 30.4028 - val_loss: 31.4950\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.0676 - val_loss: 29.9210\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.1721 - val_loss: 30.3903\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 29.5317 - val_loss: 29.7363\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 30.1066 - val_loss: 30.1086\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 28.8045 - val_loss: 29.5532\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 29.0223 - val_loss: 30.1052\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 28.2217 - val_loss: 30.6879\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 28.0521 - val_loss: 30.3557\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 27.4890 - val_loss: 30.3053\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 28.0912 - val_loss: 28.0273\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 27.5042 - val_loss: 27.7835\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 26.7333 - val_loss: 27.1335\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 570us/step - loss: 26.4748 - val_loss: 26.6896\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 26.7939 - val_loss: 26.2711\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.2841 - val_loss: 25.5057\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 24.6341 - val_loss: 25.0470\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 24.3856 - val_loss: 24.8873\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.7141 - val_loss: 24.2900\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 23.5399 - val_loss: 24.3506\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 23.2699 - val_loss: 23.9216\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 22.9964 - val_loss: 23.6908\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.9114 - val_loss: 23.8889\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 22.9176 - val_loss: 24.0857\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 23.1202 - val_loss: 23.6495\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.6837 - val_loss: 23.7586\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.5090 - val_loss: 23.2674\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 22.3721 - val_loss: 23.2654\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.3328 - val_loss: 25.2464\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.5548 - val_loss: 23.2079\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.2782 - val_loss: 22.9801\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 22.3650 - val_loss: 23.2804\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 22.2848 - val_loss: 22.9079\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 22.0510 - val_loss: 23.0406\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.8791 - val_loss: 22.8123\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 21.8617 - val_loss: 22.8714\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.6640 - val_loss: 22.6609\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 21.5938 - val_loss: 22.6522\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 21.6084 - val_loss: 22.6923\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.5436 - val_loss: 22.5687\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.4733 - val_loss: 22.5574\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.4462 - val_loss: 22.5925\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 21.4943 - val_loss: 23.0072\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 21.4769 - val_loss: 22.5179\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 21.2949 - val_loss: 22.4352\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.4975 - val_loss: 22.6286\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 21.2390 - val_loss: 22.4983\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.2238 - val_loss: 22.6762\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.2177 - val_loss: 22.4966\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.0957 - val_loss: 22.4835\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.9585 - val_loss: 47.7724\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 45.6412 - val_loss: 44.5298\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 42.8257 - val_loss: 41.2876\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 39.9068 - val_loss: 40.4027\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 40.1429 - val_loss: 39.6312\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 38.8487 - val_loss: 45.5432\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 40.2987 - val_loss: 39.1952\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 37.4770 - val_loss: 39.2723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 36.7385 - val_loss: 38.0280\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.5444 - val_loss: 36.8818\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.7032 - val_loss: 37.7002\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.7361 - val_loss: 36.6491\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.3630 - val_loss: 36.5800\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.2453 - val_loss: 36.0470\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 34.5710 - val_loss: 37.2086\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 307us/step - loss: 35.3508 - val_loss: 35.0310\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 305us/step - loss: 35.2704 - val_loss: 34.7991\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 520us/step - loss: 35.8157 - val_loss: 34.4254\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 539us/step - loss: 34.1731 - val_loss: 34.0394\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 525us/step - loss: 33.2601 - val_loss: 33.9109\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 533us/step - loss: 32.8704 - val_loss: 34.1993\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 521us/step - loss: 32.5027 - val_loss: 36.1897\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 561us/step - loss: 32.8269 - val_loss: 33.6540\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 516us/step - loss: 32.8045 - val_loss: 34.1163\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 535us/step - loss: 31.7204 - val_loss: 32.2271\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 540us/step - loss: 32.0778 - val_loss: 32.2711\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 550us/step - loss: 31.5594 - val_loss: 32.2961\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 690us/step - loss: 31.4319 - val_loss: 33.2088\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 31.7082 - val_loss: 35.3100\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 33.6073 - val_loss: 32.4598\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 60.9027 - val_loss: 43.6319\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 42.2090 - val_loss: 42.4814\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 40.1996 - val_loss: 40.3139\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 39.2996 - val_loss: 39.5960\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 40.7824 - val_loss: 41.4909\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.7980 - val_loss: 39.0075\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 37.9872 - val_loss: 45.6926\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 39.6825 - val_loss: 38.2898\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 37.9635 - val_loss: 37.7337\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 657us/step - loss: 37.4917 - val_loss: 38.1079\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 37.2594 - val_loss: 40.8917\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 667us/step - loss: 36.5033 - val_loss: 37.9436\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 35.5108 - val_loss: 36.5606\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 35.3063 - val_loss: 40.2080\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 35.8087 - val_loss: 36.5689\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 35.3164 - val_loss: 36.2042\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.0103 - val_loss: 36.7439\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 34.1388 - val_loss: 35.5185\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 660us/step - loss: 34.1925 - val_loss: 41.1293\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 36.0254 - val_loss: 35.5905\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 35.9362 - val_loss: 36.7421\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 33.9383 - val_loss: 35.7580\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.5601 - val_loss: 36.2175\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.8204 - val_loss: 48.4007\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 46.9664 - val_loss: 43.4590\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 45.1008 - val_loss: 43.7341\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 43.0149 - val_loss: 41.9306\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 43.6868 - val_loss: 45.3638\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 43.1211 - val_loss: 40.0945\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 43.0168 - val_loss: 39.7767\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 41.7818 - val_loss: 39.7648\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 41.6527 - val_loss: 38.4171\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 39.9414 - val_loss: 40.1105\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 40.8562 - val_loss: 39.4002\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 39.7469 - val_loss: 37.2341\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 39.8528 - val_loss: 38.7464\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 38.9766 - val_loss: 38.2844\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 38.3646 - val_loss: 36.1966\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 37.2575 - val_loss: 44.4705\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 38.2029 - val_loss: 35.4981\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 36.4009 - val_loss: 35.8507\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 36.2352 - val_loss: 34.7728\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 35.2771 - val_loss: 35.6450\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 35.1007 - val_loss: 34.5924\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 34.6906 - val_loss: 34.1617\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.5489 - val_loss: 35.0383\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.3317 - val_loss: 32.9806\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 33.9178 - val_loss: 32.5895\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.8272 - val_loss: 32.7102\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.6563 - val_loss: 32.4808\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 32.9282 - val_loss: 32.0774\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 33.5046 - val_loss: 33.0486\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 32.9053 - val_loss: 32.7309\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.4326 - val_loss: 35.1707\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.1921 - val_loss: 32.4584\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 35.2729 - val_loss: 33.1589\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 76.0250 - val_loss: 54.6253\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 49.6722 - val_loss: 46.4884\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 43.3929 - val_loss: 43.6336\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 42.0871 - val_loss: 41.5640\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 41.3457 - val_loss: 43.6140\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.8748 - val_loss: 39.8717\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 41.4153 - val_loss: 40.5000\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 39.1707 - val_loss: 39.0250\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 40.0105 - val_loss: 39.9207\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 39.2901 - val_loss: 41.7168\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 39.5993 - val_loss: 38.6091\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 37.8058 - val_loss: 37.6376\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.9664 - val_loss: 36.7035\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.7766 - val_loss: 35.4512\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 37.0370 - val_loss: 36.6620\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.4951 - val_loss: 35.9443\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.6029 - val_loss: 35.4014\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.7262 - val_loss: 37.7118\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 35.5853 - val_loss: 36.5744\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 34.1678 - val_loss: 35.2459\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 34.0780 - val_loss: 35.6807\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 34.2417 - val_loss: 33.2908\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 33.0227 - val_loss: 33.0503\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 34.1570 - val_loss: 35.1089\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 33.9684 - val_loss: 40.5233\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.9262 - val_loss: 34.0725\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 32.5533 - val_loss: 32.6778\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 33.1879 - val_loss: 33.5209\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 32.3477 - val_loss: 31.6510\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 31.3317 - val_loss: 33.2364\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 31.4761 - val_loss: 32.7595\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.2227 - val_loss: 32.0760\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 30.8122 - val_loss: 32.3557\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 32.4666 - val_loss: 35.8564\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 67.0571 - val_loss: 55.8497\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 47.0571 - val_loss: 44.0893\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 43.7517 - val_loss: 41.8125\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 41.1303 - val_loss: 43.5783\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 42.0082 - val_loss: 40.6916\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.9403 - val_loss: 40.0515\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 39.2512 - val_loss: 38.4909\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 40.0618 - val_loss: 40.3457\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.7472 - val_loss: 37.8747\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 38.0109 - val_loss: 37.4239\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 36.6597 - val_loss: 36.4683\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 36.1815 - val_loss: 37.3490\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 36.2165 - val_loss: 38.4263\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 37.1948 - val_loss: 36.5489\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 36.0467 - val_loss: 45.3691\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 39.3577 - val_loss: 37.0885\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.4388 - val_loss: 49.7372\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 46.2705 - val_loss: 47.4127\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 43.5444 - val_loss: 42.8475\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 40.2364 - val_loss: 41.7392\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 40.0821 - val_loss: 41.0448\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 39.5385 - val_loss: 42.3054\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 38.3966 - val_loss: 38.7230\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 37.4239 - val_loss: 39.0038\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 37.6191 - val_loss: 38.3953\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.4528 - val_loss: 38.6529\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.5065 - val_loss: 37.7731\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 35.0035 - val_loss: 37.5743\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 35.5727 - val_loss: 38.8104\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.0667 - val_loss: 35.4048\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 34.1918 - val_loss: 35.2104\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 35.0048 - val_loss: 36.2070\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.4681 - val_loss: 37.9087\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 35.5053 - val_loss: 39.0526\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.4941 - val_loss: 34.4476\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 32.9208 - val_loss: 33.7289\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.4959 - val_loss: 36.1368\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.9341 - val_loss: 33.8608\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 32.1775 - val_loss: 33.7169\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 31.2296 - val_loss: 33.4544\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 633us/step - loss: 31.3949 - val_loss: 32.7905\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.3841 - val_loss: 34.5303\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 30.8479 - val_loss: 31.8955\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 29.3358 - val_loss: 30.1994\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 28.6879 - val_loss: 29.8649\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 28.7243 - val_loss: 30.1177\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.8403 - val_loss: 28.8031\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 27.1677 - val_loss: 28.5644\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 27.2717 - val_loss: 28.4900\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 27.9482 - val_loss: 28.5872\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 27.1867 - val_loss: 27.0747\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 25.9467 - val_loss: 26.9663\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 25.6226 - val_loss: 27.5057\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 25.7385 - val_loss: 26.1392\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 24.8762 - val_loss: 25.6206\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 24.4880 - val_loss: 25.4156\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 24.3006 - val_loss: 25.2024\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 24.0387 - val_loss: 25.0745\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.9802 - val_loss: 25.5396\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 24.3086 - val_loss: 24.6835\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 23.6737 - val_loss: 24.6826\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 23.6014 - val_loss: 24.5481\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 23.2462 - val_loss: 24.3086\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.0315 - val_loss: 24.2589\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 23.1098 - val_loss: 24.0381\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 22.8967 - val_loss: 23.9252\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.7201 - val_loss: 23.8374\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 23.0118 - val_loss: 24.3058\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6412 - val_loss: 24.0063\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 22.5695 - val_loss: 23.6051\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 22.3704 - val_loss: 23.5994\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 22.5838 - val_loss: 23.6854\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 22.4631 - val_loss: 23.6433\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 22.1489 - val_loss: 23.5454\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 22.1069 - val_loss: 23.4523\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.0060 - val_loss: 23.2847\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 22.1178 - val_loss: 23.5543\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.1272 - val_loss: 23.3686\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.8229 - val_loss: 23.4097\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.7886 - val_loss: 23.3127\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.8513 - val_loss: 23.1198\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.6782 - val_loss: 23.2194\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 21.6556 - val_loss: 23.0946\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.5232 - val_loss: 23.0567\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 21.5728 - val_loss: 23.0464\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 21.7833 - val_loss: 23.0760\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.4455 - val_loss: 23.0977\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 21.3817 - val_loss: 22.9865\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 21.3149 - val_loss: 22.9396\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 21.2340 - val_loss: 23.1140\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 21.2742 - val_loss: 22.8476\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.1502 - val_loss: 22.9271\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2136 - val_loss: 23.0901\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.0603 - val_loss: 22.8969\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0527 - val_loss: 22.7773\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 20.9978 - val_loss: 22.9862\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 21.0513 - val_loss: 22.8859\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 21.1776 - val_loss: 22.8538\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.1528 - val_loss: 23.0789\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 21.2031 - val_loss: 22.9142\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 74.6568 - val_loss: 47.0085\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 47.0282 - val_loss: 47.2568\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 753us/step - loss: 44.1439 - val_loss: 41.2883\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.6955 - val_loss: 41.7578\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 707us/step - loss: 40.2552 - val_loss: 38.9278\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 744us/step - loss: 38.9980 - val_loss: 37.4138\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 854us/step - loss: 37.8124 - val_loss: 37.0723\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 37.2288 - val_loss: 35.9556\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 36.5785 - val_loss: 35.8647\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 37.5504 - val_loss: 38.8344\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 594us/step - loss: 37.0953 - val_loss: 36.0119\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.7298 - val_loss: 34.5506\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 35.5556 - val_loss: 36.4960\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 35.1048 - val_loss: 33.9270\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 35.1934 - val_loss: 34.9403\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 34.9695 - val_loss: 34.2654\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 34.4082 - val_loss: 33.9853\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 632us/step - loss: 34.6368 - val_loss: 34.1457\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 34.6262 - val_loss: 37.2533\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.0705 - val_loss: 46.0777\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 45.4551 - val_loss: 42.0647\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 42.0362 - val_loss: 40.1757\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.4535 - val_loss: 42.2910\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.6204 - val_loss: 37.9118\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.5915 - val_loss: 36.8863\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 39.3499 - val_loss: 40.4135\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.8475 - val_loss: 36.8829\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 36.5973 - val_loss: 35.8699\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 35.8561 - val_loss: 35.2496\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 36.9756 - val_loss: 36.2475\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 36.4086 - val_loss: 38.2299\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 36.1266 - val_loss: 37.9721\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 35.4594 - val_loss: 34.5599\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 34.2836 - val_loss: 34.0832\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 34.1154 - val_loss: 35.0837\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 34.3756 - val_loss: 33.2847\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.0209 - val_loss: 33.9032\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 32.9290 - val_loss: 33.6518\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 32.8574 - val_loss: 32.8111\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 35.8280 - val_loss: 34.8027\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 34.9516 - val_loss: 33.0492\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 32.3299 - val_loss: 32.5253\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.4675 - val_loss: 31.8694\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.6066 - val_loss: 31.8673\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 31.5741 - val_loss: 31.6229\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 31.3439 - val_loss: 34.9145\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 31.6276 - val_loss: 32.6784\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 31.0141 - val_loss: 30.8675\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 30.4811 - val_loss: 31.0200\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 30.8473 - val_loss: 31.6649\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 30.0489 - val_loss: 31.9295\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 30.3166 - val_loss: 30.6725\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 30.0671 - val_loss: 30.1276\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 29.6095 - val_loss: 29.7045\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 29.0221 - val_loss: 29.7153\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 28.7895 - val_loss: 34.7416\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 30.7338 - val_loss: 30.4116\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 28.4962 - val_loss: 29.9192\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 28.3846 - val_loss: 29.3277\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 649us/step - loss: 28.6669 - val_loss: 30.2762\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 666us/step - loss: 28.7805 - val_loss: 29.7318\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 29.8042 - val_loss: 33.5965\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 28.8682 - val_loss: 30.7290\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 28.0846 - val_loss: 29.2197\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 27.4873 - val_loss: 28.2921\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 27.3722 - val_loss: 28.7332\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 27.3728 - val_loss: 28.1110\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 26.7198 - val_loss: 27.4086\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 662us/step - loss: 26.2390 - val_loss: 27.5883\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 670us/step - loss: 26.0429 - val_loss: 28.1639\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 651us/step - loss: 25.7727 - val_loss: 26.7496\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 25.6686 - val_loss: 26.4141\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 25.0531 - val_loss: 27.0047\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 24.6115 - val_loss: 25.9151\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 24.1315 - val_loss: 26.1642\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 23.8039 - val_loss: 24.7828\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 24.2707 - val_loss: 24.8592\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 23.5583 - val_loss: 24.6815\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 685us/step - loss: 23.3910 - val_loss: 24.6129\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 23.1114 - val_loss: 25.5655\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 23.4439 - val_loss: 24.0628\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 22.6166 - val_loss: 23.7721\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.3816 - val_loss: 23.6147\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 22.3878 - val_loss: 23.5145\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 655us/step - loss: 22.7165 - val_loss: 23.7224\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.8785 - val_loss: 23.4512\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.1226 - val_loss: 23.4336\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 659us/step - loss: 21.9217 - val_loss: 23.2872\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.9308 - val_loss: 23.1989\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 21.6667 - val_loss: 23.1351\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 654us/step - loss: 21.5598 - val_loss: 23.3805\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 21.6508 - val_loss: 22.9257\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.5429 - val_loss: 23.3225\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 21.8765 - val_loss: 22.8798\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 639us/step - loss: 21.5010 - val_loss: 23.0435\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.2423 - val_loss: 22.7651\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 21.1589 - val_loss: 22.6954\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 21.0687 - val_loss: 23.1008\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 21.0035 - val_loss: 22.6292\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.8536 - val_loss: 22.5856\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 648us/step - loss: 20.8613 - val_loss: 23.1181\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.8746 - val_loss: 22.5430\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 20.7741 - val_loss: 22.6598\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 643us/step - loss: 20.8368 - val_loss: 22.6775\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 641us/step - loss: 20.5602 - val_loss: 22.5175\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 652us/step - loss: 20.5871 - val_loss: 22.4559\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 20.5722 - val_loss: 22.3809\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.4200 - val_loss: 23.8932\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 658us/step - loss: 21.0236 - val_loss: 22.5359\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 20.5388 - val_loss: 22.3631\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 20.3380 - val_loss: 22.5777\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.1830 - val_loss: 22.2666\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.2795 - val_loss: 22.6495\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 20.3406 - val_loss: 22.2600\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 20.0788 - val_loss: 22.2158\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 20.0153 - val_loss: 22.2518\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 20.3217 - val_loss: 22.3411\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 20.0790 - val_loss: 22.6005\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 20.0108 - val_loss: 22.4920\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 75.2743 - val_loss: 52.9548\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 47.7579 - val_loss: 44.7932\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 43.0321 - val_loss: 43.8547\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 40.9809 - val_loss: 41.1103\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 645us/step - loss: 40.1666 - val_loss: 39.3264\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 40.2417 - val_loss: 41.0966\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 39.5402 - val_loss: 38.3874\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 605us/step - loss: 38.0809 - val_loss: 37.9345\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.6024 - val_loss: 39.7585\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 37.6082 - val_loss: 36.9738\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 37.0572 - val_loss: 36.6624\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.9368 - val_loss: 35.5381\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.4101 - val_loss: 36.9578\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.6803 - val_loss: 35.4853\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 36.4196 - val_loss: 35.7792\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 35.8652 - val_loss: 35.3786\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.3755 - val_loss: 34.2839\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 35.6341 - val_loss: 35.9019\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.3838 - val_loss: 35.0680\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 34.2006 - val_loss: 34.8094\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.5805 - val_loss: 34.0880\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 34.3763 - val_loss: 36.4952\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 34.2980 - val_loss: 34.1577\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 34.4836 - val_loss: 33.2515\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 581us/step - loss: 32.7907 - val_loss: 33.4952\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 32.2125 - val_loss: 32.9068\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 32.5544 - val_loss: 32.0822\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 34.1508 - val_loss: 33.7661\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 33.8456 - val_loss: 35.1673\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 31.8493 - val_loss: 32.9775\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 32.1655 - val_loss: 33.3725\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 31.2155 - val_loss: 31.3226\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.3699 - val_loss: 32.2047\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 32.5016 - val_loss: 32.5730\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 31.4063 - val_loss: 31.4706\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 32.2315 - val_loss: 34.2898\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 31.8288 - val_loss: 32.2792\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 76.3685 - val_loss: 47.7858\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 47.2978 - val_loss: 43.8437\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 42.4253 - val_loss: 40.3746\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 41.8304 - val_loss: 39.1429\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 39.9902 - val_loss: 39.4269\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 631us/step - loss: 39.2997 - val_loss: 36.8837\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 37.8774 - val_loss: 39.2008\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 39.3015 - val_loss: 38.1993\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 37.6757 - val_loss: 34.9933\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 37.0569 - val_loss: 34.7117\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 36.2656 - val_loss: 34.5676\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 37.0273 - val_loss: 35.6808\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 36.6957 - val_loss: 35.3523\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 36.6778 - val_loss: 34.2531\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 35.0285 - val_loss: 33.6020\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 35.7040 - val_loss: 34.2895\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 34.9069 - val_loss: 33.7079\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.7519 - val_loss: 32.9894\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 33.7388 - val_loss: 34.4655\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 33.8731 - val_loss: 32.0792\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.7676 - val_loss: 32.0652\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 32.7838 - val_loss: 35.5901\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 33.2027 - val_loss: 34.3897\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 32.8186 - val_loss: 31.3234\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 595us/step - loss: 31.8234 - val_loss: 33.3726\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 33.0206 - val_loss: 31.1615\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 31.8376 - val_loss: 31.3051\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 32.6679 - val_loss: 31.0640\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 31.3976 - val_loss: 31.0541\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 31.4897 - val_loss: 30.4708\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.6733 - val_loss: 30.1216\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.9864 - val_loss: 30.5175\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.3260 - val_loss: 30.2828\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 29.9843 - val_loss: 30.5437\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 30.8456 - val_loss: 32.4823\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.4907 - val_loss: 30.3853\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 62.5096 - val_loss: 47.9383\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 45.6409 - val_loss: 42.6638\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 42.6661 - val_loss: 41.6121\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 42.1955 - val_loss: 41.9580\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.1969 - val_loss: 39.8583\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 40.2503 - val_loss: 41.2848\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 40.0459 - val_loss: 38.3601\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 639us/step - loss: 38.4913 - val_loss: 38.5423\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 38.8255 - val_loss: 38.0984\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 37.2225 - val_loss: 36.6410\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 37.0317 - val_loss: 36.3449\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 36.8697 - val_loss: 36.3813\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 35.8545 - val_loss: 35.6992\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 35.2462 - val_loss: 35.7040\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 36.3922 - val_loss: 35.0805\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 636us/step - loss: 35.7721 - val_loss: 35.4290\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 34.7625 - val_loss: 34.0929\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 35.2299 - val_loss: 35.3932\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 35.1386 - val_loss: 34.0405\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 33.7059 - val_loss: 33.5027\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.4153 - val_loss: 33.1760\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 33.6592 - val_loss: 34.6562\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 33.0686 - val_loss: 32.7813\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 33.7544 - val_loss: 32.9294\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 33.5787 - val_loss: 34.8576\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 33.1010 - val_loss: 34.7165\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 32.5926 - val_loss: 32.2759\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 31.5076 - val_loss: 32.6466\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 31.4515 - val_loss: 31.9176\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.2438 - val_loss: 31.1587\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 31.3320 - val_loss: 31.4389\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 31.8821 - val_loss: 32.9541\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 32.7220 - val_loss: 33.4727\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 32.5118 - val_loss: 34.1399\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 647us/step - loss: 32.0106 - val_loss: 33.7946\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.3688 - val_loss: 50.4342\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 47.3934 - val_loss: 44.0347\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 42.7731 - val_loss: 40.1099\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 40.2227 - val_loss: 38.5650\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 38.4262 - val_loss: 36.5586\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 38.1251 - val_loss: 39.4839\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 37.5161 - val_loss: 35.2921\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 35.1894 - val_loss: 35.3131\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 34.8599 - val_loss: 36.0255\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 35.0850 - val_loss: 34.2399\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 35.8524 - val_loss: 36.8665\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 36.3325 - val_loss: 33.6775\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 33.8637 - val_loss: 33.2896\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 33.1750 - val_loss: 35.4362\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 33.8006 - val_loss: 35.9066\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 650us/step - loss: 33.2141 - val_loss: 32.3484\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 33.0060 - val_loss: 32.3841\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 33.9145 - val_loss: 32.6203\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 32.0439 - val_loss: 31.9246\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.9114 - val_loss: 31.7246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 31.7309 - val_loss: 33.1383\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 590us/step - loss: 31.7683 - val_loss: 32.3426\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 31.3359 - val_loss: 31.7569\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 31.0057 - val_loss: 30.6531\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 31.1457 - val_loss: 31.0428\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 30.3577 - val_loss: 30.4980\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 32.6391 - val_loss: 33.3210\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 31.2579 - val_loss: 33.5443\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 30.0792 - val_loss: 30.2855\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 29.8655 - val_loss: 30.1927\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 30.9618 - val_loss: 31.0140\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 32.4614 - val_loss: 31.5922\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 30.4721 - val_loss: 30.1588\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 29.3096 - val_loss: 29.7789\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 29.3415 - val_loss: 29.2705\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 30.1652 - val_loss: 30.8705\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 30.2099 - val_loss: 29.4324\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 28.9127 - val_loss: 28.8731\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 573us/step - loss: 28.4627 - val_loss: 29.2166\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 28.7470 - val_loss: 29.5431\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 577us/step - loss: 28.3673 - val_loss: 28.7945\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 28.0881 - val_loss: 28.1597\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 27.4786 - val_loss: 28.9029\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 628us/step - loss: 29.1485 - val_loss: 28.3485\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 602us/step - loss: 28.1496 - val_loss: 28.6591\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 29.6334 - val_loss: 29.5418\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.8262 - val_loss: 27.9281\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 27.2741 - val_loss: 29.2622\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 27.2139 - val_loss: 27.4970\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 27.3207 - val_loss: 28.0535\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 27.8376 - val_loss: 27.3334\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 26.6274 - val_loss: 27.6080\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 26.9451 - val_loss: 26.9222\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 27.0468 - val_loss: 26.6828\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 26.1095 - val_loss: 26.8578\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 646us/step - loss: 25.8315 - val_loss: 26.7158\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 26.1691 - val_loss: 27.0868\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 25.3751 - val_loss: 26.0422\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 25.1005 - val_loss: 25.4954\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.5154 - val_loss: 26.1300\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 25.3473 - val_loss: 26.0797\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 24.6878 - val_loss: 25.0192\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 23.9118 - val_loss: 24.3775\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.5304 - val_loss: 24.3039\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 24.0958 - val_loss: 25.4852\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 23.6097 - val_loss: 23.6515\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 644us/step - loss: 22.9416 - val_loss: 23.4499\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 600us/step - loss: 23.1956 - val_loss: 23.3432\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.4964 - val_loss: 24.0551\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 22.5986 - val_loss: 23.2011\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 656us/step - loss: 22.6053 - val_loss: 22.9851\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 22.1043 - val_loss: 22.7045\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.0769 - val_loss: 23.2458\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 22.0743 - val_loss: 22.6764\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 21.7175 - val_loss: 22.7287\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 21.7431 - val_loss: 22.4098\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.4596 - val_loss: 22.1974\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 21.4555 - val_loss: 22.4907\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 21.6739 - val_loss: 22.3279\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 21.3026 - val_loss: 22.0685\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 21.3691 - val_loss: 22.3967\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 21.3278 - val_loss: 21.9495\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 21.0661 - val_loss: 21.8556\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 640us/step - loss: 20.9634 - val_loss: 21.9258\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 21.2458 - val_loss: 22.1404\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.0425 - val_loss: 21.8281\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 20.8200 - val_loss: 21.8093\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 20.5702 - val_loss: 21.6843\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 20.7969 - val_loss: 21.6777\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 20.8389 - val_loss: 21.7752\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 642us/step - loss: 20.6548 - val_loss: 21.9480\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 632us/step - loss: 20.4439 - val_loss: 21.9686\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 20.8211 - val_loss: 21.9801\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 20.7412 - val_loss: 21.8343\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 61.9750 - val_loss: 46.0145\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 44.6981 - val_loss: 42.9604\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 620us/step - loss: 43.1113 - val_loss: 40.8881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 42.4925 - val_loss: 40.3036\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 40.8387 - val_loss: 38.7650\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 591us/step - loss: 40.1199 - val_loss: 38.4985\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 40.1317 - val_loss: 42.2450\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 39.8090 - val_loss: 37.4863\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 40.0536 - val_loss: 39.5962\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 38.3225 - val_loss: 37.8794\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 38.2449 - val_loss: 38.0392\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 634us/step - loss: 38.5858 - val_loss: 38.3142\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 37.5925 - val_loss: 36.4042\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 588us/step - loss: 36.7135 - val_loss: 35.3154\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 635us/step - loss: 37.1596 - val_loss: 35.6903\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 37.1953 - val_loss: 35.3439\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 612us/step - loss: 36.4374 - val_loss: 39.7222\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 36.3590 - val_loss: 35.5168\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 35.6476 - val_loss: 36.8011\n",
      "Train on 350 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 72.6541 - val_loss: 49.0140\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 582us/step - loss: 47.5038 - val_loss: 43.9308\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 599us/step - loss: 42.7685 - val_loss: 41.8982\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 41.1406 - val_loss: 41.0936\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 571us/step - loss: 39.9081 - val_loss: 38.4237\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 38.7008 - val_loss: 37.3240\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 38.4043 - val_loss: 40.7975\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 607us/step - loss: 37.9810 - val_loss: 36.8843\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 37.2799 - val_loss: 39.1555\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 38.6951 - val_loss: 38.4331\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 611us/step - loss: 37.0945 - val_loss: 35.2189\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 36.3214 - val_loss: 36.5428\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 35.7220 - val_loss: 34.3064\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 35.8692 - val_loss: 38.1168\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 614us/step - loss: 36.6820 - val_loss: 34.5861\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 36.3077 - val_loss: 34.1227\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 596us/step - loss: 34.5688 - val_loss: 33.2186\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.0559 - val_loss: 34.0557\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 610us/step - loss: 33.8714 - val_loss: 32.6454\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 608us/step - loss: 34.9322 - val_loss: 34.3444\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 598us/step - loss: 33.4993 - val_loss: 36.7222\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 579us/step - loss: 33.0960 - val_loss: 31.9671\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 578us/step - loss: 32.4313 - val_loss: 31.5238\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 31.8561 - val_loss: 33.1661\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 734us/step - loss: 35.1094 - val_loss: 34.4637\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 664us/step - loss: 34.4510 - val_loss: 31.9317\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 705us/step - loss: 31.7782 - val_loss: 30.9274\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 721us/step - loss: 31.0845 - val_loss: 30.6794\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 824us/step - loss: 30.5008 - val_loss: 32.4073\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 653us/step - loss: 30.4710 - val_loss: 32.9997\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 30.7177 - val_loss: 31.7043\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 601us/step - loss: 31.4383 - val_loss: 30.0602\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 29.6021 - val_loss: 29.1029\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 29.0538 - val_loss: 28.5159\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 621us/step - loss: 28.0297 - val_loss: 27.9853\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 626us/step - loss: 27.1428 - val_loss: 27.1877\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 617us/step - loss: 26.4466 - val_loss: 26.1641\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 676us/step - loss: 25.6981 - val_loss: 25.7980\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 25.4100 - val_loss: 25.4422\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 625us/step - loss: 24.9101 - val_loss: 25.3765\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 24.3464 - val_loss: 24.5611\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 24.0954 - val_loss: 24.4531\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 661us/step - loss: 24.2339 - val_loss: 24.1303\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 23.8789 - val_loss: 24.1270\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 23.5999 - val_loss: 23.8795\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 23.2500 - val_loss: 23.6970\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 619us/step - loss: 23.1156 - val_loss: 23.7457\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 618us/step - loss: 23.0323 - val_loss: 23.5993\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 587us/step - loss: 22.7747 - val_loss: 23.4776\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 638us/step - loss: 22.6886 - val_loss: 23.3188\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 613us/step - loss: 22.6590 - val_loss: 23.2664\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.8828 - val_loss: 23.4329\n",
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 633us/step - loss: 22.3134 - val_loss: 23.1946\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 22.3484 - val_loss: 23.0642\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 622us/step - loss: 22.1160 - val_loss: 22.9828\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 630us/step - loss: 22.2010 - val_loss: 23.2493\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.9687 - val_loss: 22.8966\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.9537 - val_loss: 23.3491\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 615us/step - loss: 22.0480 - val_loss: 22.9216\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 603us/step - loss: 21.6773 - val_loss: 22.7037\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 627us/step - loss: 21.6263 - val_loss: 22.8090\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 609us/step - loss: 21.6908 - val_loss: 22.7948\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 574us/step - loss: 21.5897 - val_loss: 22.7828\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.6184 - val_loss: 22.5798\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 21.3175 - val_loss: 22.6788\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 629us/step - loss: 21.3367 - val_loss: 22.5725\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 624us/step - loss: 21.3937 - val_loss: 22.8499\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 597us/step - loss: 21.2769 - val_loss: 22.5702\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 585us/step - loss: 21.2474 - val_loss: 22.5121\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 589us/step - loss: 21.0169 - val_loss: 22.4612\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 609us/step - loss: 21.0188 - val_loss: 23.1036\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 592us/step - loss: 21.1658 - val_loss: 22.6280\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 593us/step - loss: 20.8561 - val_loss: 22.3864\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 606us/step - loss: 20.8106 - val_loss: 22.5515\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 604us/step - loss: 20.7532 - val_loss: 22.5175\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 637us/step - loss: 20.6982 - val_loss: 22.4011\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 616us/step - loss: 20.6366 - val_loss: 22.5217\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 623us/step - loss: 20.5970 - val_loss: 22.3923\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=1)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(0)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "tf.random.set_seed(0)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "degree=[0,90,180,270]\n",
    "values=[0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4]\n",
    "convo=[6]\n",
    "for goal in images:\n",
    "    y2=Image.open(goal).resize([32,32])\n",
    "    data2=cifar100.load_data()[0][0]\n",
    "    label2=cifar100.load_data()[0][1]\n",
    "    label2=label2.reshape(len(label2))\n",
    "    x_test=cifar100.load_data()[1][0]\n",
    "    y_test=cifar100.load_data()[1][1]\n",
    "    y_test=y_test.reshape(len(y_test))\n",
    "    data3=np.zeros([len(data2),32,32,3])\n",
    "    for n in range(len(data2)):\n",
    "        data3[n]=Image.fromarray(data2[n].astype(\"uint8\"))\n",
    "    data2=data3\n",
    "    \n",
    "    outputs=[]\n",
    "    outputs4=[]\n",
    "    outputs5=[]\n",
    "    for c in range(len(convo)):\n",
    "        outputs2=[]\n",
    "        outputs3=[]\n",
    "        for e in range(5):\n",
    "            ensemble=[]\n",
    "            for rot in degree:\n",
    "                error_record=[]\n",
    "                clear_session()\n",
    "                unseen_score=np.zeros([20,9])\n",
    "                AUC_score=np.zeros(20)\n",
    "                for i in range(20):\n",
    "                    x_train=data2[label2==i]\n",
    "                    y_train=np.zeros([len(x_train),32,32,3])\n",
    "                    for n in range(len(x_train)):\n",
    "                        y_train[n]=y2.rotate(rot)\n",
    "                    #x_train=x_train/255\n",
    "                    y_train=y_train\n",
    "                    #x_test=data2[label2!=i]\n",
    "                    #x_test=x_test/255\n",
    "                    x_test=x_test.reshape(len(x_test),32,32,3)\n",
    "                    y_label=np.zeros(len(y_test))\n",
    "                    y_label[y_test==i]=1\n",
    "                    #(x_train, train), (x_test, y_test) = mnist.load_data()\n",
    "                    image_height, image_width = 32, 32\n",
    "                    # \n",
    "                    if K.image_data_format() == 'channels_last':\n",
    "                        x_train = x_train.reshape(x_train.shape[0],\n",
    "                                                  image_height, image_width,3)\n",
    "                        #x_test = x_test.reshape(x_test.shape[0],image_height, image_width, 1)\n",
    "                        y_train = y_train.reshape(y_train.shape[0],\n",
    "                                                  32, 32,3)\n",
    "                        input_shape = (image_height, image_width,3)\n",
    "                    else:\n",
    "                        x_train = x_train.reshape(x_train.shape[0],\n",
    "                                                  1, image_height, image_width)\n",
    "                        x_test = x_test.reshape(x_test.shape[0],1, image_height, image_width)\n",
    "                        input_shape = (1, image_height, image_width)\n",
    "\n",
    "                    # Min-Max Normalization (0. ~ 1. )\n",
    "                    x_train = x_train.astype('float32')\n",
    "                    y_train = y_train.astype('float32')\n",
    "                    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.3, random_state=e)\n",
    "                    x_valid, x_valid2, y_valid, y_valid2 = train_test_split(x_valid, y_valid, test_size=0.3, random_state=e)\n",
    "                    #x_test = x_test.astype('float32')\n",
    "                    #x_train = (x_train - x_train.min()) / (x_train.max() - x_train.min())\n",
    "                    #x_test = (x_test - x_test.min()) / (x_test.max() - x_test.min())\n",
    "                    #  AutoEncoder  (Sequential API)\n",
    "                    model = models.Sequential()\n",
    "                    # 28 x 28 x 1\n",
    "                    model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',input_shape=input_shape))\n",
    "                    for n in range(convo[c]):\n",
    "                        model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "                    model.add(layers.Conv2D(3, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "                    # 28 x 28 x 1\n",
    "                    model.compile(optimizer='adam',\n",
    "                                  loss='mean_absolute_error')\n",
    "                    # \n",
    "                    fit_callbacks = [\n",
    "                        callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=5,\n",
    "                                                mode='min')\n",
    "                    ]\n",
    "                    # \n",
    "                    model.fit(x_train, y_train,\n",
    "                              epochs=100,\n",
    "                              batch_size=16,\n",
    "                              shuffle=True,\n",
    "                              validation_data=(x_valid, y_valid),callbacks=fit_callbacks)\n",
    "                    result=model.predict(x_valid2)\n",
    "                    result2=model.predict(x_test)\n",
    "                    y_train=y_train.reshape(y_train.shape[0],1024,3)\n",
    "                    result=result.reshape(result.shape[0],1024,3)\n",
    "                    result2=result2.reshape(result2.shape[0],1024,3)\n",
    "                    loss=np.zeros(len(result))\n",
    "                    for n in range(len(result)):\n",
    "                        loss[n]=mean_absolute_error(y_train[0],result[n])\n",
    "                    loss_outlier=np.zeros(len(result2))\n",
    "                    for n in range(len(result2)):\n",
    "                        loss_outlier[n]=mean_absolute_error(y_train[0],result2[n])\n",
    "                    error_record.append(loss_outlier)\n",
    "                    #y_one=np.ones(len(loss))\n",
    "                    #y_outlier=np.zeros(len(loss_outlier))\n",
    "                    #data=np.concatenate([loss,loss_outlier])\n",
    "                    #label=np.concatenate([y_one,y_outlier])\n",
    "                    #plt.scatter(data,label)\n",
    "                    #plt.hist([loss,loss_outlier],range=(0,0.3),stacked=False,bins=10)\n",
    "                    m=0\n",
    "                    AUC_score[i]=roc_auc_score(y_label,(-1)*loss_outlier)\n",
    "                    for p in values:\n",
    "                        y_pred=np.zeros(len(y_label))\n",
    "                        threshold=int(len(loss)*p)+1\n",
    "                        #print(loss[loss.argsort()[-threshold]])\n",
    "                        y_pred[loss_outlier<=loss[loss.argsort()[-threshold]]]=1\n",
    "                        #loss_outlier[loss_outlier>loss[loss.argsort()[-threshold]]\n",
    "                        unseen_score[i][m]=balanced_accuracy_score(y_label,y_pred)\n",
    "                        m+=1\n",
    "                #print(unseen_score)\n",
    "                #outputs.append(unseen_score)\n",
    "                outputs2.append(AUC_score)\n",
    "                outputs3.append(unseen_score)\n",
    "                ensemble.append(error_record)\n",
    "            outputs5.append(ensemble)\n",
    "            outputs.append(outputs2)\n",
    "            outputs4.append(outputs3)\n",
    "    #makefile(outputs,\"result_ocitn/cifar10_\"+str(goal)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "outputs6=[]\n",
    "for ensemble in outputs5:\n",
    "    CEtest2=None\n",
    "    value = 0\n",
    "    for scores in ensemble:\n",
    "        if type(CEtest2)==type(None):\n",
    "            CEtest2=np.array(scores)\n",
    "        else:\n",
    "            print(\"OK\")\n",
    "            CEtest2=CEtest2+np.array(scores)\n",
    "    AUC_ensemble=np.zeros(20)\n",
    "    for i in range(20):\n",
    "        y_label=np.zeros(len(y_test))\n",
    "        y_label[y_test==i]=1\n",
    "        AUC_ensemble[i]=roc_auc_score(y_label,(-1)*CEtest2[i])\n",
    "    outputs6.append(AUC_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_score2=[]\n",
    "for ensemble in outputs5:\n",
    "    AUC_score=[]\n",
    "    for scores in ensemble:\n",
    "        AUC=np.zeros(20)\n",
    "        for i in range(20):\n",
    "            y_label=np.zeros(len(y_test))\n",
    "            y_label[y_test==i]=1\n",
    "            AUC[i]=roc_auc_score(y_label,(-1)*scores[i])\n",
    "        AUC_score.append(AUC)\n",
    "    AUC_score2.append(AUC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81309354, 0.68672626, 0.63195828, 0.64734121, 0.72364495,\n",
       "        0.65592253, 0.66307626, 0.70902758, 0.6539699 , 0.61984061,\n",
       "        0.66176   , 0.62575747, 0.73498323, 0.66313374, 0.64314758,\n",
       "        0.61983646, 0.66761404, 0.83124333, 0.60737253, 0.62701697],\n",
       "       [0.80932687, 0.74062949, 0.61859333, 0.63850919, 0.65930566,\n",
       "        0.68768768, 0.63310475, 0.68935455, 0.72817283, 0.6459    ,\n",
       "        0.63364626, 0.59001434, 0.7491203 , 0.66255596, 0.59399515,\n",
       "        0.62676131, 0.63596364, 0.84617061, 0.61139899, 0.62342758],\n",
       "       [0.81553061, 0.74222283, 0.64566414, 0.66911798, 0.64988848,\n",
       "        0.68012182, 0.66321899, 0.67035111, 0.73692576, 0.65559283,\n",
       "        0.62394889, 0.63265051, 0.74003414, 0.65728141, 0.61667374,\n",
       "        0.64020667, 0.65990263, 0.85221515, 0.6000104 , 0.61602343],\n",
       "       [0.8115503 , 0.77362768, 0.61615828, 0.67720596, 0.71026091,\n",
       "        0.69886525, 0.65931485, 0.66818768, 0.70484313, 0.62877293,\n",
       "        0.6595804 , 0.60967495, 0.72414152, 0.66913889, 0.57012263,\n",
       "        0.68671626, 0.6763801 , 0.82018535, 0.59687424, 0.66404556]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(AUC_score2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01988917, 0.06407787, 0.01936488, 0.06001199, 0.02611951,\n",
       "        0.03943356, 0.01948841, 0.07578387, 0.08701337, 0.06877482,\n",
       "        0.08387472, 0.03592038, 0.01684744, 0.03857418, 0.03808018,\n",
       "        0.0421892 , 0.03903059, 0.07620687, 0.01362768, 0.02681587],\n",
       "       [0.04457232, 0.02144362, 0.05179096, 0.07537672, 0.14000135,\n",
       "        0.03877328, 0.03327133, 0.06423024, 0.03827958, 0.04496503,\n",
       "        0.07694215, 0.04031372, 0.02358579, 0.03084668, 0.06403005,\n",
       "        0.04812803, 0.04352409, 0.03643523, 0.03731217, 0.02600238],\n",
       "       [0.03063849, 0.04023375, 0.0349675 , 0.03730215, 0.10416607,\n",
       "        0.01942006, 0.00886926, 0.06929073, 0.06738665, 0.02492784,\n",
       "        0.07899576, 0.02644242, 0.02044517, 0.02211373, 0.02445088,\n",
       "        0.03418041, 0.02665937, 0.081534  , 0.07506974, 0.01478373],\n",
       "       [0.01548583, 0.03775727, 0.02250688, 0.0254822 , 0.0118833 ,\n",
       "        0.04020479, 0.02457014, 0.03226832, 0.07717239, 0.06241686,\n",
       "        0.08430038, 0.02584977, 0.02790233, 0.04752037, 0.02060524,\n",
       "        0.02138823, 0.04686845, 0.04445572, 0.06222842, 0.01778076]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(AUC_score2).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84632101, 0.76539152, 0.65901687, 0.67292889, 0.66262263,\n",
       "       0.71153768, 0.6982398 , 0.69781838, 0.69524172, 0.66173293,\n",
       "       0.64531737, 0.63269879, 0.76314323, 0.69720606, 0.62738061,\n",
       "       0.66798788, 0.68216707, 0.87280323, 0.62190768, 0.65063899])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(outputs6).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs7=[]\n",
    "outputs7.append(np.array(AUC_score2).mean(axis=0))\n",
    "outputs7.append(np.array(AUC_score2).std(axis=0))\n",
    "outputs7.append(np.array(outputs6).mean(axis=0))\n",
    "outputs7.append(np.array(outputs6).std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.81309354, 0.68672626, 0.63195828, 0.64734121, 0.72364495,\n",
       "         0.65592253, 0.66307626, 0.70902758, 0.6539699 , 0.61984061,\n",
       "         0.66176   , 0.62575747, 0.73498323, 0.66313374, 0.64314758,\n",
       "         0.61983646, 0.66761404, 0.83124333, 0.60737253, 0.62701697],\n",
       "        [0.80932687, 0.74062949, 0.61859333, 0.63850919, 0.65930566,\n",
       "         0.68768768, 0.63310475, 0.68935455, 0.72817283, 0.6459    ,\n",
       "         0.63364626, 0.59001434, 0.7491203 , 0.66255596, 0.59399515,\n",
       "         0.62676131, 0.63596364, 0.84617061, 0.61139899, 0.62342758],\n",
       "        [0.81553061, 0.74222283, 0.64566414, 0.66911798, 0.64988848,\n",
       "         0.68012182, 0.66321899, 0.67035111, 0.73692576, 0.65559283,\n",
       "         0.62394889, 0.63265051, 0.74003414, 0.65728141, 0.61667374,\n",
       "         0.64020667, 0.65990263, 0.85221515, 0.6000104 , 0.61602343],\n",
       "        [0.8115503 , 0.77362768, 0.61615828, 0.67720596, 0.71026091,\n",
       "         0.69886525, 0.65931485, 0.66818768, 0.70484313, 0.62877293,\n",
       "         0.6595804 , 0.60967495, 0.72414152, 0.66913889, 0.57012263,\n",
       "         0.68671626, 0.6763801 , 0.82018535, 0.59687424, 0.66404556]]),\n",
       " array([[0.01988917, 0.06407787, 0.01936488, 0.06001199, 0.02611951,\n",
       "         0.03943356, 0.01948841, 0.07578387, 0.08701337, 0.06877482,\n",
       "         0.08387472, 0.03592038, 0.01684744, 0.03857418, 0.03808018,\n",
       "         0.0421892 , 0.03903059, 0.07620687, 0.01362768, 0.02681587],\n",
       "        [0.04457232, 0.02144362, 0.05179096, 0.07537672, 0.14000135,\n",
       "         0.03877328, 0.03327133, 0.06423024, 0.03827958, 0.04496503,\n",
       "         0.07694215, 0.04031372, 0.02358579, 0.03084668, 0.06403005,\n",
       "         0.04812803, 0.04352409, 0.03643523, 0.03731217, 0.02600238],\n",
       "        [0.03063849, 0.04023375, 0.0349675 , 0.03730215, 0.10416607,\n",
       "         0.01942006, 0.00886926, 0.06929073, 0.06738665, 0.02492784,\n",
       "         0.07899576, 0.02644242, 0.02044517, 0.02211373, 0.02445088,\n",
       "         0.03418041, 0.02665937, 0.081534  , 0.07506974, 0.01478373],\n",
       "        [0.01548583, 0.03775727, 0.02250688, 0.0254822 , 0.0118833 ,\n",
       "         0.04020479, 0.02457014, 0.03226832, 0.07717239, 0.06241686,\n",
       "         0.08430038, 0.02584977, 0.02790233, 0.04752037, 0.02060524,\n",
       "         0.02138823, 0.04686845, 0.04445572, 0.06222842, 0.01778076]]),\n",
       " array([0.84632101, 0.76539152, 0.65901687, 0.67292889, 0.66262263,\n",
       "        0.71153768, 0.6982398 , 0.69781838, 0.69524172, 0.66173293,\n",
       "        0.64531737, 0.63269879, 0.76314323, 0.69720606, 0.62738061,\n",
       "        0.66798788, 0.68216707, 0.87280323, 0.62190768, 0.65063899]),\n",
       " array([0.01615276, 0.03555334, 0.01832377, 0.01530089, 0.11696245,\n",
       "        0.02150917, 0.02477804, 0.03173685, 0.03661399, 0.02915524,\n",
       "        0.02098118, 0.02120914, 0.00639574, 0.01766495, 0.03043014,\n",
       "        0.02003272, 0.01578654, 0.01699791, 0.06373055, 0.01444691])]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "makefile(outputs7,\"ITNensemble/cifar100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
