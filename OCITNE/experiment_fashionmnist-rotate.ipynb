{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.datasets import fashion_mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score,log_loss, mean_absolute_error,median_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "def makefile(what,filename):\n",
    "    with open(filename,\"wb\") as f3:\n",
    "        pickle.dump(what,f3)\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename,\"rb\") as f4:\n",
    "        ans=pickle.load(f4)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[\"Lenna.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2=Image.open(\"Lenna.png\").resize([28,28]).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 6s 1ms/step - loss: 39.1382 - val_loss: 28.0584\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 3s 602us/step - loss: 24.3655 - val_loss: 23.4114\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 3s 621us/step - loss: 21.3432 - val_loss: 20.9379\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 3s 601us/step - loss: 19.4240 - val_loss: 19.3635\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 580us/step - loss: 18.4058 - val_loss: 18.3815\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 573us/step - loss: 17.4890 - val_loss: 17.7892\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 4s 1ms/step - loss: 16.6064 - val_loss: 16.5779\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 4s 1ms/step - loss: 15.9615 - val_loss: 16.9885\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 4s 910us/step - loss: 15.3473 - val_loss: 15.0263\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 4s 896us/step - loss: 14.7369 - val_loss: 14.7366\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 3s 748us/step - loss: 14.3613 - val_loss: 13.8773\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 13.8798 - val_loss: 13.8768\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 13.8263 - val_loss: 13.4186\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 13.3292 - val_loss: 13.3063\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 13.0181 - val_loss: 12.9263\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 12.9183 - val_loss: 12.8458\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 12.6885 - val_loss: 12.5930\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 12.6817 - val_loss: 12.5321\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 12.2523 - val_loss: 12.8546\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 12.1451 - val_loss: 12.3340\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.9956 - val_loss: 12.1054\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 11.8864 - val_loss: 11.9709\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 3s 676us/step - loss: 11.8012 - val_loss: 12.5105\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 3s 609us/step - loss: 11.6320 - val_loss: 12.1495\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 11.5867 - val_loss: 12.5002\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 589us/step - loss: 11.4320 - val_loss: 11.5501\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 562us/step - loss: 11.3434 - val_loss: 12.0254\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 11.2621 - val_loss: 11.3496\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 582us/step - loss: 11.2930 - val_loss: 11.8262\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 11.1282 - val_loss: 11.2003\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 3s 599us/step - loss: 10.9488 - val_loss: 11.1503\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 3s 664us/step - loss: 10.8787 - val_loss: 10.9520\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 10.8025 - val_loss: 10.7934\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 10.7212 - val_loss: 11.4262\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 10.8287 - val_loss: 10.8389\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 10.5640 - val_loss: 11.1226\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 10.6112 - val_loss: 10.7187\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 568us/step - loss: 10.6137 - val_loss: 10.7542\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 594us/step - loss: 10.4659 - val_loss: 10.6967\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 579us/step - loss: 10.4149 - val_loss: 10.5742\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 3s 641us/step - loss: 10.4046 - val_loss: 10.5499\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 3s 657us/step - loss: 10.2238 - val_loss: 10.5515\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.3104 - val_loss: 10.6594\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.3339 - val_loss: 10.4071\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.1831 - val_loss: 10.5616\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.1085 - val_loss: 10.7350\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 10.1387 - val_loss: 10.7318\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 3s 603us/step - loss: 10.0365 - val_loss: 10.2557\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 3s 751us/step - loss: 10.0537 - val_loss: 10.1721\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 3s 747us/step - loss: 9.9518 - val_loss: 10.2266\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 3s 750us/step - loss: 9.8888 - val_loss: 10.0560\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 3s 635us/step - loss: 10.0024 - val_loss: 10.0198\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 585us/step - loss: 9.8419 - val_loss: 10.3118\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 9.9160 - val_loss: 10.1233\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 9.9033 - val_loss: 10.1702\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 9.8735 - val_loss: 10.3500\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 9.7897 - val_loss: 9.9666\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 9.8240 - val_loss: 10.3683\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 9.6967 - val_loss: 9.9468\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 3s 681us/step - loss: 9.7742 - val_loss: 10.4191\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 3s 724us/step - loss: 9.6241 - val_loss: 9.9654\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 584us/step - loss: 9.6912 - val_loss: 10.0240\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 575us/step - loss: 9.6858 - val_loss: 9.9841\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 575us/step - loss: 9.6041 - val_loss: 9.9777\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 657us/step - loss: 36.2956 - val_loss: 23.3264\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 571us/step - loss: 21.7290 - val_loss: 19.5869\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 18.3951 - val_loss: 19.1210\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 16.8854 - val_loss: 16.4299\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 16.0208 - val_loss: 15.5943\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 15.2371 - val_loss: 15.7870\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 14.7761 - val_loss: 14.4802\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 14.1828 - val_loss: 14.7204\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 13.6265 - val_loss: 13.2770\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.1747 - val_loss: 13.2637\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 13.0049 - val_loss: 12.7457\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.5571 - val_loss: 14.0405\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.2145 - val_loss: 12.3313\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.0504 - val_loss: 11.9301\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.7508 - val_loss: 12.2013\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.6598 - val_loss: 11.6465\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.4235 - val_loss: 13.0267\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 11.2928 - val_loss: 11.3620\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 11.2174 - val_loss: 11.1324\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.8563 - val_loss: 11.4591\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.9381 - val_loss: 11.0698\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 11.0064 - val_loss: 10.6866\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.5290 - val_loss: 10.7253\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5032 - val_loss: 10.6250\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.3551 - val_loss: 10.5431\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.3011 - val_loss: 10.3819\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.0984 - val_loss: 10.0710\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 10.1521 - val_loss: 9.9012\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 10.3571 - val_loss: 10.2755\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.9016 - val_loss: 9.8168\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 9.9247 - val_loss: 9.6472\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 9.8037 - val_loss: 9.6445\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 9.7859 - val_loss: 12.2654\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 9.7103 - val_loss: 9.5929\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 566us/step - loss: 9.6626 - val_loss: 9.6892\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 9.5483 - val_loss: 9.6263\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 3s 636us/step - loss: 9.4686 - val_loss: 11.5282\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.6078 - val_loss: 9.3893\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.3738 - val_loss: 9.6087\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.2638 - val_loss: 9.3755\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 9.2286 - val_loss: 9.3161\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 9.2447 - val_loss: 9.3615\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.4470 - val_loss: 9.4401\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.0864 - val_loss: 9.0847\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 9.1129 - val_loss: 9.1281\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 8.9797 - val_loss: 9.0285\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.0662 - val_loss: 8.9797\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 8.9805 - val_loss: 9.2538\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.0624 - val_loss: 8.8232\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 8.8247 - val_loss: 8.8400\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 8.8661 - val_loss: 8.8801\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 8.8373 - val_loss: 9.0907\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 8.9112 - val_loss: 9.3007\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 8.8945 - val_loss: 8.7235\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 8.7231 - val_loss: 8.8731\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 8.7072 - val_loss: 8.5730\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 8.6972 - val_loss: 8.6806\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 8.6378 - val_loss: 8.5098\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 8.5738 - val_loss: 8.5238\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 8.4450 - val_loss: 9.0576\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 8.4919 - val_loss: 8.4173\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 8.4779 - val_loss: 8.8389\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 8.5018 - val_loss: 8.5356\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 8.4342 - val_loss: 9.0766\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 8.4375 - val_loss: 8.5342\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 8.3666 - val_loss: 8.5001\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 595us/step - loss: 38.2192 - val_loss: 30.4783\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 27.1874 - val_loss: 27.0357\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 22.8904 - val_loss: 21.9190\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 20.2628 - val_loss: 21.2539\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 18.5490 - val_loss: 18.0098\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 17.3543 - val_loss: 16.6025\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 16.2795 - val_loss: 15.3517\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 15.6080 - val_loss: 16.7125\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 14.9581 - val_loss: 14.4713\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 14.3837 - val_loss: 14.7424\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 14.2373 - val_loss: 14.7536\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 13.6726 - val_loss: 14.0013\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.5758 - val_loss: 13.3322\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.1172 - val_loss: 12.9415\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.0473 - val_loss: 12.9925\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.6386 - val_loss: 12.8904\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.6103 - val_loss: 12.4221\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.3583 - val_loss: 12.3421\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.1678 - val_loss: 12.2043\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.9834 - val_loss: 12.2758\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 11.8337 - val_loss: 11.7697\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.7219 - val_loss: 11.9008\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.5698 - val_loss: 12.1213\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.5060 - val_loss: 11.5162\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.3605 - val_loss: 11.3507\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.3146 - val_loss: 11.9368\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 11.2371 - val_loss: 11.5120\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.1347 - val_loss: 11.3218\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 10.9924 - val_loss: 11.2418\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.9000 - val_loss: 10.9718\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.7958 - val_loss: 10.9556\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.7655 - val_loss: 11.0197\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.7178 - val_loss: 10.9741\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 10.6309 - val_loss: 11.1187\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.5570 - val_loss: 11.2843\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.4017 - val_loss: 10.6105\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.3694 - val_loss: 10.8957\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.3745 - val_loss: 10.5109\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.2036 - val_loss: 10.4219\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.2395 - val_loss: 10.7121\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.1047 - val_loss: 10.3591\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.0302 - val_loss: 10.2684\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 9.9475 - val_loss: 10.1092\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 9.9057 - val_loss: 10.1450\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.8593 - val_loss: 10.1751\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 9.7505 - val_loss: 10.0963\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 9.7974 - val_loss: 9.9189\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.6785 - val_loss: 9.9445\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.6652 - val_loss: 9.8538\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.6493 - val_loss: 9.8881\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 9.5441 - val_loss: 9.8048\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.4739 - val_loss: 9.6844\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.4647 - val_loss: 10.3350\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.3856 - val_loss: 9.6700\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.3938 - val_loss: 9.8146\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 3s 677us/step - loss: 9.6451 - val_loss: 9.6748\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 3s 597us/step - loss: 9.2251 - val_loss: 9.8242\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 9.2019 - val_loss: 9.5470\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 9.2396 - val_loss: 9.6119\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 3s 612us/step - loss: 9.2103 - val_loss: 9.9591\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 576us/step - loss: 9.1660 - val_loss: 9.5578\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 584us/step - loss: 9.0830 - val_loss: 9.5443\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 3s 625us/step - loss: 9.0828 - val_loss: 9.3285\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 3s 648us/step - loss: 9.0710 - val_loss: 9.4522\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 3s 619us/step - loss: 9.0376 - val_loss: 9.3827\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 3s 698us/step - loss: 9.0068 - val_loss: 9.3353\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 3s 669us/step - loss: 9.0521 - val_loss: 9.4532\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 3s 659us/step - loss: 8.9778 - val_loss: 9.2008\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 582us/step - loss: 8.8666 - val_loss: 9.1926\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 8.8420 - val_loss: 9.4019\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 8.8986 - val_loss: 9.1795\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 3s 628us/step - loss: 8.8965 - val_loss: 9.1261\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 3s 655us/step - loss: 8.8387 - val_loss: 9.5729\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 8.8122 - val_loss: 9.1931\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 566us/step - loss: 8.7852 - val_loss: 9.2362\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 3s 702us/step - loss: 8.7818 - val_loss: 9.1037\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 3s 651us/step - loss: 8.7132 - val_loss: 9.6019\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 591us/step - loss: 8.7332 - val_loss: 9.2459\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 8.6659 - val_loss: 9.9773\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 8.7037 - val_loss: 9.3663\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 8.7872 - val_loss: 9.0227\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 8.6162 - val_loss: 8.9933\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 8.6024 - val_loss: 10.2543\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 8.6294 - val_loss: 9.1541\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 8.5343 - val_loss: 9.1468\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 8.5151 - val_loss: 9.0693\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 8.5439 - val_loss: 9.1501\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 36.0596 - val_loss: 27.0251\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 23.6033 - val_loss: 21.6964\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.9201 - val_loss: 20.0818\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 19.0792 - val_loss: 18.9300\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.2089 - val_loss: 17.6290\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.2145 - val_loss: 16.8043\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.6747 - val_loss: 16.3746\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 16.0495 - val_loss: 16.3575\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.5482 - val_loss: 15.1356\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.2846 - val_loss: 15.5437\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.8785 - val_loss: 15.1166\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.5952 - val_loss: 15.7637\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.4327 - val_loss: 14.5405\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1147 - val_loss: 13.7313\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.0182 - val_loss: 14.1690\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.6257 - val_loss: 13.6734\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.3945 - val_loss: 13.4140\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 13.2496 - val_loss: 13.1686\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 13.1856 - val_loss: 13.2007\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 12.9099 - val_loss: 12.6365\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 12.6771 - val_loss: 13.4738\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 12.7172 - val_loss: 12.9144\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.5138 - val_loss: 12.6403\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4413 - val_loss: 12.5381\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.3765 - val_loss: 12.4930\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.1092 - val_loss: 13.7832\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1155 - val_loss: 12.5724\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.9847 - val_loss: 12.0602\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8722 - val_loss: 12.2157\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.9592 - val_loss: 11.9982\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7703 - val_loss: 12.1663\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.6767 - val_loss: 11.9376\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.6205 - val_loss: 11.8139\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5723 - val_loss: 12.1433\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4683 - val_loss: 11.9752\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4704 - val_loss: 11.6438\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5400 - val_loss: 12.3102\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.3953 - val_loss: 12.2567\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3134 - val_loss: 11.4115\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1625 - val_loss: 11.5658\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1920 - val_loss: 11.2446\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1293 - val_loss: 11.1658\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.0968 - val_loss: 11.2498\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0658 - val_loss: 11.1730\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9916 - val_loss: 11.1405\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0488 - val_loss: 11.1346\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0224 - val_loss: 12.4390\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.0797 - val_loss: 11.0133\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.8251 - val_loss: 10.9624\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.8134 - val_loss: 11.0271\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.8028 - val_loss: 11.1035\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.7540 - val_loss: 11.2363\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7919 - val_loss: 10.9273\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6614 - val_loss: 10.8692\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5607 - val_loss: 11.0367\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.6344 - val_loss: 10.8129\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.6123 - val_loss: 10.7670\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5534 - val_loss: 10.6692\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.4932 - val_loss: 10.8114\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5016 - val_loss: 10.7002\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5055 - val_loss: 10.6096\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.4533 - val_loss: 10.7851\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.3739 - val_loss: 10.6344\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.3737 - val_loss: 11.5537\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.4700 - val_loss: 10.8709\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3595 - val_loss: 10.5516\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.3011 - val_loss: 10.5340\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.2401 - val_loss: 10.4927\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.2459 - val_loss: 10.4969\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.3144 - val_loss: 10.5942\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.2188 - val_loss: 10.7545\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.1820 - val_loss: 10.3746\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.1155 - val_loss: 10.4313\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.1279 - val_loss: 10.4912\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1853 - val_loss: 10.3259\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.1285 - val_loss: 10.3105\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 415us/step - loss: 10.0766 - val_loss: 11.1421\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0586 - val_loss: 10.3318\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 492us/step - loss: 10.1560 - val_loss: 10.4954\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.0303 - val_loss: 10.3705\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 10.0325 - val_loss: 10.3261\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 640us/step - loss: 34.2658 - val_loss: 24.2341\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 22.4457 - val_loss: 20.0117\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 19.5608 - val_loss: 18.8819\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.1478 - val_loss: 17.5713\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 438us/step - loss: 17.0603 - val_loss: 15.9070\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.8571 - val_loss: 15.8751\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 434us/step - loss: 15.2949 - val_loss: 16.5499\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 14.8191 - val_loss: 14.9558\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.5729 - val_loss: 13.9596\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.0791 - val_loss: 13.4198\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 13.5895 - val_loss: 13.1586\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.1895 - val_loss: 13.8046\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 13.2963 - val_loss: 13.8679\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 12.6746 - val_loss: 13.0319\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 12.5217 - val_loss: 12.7894\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 12.3125 - val_loss: 12.1700\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 12.1204 - val_loss: 12.8886\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.8572 - val_loss: 11.6775\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 11.6373 - val_loss: 11.6391\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.6037 - val_loss: 11.8849\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.2684 - val_loss: 11.2724\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.1882 - val_loss: 11.0919\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0079 - val_loss: 11.0380\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.9328 - val_loss: 10.7256\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8727 - val_loss: 10.7326\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.6432 - val_loss: 10.7520\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.6325 - val_loss: 10.6030\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 10.4882 - val_loss: 10.6627\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5066 - val_loss: 10.6698\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.3401 - val_loss: 10.3591\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.1669 - val_loss: 10.0782\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.1767 - val_loss: 10.1413\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0698 - val_loss: 10.5468\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0123 - val_loss: 10.1701\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.0620 - val_loss: 10.3775\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.8193 - val_loss: 9.8223\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.9664 - val_loss: 9.8120\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.9478 - val_loss: 10.1143\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.7051 - val_loss: 9.7266\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 9.6980 - val_loss: 10.0322\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.6028 - val_loss: 9.9745\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.5906 - val_loss: 9.6106\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 9.7329 - val_loss: 9.5423\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 9.5003 - val_loss: 9.6309\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.5516 - val_loss: 9.4161\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4408 - val_loss: 10.5522\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.4347 - val_loss: 9.5113\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.3978 - val_loss: 9.5433\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.2630 - val_loss: 9.5777\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.3247 - val_loss: 9.8185\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 41.7161 - val_loss: 29.1105\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 27.1025 - val_loss: 25.1136\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 24.3757 - val_loss: 22.8093\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 22.6461 - val_loss: 21.2326\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 21.2506 - val_loss: 21.9164\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 20.3676 - val_loss: 19.5356\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 19.5034 - val_loss: 18.9529\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 18.8108 - val_loss: 19.1941\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 18.4883 - val_loss: 18.8256\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 18.0476 - val_loss: 18.8282\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.3588 - val_loss: 16.9001\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 16.8197 - val_loss: 18.7874\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 16.7345 - val_loss: 17.0206\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 16.3301 - val_loss: 15.6230\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 16.0680 - val_loss: 16.5073\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 15.7251 - val_loss: 15.2934\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.5272 - val_loss: 15.2905\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 15.3589 - val_loss: 14.9316\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.0308 - val_loss: 15.0030\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.8992 - val_loss: 14.6929\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.7729 - val_loss: 14.5771\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.5504 - val_loss: 14.3784\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.3524 - val_loss: 15.3180\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.2568 - val_loss: 13.9226\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.1846 - val_loss: 14.0925\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.1871 - val_loss: 14.6201\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.9467 - val_loss: 13.7753\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.7807 - val_loss: 14.5713\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.6888 - val_loss: 13.7608\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.7522 - val_loss: 13.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.4401 - val_loss: 14.1564\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 13.7765 - val_loss: 13.5766\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.3082 - val_loss: 13.5880\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 13.2651 - val_loss: 13.9521\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.1284 - val_loss: 13.8033\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.2238 - val_loss: 13.5190\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.0159 - val_loss: 15.3357\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.0036 - val_loss: 13.0465\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.9572 - val_loss: 13.2481\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.8740 - val_loss: 12.7476\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.8094 - val_loss: 12.6821\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7942 - val_loss: 12.6285\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 424us/step - loss: 12.6576 - val_loss: 12.6773\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.5835 - val_loss: 12.8982\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 12.6040 - val_loss: 12.7145\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 12.4173 - val_loss: 12.4343\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 12.4599 - val_loss: 12.3236\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 12.4520 - val_loss: 12.3519\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.3882 - val_loss: 12.3921\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 12.2872 - val_loss: 12.4860\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 12.3446 - val_loss: 12.4618\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2503 - val_loss: 13.2945\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 41.1406 - val_loss: 30.9004\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 433us/step - loss: 26.1919 - val_loss: 22.7698\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 22.6638 - val_loss: 22.5169\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 20.8515 - val_loss: 19.4296\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 19.5179 - val_loss: 18.2943\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.3141 - val_loss: 18.5751\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.6605 - val_loss: 17.4431\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.5009 - val_loss: 17.0053\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.1129 - val_loss: 16.2524\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.5737 - val_loss: 15.3385\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.0775 - val_loss: 14.5892\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.6634 - val_loss: 15.0736\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.4214 - val_loss: 14.0332\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.0742 - val_loss: 13.7928\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.9309 - val_loss: 13.4624\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.4475 - val_loss: 13.4925\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.3377 - val_loss: 13.1618\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2047 - val_loss: 13.0961\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.8369 - val_loss: 13.0702\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.9198 - val_loss: 12.4254\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6787 - val_loss: 13.0327\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.3901 - val_loss: 12.4007\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.4027 - val_loss: 12.1570\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.3285 - val_loss: 12.1030\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.0419 - val_loss: 12.2498\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0389 - val_loss: 11.9505\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.9150 - val_loss: 11.7730\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.8507 - val_loss: 11.8423\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7231 - val_loss: 11.5382\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.8799 - val_loss: 11.6393\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 11.6137 - val_loss: 11.9141\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6097 - val_loss: 11.4105\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.3875 - val_loss: 11.2768\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4684 - val_loss: 11.3554\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.3816 - val_loss: 11.6023\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.2404 - val_loss: 11.1732\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 11.2361 - val_loss: 11.5570\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 11.1164 - val_loss: 11.1649\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 11.2216 - val_loss: 11.2002\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 11.1020 - val_loss: 11.0184\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.0171 - val_loss: 10.8496\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9360 - val_loss: 11.1848\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1662 - val_loss: 11.5998\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.8868 - val_loss: 10.7821\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.7896 - val_loss: 10.7943\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.8265 - val_loss: 11.2466\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.7239 - val_loss: 10.9007\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7357 - val_loss: 10.5940\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.5793 - val_loss: 10.4564\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.6800 - val_loss: 10.6763\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5954 - val_loss: 10.6869\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.6197 - val_loss: 10.7472\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5576 - val_loss: 10.5425\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.4415 - val_loss: 10.6315\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 37.8797 - val_loss: 25.0527\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 22.6322 - val_loss: 19.7654\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 19.5321 - val_loss: 18.1003\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 18.2601 - val_loss: 17.6791\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.1167 - val_loss: 17.1496\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.5166 - val_loss: 16.0503\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.8083 - val_loss: 15.4888\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.4406 - val_loss: 15.0772\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.9209 - val_loss: 14.4657\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.5664 - val_loss: 14.3928\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.3658 - val_loss: 13.7296\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.2012 - val_loss: 13.6690\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.7385 - val_loss: 13.4025\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.5284 - val_loss: 13.2701\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.2275 - val_loss: 13.5912\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2516 - val_loss: 12.9180\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9851 - val_loss: 12.8409\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8045 - val_loss: 13.3952\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7244 - val_loss: 12.4029\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.5375 - val_loss: 12.0722\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4466 - val_loss: 11.8708\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.2189 - val_loss: 13.2126\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.1352 - val_loss: 11.8167\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.9500 - val_loss: 11.8198\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1388 - val_loss: 11.9793\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.5947 - val_loss: 11.5387\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6119 - val_loss: 11.2065\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5056 - val_loss: 11.8266\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.3350 - val_loss: 11.0904\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.2785 - val_loss: 10.9217\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2294 - val_loss: 10.8381\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.1544 - val_loss: 10.8551\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.0504 - val_loss: 10.5083\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.9076 - val_loss: 10.9028\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8950 - val_loss: 10.5909\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.7675 - val_loss: 10.6011\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 399us/step - loss: 10.6658 - val_loss: 10.3733\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6482 - val_loss: 10.4120\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 10.4979 - val_loss: 10.3324\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 10.5043 - val_loss: 10.5825\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 10.4501 - val_loss: 10.2204\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 10.3504 - val_loss: 10.3968\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 10.3630 - val_loss: 10.0374\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 10.1910 - val_loss: 9.9409\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1566 - val_loss: 10.1626\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.2685 - val_loss: 10.2553\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.1152 - val_loss: 10.0448\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.1226 - val_loss: 9.6455\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9834 - val_loss: 9.8398\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9525 - val_loss: 9.6137\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 9.9466 - val_loss: 10.0163\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.9506 - val_loss: 9.7131\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 9.8484 - val_loss: 9.6491\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.8191 - val_loss: 9.4835\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 9.8331 - val_loss: 10.0367\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.6811 - val_loss: 9.7853\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 9.8414 - val_loss: 9.7793\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 9.5967 - val_loss: 9.3400\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 9.6583 - val_loss: 9.5456\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.6864 - val_loss: 9.7173\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.5448 - val_loss: 9.1854\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 9.4671 - val_loss: 9.2707\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.4537 - val_loss: 9.2580\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 9.5975 - val_loss: 9.5207\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.5634 - val_loss: 11.0584\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.4875 - val_loss: 9.2968\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 38.1482 - val_loss: 30.3396\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 27.5093 - val_loss: 26.6068\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 24.5546 - val_loss: 23.6069\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 22.6435 - val_loss: 22.8740\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 21.6439 - val_loss: 21.0459\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 21.0848 - val_loss: 20.3646\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 20.4382 - val_loss: 20.7220\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 19.9167 - val_loss: 19.9647\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 442us/step - loss: 19.4769 - val_loss: 19.2828\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 19.1116 - val_loss: 18.8612\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.6405 - val_loss: 18.4639\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.2569 - val_loss: 18.5280\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 18.1401 - val_loss: 17.6071\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 17.7979 - val_loss: 18.5992\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 17.5188 - val_loss: 17.4084\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 17.3462 - val_loss: 17.1772\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 17.0303 - val_loss: 16.7479\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 16.8738 - val_loss: 16.3782\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 16.5484 - val_loss: 17.1212\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.3327 - val_loss: 16.2148\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.1565 - val_loss: 16.0912\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 16.0406 - val_loss: 16.9941\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.8548 - val_loss: 16.2240\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.7400 - val_loss: 15.7774\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7404 - val_loss: 15.8261\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.5365 - val_loss: 15.3738\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.3400 - val_loss: 15.9228\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.1801 - val_loss: 15.4749\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.2479 - val_loss: 15.7182\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.1007 - val_loss: 15.1037\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.0039 - val_loss: 14.9828\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.8585 - val_loss: 16.1537\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.8814 - val_loss: 15.3073\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.7032 - val_loss: 15.4248\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.6937 - val_loss: 16.1662\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.6258 - val_loss: 14.6805\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.5610 - val_loss: 15.1919\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.4729 - val_loss: 14.5078\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.4760 - val_loss: 14.4749\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.4038 - val_loss: 14.6438\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.3527 - val_loss: 14.3068\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.4455 - val_loss: 14.3494\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.2701 - val_loss: 14.3375\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.2456 - val_loss: 14.4185\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.0969 - val_loss: 14.3625\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.1091 - val_loss: 14.2139\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.1815 - val_loss: 14.2257\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.0059 - val_loss: 14.2657\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.0276 - val_loss: 14.1272\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8949 - val_loss: 14.2293\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.9235 - val_loss: 14.1671\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.8638 - val_loss: 14.3096\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.8875 - val_loss: 14.1390\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.7406 - val_loss: 14.3396\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 36.0390 - val_loss: 25.0608\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 23.5661 - val_loss: 21.7234\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 21.0297 - val_loss: 19.2985\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.2977 - val_loss: 18.5030\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.4296 - val_loss: 18.5689\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 17.6179 - val_loss: 16.6522\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 17.0464 - val_loss: 16.6978\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.7365 - val_loss: 16.4003\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.2386 - val_loss: 15.5491\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.8138 - val_loss: 15.9414\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.3899 - val_loss: 15.6721\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.2028 - val_loss: 14.5754\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.8706 - val_loss: 14.5639\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.5463 - val_loss: 14.4351\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.4406 - val_loss: 15.0865\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 417us/step - loss: 14.2215 - val_loss: 13.7382\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.9092 - val_loss: 14.2649\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 13.6995 - val_loss: 13.3329\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 13.4839 - val_loss: 14.0146\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 13.6182 - val_loss: 13.7355\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 13.2824 - val_loss: 13.2915\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 13.0182 - val_loss: 12.7877\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 13.0922 - val_loss: 12.7480\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.8140 - val_loss: 12.8587\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 12.6713 - val_loss: 12.5125\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.6498 - val_loss: 12.2716\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.4337 - val_loss: 12.2856\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.3735 - val_loss: 12.5475\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.2297 - val_loss: 11.9211\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 1s 321us/step - loss: 12.0428 - val_loss: 12.4194\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 1s 288us/step - loss: 12.0236 - val_loss: 12.2272\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 414us/step - loss: 11.8582 - val_loss: 11.8179\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.7894 - val_loss: 12.0753\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 11.6874 - val_loss: 12.0572\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.6531 - val_loss: 11.7736\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.6833 - val_loss: 11.4067\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.5022 - val_loss: 11.3013\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.4102 - val_loss: 11.1597\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.3194 - val_loss: 11.2911\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 11.2907 - val_loss: 13.4560\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.2111 - val_loss: 11.2101\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.2053 - val_loss: 11.1203\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.0749 - val_loss: 11.2024\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.9532 - val_loss: 11.0532\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9597 - val_loss: 11.0094\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.9796 - val_loss: 10.7595\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.8307 - val_loss: 11.0669\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7417 - val_loss: 11.0688\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8161 - val_loss: 11.4445\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.7723 - val_loss: 11.4195\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6823 - val_loss: 10.7258\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.7045 - val_loss: 10.7905\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.5902 - val_loss: 10.5105\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6229 - val_loss: 10.5842\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.5388 - val_loss: 10.4396\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.4448 - val_loss: 10.5424\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4030 - val_loss: 10.6398\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.3847 - val_loss: 10.7188\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3996 - val_loss: 10.7784\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4576 - val_loss: 10.3674\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.3364 - val_loss: 10.4375\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.2792 - val_loss: 10.3478\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 10.3519 - val_loss: 10.4086\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.2238 - val_loss: 10.4266\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.2119 - val_loss: 10.3876\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 10.2766 - val_loss: 10.3520\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.1544 - val_loss: 10.4156\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 38.3299 - val_loss: 29.7384\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 25.5481 - val_loss: 27.8005\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 21.7112 - val_loss: 21.0765\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 19.9732 - val_loss: 20.0302\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.7532 - val_loss: 20.0967\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.6482 - val_loss: 16.9574\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 16.8174 - val_loss: 16.3477\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.0917 - val_loss: 16.0008\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.6486 - val_loss: 15.6060\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.3423 - val_loss: 15.3392\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.0222 - val_loss: 15.5645\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.5520 - val_loss: 14.7442\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.1634 - val_loss: 14.6580\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.1504 - val_loss: 14.0001\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.7586 - val_loss: 13.7254\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.6485 - val_loss: 13.5788\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4047 - val_loss: 13.5968\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.2429 - val_loss: 13.4369\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.0146 - val_loss: 13.1663\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.9094 - val_loss: 13.1198\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7636 - val_loss: 13.3811\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.7048 - val_loss: 12.8030\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.4960 - val_loss: 12.6488\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.4866 - val_loss: 13.0090\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.1977 - val_loss: 12.4994\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1917 - val_loss: 13.2574\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0854 - val_loss: 12.4122\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.0149 - val_loss: 12.1368\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8442 - val_loss: 12.8623\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.7945 - val_loss: 11.9414\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.7290 - val_loss: 11.9425\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.5483 - val_loss: 11.9361\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5542 - val_loss: 11.6386\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.4451 - val_loss: 11.8010\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3794 - val_loss: 11.6931\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2890 - val_loss: 11.5749\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4127 - val_loss: 11.7250\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.2057 - val_loss: 11.3554\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.0686 - val_loss: 11.5529\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.9882 - val_loss: 11.8158\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.0076 - val_loss: 11.8681\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.9698 - val_loss: 11.9003\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.9884 - val_loss: 11.4394\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 36.9937 - val_loss: 25.3308\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 21.9880 - val_loss: 19.7142\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 19.4597 - val_loss: 19.5068\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.2343 - val_loss: 17.6044\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 17.2436 - val_loss: 17.5224\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 391us/step - loss: 16.4914 - val_loss: 16.6515\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 1s 203us/step - loss: 16.3140 - val_loss: 16.1856\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 359us/step - loss: 15.6424 - val_loss: 15.5392\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 15.1971 - val_loss: 15.4731\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 14.8520 - val_loss: 14.5654\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 14.7017 - val_loss: 15.1821\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 14.5073 - val_loss: 14.6741\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 14.1238 - val_loss: 13.9712\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 13.8072 - val_loss: 14.2849\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 13.5769 - val_loss: 13.8682\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3925 - val_loss: 13.2432\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2473 - val_loss: 13.3131\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.9896 - val_loss: 13.0328\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.8497 - val_loss: 12.8490\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.7481 - val_loss: 12.5217\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 12.5038 - val_loss: 12.7759\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.4809 - val_loss: 12.6462\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.3164 - val_loss: 12.4830\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0690 - val_loss: 12.0528\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.1871 - val_loss: 12.2005\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.2560 - val_loss: 11.9556\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.8498 - val_loss: 12.2608\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.7262 - val_loss: 11.9453\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6339 - val_loss: 11.8335\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4893 - val_loss: 11.5854\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.5236 - val_loss: 12.1307\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.3892 - val_loss: 11.8342\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.3499 - val_loss: 11.3567\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.3182 - val_loss: 11.3654\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.1193 - val_loss: 11.7879\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.2331 - val_loss: 11.6079\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.0461 - val_loss: 11.1431\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.9786 - val_loss: 11.1080\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.1510 - val_loss: 11.5477\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.7603 - val_loss: 11.1636\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8732 - val_loss: 10.8618\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9803 - val_loss: 10.9041\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.6448 - val_loss: 10.7768\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5723 - val_loss: 11.0254\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.5552 - val_loss: 10.9079\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.5226 - val_loss: 11.9025\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4954 - val_loss: 10.7102\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.5135 - val_loss: 10.6527\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4448 - val_loss: 10.6146\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3227 - val_loss: 10.6650\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.3233 - val_loss: 11.0852\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3096 - val_loss: 10.7701\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.2902 - val_loss: 11.6438\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.4616 - val_loss: 11.1973\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 38.2147 - val_loss: 29.1721\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 26.7685 - val_loss: 25.3127\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 22.8563 - val_loss: 21.9176\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 21.0763 - val_loss: 19.8108\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 19.3025 - val_loss: 20.9709\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.2789 - val_loss: 17.6362\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 17.6018 - val_loss: 18.7281\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.6464 - val_loss: 16.1072\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.9310 - val_loss: 15.8543\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.5381 - val_loss: 15.0623\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.9292 - val_loss: 14.5101\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.6103 - val_loss: 14.5951\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.2421 - val_loss: 14.0335\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.9292 - val_loss: 14.8293\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.6686 - val_loss: 14.4409\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.4733 - val_loss: 13.3474\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.2203 - val_loss: 13.3303\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.0918 - val_loss: 14.2800\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.9168 - val_loss: 13.1052\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.6779 - val_loss: 12.6488\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5917 - val_loss: 12.6332\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.4135 - val_loss: 12.5420\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.3351 - val_loss: 12.8786\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.2431 - val_loss: 12.3560\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0123 - val_loss: 12.2010\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8539 - val_loss: 12.3747\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.8850 - val_loss: 12.1647\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 11.8561 - val_loss: 12.5779\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.6973 - val_loss: 11.7982\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5739 - val_loss: 12.1682\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6524 - val_loss: 11.6369\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.3660 - val_loss: 11.5965\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2411 - val_loss: 11.4586\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.3313 - val_loss: 11.4177\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2555 - val_loss: 11.9959\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.3556 - val_loss: 11.1999\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.9611 - val_loss: 11.1737\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9900 - val_loss: 11.0980\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.9438 - val_loss: 11.0681\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.8534 - val_loss: 11.4687\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.9111 - val_loss: 11.2850\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.6896 - val_loss: 10.9779\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.6803 - val_loss: 11.1941\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.6719 - val_loss: 11.1164\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 10.6634 - val_loss: 10.7727\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.7327 - val_loss: 11.2426\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.4979 - val_loss: 12.2582\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5347 - val_loss: 10.8204\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.3576 - val_loss: 10.6051\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.5222 - val_loss: 10.6852\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3281 - val_loss: 10.7073\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3435 - val_loss: 11.0227\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.4122 - val_loss: 10.3910\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1871 - val_loss: 10.9611\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.1894 - val_loss: 10.8330\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.1441 - val_loss: 10.4355\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.0968 - val_loss: 10.4719\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.0237 - val_loss: 10.8198\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 38.2164 - val_loss: 28.2871\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 26.6870 - val_loss: 25.3761\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 22.9695 - val_loss: 21.8345\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 21.5481 - val_loss: 20.7560\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.5842 - val_loss: 19.6069\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 19.5453 - val_loss: 19.0029\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 18.7388 - val_loss: 18.5199\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 435us/step - loss: 18.3455 - val_loss: 17.8881\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 435us/step - loss: 17.8018 - val_loss: 17.7150\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.4159 - val_loss: 17.1833\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.1970 - val_loss: 16.8716\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.6773 - val_loss: 17.1045\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.4775 - val_loss: 16.5234\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.1014 - val_loss: 15.8461\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.8754 - val_loss: 15.5690\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 15.6109 - val_loss: 16.0465\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.6442 - val_loss: 18.8588\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.4270 - val_loss: 15.1123\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.1362 - val_loss: 14.9609\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8591 - val_loss: 15.4317\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.8518 - val_loss: 14.5978\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7943 - val_loss: 15.4245\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.5046 - val_loss: 14.7307\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.3186 - val_loss: 14.4285\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.1970 - val_loss: 14.0653\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.1372 - val_loss: 14.4051\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.1652 - val_loss: 14.5875\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.9554 - val_loss: 13.9757\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.7712 - val_loss: 14.3055\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.7898 - val_loss: 13.8078\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.5939 - val_loss: 13.8638\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.6192 - val_loss: 13.6570\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.4564 - val_loss: 13.5505\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.4132 - val_loss: 13.3479\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.2448 - val_loss: 13.6653\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.2098 - val_loss: 13.1808\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.2481 - val_loss: 13.1947\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.1646 - val_loss: 13.0387\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.9220 - val_loss: 13.7157\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.8787 - val_loss: 12.9806\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.8498 - val_loss: 12.8655\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.7769 - val_loss: 13.9086\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 12.8045 - val_loss: 12.7411\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 12.6648 - val_loss: 12.7718\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 12.5768 - val_loss: 12.8983\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 12.6363 - val_loss: 13.1847\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 12.5315 - val_loss: 12.6062\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 12.4207 - val_loss: 12.7223\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 12.4542 - val_loss: 13.0622\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.4172 - val_loss: 12.7046\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.4018 - val_loss: 12.5862\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.2388 - val_loss: 12.4317\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.2233 - val_loss: 12.9719\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 12.1802 - val_loss: 12.1409\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.1871 - val_loss: 12.4640\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.1444 - val_loss: 12.2454\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0214 - val_loss: 12.4799\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 12.0992 - val_loss: 12.1661\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.0364 - val_loss: 12.8162\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 35.2624 - val_loss: 26.5517\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 24.6024 - val_loss: 21.8743\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 21.4443 - val_loss: 20.5724\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.5601 - val_loss: 20.4759\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.3551 - val_loss: 17.8533\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.6920 - val_loss: 18.4728\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.1799 - val_loss: 16.3741\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.5614 - val_loss: 16.7823\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.0949 - val_loss: 15.4790\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7822 - val_loss: 15.2563\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.4809 - val_loss: 15.2713\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.1371 - val_loss: 15.1049\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.8581 - val_loss: 14.3117\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.8817 - val_loss: 14.8210\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.4481 - val_loss: 14.2006\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.0958 - val_loss: 14.7669\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.8970 - val_loss: 14.0742\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.9725 - val_loss: 13.6901\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 13.7424 - val_loss: 13.9771\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.3255 - val_loss: 13.9960\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2512 - val_loss: 13.3282\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.2057 - val_loss: 12.9964\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1224 - val_loss: 13.4990\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.0144 - val_loss: 13.4085\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.7129 - val_loss: 13.5329\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.5798 - val_loss: 12.4707\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.5292 - val_loss: 12.2177\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3189 - val_loss: 12.1425\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2540 - val_loss: 12.3519\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2818 - val_loss: 12.3932\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2785 - val_loss: 12.4476\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8875 - val_loss: 12.3940\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.0185 - val_loss: 12.8049\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 41.2075 - val_loss: 29.7261\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 27.6281 - val_loss: 26.2607\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 412us/step - loss: 24.3883 - val_loss: 23.8683\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 1s 353us/step - loss: 23.0457 - val_loss: 22.3501\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 21.6889 - val_loss: 21.4460\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 20.8839 - val_loss: 21.5585\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 20.3280 - val_loss: 19.7272\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 19.4460 - val_loss: 19.8496\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 18.8987 - val_loss: 18.5888\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 18.6467 - val_loss: 19.1389\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 18.1197 - val_loss: 19.0195\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.7981 - val_loss: 17.2293\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 17.4880 - val_loss: 17.0092\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.2551 - val_loss: 17.0411\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.9088 - val_loss: 16.6774\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 439us/step - loss: 16.6702 - val_loss: 17.0910\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 16.5371 - val_loss: 16.6852\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 16.2063 - val_loss: 16.9501\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.1758 - val_loss: 16.4018\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.7246 - val_loss: 15.4368\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.6863 - val_loss: 15.3337\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.6957 - val_loss: 15.6559\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.2999 - val_loss: 15.9142\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.2499 - val_loss: 15.8412\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.2065 - val_loss: 16.1502\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.1073 - val_loss: 15.0203\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.8469 - val_loss: 14.8103\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.8588 - val_loss: 14.7377\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.7909 - val_loss: 14.6027\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.7077 - val_loss: 14.7453\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.5030 - val_loss: 14.5017\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.4219 - val_loss: 14.4654\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3838 - val_loss: 14.8193\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.2913 - val_loss: 14.2124\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.2491 - val_loss: 14.0828\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.0501 - val_loss: 14.0132\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1712 - val_loss: 14.2802\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.0426 - val_loss: 13.7448\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.8707 - val_loss: 13.9313\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8197 - val_loss: 14.5758\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.8217 - val_loss: 13.6486\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.6915 - val_loss: 14.1106\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.8652 - val_loss: 13.8370\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.5333 - val_loss: 13.7495\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.5594 - val_loss: 13.4731\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4792 - val_loss: 13.6451\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.4150 - val_loss: 13.4161\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4013 - val_loss: 13.5047\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3981 - val_loss: 13.3637\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 13.3826 - val_loss: 13.3062\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.2677 - val_loss: 13.3157\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 13.1561 - val_loss: 13.2495\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.1658 - val_loss: 13.0582\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.0603 - val_loss: 13.9682\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.1398 - val_loss: 13.2164\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.0849 - val_loss: 13.0520\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.0134 - val_loss: 13.1307\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.9848 - val_loss: 12.9730\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.9596 - val_loss: 13.2927\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.9326 - val_loss: 12.9109\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8291 - val_loss: 13.1224\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.8719 - val_loss: 13.3018\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.9039 - val_loss: 13.0236\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7968 - val_loss: 12.9450\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.7298 - val_loss: 12.9085\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.8483 - val_loss: 13.0078\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6804 - val_loss: 12.7061\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.6611 - val_loss: 12.8217\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.6938 - val_loss: 13.0473\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.6068 - val_loss: 12.8906\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.6416 - val_loss: 12.7397\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5610 - val_loss: 12.9362\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 40.6455 - val_loss: 31.6965\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 27.3067 - val_loss: 24.3184\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 23.7644 - val_loss: 24.0047\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 21.9004 - val_loss: 21.2310\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 20.5713 - val_loss: 19.8252\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 19.2007 - val_loss: 18.3775\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 18.1831 - val_loss: 18.1363\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 17.5808 - val_loss: 17.2864\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.0510 - val_loss: 18.5141\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.7505 - val_loss: 17.0801\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.2854 - val_loss: 17.1153\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.0667 - val_loss: 15.6085\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.5961 - val_loss: 15.1766\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.3718 - val_loss: 14.8630\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.2540 - val_loss: 15.5110\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 15.0023 - val_loss: 15.0066\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.8072 - val_loss: 14.9720\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.5149 - val_loss: 14.2808\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.3500 - val_loss: 14.0900\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.1333 - val_loss: 14.3280\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 14.0180 - val_loss: 13.8473\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 13.7141 - val_loss: 13.6311\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.7820 - val_loss: 13.5300\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.5432 - val_loss: 13.2008\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 13.3676 - val_loss: 13.5340\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.2200 - val_loss: 13.1869\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 13.1019 - val_loss: 13.0445\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.0529 - val_loss: 12.9776\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.9413 - val_loss: 12.8359\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 12.8974 - val_loss: 12.6275\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.6840 - val_loss: 13.8874\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 12.7005 - val_loss: 12.6420\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6010 - val_loss: 12.9584\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.5079 - val_loss: 12.4795\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 380us/step - loss: 12.3544 - val_loss: 12.4004\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 425us/step - loss: 12.4433 - val_loss: 12.2366\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 12.3108 - val_loss: 12.2487\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 12.1533 - val_loss: 12.2924\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.2003 - val_loss: 12.1736\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.1436 - val_loss: 12.0912\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 12.0257 - val_loss: 12.1000\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 11.9618 - val_loss: 12.0890\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 11.8892 - val_loss: 11.7803\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.9399 - val_loss: 12.0567\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8135 - val_loss: 12.0344\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.7907 - val_loss: 12.1301\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 11.7109 - val_loss: 11.8642\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 11.6957 - val_loss: 11.6878\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.6694 - val_loss: 12.0701\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5725 - val_loss: 11.5927\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7214 - val_loss: 12.4434\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5943 - val_loss: 11.5429\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.4757 - val_loss: 11.6217\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.4870 - val_loss: 11.6404\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.4239 - val_loss: 11.9735\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5272 - val_loss: 11.4424\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2754 - val_loss: 11.8215\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3041 - val_loss: 11.5041\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3235 - val_loss: 11.3615\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.1888 - val_loss: 11.3182\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2526 - val_loss: 11.4969\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1504 - val_loss: 11.2481\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0998 - val_loss: 11.5067\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.2348 - val_loss: 11.2368\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1204 - val_loss: 11.3561\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.0790 - val_loss: 11.2581\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 11.0191 - val_loss: 11.1535\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.9386 - val_loss: 11.2432\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.8983 - val_loss: 11.0981\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.9554 - val_loss: 11.4297\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.8812 - val_loss: 11.8722\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0153 - val_loss: 11.1290\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8770 - val_loss: 11.2312\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.8235 - val_loss: 11.3365\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 38.5084 - val_loss: 24.9174\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 22.0806 - val_loss: 19.9392\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.1041 - val_loss: 18.1627\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.1992 - val_loss: 16.0977\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 16.1140 - val_loss: 15.5339\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 15.4861 - val_loss: 14.6974\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 15.0544 - val_loss: 14.6861\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 14.5520 - val_loss: 14.4812\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 14.2129 - val_loss: 14.2327\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 13.8238 - val_loss: 14.0703\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.6243 - val_loss: 13.2341\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3227 - val_loss: 13.0112\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.1025 - val_loss: 12.7947\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9414 - val_loss: 12.4765\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7539 - val_loss: 12.6843\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.5216 - val_loss: 12.1704\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4510 - val_loss: 12.2707\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 12.2607 - val_loss: 12.3275\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0372 - val_loss: 12.1347\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.8603 - val_loss: 11.7103\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8253 - val_loss: 11.8862\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.7230 - val_loss: 11.4085\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6598 - val_loss: 11.2148\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.3964 - val_loss: 11.1277\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.3680 - val_loss: 11.0597\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.2985 - val_loss: 11.0294\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.1954 - val_loss: 11.0759\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.1091 - val_loss: 11.0307\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.9594 - val_loss: 10.5965\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.9851 - val_loss: 10.7719\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.9817 - val_loss: 10.9810\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8374 - val_loss: 10.5114\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8117 - val_loss: 10.7094\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6757 - val_loss: 10.4512\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5991 - val_loss: 10.5372\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6247 - val_loss: 10.4874\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.6124 - val_loss: 10.2705\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5323 - val_loss: 10.2361\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4959 - val_loss: 10.4804\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4051 - val_loss: 10.5889\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4309 - val_loss: 10.7440\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3177 - val_loss: 10.2051\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3657 - val_loss: 10.1766\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3029 - val_loss: 10.3841\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3509 - val_loss: 10.7745\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1690 - val_loss: 9.8935\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1464 - val_loss: 10.2449\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1629 - val_loss: 10.3451\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0818 - val_loss: 9.8635\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0763 - val_loss: 9.9595\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.1077 - val_loss: 10.1157\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.0654 - val_loss: 10.2354\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0380 - val_loss: 10.0670\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9649 - val_loss: 9.9684\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 36.8689 - val_loss: 30.1740\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 27.8541 - val_loss: 27.0315\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 25.4690 - val_loss: 25.1162\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 23.7544 - val_loss: 22.5059\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 22.3462 - val_loss: 21.7998\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 21.2510 - val_loss: 20.3821\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 20.3371 - val_loss: 19.6514\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 19.7966 - val_loss: 19.1101\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 19.1779 - val_loss: 19.4924\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 18.7487 - val_loss: 18.5442\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 18.3181 - val_loss: 19.7072\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 17.9754 - val_loss: 18.3804\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 564us/step - loss: 17.6032 - val_loss: 17.9981\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.5199 - val_loss: 17.2950\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.2803 - val_loss: 18.1259\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.9071 - val_loss: 17.3013\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.7308 - val_loss: 16.7760\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.7492 - val_loss: 16.2718\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.3577 - val_loss: 16.2890\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.2201 - val_loss: 16.4440\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.0816 - val_loss: 16.1833\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.9569 - val_loss: 15.9677\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.7616 - val_loss: 15.6014\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.8069 - val_loss: 15.8765\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.7181 - val_loss: 15.5406\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.3899 - val_loss: 15.3803\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.4608 - val_loss: 16.7946\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.3372 - val_loss: 15.5104\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.1037 - val_loss: 15.2685\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 15.1259 - val_loss: 15.3084\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.0791 - val_loss: 15.6036\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.9368 - val_loss: 15.1406\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.9012 - val_loss: 14.8593\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.8977 - val_loss: 15.2407\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7113 - val_loss: 14.8701\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.7669 - val_loss: 14.8277\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.6286 - val_loss: 14.7865\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.6726 - val_loss: 14.6990\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.5024 - val_loss: 15.0149\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.5047 - val_loss: 14.6313\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.5077 - val_loss: 14.4056\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.3885 - val_loss: 14.4491\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.4024 - val_loss: 16.3921\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.2467 - val_loss: 14.4365\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3090 - val_loss: 14.5346\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.1742 - val_loss: 14.4551\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 35.6791 - val_loss: 26.1047\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 24.2431 - val_loss: 22.0062\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 21.3836 - val_loss: 22.3548\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 19.6693 - val_loss: 18.6727\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 18.6196 - val_loss: 17.7552\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 17.7103 - val_loss: 17.1141\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 17.1172 - val_loss: 16.7572\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 16.6923 - val_loss: 16.5783\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 16.2149 - val_loss: 15.9463\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.9450 - val_loss: 15.5493\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.7228 - val_loss: 16.4494\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.3881 - val_loss: 15.4932\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.2234 - val_loss: 14.8712\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.0322 - val_loss: 15.6728\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8573 - val_loss: 14.6549\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.6270 - val_loss: 14.4282\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.5424 - val_loss: 14.7251\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.4260 - val_loss: 16.9878\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.2760 - val_loss: 13.8103\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.1144 - val_loss: 14.2008\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.0284 - val_loss: 13.9510\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9703 - val_loss: 13.5358\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8115 - val_loss: 13.4836\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8668 - val_loss: 13.6737\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.7959 - val_loss: 13.5164\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.7175 - val_loss: 13.2314\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.5316 - val_loss: 13.6889\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4601 - val_loss: 13.4139\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.3593 - val_loss: 13.4613\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.2454 - val_loss: 13.5669\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3207 - val_loss: 12.9093\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2454 - val_loss: 13.5990\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1287 - val_loss: 12.9555\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.0031 - val_loss: 13.0896\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9467 - val_loss: 13.3813\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8583 - val_loss: 13.1012\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 41.9586 - val_loss: 29.6971\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 26.5549 - val_loss: 23.1948\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.3914 - val_loss: 20.4102\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 19.2549 - val_loss: 18.1814\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 17.9926 - val_loss: 17.2775\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.0002 - val_loss: 16.0774\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 16.2168 - val_loss: 15.7372\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.8623 - val_loss: 15.4407\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 15.1447 - val_loss: 15.4425\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.7236 - val_loss: 15.2113\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3966 - val_loss: 14.9969\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.9354 - val_loss: 14.0902\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.5918 - val_loss: 13.4154\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.3036 - val_loss: 13.9877\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.1327 - val_loss: 13.1899\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.8487 - val_loss: 12.7223\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6091 - val_loss: 12.5869\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.4841 - val_loss: 12.3115\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.1708 - val_loss: 12.2372\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.9116 - val_loss: 12.2731\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.8572 - val_loss: 11.6862\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6033 - val_loss: 11.8071\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5997 - val_loss: 11.8702\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.4320 - val_loss: 11.4103\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 11.3060 - val_loss: 11.3522\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 11.1793 - val_loss: 11.6769\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 11.0389 - val_loss: 11.1200\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 10.9666 - val_loss: 11.1417\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.8537 - val_loss: 11.5159\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 10.7821 - val_loss: 11.0225\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 569us/step - loss: 10.7288 - val_loss: 11.0401\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8099 - val_loss: 11.4504\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5928 - val_loss: 10.9633\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5975 - val_loss: 10.6675\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 10.4605 - val_loss: 10.7041\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.3241 - val_loss: 11.2681\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.3771 - val_loss: 10.5286\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3009 - val_loss: 10.3685\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1993 - val_loss: 10.2918\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.1901 - val_loss: 10.3261\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1964 - val_loss: 10.8048\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.0584 - val_loss: 10.1979\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.0673 - val_loss: 10.0843\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.0041 - val_loss: 10.4106\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.9475 - val_loss: 10.2701\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.9413 - val_loss: 10.4602\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.8874 - val_loss: 10.2805\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.8227 - val_loss: 10.0436\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.7288 - val_loss: 10.8335\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.7350 - val_loss: 9.9192\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.7084 - val_loss: 10.1168\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.6747 - val_loss: 10.0014\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.7017 - val_loss: 10.1960\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.6377 - val_loss: 9.9913\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 9.5792 - val_loss: 9.8173\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.5203 - val_loss: 9.7357\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.5189 - val_loss: 9.7190\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 9.4313 - val_loss: 9.7240\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.6524 - val_loss: 9.7333\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.4510 - val_loss: 9.7065\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.3486 - val_loss: 9.6094\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.4022 - val_loss: 9.7282\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.4134 - val_loss: 9.8636\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.3125 - val_loss: 9.6088\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.2695 - val_loss: 9.9079\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.3077 - val_loss: 9.5298\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.3466 - val_loss: 9.6942\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.1852 - val_loss: 9.5954\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.1870 - val_loss: 9.8164\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.1657 - val_loss: 9.9332\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 9.2357 - val_loss: 9.7302\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 37.2132 - val_loss: 23.2544\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 20.8019 - val_loss: 19.2015\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.1670 - val_loss: 18.0916\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.8001 - val_loss: 17.6537\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.7724 - val_loss: 16.2345\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.0233 - val_loss: 14.7237\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.7838 - val_loss: 14.2068\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0826 - val_loss: 13.9609\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.7173 - val_loss: 13.5890\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.2711 - val_loss: 15.7975\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.9709 - val_loss: 12.6553\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.7035 - val_loss: 12.6428\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.4966 - val_loss: 12.8109\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.4109 - val_loss: 12.3562\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.0094 - val_loss: 12.2279\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.9531 - val_loss: 12.1383\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8962 - val_loss: 11.7627\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.6460 - val_loss: 11.3140\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.5368 - val_loss: 11.5483\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.2505 - val_loss: 11.1339\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.2421 - val_loss: 11.1746\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.1378 - val_loss: 11.2729\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.0313 - val_loss: 10.9205\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.8310 - val_loss: 11.4775\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.8448 - val_loss: 11.4018\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.7336 - val_loss: 11.1219\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.6801 - val_loss: 10.8809\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4076 - val_loss: 11.2071\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.5298 - val_loss: 10.4469\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2956 - val_loss: 10.4916\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.3169 - val_loss: 10.3611\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.3215 - val_loss: 10.6371\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0561 - val_loss: 9.9244\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.1408 - val_loss: 10.2464\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.9498 - val_loss: 10.0567\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.9205 - val_loss: 10.1194\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.8174 - val_loss: 10.2373\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7675 - val_loss: 11.0744\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 527us/step - loss: 39.0288 - val_loss: 30.7740\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 25.6822 - val_loss: 22.5640\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 21.5303 - val_loss: 20.2462\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 19.6388 - val_loss: 18.4508\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 18.0197 - val_loss: 19.2400\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 17.3458 - val_loss: 16.8724\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.4630 - val_loss: 15.7211\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 15.6273 - val_loss: 15.0904\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.9057 - val_loss: 14.7279\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.5658 - val_loss: 14.1239\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.1665 - val_loss: 14.3600\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.9025 - val_loss: 13.4379\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.3806 - val_loss: 13.2279\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.1379 - val_loss: 12.9808\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8585 - val_loss: 12.6620\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 12.6683 - val_loss: 13.0270\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 12.4980 - val_loss: 12.2352\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 12.2525 - val_loss: 12.2156\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 11.9815 - val_loss: 11.7932\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 493us/step - loss: 11.9690 - val_loss: 11.7185\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 11.6818 - val_loss: 11.8295\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 11.5669 - val_loss: 11.7261\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3960 - val_loss: 11.5367\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.1385 - val_loss: 11.5985\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1192 - val_loss: 11.2311\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1088 - val_loss: 11.0964\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.0049 - val_loss: 11.2055\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7877 - val_loss: 10.9564\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.6747 - val_loss: 10.8037\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6857 - val_loss: 10.8681\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6056 - val_loss: 11.1146\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5161 - val_loss: 11.3001\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.5006 - val_loss: 10.5244\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.3382 - val_loss: 11.5057\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3517 - val_loss: 10.3497\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1681 - val_loss: 10.4805\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.2949 - val_loss: 10.3823\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.1440 - val_loss: 10.2754\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1440 - val_loss: 10.3921\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1023 - val_loss: 10.4736\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.9408 - val_loss: 10.1967\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.9486 - val_loss: 10.2333\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9276 - val_loss: 10.7005\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.8089 - val_loss: 10.3897\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.7776 - val_loss: 10.5631\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.7538 - val_loss: 10.0175\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.7424 - val_loss: 9.9321\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.6838 - val_loss: 9.9396\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.7250 - val_loss: 10.2303\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.6726 - val_loss: 9.8475\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.5413 - val_loss: 9.7194\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.6067 - val_loss: 10.2092\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.4985 - val_loss: 9.6493\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.4562 - val_loss: 10.0379\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.4026 - val_loss: 9.5977\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.3718 - val_loss: 9.6405\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.3961 - val_loss: 9.5952\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.3448 - val_loss: 9.9176\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.3611 - val_loss: 9.6518\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.2407 - val_loss: 9.9881\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.2617 - val_loss: 9.8691\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 9.2181 - val_loss: 9.8869\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 564us/step - loss: 39.8334 - val_loss: 27.2128\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 25.0647 - val_loss: 23.4174\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 22.3422 - val_loss: 21.7974\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.0873 - val_loss: 20.5671\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 19.9051 - val_loss: 19.2277\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 18.8473 - val_loss: 19.1221\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.2612 - val_loss: 20.2644\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.7626 - val_loss: 17.3895\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.1827 - val_loss: 16.8102\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.7477 - val_loss: 16.3182\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 16.4829 - val_loss: 16.0317\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.0885 - val_loss: 16.7915\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.6944 - val_loss: 16.7924\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.5997 - val_loss: 15.1067\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.1332 - val_loss: 15.0095\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.9347 - val_loss: 15.3485\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.8093 - val_loss: 14.5042\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 14.5578 - val_loss: 14.7790\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.4208 - val_loss: 14.5122\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.1300 - val_loss: 14.4310\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.9439 - val_loss: 14.1510\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.9737 - val_loss: 13.5245\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.7578 - val_loss: 14.2868\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.6805 - val_loss: 14.3992\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.4627 - val_loss: 13.6680\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3665 - val_loss: 13.3385\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.1486 - val_loss: 13.4211\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1578 - val_loss: 12.9956\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1086 - val_loss: 12.9662\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.0219 - val_loss: 12.9588\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.8084 - val_loss: 13.1171\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8915 - val_loss: 12.7127\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.6846 - val_loss: 13.6338\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.7131 - val_loss: 12.8761\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5789 - val_loss: 12.6698\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.4673 - val_loss: 13.3708\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.4351 - val_loss: 12.4902\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.4191 - val_loss: 13.1416\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2255 - val_loss: 12.2088\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.2016 - val_loss: 12.4597\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.1478 - val_loss: 12.3294\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.1827 - val_loss: 12.8615\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0480 - val_loss: 11.9544\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0585 - val_loss: 12.1236\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.9460 - val_loss: 11.8654\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.9552 - val_loss: 11.8202\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.7884 - val_loss: 12.4537\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.7421 - val_loss: 11.9934\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.7220 - val_loss: 11.8775\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.6885 - val_loss: 11.7489\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.6254 - val_loss: 11.7563\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5225 - val_loss: 11.6465\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.5630 - val_loss: 11.8625\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4837 - val_loss: 11.6879\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 11.3866 - val_loss: 11.8906\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 11.4431 - val_loss: 12.4348\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 11.3437 - val_loss: 12.2149\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 633us/step - loss: 33.6297 - val_loss: 25.4407\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 22.7362 - val_loss: 20.0200\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 19.4895 - val_loss: 18.1860\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 18.1818 - val_loss: 17.0514\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 17.0986 - val_loss: 16.6563\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 16.2965 - val_loss: 15.9422\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 15.5043 - val_loss: 15.2344\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 15.0914 - val_loss: 16.7709\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 14.8695 - val_loss: 14.5457\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.1442 - val_loss: 15.3080\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.9706 - val_loss: 13.3314\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 13.5654 - val_loss: 13.3747\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 13.2488 - val_loss: 12.9481\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 13.0604 - val_loss: 13.1353\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 12.9198 - val_loss: 12.9530\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 12.4920 - val_loss: 12.2941\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 12.4426 - val_loss: 12.0566\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 12.2282 - val_loss: 11.7958\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.9394 - val_loss: 12.5703\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 11.9188 - val_loss: 11.5759\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 11.6722 - val_loss: 12.0437\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.3592 - val_loss: 11.3690\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 11.4229 - val_loss: 11.5006\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.3260 - val_loss: 11.2665\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.0587 - val_loss: 12.0183\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.1306 - val_loss: 11.0393\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.8257 - val_loss: 11.4696\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.7674 - val_loss: 10.8617\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 10.6806 - val_loss: 10.3880\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.6360 - val_loss: 10.4099\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.4757 - val_loss: 10.3044\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.4282 - val_loss: 10.5439\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.3512 - val_loss: 10.3532\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.2234 - val_loss: 10.9862\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 10.2604 - val_loss: 10.0472\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 10.0851 - val_loss: 10.0156\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 10.0315 - val_loss: 10.2177\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.0601 - val_loss: 10.2303\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 9.8657 - val_loss: 9.7775\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 9.8738 - val_loss: 9.8173\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 9.8607 - val_loss: 9.8038\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 9.7051 - val_loss: 9.9419\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 9.7720 - val_loss: 9.6233\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 3s 603us/step - loss: 9.6116 - val_loss: 9.5256\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.6534 - val_loss: 9.6672\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.5438 - val_loss: 9.4729\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.4494 - val_loss: 9.7015\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 9.5703 - val_loss: 9.7026\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 9.4242 - val_loss: 9.5978\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 9.4162 - val_loss: 9.9854\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 9.3861 - val_loss: 9.4687\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.3619 - val_loss: 9.2353\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 9.3800 - val_loss: 9.5842\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 9.1984 - val_loss: 9.1597\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.2429 - val_loss: 9.2428\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 9.2265 - val_loss: 9.3761\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 9.1591 - val_loss: 9.4440\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 3s 606us/step - loss: 9.1319 - val_loss: 9.0777\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 9.1243 - val_loss: 9.2660\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.1129 - val_loss: 9.2081\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 9.0420 - val_loss: 9.2842\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 9.0564 - val_loss: 9.0483\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 8.9963 - val_loss: 9.1467\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 8.9650 - val_loss: 9.1882\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 8.8953 - val_loss: 9.0912\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 8.9152 - val_loss: 9.2076\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 8.8702 - val_loss: 9.0791\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 41.8094 - val_loss: 31.3327\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 28.0897 - val_loss: 25.8185\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 24.4072 - val_loss: 23.2368\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 22.1450 - val_loss: 21.8040\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 21.1505 - val_loss: 20.7669\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.1637 - val_loss: 19.8024\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 19.4834 - val_loss: 18.9508\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.9464 - val_loss: 18.5910\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.5275 - val_loss: 18.3420\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.2257 - val_loss: 17.7060\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 17.7277 - val_loss: 17.4091\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 17.4270 - val_loss: 16.9486\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 17.2679 - val_loss: 17.5529\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.9704 - val_loss: 16.7270\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.7280 - val_loss: 16.5634\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.6246 - val_loss: 16.2113\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.3641 - val_loss: 16.0199\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.1570 - val_loss: 15.8091\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.1953 - val_loss: 16.4387\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.7275 - val_loss: 15.9489\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.9180 - val_loss: 15.6109\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.4401 - val_loss: 15.4467\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.3737 - val_loss: 15.4316\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.2708 - val_loss: 15.2927\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.2656 - val_loss: 15.3046\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.0030 - val_loss: 17.1240\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.9282 - val_loss: 15.2589\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 420us/step - loss: 15.1123 - val_loss: 15.7429\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.8716 - val_loss: 15.4247\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 14.5994 - val_loss: 14.5590\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 14.4353 - val_loss: 14.4417\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 14.5942 - val_loss: 14.6308\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 14.4673 - val_loss: 14.6505\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 14.3090 - val_loss: 14.2566\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 14.1591 - val_loss: 14.4865\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 3s 686us/step - loss: 14.2784 - val_loss: 14.0786\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 3s 664us/step - loss: 13.9890 - val_loss: 14.3698\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 3s 662us/step - loss: 14.0609 - val_loss: 14.8800\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 3s 663us/step - loss: 13.9093 - val_loss: 13.8005\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 3s 662us/step - loss: 13.8411 - val_loss: 14.5044\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 3s 663us/step - loss: 13.8023 - val_loss: 14.2318\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 3s 664us/step - loss: 13.7370 - val_loss: 13.7986\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 3s 665us/step - loss: 13.7403 - val_loss: 13.5788\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 3s 661us/step - loss: 13.6049 - val_loss: 14.1446\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 3s 744us/step - loss: 13.6783 - val_loss: 13.5340\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 3s 663us/step - loss: 13.3906 - val_loss: 13.7352\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 3s 668us/step - loss: 13.5218 - val_loss: 14.3461\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 590us/step - loss: 13.4747 - val_loss: 13.5813\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 13.3609 - val_loss: 13.4409\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 3s 668us/step - loss: 13.3433 - val_loss: 13.4671\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 3s 654us/step - loss: 13.2003 - val_loss: 13.4348\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 3s 660us/step - loss: 13.2046 - val_loss: 13.9590\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 3s 652us/step - loss: 13.2287 - val_loss: 13.7202\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 3s 655us/step - loss: 13.1205 - val_loss: 13.0818\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 3s 657us/step - loss: 13.0697 - val_loss: 13.3819\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 3s 655us/step - loss: 13.4014 - val_loss: 13.8311\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 3s 659us/step - loss: 13.0451 - val_loss: 13.3071\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 3s 654us/step - loss: 12.9886 - val_loss: 13.6064\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 3s 657us/step - loss: 12.9004 - val_loss: 13.0453\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 3s 657us/step - loss: 12.8926 - val_loss: 13.3041\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 3s 656us/step - loss: 12.8919 - val_loss: 13.1068\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 3s 660us/step - loss: 12.8687 - val_loss: 13.1555\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 3s 690us/step - loss: 12.7810 - val_loss: 13.0973\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 3s 658us/step - loss: 12.7904 - val_loss: 13.1402\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 625us/step - loss: 39.8598 - val_loss: 32.1735\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 27.5648 - val_loss: 24.2023\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 23.3320 - val_loss: 21.3942\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 20.9064 - val_loss: 19.3984\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 19.6188 - val_loss: 18.6632\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 18.1253 - val_loss: 16.8678\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 16.7523 - val_loss: 16.1389\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 16.0224 - val_loss: 17.6271\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.3861 - val_loss: 14.8509\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.8797 - val_loss: 14.5523\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.5771 - val_loss: 14.6028\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.3367 - val_loss: 14.1312\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0796 - val_loss: 13.7289\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.7603 - val_loss: 13.8413\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5906 - val_loss: 13.2932\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.4181 - val_loss: 13.6772\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.1941 - val_loss: 13.0355\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1478 - val_loss: 12.8558\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.8256 - val_loss: 13.0219\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.8692 - val_loss: 12.6885\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.6044 - val_loss: 13.0319\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.3040 - val_loss: 12.2719\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.3023 - val_loss: 12.0598\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.1977 - val_loss: 12.0964\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.9175 - val_loss: 11.7330\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.9162 - val_loss: 11.7446\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.6871 - val_loss: 11.6081\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.5789 - val_loss: 11.5165\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.4730 - val_loss: 11.5789\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.4039 - val_loss: 11.5211\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3502 - val_loss: 11.7022\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.2228 - val_loss: 11.1761\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.2354 - val_loss: 11.4744\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.0982 - val_loss: 11.2643\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.1177 - val_loss: 11.2852\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.0379 - val_loss: 10.9935\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.9272 - val_loss: 10.8660\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.8753 - val_loss: 10.8604\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.8766 - val_loss: 11.3410\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.7766 - val_loss: 11.3295\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7131 - val_loss: 11.0763\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.6943 - val_loss: 10.7799\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.6182 - val_loss: 10.5991\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.6360 - val_loss: 10.7612\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.6289 - val_loss: 10.8607\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.6859 - val_loss: 10.6096\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4387 - val_loss: 11.3016\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4335 - val_loss: 10.4938\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.3546 - val_loss: 10.4941\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4435 - val_loss: 10.6021\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5167 - val_loss: 10.4424\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.2986 - val_loss: 10.2745\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.2106 - val_loss: 10.3503\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2442 - val_loss: 10.3576\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2334 - val_loss: 10.2202\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 586us/step - loss: 10.1837 - val_loss: 10.6079\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.2381 - val_loss: 10.2482\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.1481 - val_loss: 10.3145\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.0980 - val_loss: 10.7029\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.0843 - val_loss: 10.1188\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.1006 - val_loss: 10.1619\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 10.0743 - val_loss: 10.1259\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 9.9337 - val_loss: 9.9587\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 10.0623 - val_loss: 10.0372\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 9.9123 - val_loss: 10.0240\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 9.9285 - val_loss: 10.3938\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 9.9283 - val_loss: 10.0912\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 572us/step - loss: 9.8571 - val_loss: 9.9212\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.8498 - val_loss: 10.6077\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.8716 - val_loss: 10.2621\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.8023 - val_loss: 9.8929\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.7354 - val_loss: 10.2977\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.8105 - val_loss: 9.9510\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.7859 - val_loss: 9.9595\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.7425 - val_loss: 10.3271\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.7378 - val_loss: 9.7803\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.7070 - val_loss: 10.2123\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.7094 - val_loss: 9.8845\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.6849 - val_loss: 9.7939\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 9.6242 - val_loss: 9.7996\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.6324 - val_loss: 9.7347\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 9.6449 - val_loss: 10.0832\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.6106 - val_loss: 10.1664\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 9.5787 - val_loss: 9.8094\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.5375 - val_loss: 9.7157\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 9.5224 - val_loss: 9.8289\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.5678 - val_loss: 9.8551\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.4574 - val_loss: 9.9527\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.5234 - val_loss: 9.8907\n",
      "Epoch 90/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.4683 - val_loss: 9.6211\n",
      "Epoch 91/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.5500 - val_loss: 9.7978\n",
      "Epoch 92/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.6805 - val_loss: 10.4339\n",
      "Epoch 93/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.4212 - val_loss: 10.1091\n",
      "Epoch 94/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.3797 - val_loss: 9.6074\n",
      "Epoch 95/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.3567 - val_loss: 9.6659\n",
      "Epoch 96/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.3949 - val_loss: 9.6629\n",
      "Epoch 97/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.3325 - val_loss: 9.7293\n",
      "Epoch 98/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.4413 - val_loss: 9.6737\n",
      "Epoch 99/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.3474 - val_loss: 9.5142\n",
      "Epoch 100/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.2998 - val_loss: 9.5750\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 38.6759 - val_loss: 25.2511\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 23.2163 - val_loss: 21.4997\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 19.9261 - val_loss: 18.5696\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 18.1542 - val_loss: 18.9233\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 17.1593 - val_loss: 16.6375\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 16.3516 - val_loss: 16.5794\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 15.5491 - val_loss: 14.8926\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 14.9549 - val_loss: 14.5534\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 14.5497 - val_loss: 15.1489\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 14.1184 - val_loss: 14.0156\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.8183 - val_loss: 14.0471\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.4531 - val_loss: 13.1102\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3958 - val_loss: 13.9341\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.2151 - val_loss: 12.9646\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.0022 - val_loss: 12.6178\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 12.8514 - val_loss: 12.5130\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7535 - val_loss: 12.4860\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 12.7826 - val_loss: 12.9649\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.4506 - val_loss: 12.4621\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3384 - val_loss: 12.0178\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.3047 - val_loss: 12.2642\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.1734 - val_loss: 11.9669\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0725 - val_loss: 11.7892\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.0344 - val_loss: 12.4295\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.8591 - val_loss: 11.4648\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.8791 - val_loss: 11.8400\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.7817 - val_loss: 11.3290\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.6802 - val_loss: 11.3458\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.5551 - val_loss: 11.3718\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.4867 - val_loss: 11.1250\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.8140 - val_loss: 11.5806\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3120 - val_loss: 10.9808\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2675 - val_loss: 11.1822\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2719 - val_loss: 10.8936\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.2805 - val_loss: 11.1807\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.1915 - val_loss: 10.9026\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.0728 - val_loss: 13.1871\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.1820 - val_loss: 11.0900\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.9706 - val_loss: 10.7186\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.0057 - val_loss: 10.6662\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.9756 - val_loss: 10.7705\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.9360 - val_loss: 10.4714\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.8414 - val_loss: 10.5579\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7116 - val_loss: 10.5989\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7705 - val_loss: 10.6564\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.8038 - val_loss: 10.6932\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.6924 - val_loss: 10.9032\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 37.1432 - val_loss: 29.9535\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 27.4750 - val_loss: 25.7550\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 24.6627 - val_loss: 24.6179\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 23.1126 - val_loss: 22.2408\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 21.8031 - val_loss: 21.2217\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 21.1755 - val_loss: 20.4263\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 20.3957 - val_loss: 21.0749\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 19.8159 - val_loss: 19.3513\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 19.2780 - val_loss: 19.1460\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.8485 - val_loss: 19.1807\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 19.0882 - val_loss: 18.6285\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.1847 - val_loss: 18.4406\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.9822 - val_loss: 17.5363\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 410us/step - loss: 17.4457 - val_loss: 18.3259\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.2148 - val_loss: 17.9202\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 17.0541 - val_loss: 18.0597\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 16.7015 - val_loss: 16.8748\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 16.4873 - val_loss: 16.4594\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 16.3421 - val_loss: 16.5708\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 16.1578 - val_loss: 16.0737\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 570us/step - loss: 16.0306 - val_loss: 15.8678\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7730 - val_loss: 15.9043\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 15.8523 - val_loss: 15.7248\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.7157 - val_loss: 16.1186\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.4777 - val_loss: 15.6595\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.3853 - val_loss: 15.5899\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.3765 - val_loss: 15.4049\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 15.2338 - val_loss: 15.2461\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 15.0758 - val_loss: 16.0648\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 15.1651 - val_loss: 15.8694\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 15.0587 - val_loss: 15.0937\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.8597 - val_loss: 15.2863\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.8818 - val_loss: 15.3398\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.7889 - val_loss: 14.8629\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.6813 - val_loss: 14.9636\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 14.6542 - val_loss: 14.8307\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.5732 - val_loss: 14.9258\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.5808 - val_loss: 14.7713\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.4951 - val_loss: 14.6217\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.3629 - val_loss: 14.5816\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 14.3862 - val_loss: 14.5632\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.4273 - val_loss: 14.7642\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.3441 - val_loss: 14.6276\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.3258 - val_loss: 14.5193\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.3113 - val_loss: 14.9606\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.1826 - val_loss: 14.4822\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.1861 - val_loss: 15.2656\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.1908 - val_loss: 14.6759\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.1138 - val_loss: 14.8359\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0161 - val_loss: 14.4253\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.0174 - val_loss: 14.4679\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.0463 - val_loss: 14.2737\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.1022 - val_loss: 14.2262\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.8588 - val_loss: 14.2561\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.9786 - val_loss: 14.1193\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.8769 - val_loss: 14.1697\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.8508 - val_loss: 14.1369\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.8613 - val_loss: 14.0989\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.8041 - val_loss: 14.3826\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 13.7901 - val_loss: 13.9553\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 13.7366 - val_loss: 14.0328\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 13.7122 - val_loss: 14.5860\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 13.6939 - val_loss: 14.2081\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 13.6701 - val_loss: 14.2422\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 13.7464 - val_loss: 14.1424\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 36.3497 - val_loss: 26.6119\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 23.5349 - val_loss: 21.1965\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 20.4364 - val_loss: 19.3499\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.8009 - val_loss: 18.1722\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 18.0146 - val_loss: 17.1352\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.1879 - val_loss: 16.6629\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.4227 - val_loss: 16.0978\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.0391 - val_loss: 15.4884\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.4537 - val_loss: 15.1495\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.2681 - val_loss: 15.0670\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.0453 - val_loss: 15.3206\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.9661 - val_loss: 15.7458\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.6821 - val_loss: 15.3537\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.5518 - val_loss: 13.9954\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.4580 - val_loss: 14.0032\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.1339 - val_loss: 14.2240\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.0415 - val_loss: 14.5664\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.9317 - val_loss: 13.8138\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.7189 - val_loss: 14.0582\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.7728 - val_loss: 13.2619\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.4171 - val_loss: 13.4895\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.3936 - val_loss: 14.1938\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.3200 - val_loss: 13.3339\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.1374 - val_loss: 13.0006\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.0860 - val_loss: 12.7590\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.0007 - val_loss: 12.7360\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.8387 - val_loss: 12.9477\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8056 - val_loss: 12.6581\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.5721 - val_loss: 15.1939\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7167 - val_loss: 12.4034\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.5897 - val_loss: 12.4702\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4298 - val_loss: 12.1967\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.2488 - val_loss: 12.4223\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.2664 - val_loss: 12.2383\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.1289 - val_loss: 12.0077\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.1592 - val_loss: 12.1725\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.0997 - val_loss: 11.9372\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.9921 - val_loss: 12.2536\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.9632 - val_loss: 11.7248\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7917 - val_loss: 11.9202\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8125 - val_loss: 11.9987\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.7337 - val_loss: 11.5741\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.5804 - val_loss: 11.4462\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6483 - val_loss: 12.0174\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.5363 - val_loss: 11.4870\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.4500 - val_loss: 11.3533\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.4748 - val_loss: 11.5892\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 11.3931 - val_loss: 11.1929\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.3547 - val_loss: 11.3537\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2247 - val_loss: 11.1050\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3249 - val_loss: 12.9035\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 1s 356us/step - loss: 11.2127 - val_loss: 11.3206\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.2065 - val_loss: 11.1410\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 11.1888 - val_loss: 11.5360\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 11.1743 - val_loss: 11.2546\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 656us/step - loss: 38.5021 - val_loss: 28.4354\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 25.7411 - val_loss: 23.0722\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 22.1032 - val_loss: 21.2189\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.2377 - val_loss: 18.8162\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.5893 - val_loss: 18.2493\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.9664 - val_loss: 17.8507\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.2155 - val_loss: 16.6086\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.6261 - val_loss: 16.1637\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 16.4101 - val_loss: 16.3478\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.5887 - val_loss: 16.1754\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.4651 - val_loss: 15.5369\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.0477 - val_loss: 15.5885\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.7614 - val_loss: 14.8500\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.4843 - val_loss: 14.2261\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.2353 - val_loss: 14.0661\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.9999 - val_loss: 15.2095\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.8267 - val_loss: 13.6434\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.6921 - val_loss: 13.4533\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.6559 - val_loss: 14.0706\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.2765 - val_loss: 13.9339\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.1285 - val_loss: 13.2911\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.9095 - val_loss: 13.3778\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9761 - val_loss: 12.9530\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.7770 - val_loss: 13.0385\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.5911 - val_loss: 12.7524\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.4676 - val_loss: 12.5482\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.3144 - val_loss: 13.4413\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3361 - val_loss: 12.8831\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2755 - val_loss: 13.5569\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.9573 - val_loss: 12.7406\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 11.9578 - val_loss: 12.2944\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8203 - val_loss: 12.6948\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8050 - val_loss: 12.2504\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6453 - val_loss: 12.1870\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5944 - val_loss: 11.7690\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.4583 - val_loss: 11.5652\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.3198 - val_loss: 11.6075\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3462 - val_loss: 12.4250\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4108 - val_loss: 11.5748\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 11.1658 - val_loss: 11.5313\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.2884 - val_loss: 12.2751\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.1097 - val_loss: 11.6009\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 11.1890 - val_loss: 11.3884\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.0134 - val_loss: 11.3046\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.8595 - val_loss: 11.6566\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.8222 - val_loss: 11.0677\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8031 - val_loss: 11.0878\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.8893 - val_loss: 11.5698\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7403 - val_loss: 11.1060\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7458 - val_loss: 11.5495\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7320 - val_loss: 10.8750\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6535 - val_loss: 11.1335\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6332 - val_loss: 11.0442\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5359 - val_loss: 11.0334\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.4835 - val_loss: 10.9371\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4414 - val_loss: 10.9521\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 35.3516 - val_loss: 25.1562\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 23.2866 - val_loss: 21.1734\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 20.4981 - val_loss: 21.1794\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 18.5743 - val_loss: 17.7197\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.4947 - val_loss: 16.8648\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.8581 - val_loss: 16.3332\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.3924 - val_loss: 15.9245\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.6857 - val_loss: 15.2758\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.2373 - val_loss: 15.1514\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.0330 - val_loss: 15.2948\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8300 - val_loss: 14.2851\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.3948 - val_loss: 14.1518\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.2044 - val_loss: 13.9041\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8140 - val_loss: 13.6742\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6220 - val_loss: 13.3916\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.4358 - val_loss: 13.4070\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.3002 - val_loss: 13.0537\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.0834 - val_loss: 14.0103\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.8868 - val_loss: 13.1348\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.9488 - val_loss: 13.1574\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.5855 - val_loss: 12.6479\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.4562 - val_loss: 12.6093\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.5009 - val_loss: 12.3386\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.2476 - val_loss: 12.2497\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.3008 - val_loss: 12.4560\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.9385 - val_loss: 12.0794\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8470 - val_loss: 12.2958\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.9105 - val_loss: 12.3986\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.7094 - val_loss: 11.9853\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.6632 - val_loss: 12.2639\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6743 - val_loss: 12.4171\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.5555 - val_loss: 12.0265\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.6060 - val_loss: 11.2987\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2563 - val_loss: 11.4066\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 11.2784 - val_loss: 11.7056\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.3715 - val_loss: 11.2258\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.1208 - val_loss: 11.6855\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.0720 - val_loss: 11.0556\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9878 - val_loss: 11.1912\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.3332 - val_loss: 11.2031\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.9258 - val_loss: 10.9361\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 10.7956 - val_loss: 11.2892\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 10.7345 - val_loss: 11.0729\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 10.7376 - val_loss: 10.9047\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 10.7422 - val_loss: 10.7328\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 10.7208 - val_loss: 10.8104\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.6324 - val_loss: 10.6252\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 10.7372 - val_loss: 10.6663\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4906 - val_loss: 11.2258\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.7043 - val_loss: 10.7382\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.4304 - val_loss: 10.9602\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3626 - val_loss: 10.7010\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 39.0183 - val_loss: 30.1889\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 26.9458 - val_loss: 26.2966\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 22.7831 - val_loss: 21.1289\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 20.7956 - val_loss: 19.4687\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 19.1171 - val_loss: 18.7041\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.3179 - val_loss: 18.1832\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 17.4466 - val_loss: 18.2436\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.7953 - val_loss: 16.8260\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.3432 - val_loss: 15.7639\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 15.9201 - val_loss: 15.7153\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 15.3429 - val_loss: 15.6030\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.1427 - val_loss: 14.8065\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.6312 - val_loss: 14.5065\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.4551 - val_loss: 14.7444\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.1931 - val_loss: 14.2153\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.0092 - val_loss: 14.1275\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.9148 - val_loss: 13.9787\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6512 - val_loss: 14.9445\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5762 - val_loss: 13.7004\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.1466 - val_loss: 13.2618\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.1258 - val_loss: 13.3243\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.0303 - val_loss: 13.2542\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.9180 - val_loss: 12.8756\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.6165 - val_loss: 12.6513\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7015 - val_loss: 12.7221\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4594 - val_loss: 12.4837\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4665 - val_loss: 12.2626\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.2324 - val_loss: 13.0262\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2295 - val_loss: 12.2185\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.1416 - val_loss: 12.3872\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.9918 - val_loss: 12.2748\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 11.9146 - val_loss: 12.1278\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 11.8839 - val_loss: 12.3624\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.7147 - val_loss: 11.7572\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 11.6011 - val_loss: 12.0697\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.6245 - val_loss: 13.1817\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 11.4790 - val_loss: 11.5740\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.3575 - val_loss: 11.9142\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.3566 - val_loss: 11.8274\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.2879 - val_loss: 11.4027\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.2133 - val_loss: 11.5583\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.1031 - val_loss: 11.4792\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 11.0423 - val_loss: 11.1747\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.9939 - val_loss: 11.8748\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.0404 - val_loss: 12.0873\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.9417 - val_loss: 11.1579\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.7659 - val_loss: 10.9295\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.8529 - val_loss: 10.9719\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.6647 - val_loss: 10.8508\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.8837 - val_loss: 10.7862\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.6907 - val_loss: 10.8754\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5334 - val_loss: 10.8911\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.6043 - val_loss: 10.7327\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4215 - val_loss: 10.7060\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4328 - val_loss: 10.7850\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6765 - val_loss: 10.9764\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3751 - val_loss: 10.5069\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.2793 - val_loss: 10.5414\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.2684 - val_loss: 10.6837\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.2295 - val_loss: 10.7243\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.2223 - val_loss: 10.6901\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.1485 - val_loss: 10.4410\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1247 - val_loss: 10.4952\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.1294 - val_loss: 10.6509\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.0059 - val_loss: 10.6087\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.0027 - val_loss: 10.8452\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.1452 - val_loss: 10.3337\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.9593 - val_loss: 10.7514\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9255 - val_loss: 10.3198\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.9461 - val_loss: 10.5210\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.8647 - val_loss: 10.1321\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.7709 - val_loss: 10.3184\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.8206 - val_loss: 10.1354\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.7907 - val_loss: 10.3600\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7553 - val_loss: 10.3265\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.6688 - val_loss: 10.2452\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 39.6037 - val_loss: 28.3778\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 25.5644 - val_loss: 23.2929\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 22.3913 - val_loss: 21.0902\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 20.9649 - val_loss: 20.5362\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 19.8227 - val_loss: 19.6495\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 19.2057 - val_loss: 18.6088\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 18.4713 - val_loss: 19.9330\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 17.7857 - val_loss: 18.7839\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 17.4053 - val_loss: 18.4575\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 17.0569 - val_loss: 17.0424\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 16.6802 - val_loss: 18.0899\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 16.5256 - val_loss: 16.1514\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 16.3148 - val_loss: 16.5440\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 16.2081 - val_loss: 15.8580\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 492us/step - loss: 15.7167 - val_loss: 15.8758\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 15.7429 - val_loss: 15.7693\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 15.5388 - val_loss: 16.1714\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 15.2299 - val_loss: 15.6901\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 572us/step - loss: 15.4218 - val_loss: 15.1219\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.9244 - val_loss: 15.8115\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.8614 - val_loss: 14.9595\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.6136 - val_loss: 15.2269\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.5390 - val_loss: 14.4958\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.2985 - val_loss: 14.2214\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.4518 - val_loss: 17.8754\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 14.2859 - val_loss: 14.5413\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 14.1864 - val_loss: 14.0853\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 14.0662 - val_loss: 14.1876\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.7895 - val_loss: 13.7081\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 13.7320 - val_loss: 13.8183\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.7046 - val_loss: 13.6586\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.6373 - val_loss: 14.1303\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 13.4501 - val_loss: 13.6485\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 13.4242 - val_loss: 13.4165\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.3305 - val_loss: 13.8181\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 13.1964 - val_loss: 14.0475\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.1140 - val_loss: 13.7093\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 13.0941 - val_loss: 13.0702\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.1200 - val_loss: 13.1887\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 13.0345 - val_loss: 13.1589\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.0120 - val_loss: 13.2072\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.8380 - val_loss: 12.8337\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 12.8414 - val_loss: 13.2675\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 12.7065 - val_loss: 12.9756\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 12.7221 - val_loss: 12.9188\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.6787 - val_loss: 13.0390\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 12.6123 - val_loss: 13.0260\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 35.8760 - val_loss: 28.3700\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 25.8849 - val_loss: 24.2228\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 22.1842 - val_loss: 20.2237\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 20.0081 - val_loss: 18.8800\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 18.8651 - val_loss: 18.7532\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.9353 - val_loss: 18.0556\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 17.2610 - val_loss: 17.6993\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 16.8216 - val_loss: 16.1410\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 16.1668 - val_loss: 15.5833\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 15.8801 - val_loss: 16.0561\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 15.5980 - val_loss: 15.1474\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 15.2035 - val_loss: 15.5102\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 14.8799 - val_loss: 14.3101\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.5855 - val_loss: 14.5673\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.2965 - val_loss: 13.8598\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.9398 - val_loss: 13.5116\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.8294 - val_loss: 14.0894\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.6782 - val_loss: 13.1620\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.4966 - val_loss: 13.1262\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.2749 - val_loss: 13.7729\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1371 - val_loss: 12.9738\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.8983 - val_loss: 13.3273\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8192 - val_loss: 12.3200\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.5868 - val_loss: 12.4861\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.5711 - val_loss: 12.2664\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.5212 - val_loss: 12.3359\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.3656 - val_loss: 12.1519\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.1211 - val_loss: 12.0161\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.0768 - val_loss: 11.7280\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0154 - val_loss: 12.3964\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.7776 - val_loss: 11.6394\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.8751 - val_loss: 11.6919\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.6708 - val_loss: 12.5110\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.5849 - val_loss: 11.2597\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.4446 - val_loss: 11.5817\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.3218 - val_loss: 11.2540\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.4355 - val_loss: 11.5075\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.2800 - val_loss: 11.1082\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.1186 - val_loss: 10.9660\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.1759 - val_loss: 11.3463\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.0967 - val_loss: 11.2304\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9708 - val_loss: 11.1561\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.0106 - val_loss: 11.0896\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8347 - val_loss: 11.0865\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 41.3359 - val_loss: 30.3840\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 28.4677 - val_loss: 26.6214\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 25.5903 - val_loss: 24.4403\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 23.2568 - val_loss: 22.1078\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 21.7986 - val_loss: 20.8484\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 20.5271 - val_loss: 20.4625\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 19.7586 - val_loss: 19.7007\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.8088 - val_loss: 19.1640\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 18.2865 - val_loss: 18.9549\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 17.7889 - val_loss: 17.4248\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 17.1641 - val_loss: 17.4449\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.8192 - val_loss: 16.8336\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.4413 - val_loss: 16.1217\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 16.1095 - val_loss: 15.8302\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.7953 - val_loss: 15.6820\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.7619 - val_loss: 15.7335\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.4963 - val_loss: 15.8033\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.2844 - val_loss: 15.5425\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.9993 - val_loss: 16.2901\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 398us/step - loss: 15.1069 - val_loss: 15.4780\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 14.6295 - val_loss: 14.7197\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 14.6637 - val_loss: 14.4500\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 14.3280 - val_loss: 14.4735\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 14.2093 - val_loss: 17.5200\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 14.3829 - val_loss: 14.4298\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 13.9868 - val_loss: 13.9546\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 14.0769 - val_loss: 14.8441\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.7467 - val_loss: 13.7442\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.6830 - val_loss: 14.1066\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.6650 - val_loss: 13.5295\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.5049 - val_loss: 14.2740\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4966 - val_loss: 13.5572\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4288 - val_loss: 13.3607\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 13.4133 - val_loss: 13.3962\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.2658 - val_loss: 13.8865\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.1669 - val_loss: 13.1771\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.2252 - val_loss: 13.5473\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.0113 - val_loss: 13.4266\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.0429 - val_loss: 13.0304\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.8804 - val_loss: 12.8342\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.8731 - val_loss: 12.9267\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8746 - val_loss: 13.0677\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.7596 - val_loss: 12.8650\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.8105 - val_loss: 12.9612\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7278 - val_loss: 12.9444\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 39.8265 - val_loss: 31.0947\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 28.3928 - val_loss: 24.8154\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 23.9544 - val_loss: 24.3800\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.8424 - val_loss: 20.2590\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.3460 - val_loss: 19.0982\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 19.2159 - val_loss: 18.0923\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.3532 - val_loss: 17.6192\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.7971 - val_loss: 17.3265\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 16.9430 - val_loss: 17.3284\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.6015 - val_loss: 15.7634\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.1148 - val_loss: 15.6953\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.6200 - val_loss: 15.7658\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.4817 - val_loss: 14.8137\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.0930 - val_loss: 16.2230\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.9599 - val_loss: 14.9097\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.5136 - val_loss: 14.6945\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.5705 - val_loss: 14.3112\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 14.2050 - val_loss: 14.9910\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 14.1119 - val_loss: 14.3796\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.9110 - val_loss: 13.5225\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.9890 - val_loss: 14.9041\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 13.5173 - val_loss: 13.3525\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.3104 - val_loss: 13.8845\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 13.3583 - val_loss: 13.0366\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.2468 - val_loss: 13.5351\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.1420 - val_loss: 12.7863\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9035 - val_loss: 12.9676\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.8392 - val_loss: 12.6672\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.6954 - val_loss: 12.5549\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.6326 - val_loss: 12.4649\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.5239 - val_loss: 12.9105\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4886 - val_loss: 12.6073\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.3849 - val_loss: 12.1164\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.2080 - val_loss: 12.0629\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.1801 - val_loss: 12.5042\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.1501 - val_loss: 12.0841\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.1036 - val_loss: 12.3849\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.9967 - val_loss: 12.1922\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8721 - val_loss: 11.6945\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.9352 - val_loss: 11.8680\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.7721 - val_loss: 11.6481\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.8272 - val_loss: 11.8509\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.6618 - val_loss: 11.5807\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6382 - val_loss: 11.5391\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.7170 - val_loss: 11.6880\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.4663 - val_loss: 11.6482\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.4784 - val_loss: 11.5779\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.4180 - val_loss: 11.9847\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4598 - val_loss: 11.4156\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.3965 - val_loss: 11.6988\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.2980 - val_loss: 11.2249\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2261 - val_loss: 11.5719\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.3348 - val_loss: 11.4676\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.2180 - val_loss: 11.9843\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.0882 - val_loss: 11.2397\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.1252 - val_loss: 11.4535\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 38.7276 - val_loss: 25.8246\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 24.6149 - val_loss: 23.1674\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 22.1667 - val_loss: 20.6236\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 20.0560 - val_loss: 18.7579\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 18.5665 - val_loss: 18.8037\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.6115 - val_loss: 16.7434\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.8610 - val_loss: 16.5745\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.2445 - val_loss: 15.4431\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.6889 - val_loss: 15.8734\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.1815 - val_loss: 14.8047\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.9079 - val_loss: 14.1854\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.5824 - val_loss: 13.7263\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.1041 - val_loss: 13.6010\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 14.0099 - val_loss: 13.4446\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 13.6187 - val_loss: 13.0943\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3585 - val_loss: 12.8103\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1037 - val_loss: 13.7758\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 427us/step - loss: 12.7968 - val_loss: 13.1081\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.6689 - val_loss: 12.0701\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 12.3828 - val_loss: 12.1817\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 12.3317 - val_loss: 12.0773\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 12.1502 - val_loss: 11.6976\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 11.9424 - val_loss: 11.8760\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 11.9964 - val_loss: 11.4832\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 11.7780 - val_loss: 11.4038\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.5784 - val_loss: 11.4536\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.5205 - val_loss: 11.5270\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4074 - val_loss: 11.4985\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.4732 - val_loss: 11.0755\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.1891 - val_loss: 11.3580\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.2424 - val_loss: 10.8049\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2131 - val_loss: 10.8867\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.1511 - val_loss: 10.9469\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9175 - val_loss: 10.9385\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.8688 - val_loss: 10.6449\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.8419 - val_loss: 11.5720\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.8317 - val_loss: 10.4641\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.6920 - val_loss: 10.5526\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.7216 - val_loss: 10.8596\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6740 - val_loss: 10.4092\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.5968 - val_loss: 11.1687\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.5650 - val_loss: 10.2613\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.3919 - val_loss: 10.2356\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.4358 - val_loss: 10.5431\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.4713 - val_loss: 10.0255\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.3839 - val_loss: 10.2213\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4070 - val_loss: 9.9774\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.1955 - val_loss: 9.9633\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.3458 - val_loss: 10.1949\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.1415 - val_loss: 10.2360\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.2566 - val_loss: 10.2409\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.1505 - val_loss: 9.8220\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1502 - val_loss: 9.7596\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.1517 - val_loss: 10.1083\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.0269 - val_loss: 10.0327\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.1066 - val_loss: 9.8643\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.9365 - val_loss: 10.5162\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.9820 - val_loss: 10.9956\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 38.3133 - val_loss: 29.8726\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 28.0150 - val_loss: 26.3417\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 25.3741 - val_loss: 24.9909\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 23.7685 - val_loss: 23.1361\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 22.4313 - val_loss: 23.5874\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 22.2603 - val_loss: 20.9907\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 21.0968 - val_loss: 21.5044\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 20.5972 - val_loss: 20.2469\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 20.2800 - val_loss: 20.2913\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 19.7679 - val_loss: 19.9411\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 19.1967 - val_loss: 19.5444\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 19.1281 - val_loss: 19.3109\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 3s 623us/step - loss: 18.7190 - val_loss: 18.3514\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 3s 662us/step - loss: 18.3705 - val_loss: 18.3981\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 3s 726us/step - loss: 18.0834 - val_loss: 17.8546\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 3s 693us/step - loss: 17.8493 - val_loss: 17.6386\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 3s 626us/step - loss: 17.4894 - val_loss: 17.5328\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 3s 661us/step - loss: 17.3285 - val_loss: 16.8697\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 3s 603us/step - loss: 16.9113 - val_loss: 16.8075\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 16.9306 - val_loss: 16.8112\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 16.5738 - val_loss: 16.4975\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.4482 - val_loss: 16.7302\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.2345 - val_loss: 17.0315\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.1492 - val_loss: 16.1838\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.9353 - val_loss: 15.7665\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 16.0580 - val_loss: 16.1933\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.7535 - val_loss: 15.8962\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.6844 - val_loss: 16.2944\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.6604 - val_loss: 15.5028\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.6308 - val_loss: 15.5497\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.4238 - val_loss: 15.3885\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.3057 - val_loss: 15.6664\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.3058 - val_loss: 15.6797\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.2224 - val_loss: 15.1114\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.1761 - val_loss: 15.1660\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.1922 - val_loss: 15.1790\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.9669 - val_loss: 15.3162\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.0033 - val_loss: 15.2683\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.9091 - val_loss: 15.1257\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 35.8762 - val_loss: 27.1528\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 25.4614 - val_loss: 23.5560\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 22.6858 - val_loss: 21.6305\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 21.0351 - val_loss: 21.5688\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 19.6674 - val_loss: 20.3019\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.6555 - val_loss: 17.9804\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.9036 - val_loss: 17.3095\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 17.5157 - val_loss: 17.0182\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.8568 - val_loss: 16.7223\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 16.3578 - val_loss: 16.1829\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.8985 - val_loss: 15.8244\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.5967 - val_loss: 15.8253\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.4676 - val_loss: 15.7858\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.1072 - val_loss: 16.0489\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.8656 - val_loss: 15.1815\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 14.6838 - val_loss: 16.0477\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.3770 - val_loss: 14.6606\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.1380 - val_loss: 13.9032\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.0522 - val_loss: 13.8218\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.8877 - val_loss: 14.3439\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 399us/step - loss: 13.7653 - val_loss: 13.6617\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.5945 - val_loss: 13.3816\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 13.4963 - val_loss: 14.7498\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 13.3125 - val_loss: 13.1664\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 13.3149 - val_loss: 13.6158\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 13.1474 - val_loss: 13.5198\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 13.0130 - val_loss: 13.5369\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 12.9808 - val_loss: 12.7507\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8725 - val_loss: 12.8265\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.8302 - val_loss: 13.0020\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.7176 - val_loss: 12.6346\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.6192 - val_loss: 13.9256\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.6787 - val_loss: 13.4959\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 3s 659us/step - loss: 12.5975 - val_loss: 13.6432\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 12.4327 - val_loss: 13.2296\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.2552 - val_loss: 12.4679\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.3573 - val_loss: 12.4918\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.2323 - val_loss: 12.8500\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.2506 - val_loss: 12.5518\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.2271 - val_loss: 12.1063\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0566 - val_loss: 12.0929\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0169 - val_loss: 12.1433\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.9497 - val_loss: 11.9286\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0117 - val_loss: 11.9178\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9058 - val_loss: 11.9140\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.9289 - val_loss: 12.0291\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.7510 - val_loss: 11.6578\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7232 - val_loss: 11.9773\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7516 - val_loss: 12.4051\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.7283 - val_loss: 11.8788\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6260 - val_loss: 11.5107\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.6198 - val_loss: 11.5451\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5347 - val_loss: 11.5121\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.5673 - val_loss: 11.5900\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5858 - val_loss: 11.7895\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4967 - val_loss: 11.4508\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3853 - val_loss: 11.5988\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5418 - val_loss: 11.3019\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3846 - val_loss: 11.6144\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.3947 - val_loss: 11.4173\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3178 - val_loss: 11.4288\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2629 - val_loss: 11.6156\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.3182 - val_loss: 11.3635\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 552us/step - loss: 38.2144 - val_loss: 26.8807\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 24.6664 - val_loss: 21.9411\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 21.3109 - val_loss: 20.7385\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 19.6635 - val_loss: 18.6628\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 18.4088 - val_loss: 17.3614\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.4022 - val_loss: 18.6345\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 16.5192 - val_loss: 15.3046\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 15.5908 - val_loss: 14.6622\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.9292 - val_loss: 14.4211\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.4235 - val_loss: 15.8240\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.9923 - val_loss: 13.2996\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 13.6427 - val_loss: 13.1955\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.5567 - val_loss: 13.2146\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.0763 - val_loss: 12.8600\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.0544 - val_loss: 12.3784\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6864 - val_loss: 12.2780\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 12.4547 - val_loss: 12.3063\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.3195 - val_loss: 11.9187\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 12.1000 - val_loss: 11.7088\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.0760 - val_loss: 11.5341\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.8325 - val_loss: 11.3466\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 11.6684 - val_loss: 11.3950\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.5017 - val_loss: 11.4052\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.3743 - val_loss: 11.8064\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.3731 - val_loss: 11.2586\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.2367 - val_loss: 11.0031\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.0776 - val_loss: 11.6786\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0064 - val_loss: 10.8730\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.9613 - val_loss: 10.6088\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.9820 - val_loss: 10.7724\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.7468 - val_loss: 10.5085\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.7018 - val_loss: 10.6439\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.6457 - val_loss: 10.5053\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5596 - val_loss: 10.3531\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.5644 - val_loss: 10.9332\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 10.5101 - val_loss: 10.3770\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5723 - val_loss: 10.3338\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.3735 - val_loss: 10.3506\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.4108 - val_loss: 10.5740\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.3253 - val_loss: 10.4378\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.1983 - val_loss: 10.0930\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.2447 - val_loss: 10.2717\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.2103 - val_loss: 9.9518\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 10.1269 - val_loss: 10.3723\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.1206 - val_loss: 10.3219\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.0312 - val_loss: 10.0847\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.1113 - val_loss: 10.2067\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.9666 - val_loss: 9.9923\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 34.9391 - val_loss: 23.4143\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 20.7161 - val_loss: 18.3428\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.1580 - val_loss: 18.4621\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.5918 - val_loss: 16.4395\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.5038 - val_loss: 15.4082\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.8614 - val_loss: 14.8780\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.3339 - val_loss: 13.7793\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.7974 - val_loss: 14.1550\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 413us/step - loss: 13.3065 - val_loss: 13.6979\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.8875 - val_loss: 12.6207\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 12.6316 - val_loss: 13.1389\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 12.2463 - val_loss: 13.3440\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 12.1267 - val_loss: 11.8397\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 11.9993 - val_loss: 13.2525\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.6360 - val_loss: 11.8018\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 570us/step - loss: 11.6339 - val_loss: 12.5952\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.5698 - val_loss: 11.5794\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1229 - val_loss: 10.9189\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.0379 - val_loss: 11.2164\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.0334 - val_loss: 11.1717\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.7739 - val_loss: 10.9467\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5469 - val_loss: 10.3712\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 10.4991 - val_loss: 11.1810\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.3262 - val_loss: 10.4038\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.4182 - val_loss: 10.4797\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.2632 - val_loss: 9.9377\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.0147 - val_loss: 9.7500\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 458us/step - loss: 9.9230 - val_loss: 10.5107\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.0990 - val_loss: 10.5153\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.7575 - val_loss: 9.7130\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.7468 - val_loss: 9.8923\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.6990 - val_loss: 9.6140\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.6619 - val_loss: 9.4724\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.4568 - val_loss: 9.5830\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.4362 - val_loss: 9.4597\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.3945 - val_loss: 9.2916\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.5203 - val_loss: 9.8550\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.3430 - val_loss: 9.3561\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.2728 - val_loss: 9.3001\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.2099 - val_loss: 9.3740\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.0173 - val_loss: 9.1019\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.1156 - val_loss: 9.2446\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.0712 - val_loss: 8.9432\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 9.0985 - val_loss: 9.2852\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 8.9000 - val_loss: 8.8633\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 8.9124 - val_loss: 8.8442\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 8.8839 - val_loss: 9.1639\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 8.8897 - val_loss: 9.9092\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 8.8164 - val_loss: 8.9940\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 8.8241 - val_loss: 9.7475\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 8.8647 - val_loss: 9.7334\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 39.0282 - val_loss: 29.1567\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 25.7708 - val_loss: 22.9012\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 21.3276 - val_loss: 19.7581\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 19.0659 - val_loss: 23.7255\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 17.6932 - val_loss: 17.1964\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 16.7865 - val_loss: 16.0802\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 15.6380 - val_loss: 14.7726\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.7923 - val_loss: 14.1642\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.2586 - val_loss: 14.3248\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8625 - val_loss: 13.4602\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.4867 - val_loss: 13.9044\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.1366 - val_loss: 12.9014\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.8779 - val_loss: 12.6551\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6404 - val_loss: 12.3030\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.3104 - val_loss: 12.2229\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3068 - val_loss: 12.3651\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0684 - val_loss: 11.9934\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.8823 - val_loss: 11.7653\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.7570 - val_loss: 11.6391\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.6137 - val_loss: 11.3628\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7238 - val_loss: 11.4039\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2988 - val_loss: 11.8793\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.2575 - val_loss: 11.1662\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1807 - val_loss: 11.0298\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.9787 - val_loss: 11.4987\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.9972 - val_loss: 10.8368\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8304 - val_loss: 10.9476\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7715 - val_loss: 10.8736\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6829 - val_loss: 10.9433\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6089 - val_loss: 10.8456\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6139 - val_loss: 10.4698\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.4659 - val_loss: 10.6767\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4874 - val_loss: 10.3353\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4075 - val_loss: 10.3541\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.2665 - val_loss: 10.4516\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3003 - val_loss: 10.4283\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.2278 - val_loss: 10.3572\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.1896 - val_loss: 10.4905\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 37.6059 - val_loss: 26.6654\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 24.3291 - val_loss: 24.0224\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 21.3122 - val_loss: 19.9473\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.6329 - val_loss: 19.4395\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 18.9269 - val_loss: 18.0904\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.9882 - val_loss: 19.0041\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.6015 - val_loss: 17.0548\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.9456 - val_loss: 18.2287\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.5498 - val_loss: 16.2235\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.2332 - val_loss: 15.9764\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.9966 - val_loss: 18.0460\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.4950 - val_loss: 15.3772\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 15.1804 - val_loss: 14.8806\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.9231 - val_loss: 14.9030\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.6789 - val_loss: 14.4950\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.3985 - val_loss: 14.3857\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.3600 - val_loss: 14.1341\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.9989 - val_loss: 13.8404\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 427us/step - loss: 13.8104 - val_loss: 13.6092\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 3s 597us/step - loss: 13.8064 - val_loss: 14.2984\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 13.4872 - val_loss: 13.9948\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 13.3004 - val_loss: 14.1652\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 13.2296 - val_loss: 13.3167\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 13.0611 - val_loss: 13.0424\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 12.9437 - val_loss: 12.8412\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 569us/step - loss: 12.8205 - val_loss: 13.0386\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.6156 - val_loss: 13.1738\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.5816 - val_loss: 12.5311\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.4532 - val_loss: 12.4445\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.4148 - val_loss: 12.3395\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.3347 - val_loss: 12.5859\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.2833 - val_loss: 12.3563\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 385us/step - loss: 12.0913 - val_loss: 12.3584\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 396us/step - loss: 12.0588 - val_loss: 12.3028\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1335 - val_loss: 12.2064\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.8427 - val_loss: 12.0160\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.8075 - val_loss: 11.9659\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.8486 - val_loss: 11.9242\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.7394 - val_loss: 11.7688\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.6647 - val_loss: 12.2340\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.6685 - val_loss: 11.6171\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.4163 - val_loss: 11.5375\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.5631 - val_loss: 12.9063\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.4257 - val_loss: 11.7184\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.3741 - val_loss: 11.6317\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.4192 - val_loss: 11.6829\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.2804 - val_loss: 11.5816\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 34.8563 - val_loss: 25.2731\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 22.8011 - val_loss: 21.9610\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.7206 - val_loss: 20.7620\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.2450 - val_loss: 17.5542\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.2427 - val_loss: 16.3666\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.5419 - val_loss: 15.7286\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.6894 - val_loss: 16.0014\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.2943 - val_loss: 15.1323\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.5834 - val_loss: 15.6808\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.2630 - val_loss: 14.3318\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.9169 - val_loss: 14.3185\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.6816 - val_loss: 13.5650\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1889 - val_loss: 12.9640\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.0173 - val_loss: 13.5229\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.7321 - val_loss: 13.2353\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 12.4855 - val_loss: 12.4650\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.4208 - val_loss: 12.7133\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 12.0188 - val_loss: 11.6879\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 11.9869 - val_loss: 12.5723\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 11.7278 - val_loss: 12.7857\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 11.8462 - val_loss: 11.8750\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.4016 - val_loss: 12.7326\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3389 - val_loss: 11.1722\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.2384 - val_loss: 11.1220\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.1282 - val_loss: 10.9390\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 10.9554 - val_loss: 10.7759\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.9194 - val_loss: 11.0060\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.9088 - val_loss: 10.7327\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6729 - val_loss: 10.5776\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5585 - val_loss: 10.5580\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4761 - val_loss: 10.4749\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.3927 - val_loss: 10.4021\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3873 - val_loss: 10.4034\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.2924 - val_loss: 10.2376\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.3125 - val_loss: 10.4939\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1137 - val_loss: 10.1284\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0031 - val_loss: 10.0968\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.2274 - val_loss: 10.2431\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.8670 - val_loss: 10.2951\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.9404 - val_loss: 10.2727\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.7705 - val_loss: 9.8093\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.6721 - val_loss: 9.8349\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.7283 - val_loss: 9.8449\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.6914 - val_loss: 9.9340\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.6339 - val_loss: 9.6967\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.5821 - val_loss: 9.8979\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.5734 - val_loss: 9.6115\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.5027 - val_loss: 9.6496\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.6148 - val_loss: 12.2386\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.4793 - val_loss: 9.3266\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.3438 - val_loss: 9.7476\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.3759 - val_loss: 9.6677\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.2427 - val_loss: 9.3206\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.2812 - val_loss: 9.3249\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.3220 - val_loss: 9.4686\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.2632 - val_loss: 10.1321\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.2004 - val_loss: 9.3515\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.2017 - val_loss: 9.3494\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 40.6971 - val_loss: 30.7559\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 27.6861 - val_loss: 25.0588\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 24.5744 - val_loss: 23.4029\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 22.7295 - val_loss: 22.3897\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.4459 - val_loss: 21.1537\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.6193 - val_loss: 20.0530\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 19.6669 - val_loss: 19.3595\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 19.0347 - val_loss: 19.6681\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.5290 - val_loss: 17.8638\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 17.8570 - val_loss: 17.3982\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.4874 - val_loss: 17.2731\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.1957 - val_loss: 17.1121\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.8465 - val_loss: 16.4812\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 387us/step - loss: 16.4175 - val_loss: 16.0349\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 431us/step - loss: 16.2382 - val_loss: 16.8890\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 15.8956 - val_loss: 15.8205\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 15.6549 - val_loss: 15.6181\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 15.4347 - val_loss: 15.4412\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 15.2653 - val_loss: 15.1795\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 14.9615 - val_loss: 15.4180\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 14.8277 - val_loss: 15.2042\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.7734 - val_loss: 14.4975\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.4590 - val_loss: 15.0556\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.4386 - val_loss: 14.3451\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.3027 - val_loss: 16.7181\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.1367 - val_loss: 14.7347\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 14.0940 - val_loss: 14.2746\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.8937 - val_loss: 13.8708\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 13.7798 - val_loss: 13.6651\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.7482 - val_loss: 13.7690\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.6427 - val_loss: 13.9111\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.4747 - val_loss: 13.4603\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3893 - val_loss: 13.5883\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.3919 - val_loss: 13.3873\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.2906 - val_loss: 13.3877\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1037 - val_loss: 13.4622\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.0713 - val_loss: 12.9863\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.9773 - val_loss: 13.0670\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9604 - val_loss: 12.9530\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.8387 - val_loss: 13.1550\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7825 - val_loss: 14.0950\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.7231 - val_loss: 12.8288\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.6916 - val_loss: 12.6931\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5924 - val_loss: 12.7109\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6070 - val_loss: 13.0920\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6101 - val_loss: 13.0330\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.3872 - val_loss: 12.7312\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.4183 - val_loss: 12.6512\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.2739 - val_loss: 12.8187\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.3528 - val_loss: 13.1404\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.2612 - val_loss: 12.5649\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.2409 - val_loss: 12.5763\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.2714 - val_loss: 12.2909\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.1392 - val_loss: 12.2676\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.0660 - val_loss: 12.2871\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.0800 - val_loss: 12.3273\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.9638 - val_loss: 12.4577\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.9831 - val_loss: 12.2158\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8515 - val_loss: 12.2189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.9320 - val_loss: 12.2198\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 11.8458 - val_loss: 11.9712\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.8169 - val_loss: 12.4100\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 11.8224 - val_loss: 12.3055\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 11.8372 - val_loss: 11.9065\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 11.6722 - val_loss: 12.8102\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.7835 - val_loss: 12.0858\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8603 - val_loss: 12.1683\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.6127 - val_loss: 12.0996\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5349 - val_loss: 11.7258\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5600 - val_loss: 11.9628\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5346 - val_loss: 11.7196\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4133 - val_loss: 11.9159\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4814 - val_loss: 11.7710\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4388 - val_loss: 11.7782\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.3714 - val_loss: 11.8706\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4026 - val_loss: 12.1362\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 40.5520 - val_loss: 27.7521\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 25.2929 - val_loss: 23.3059\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 21.4471 - val_loss: 21.5782\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.1629 - val_loss: 18.9878\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.7847 - val_loss: 18.6838\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.9212 - val_loss: 18.0426\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.9131 - val_loss: 16.6935\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.3445 - val_loss: 16.0366\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.7714 - val_loss: 15.9918\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.1573 - val_loss: 14.7413\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8467 - val_loss: 14.6852\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.4401 - val_loss: 14.7847\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.1569 - val_loss: 13.9021\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.9301 - val_loss: 13.4520\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.6109 - val_loss: 13.4122\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.3900 - val_loss: 13.1262\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.2108 - val_loss: 12.9550\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8778 - val_loss: 13.1799\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.8910 - val_loss: 13.0604\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.6730 - val_loss: 12.7277\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.5381 - val_loss: 12.9125\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.4428 - val_loss: 12.8377\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.3398 - val_loss: 12.2837\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.3101 - val_loss: 12.4227\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.1110 - val_loss: 12.0704\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0062 - val_loss: 12.0022\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9588 - val_loss: 12.0537\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8591 - val_loss: 12.0906\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7779 - val_loss: 11.9474\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6616 - val_loss: 12.0285\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6051 - val_loss: 11.6181\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6226 - val_loss: 11.9210\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.5074 - val_loss: 11.6341\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3476 - val_loss: 11.5149\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.4427 - val_loss: 11.3266\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.2187 - val_loss: 11.7086\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.2459 - val_loss: 11.6341\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1883 - val_loss: 11.8931\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1165 - val_loss: 11.0297\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1431 - val_loss: 11.3664\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 407us/step - loss: 11.0333 - val_loss: 10.9690\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 10.9423 - val_loss: 10.9772\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 10.8866 - val_loss: 10.9094\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 10.8939 - val_loss: 11.5881\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.8770 - val_loss: 11.1736\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 10.8466 - val_loss: 10.9928\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.7794 - val_loss: 10.9555\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 10.7064 - val_loss: 10.7416\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.7121 - val_loss: 10.9438\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.6560 - val_loss: 10.8309\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.6620 - val_loss: 11.0687\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6429 - val_loss: 10.6871\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.5536 - val_loss: 10.9816\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.4913 - val_loss: 10.5300\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.6186 - val_loss: 11.2055\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4312 - val_loss: 10.4437\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4194 - val_loss: 10.9326\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4003 - val_loss: 10.8012\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.3568 - val_loss: 10.5825\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.2800 - val_loss: 10.5837\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2975 - val_loss: 10.3461\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4603 - val_loss: 10.8737\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.2650 - val_loss: 10.6290\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1768 - val_loss: 10.2964\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1682 - val_loss: 10.5208\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1571 - val_loss: 10.3842\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.1424 - val_loss: 10.6744\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1477 - val_loss: 10.3604\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.0804 - val_loss: 10.2630\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.0827 - val_loss: 10.3147\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0302 - val_loss: 10.7226\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.0808 - val_loss: 10.4962\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.9631 - val_loss: 10.1825\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.9840 - val_loss: 10.3551\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.9485 - val_loss: 10.0615\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0105 - val_loss: 10.1606\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.8750 - val_loss: 10.3796\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 9.8983 - val_loss: 10.1732\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.8891 - val_loss: 10.0974\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.8960 - val_loss: 11.1229\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 37.8328 - val_loss: 26.2280\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 23.6763 - val_loss: 21.4417\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 20.1865 - val_loss: 20.8226\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 18.4456 - val_loss: 17.9179\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 17.3707 - val_loss: 17.2758\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 16.6630 - val_loss: 16.8035\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 15.9674 - val_loss: 15.9029\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 15.5334 - val_loss: 15.3277\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 15.2412 - val_loss: 14.8498\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 14.8851 - val_loss: 14.7804\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.6726 - val_loss: 14.2307\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 14.3183 - val_loss: 13.8818\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.9111 - val_loss: 13.8954\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.8178 - val_loss: 13.8325\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.5154 - val_loss: 13.4084\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.3321 - val_loss: 14.6586\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1130 - val_loss: 13.8930\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.2250 - val_loss: 12.7864\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.7010 - val_loss: 13.2713\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.5723 - val_loss: 12.5774\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.4840 - val_loss: 12.5107\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.2849 - val_loss: 12.1663\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1858 - val_loss: 12.4864\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.1825 - val_loss: 11.8323\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.9528 - val_loss: 12.2554\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.8823 - val_loss: 11.6673\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.7062 - val_loss: 12.0691\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.6362 - val_loss: 11.7427\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.5664 - val_loss: 11.7579\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.6067 - val_loss: 12.2356\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.3420 - val_loss: 11.8213\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 38.0611 - val_loss: 29.3569\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 27.5767 - val_loss: 25.3166\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 24.8274 - val_loss: 24.3478\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 22.9995 - val_loss: 22.1730\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 21.8469 - val_loss: 21.6621\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.9381 - val_loss: 20.2236\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 20.1830 - val_loss: 19.5487\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 19.9094 - val_loss: 19.4027\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.1546 - val_loss: 18.7138\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.1698 - val_loss: 19.3370\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 18.4676 - val_loss: 18.0249\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.1471 - val_loss: 18.8318\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.2208 - val_loss: 19.4426\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.7765 - val_loss: 17.3884\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.4149 - val_loss: 17.0310\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.1378 - val_loss: 17.1417\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.9988 - val_loss: 16.5118\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.7359 - val_loss: 16.3882\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.4632 - val_loss: 16.5373\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.3596 - val_loss: 16.6145\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.0838 - val_loss: 16.9223\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.9120 - val_loss: 16.1327\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 467us/step - loss: 15.6102 - val_loss: 16.2443\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.6700 - val_loss: 15.8796\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 15.4519 - val_loss: 15.1041\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.3481 - val_loss: 15.2082\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.1626 - val_loss: 15.1240\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.2381 - val_loss: 15.0272\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.9913 - val_loss: 15.0302\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 14.9033 - val_loss: 16.0161\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 14.9004 - val_loss: 14.8195\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 14.7663 - val_loss: 14.8914\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 14.6411 - val_loss: 14.8849\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 14.7336 - val_loss: 14.5666\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 567us/step - loss: 14.5171 - val_loss: 14.5401\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.6541 - val_loss: 14.4892\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.4981 - val_loss: 14.7847\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.3935 - val_loss: 14.1684\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.2431 - val_loss: 14.5068\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.1577 - val_loss: 14.3332\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1325 - val_loss: 14.3952\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.1839 - val_loss: 14.2227\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0813 - val_loss: 14.0459\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0139 - val_loss: 14.4348\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.9591 - val_loss: 13.9996\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9329 - val_loss: 14.0428\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.8607 - val_loss: 13.8888\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8969 - val_loss: 14.0552\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.8578 - val_loss: 13.8599\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.8087 - val_loss: 13.8305\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6905 - val_loss: 13.8878\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.6819 - val_loss: 13.6937\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.7314 - val_loss: 14.0595\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.8314 - val_loss: 14.2544\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 13.6592 - val_loss: 13.7692\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.5489 - val_loss: 13.5765\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.5634 - val_loss: 13.7059\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.5645 - val_loss: 13.6470\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.5684 - val_loss: 13.9996\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.5167 - val_loss: 13.6551\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4783 - val_loss: 13.6881\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 36.7946 - val_loss: 26.7496\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 23.4770 - val_loss: 22.1887\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.2338 - val_loss: 19.5581\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.7098 - val_loss: 18.7443\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 18.0270 - val_loss: 17.5053\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.2654 - val_loss: 17.0572\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.5878 - val_loss: 15.9629\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 16.1611 - val_loss: 15.6774\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.9181 - val_loss: 15.5440\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 15.5949 - val_loss: 15.2980\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 15.0042 - val_loss: 14.8128\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 14.6036 - val_loss: 14.3210\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 14.5299 - val_loss: 14.0569\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 14.1917 - val_loss: 13.9264\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 13.8957 - val_loss: 15.1569\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.6132 - val_loss: 13.1686\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.5260 - val_loss: 12.9724\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2210 - val_loss: 12.8774\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.0861 - val_loss: 12.8647\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.9611 - val_loss: 12.4908\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.7760 - val_loss: 12.4728\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.7058 - val_loss: 12.7181\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.4176 - val_loss: 12.3664\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 12.4484 - val_loss: 12.4392\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.3553 - val_loss: 11.9919\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.2402 - val_loss: 11.9294\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9871 - val_loss: 12.0211\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.9300 - val_loss: 11.8193\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8333 - val_loss: 11.6823\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.7464 - val_loss: 11.6862\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6926 - val_loss: 11.5141\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.5934 - val_loss: 11.5514\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.5568 - val_loss: 12.1585\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.4083 - val_loss: 11.1939\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.3726 - val_loss: 11.2505\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2550 - val_loss: 11.3498\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2634 - val_loss: 11.1463\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1271 - val_loss: 11.2265\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2443 - val_loss: 11.1534\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.0551 - val_loss: 11.0258\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.9583 - val_loss: 10.7614\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9256 - val_loss: 10.8062\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.8830 - val_loss: 10.9918\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.9024 - val_loss: 12.1704\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 10.7845 - val_loss: 11.0939\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.7163 - val_loss: 11.5959\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 39.4063 - val_loss: 31.5053\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 27.2525 - val_loss: 24.7508\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 23.6491 - val_loss: 21.0470\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.3828 - val_loss: 19.6491\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 19.3278 - val_loss: 17.9354\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.2853 - val_loss: 19.5168\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.2765 - val_loss: 16.5566\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.4926 - val_loss: 16.7078\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.0024 - val_loss: 15.4738\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.5531 - val_loss: 15.5056\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.0728 - val_loss: 14.7974\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.8165 - val_loss: 14.3574\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.4388 - val_loss: 14.0975\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.2022 - val_loss: 14.1037\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.2497 - val_loss: 14.3169\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.7378 - val_loss: 13.5363\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.7136 - val_loss: 13.3593\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.3001 - val_loss: 13.4340\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.2586 - val_loss: 13.4309\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.1732 - val_loss: 12.8628\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 406us/step - loss: 12.8805 - val_loss: 12.8584\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 420us/step - loss: 12.9811 - val_loss: 12.8435\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 12.7023 - val_loss: 12.5498\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 12.6083 - val_loss: 12.5136\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 12.4719 - val_loss: 12.4421\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 12.3516 - val_loss: 12.3889\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.3294 - val_loss: 12.1117\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 12.1339 - val_loss: 12.0821\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0571 - val_loss: 12.2751\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9208 - val_loss: 12.1888\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.8642 - val_loss: 11.7167\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7444 - val_loss: 11.5579\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5966 - val_loss: 11.6200\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5650 - val_loss: 11.5861\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.4097 - val_loss: 11.2603\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3024 - val_loss: 11.5792\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.2508 - val_loss: 11.1988\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.1795 - val_loss: 11.1893\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.1654 - val_loss: 11.0100\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 11.0480 - val_loss: 12.4910\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.9183 - val_loss: 11.2860\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.9868 - val_loss: 10.7413\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.8503 - val_loss: 10.9624\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.7523 - val_loss: 10.8359\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.7722 - val_loss: 10.6901\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.6964 - val_loss: 10.8604\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.7329 - val_loss: 10.5800\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.5797 - val_loss: 10.6167\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.5129 - val_loss: 10.5184\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5082 - val_loss: 10.7666\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.4036 - val_loss: 10.4878\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.4586 - val_loss: 10.4208\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3910 - val_loss: 10.3916\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.2859 - val_loss: 10.3600\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3094 - val_loss: 10.3099\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.2587 - val_loss: 10.3555\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.2488 - val_loss: 10.6415\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1955 - val_loss: 10.2534\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1298 - val_loss: 10.2934\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.2709 - val_loss: 10.2520\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0553 - val_loss: 10.1857\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.2113 - val_loss: 10.3055\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.1463 - val_loss: 10.0998\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0900 - val_loss: 10.0848\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.9303 - val_loss: 10.6424\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0072 - val_loss: 10.1029\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 10.0431 - val_loss: 10.8601\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 9.9555 - val_loss: 9.9135\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 9.8030 - val_loss: 10.1229\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.0290 - val_loss: 10.1767\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 9.7815 - val_loss: 10.0001\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 9.9256 - val_loss: 10.4094\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 9.6811 - val_loss: 9.9348\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 35.2623 - val_loss: 25.1525\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 22.4946 - val_loss: 20.8279\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 19.5609 - val_loss: 18.4551\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 18.0704 - val_loss: 17.5029\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 17.4530 - val_loss: 17.9818\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 16.5049 - val_loss: 16.3744\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 15.9909 - val_loss: 16.0244\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 15.5504 - val_loss: 15.4046\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 15.2801 - val_loss: 15.1118\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 14.8767 - val_loss: 15.6760\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.6899 - val_loss: 15.2279\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 14.4587 - val_loss: 14.2419\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.2282 - val_loss: 13.9005\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.0030 - val_loss: 16.1679\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 13.7982 - val_loss: 13.7164\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 13.4991 - val_loss: 13.4005\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 13.4341 - val_loss: 13.4937\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 13.2906 - val_loss: 13.1191\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 12.9422 - val_loss: 13.0286\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 12.8731 - val_loss: 12.9097\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 12.6821 - val_loss: 12.7496\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 12.5432 - val_loss: 12.6817\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 12.5556 - val_loss: 13.0534\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 12.3429 - val_loss: 12.2340\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 12.3443 - val_loss: 12.8033\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 12.0137 - val_loss: 12.3290\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 11.9435 - val_loss: 12.2528\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.9586 - val_loss: 11.9287\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.6653 - val_loss: 11.9748\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.6080 - val_loss: 11.5974\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.5492 - val_loss: 11.4513\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 11.4218 - val_loss: 11.7177\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.3661 - val_loss: 11.6505\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.4780 - val_loss: 11.2125\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.2828 - val_loss: 11.4469\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 11.0698 - val_loss: 11.4484\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.0600 - val_loss: 11.4190\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.0535 - val_loss: 10.9706\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 11.1018 - val_loss: 11.1673\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.9135 - val_loss: 11.2897\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.7082 - val_loss: 10.7960\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.7594 - val_loss: 10.8273\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.8811 - val_loss: 10.7981\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.8148 - val_loss: 10.8828\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.4898 - val_loss: 10.5245\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.5063 - val_loss: 10.6615\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.6353 - val_loss: 10.4929\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 1s 325us/step - loss: 10.4010 - val_loss: 10.5278\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 1s 348us/step - loss: 10.4315 - val_loss: 11.3291\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 10.2704 - val_loss: 10.5117\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 10.2398 - val_loss: 10.2232\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 492us/step - loss: 10.2674 - val_loss: 10.4329\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 492us/step - loss: 10.1675 - val_loss: 10.5449\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 10.1299 - val_loss: 10.5818\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 10.0919 - val_loss: 10.2714\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 10.1456 - val_loss: 11.3577\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 38.7132 - val_loss: 31.7482\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 28.3637 - val_loss: 28.4538\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 23.8738 - val_loss: 22.1982\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 20.9868 - val_loss: 19.8355\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 19.6810 - val_loss: 18.8883\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.5300 - val_loss: 18.1809\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 17.7972 - val_loss: 16.9610\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 17.2860 - val_loss: 17.5021\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.6818 - val_loss: 16.2563\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.1126 - val_loss: 16.4583\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.6758 - val_loss: 15.8718\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.1548 - val_loss: 14.6696\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.9591 - val_loss: 14.9468\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.7250 - val_loss: 15.5793\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.3123 - val_loss: 14.1218\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.0417 - val_loss: 14.5508\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.8428 - val_loss: 14.8803\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5453 - val_loss: 13.2097\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.5916 - val_loss: 13.6470\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.1188 - val_loss: 13.1464\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.0126 - val_loss: 12.9463\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.0357 - val_loss: 12.5278\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.6299 - val_loss: 12.4676\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.5861 - val_loss: 12.3553\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.4833 - val_loss: 12.4867\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.3073 - val_loss: 12.0890\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.1372 - val_loss: 12.6781\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0346 - val_loss: 12.1253\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.0535 - val_loss: 12.1111\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9377 - val_loss: 11.8174\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 11.6643 - val_loss: 11.5662\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.6298 - val_loss: 11.8668\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6155 - val_loss: 11.4244\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4825 - val_loss: 11.4322\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.3668 - val_loss: 12.3467\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 11.4627 - val_loss: 11.1490\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 11.2386 - val_loss: 11.7888\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.2598 - val_loss: 11.8635\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.1284 - val_loss: 11.0153\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 11.0822 - val_loss: 11.3111\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.0006 - val_loss: 11.3859\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.9834 - val_loss: 11.1781\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.8808 - val_loss: 10.9318\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7666 - val_loss: 11.1344\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7821 - val_loss: 11.7726\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7672 - val_loss: 11.1346\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.6909 - val_loss: 10.8261\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6367 - val_loss: 10.7170\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5891 - val_loss: 10.5551\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.7622 - val_loss: 10.6108\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5237 - val_loss: 10.5649\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.3713 - val_loss: 10.7093\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3230 - val_loss: 10.3450\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3745 - val_loss: 10.6790\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2879 - val_loss: 10.4094\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.2760 - val_loss: 10.4557\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4752 - val_loss: 10.3992\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1831 - val_loss: 10.3368\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1576 - val_loss: 10.4619\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0719 - val_loss: 10.1649\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.1210 - val_loss: 10.4455\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1017 - val_loss: 10.2493\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.0775 - val_loss: 10.2659\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.9718 - val_loss: 10.3788\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0265 - val_loss: 10.9602\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 38.3631 - val_loss: 29.0100\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 26.9705 - val_loss: 25.5521\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 23.8354 - val_loss: 22.0663\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.6281 - val_loss: 21.4867\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.5823 - val_loss: 20.3377\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.5871 - val_loss: 18.9020\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.9725 - val_loss: 19.5420\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.4062 - val_loss: 17.8720\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.0144 - val_loss: 17.9691\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.5514 - val_loss: 17.8570\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.1837 - val_loss: 17.0402\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.8297 - val_loss: 16.5277\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.4241 - val_loss: 16.7478\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.2017 - val_loss: 15.8853\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.9068 - val_loss: 15.6547\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.6119 - val_loss: 15.3987\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.2947 - val_loss: 16.6968\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.2373 - val_loss: 15.2499\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.8688 - val_loss: 15.1657\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7903 - val_loss: 15.3289\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.5175 - val_loss: 14.9457\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4811 - val_loss: 14.7519\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.3392 - val_loss: 14.4840\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 14.1416 - val_loss: 14.7330\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.0142 - val_loss: 14.7347\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8917 - val_loss: 14.1614\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 13.7633 - val_loss: 15.1431\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 13.8555 - val_loss: 13.7138\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 13.5727 - val_loss: 13.6899\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 13.5386 - val_loss: 14.0258\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 13.4097 - val_loss: 13.7391\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 13.3692 - val_loss: 13.4907\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 13.2625 - val_loss: 13.4646\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.1591 - val_loss: 13.4895\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.1250 - val_loss: 13.2975\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.0697 - val_loss: 13.3136\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9188 - val_loss: 13.2790\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.9203 - val_loss: 13.3758\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.1362 - val_loss: 14.2257\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.7641 - val_loss: 12.8939\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9035 - val_loss: 13.0326\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.6488 - val_loss: 12.9692\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.6428 - val_loss: 12.8800\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.5805 - val_loss: 12.8104\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 12.5798 - val_loss: 13.3509\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.6523 - val_loss: 12.7780\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.3812 - val_loss: 13.1174\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.4188 - val_loss: 12.7772\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.3906 - val_loss: 13.0672\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.1797 - val_loss: 12.5900\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.2330 - val_loss: 12.5810\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.1978 - val_loss: 12.5729\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.0981 - val_loss: 12.6730\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.2092 - val_loss: 12.4713\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.0527 - val_loss: 12.4504\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.9593 - val_loss: 12.6034\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0304 - val_loss: 12.5177\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8928 - val_loss: 12.5579\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.8545 - val_loss: 12.4518\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0444 - val_loss: 12.1042\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.8020 - val_loss: 12.3115\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7845 - val_loss: 12.4574\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7848 - val_loss: 12.5098\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7283 - val_loss: 12.1252\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7917 - val_loss: 12.0527\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.5674 - val_loss: 12.5243\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8909 - val_loss: 12.9179\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5937 - val_loss: 12.0087\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5000 - val_loss: 12.1941\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5322 - val_loss: 11.8964\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 11.5120 - val_loss: 11.9679\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 11.4351 - val_loss: 12.1656\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.4749 - val_loss: 12.0807\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 11.4462 - val_loss: 12.5598\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.4136 - val_loss: 12.2112\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 34.6001 - val_loss: 27.0740\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 24.3468 - val_loss: 23.9078\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 21.1057 - val_loss: 20.2928\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.6023 - val_loss: 18.6028\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.4784 - val_loss: 18.7936\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.6309 - val_loss: 18.2889\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.1550 - val_loss: 16.9758\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.4396 - val_loss: 16.4098\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.0210 - val_loss: 15.9985\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.7609 - val_loss: 16.2057\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.3856 - val_loss: 15.7351\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.9365 - val_loss: 14.3520\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 14.6478 - val_loss: 14.4564\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.3679 - val_loss: 14.4827\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.1699 - val_loss: 13.9556\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9500 - val_loss: 13.5856\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6441 - val_loss: 13.8608\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.5383 - val_loss: 13.3501\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3492 - val_loss: 13.0367\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.1812 - val_loss: 13.1545\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.9530 - val_loss: 13.0617\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8413 - val_loss: 12.5620\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.6553 - val_loss: 12.8619\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.5839 - val_loss: 12.4430\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.3165 - val_loss: 12.0421\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.3348 - val_loss: 12.0505\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1404 - val_loss: 12.3889\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.0768 - val_loss: 12.3026\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.9340 - val_loss: 11.8603\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.8367 - val_loss: 11.7976\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.7148 - val_loss: 11.4444\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7217 - val_loss: 11.5978\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5157 - val_loss: 11.3296\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4279 - val_loss: 11.3847\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4467 - val_loss: 11.3041\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2288 - val_loss: 11.0730\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1657 - val_loss: 11.1718\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.1092 - val_loss: 11.3401\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.0356 - val_loss: 11.1694\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0003 - val_loss: 11.6208\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1391 - val_loss: 10.9049\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.9876 - val_loss: 10.9565\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.8498 - val_loss: 10.7327\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6602 - val_loss: 11.0267\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9080 - val_loss: 11.0428\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7569 - val_loss: 10.6500\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5555 - val_loss: 10.6294\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5509 - val_loss: 10.7773\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.5198 - val_loss: 10.5266\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6237 - val_loss: 10.3609\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.4151 - val_loss: 10.5201\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5757 - val_loss: 10.6236\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 421us/step - loss: 10.4067 - val_loss: 10.5442\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.4381 - val_loss: 10.5228\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 10.2669 - val_loss: 10.5336\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 573us/step - loss: 40.3266 - val_loss: 32.2041\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 27.0052 - val_loss: 25.2999\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 24.4496 - val_loss: 23.3317\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 22.6646 - val_loss: 22.1902\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.6918 - val_loss: 22.0857\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.7008 - val_loss: 22.1476\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.1645 - val_loss: 20.3487\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 19.4977 - val_loss: 19.2738\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 18.8432 - val_loss: 18.4255\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 18.6771 - val_loss: 19.6781\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.1103 - val_loss: 17.5235\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.7760 - val_loss: 18.1000\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.4953 - val_loss: 17.1804\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 17.1092 - val_loss: 17.5050\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.9096 - val_loss: 16.9733\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.5865 - val_loss: 16.8726\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.3500 - val_loss: 16.8891\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 16.3565 - val_loss: 16.5653\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 16.0398 - val_loss: 15.6996\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.6650 - val_loss: 16.9860\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 15.6331 - val_loss: 15.3657\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.3447 - val_loss: 15.5532\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.3238 - val_loss: 15.2319\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.1320 - val_loss: 15.3529\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.9337 - val_loss: 15.2170\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.7121 - val_loss: 14.9519\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.6788 - val_loss: 14.8100\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.5117 - val_loss: 14.4356\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.4724 - val_loss: 16.2587\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3151 - val_loss: 14.5060\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1815 - val_loss: 14.3005\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.1638 - val_loss: 14.0650\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.0318 - val_loss: 14.7582\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.9646 - val_loss: 14.0605\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8863 - val_loss: 13.8924\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.7700 - val_loss: 13.9764\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.8418 - val_loss: 13.6974\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.6733 - val_loss: 13.7285\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5778 - val_loss: 14.2678\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.5818 - val_loss: 14.4425\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 13.4120 - val_loss: 13.6584\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 470us/step - loss: 13.4242 - val_loss: 13.5185\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.5303 - val_loss: 13.4018\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 13.2686 - val_loss: 13.3978\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.2779 - val_loss: 13.3067\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 13.2853 - val_loss: 13.4877\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 13.0938 - val_loss: 13.2583\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1645 - val_loss: 13.1706\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.1750 - val_loss: 13.6141\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9976 - val_loss: 13.5274\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.0182 - val_loss: 13.1761\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.9082 - val_loss: 13.2783\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.8876 - val_loss: 13.2608\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 41.4027 - val_loss: 34.2530\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 30.0578 - val_loss: 25.3771\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 24.7464 - val_loss: 23.2878\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 22.3835 - val_loss: 21.5156\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 21.2398 - val_loss: 19.6733\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.0747 - val_loss: 19.7257\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.2285 - val_loss: 20.5919\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.6539 - val_loss: 17.9354\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.1818 - val_loss: 17.7485\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.6771 - val_loss: 17.0845\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.3070 - val_loss: 17.0743\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.7332 - val_loss: 16.3297\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.3608 - val_loss: 16.1134\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.2918 - val_loss: 15.6681\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7484 - val_loss: 15.7593\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.7800 - val_loss: 16.9213\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.2417 - val_loss: 16.4355\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.9715 - val_loss: 14.6958\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7896 - val_loss: 17.0185\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.7679 - val_loss: 14.5481\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4127 - val_loss: 14.3164\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.1979 - val_loss: 14.2926\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.1401 - val_loss: 14.1197\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.9079 - val_loss: 14.7224\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.7629 - val_loss: 16.0186\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.7020 - val_loss: 14.1349\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.4269 - val_loss: 13.4448\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3072 - val_loss: 14.9835\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3995 - val_loss: 13.2255\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9206 - val_loss: 13.3712\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.8946 - val_loss: 12.7868\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.8064 - val_loss: 12.7511\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8785 - val_loss: 13.7747\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.5824 - val_loss: 12.4066\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.4461 - val_loss: 12.5692\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.4065 - val_loss: 12.5824\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.3090 - val_loss: 12.6147\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2945 - val_loss: 12.1797\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0976 - val_loss: 12.1763\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.1042 - val_loss: 12.8732\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.1091 - val_loss: 11.9182\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 11.8796 - val_loss: 12.2011\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.9417 - val_loss: 12.4684\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 406us/step - loss: 11.8166 - val_loss: 12.6044\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 426us/step - loss: 11.8623 - val_loss: 11.8303\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 11.6710 - val_loss: 11.8859\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 11.6477 - val_loss: 11.8679\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 11.7187 - val_loss: 12.9348\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 11.6402 - val_loss: 11.5587\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 11.4532 - val_loss: 11.8104\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 573us/step - loss: 11.7107 - val_loss: 11.6033\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3549 - val_loss: 11.8485\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5160 - val_loss: 11.7368\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.2902 - val_loss: 11.4852\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2719 - val_loss: 11.6037\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.2595 - val_loss: 11.4756\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.2261 - val_loss: 11.2664\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.2105 - val_loss: 11.3516\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.1255 - val_loss: 11.9324\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.2426 - val_loss: 11.7060\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.0937 - val_loss: 11.3580\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.0339 - val_loss: 11.2369\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.0072 - val_loss: 11.6821\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.0973 - val_loss: 11.3579\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.0471 - val_loss: 11.1091\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.8404 - val_loss: 11.1953\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.1197 - val_loss: 11.9445\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.9569 - val_loss: 11.1912\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.7421 - val_loss: 10.9779\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.8571 - val_loss: 11.4600\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7183 - val_loss: 11.0723\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7109 - val_loss: 11.5702\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.7067 - val_loss: 10.9522\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.7345 - val_loss: 10.9283\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.7850 - val_loss: 10.8868\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.5690 - val_loss: 10.9017\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6112 - val_loss: 11.2963\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.6932 - val_loss: 10.8970\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.6006 - val_loss: 11.0444\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.5808 - val_loss: 10.8751\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.4677 - val_loss: 10.9970\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.5120 - val_loss: 11.0596\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4977 - val_loss: 11.4036\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.4739 - val_loss: 11.1013\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4243 - val_loss: 11.1954\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 572us/step - loss: 37.8120 - val_loss: 24.9317\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 23.0793 - val_loss: 21.7695\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 20.3817 - val_loss: 19.1997\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 18.8437 - val_loss: 17.9276\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 17.3365 - val_loss: 17.2551\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 16.5342 - val_loss: 15.9681\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 15.8252 - val_loss: 15.6438\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 15.2266 - val_loss: 14.8827\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.8712 - val_loss: 14.6894\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.4590 - val_loss: 14.3795\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.0735 - val_loss: 13.7970\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8527 - val_loss: 14.5979\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5468 - val_loss: 13.5004\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2630 - val_loss: 13.2129\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.9513 - val_loss: 12.8671\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.6632 - val_loss: 12.5691\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5185 - val_loss: 12.5963\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3277 - val_loss: 12.3606\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0683 - val_loss: 12.0717\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0020 - val_loss: 12.1750\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8315 - val_loss: 12.2329\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7282 - val_loss: 11.8260\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5421 - val_loss: 11.5635\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4562 - val_loss: 11.7430\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3696 - val_loss: 11.5402\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.5569 - val_loss: 11.7992\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.1126 - val_loss: 10.9660\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.1199 - val_loss: 11.1108\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.0188 - val_loss: 10.9034\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.9575 - val_loss: 10.9297\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.9821 - val_loss: 11.0514\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8387 - val_loss: 11.0987\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.6702 - val_loss: 10.7390\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7776 - val_loss: 10.7332\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6304 - val_loss: 10.6340\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.6106 - val_loss: 11.0292\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.4892 - val_loss: 10.7348\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5191 - val_loss: 10.4009\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3833 - val_loss: 10.6389\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5174 - val_loss: 10.3793\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.3816 - val_loss: 14.4358\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3578 - val_loss: 10.4578\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3331 - val_loss: 10.1253\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1928 - val_loss: 10.2646\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1005 - val_loss: 10.2408\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0595 - val_loss: 10.4475\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0477 - val_loss: 10.0929\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0316 - val_loss: 10.0846\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0719 - val_loss: 10.1667\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0282 - val_loss: 10.2542\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.0015 - val_loss: 10.1087\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9067 - val_loss: 10.1171\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.8326 - val_loss: 10.2088\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 545us/step - loss: 37.3702 - val_loss: 30.0928\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 28.8397 - val_loss: 27.2734\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 26.1506 - val_loss: 24.1960\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 24.0213 - val_loss: 23.1147\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 22.8313 - val_loss: 23.2941\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 21.7074 - val_loss: 21.6620\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 21.1514 - val_loss: 20.2749\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 426us/step - loss: 20.2475 - val_loss: 19.8057\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 19.8778 - val_loss: 19.0851\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 19.5558 - val_loss: 18.7934\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 18.7842 - val_loss: 19.1010\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 18.6315 - val_loss: 18.4809\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 18.1431 - val_loss: 17.7914\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.9831 - val_loss: 17.8488\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.5634 - val_loss: 17.0744\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.3948 - val_loss: 17.5963\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.9450 - val_loss: 17.0380\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.0494 - val_loss: 17.4429\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.5457 - val_loss: 16.2286\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 16.3192 - val_loss: 16.5237\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.2459 - val_loss: 16.4376\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.0575 - val_loss: 16.4320\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.9414 - val_loss: 16.0311\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7675 - val_loss: 15.6113\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.8468 - val_loss: 15.8368\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.5729 - val_loss: 15.5868\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.5454 - val_loss: 15.6028\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.4308 - val_loss: 15.6416\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.3424 - val_loss: 15.3280\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.2096 - val_loss: 15.6561\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 15.1427 - val_loss: 15.1612\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.0291 - val_loss: 16.6819\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.0752 - val_loss: 15.2717\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.9815 - val_loss: 15.1184\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.7960 - val_loss: 14.8935\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.8354 - val_loss: 14.7300\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.7745 - val_loss: 15.0971\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.6504 - val_loss: 14.8741\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7273 - val_loss: 14.7705\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.5271 - val_loss: 14.6228\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4756 - val_loss: 14.5439\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.5499 - val_loss: 14.4712\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.4301 - val_loss: 14.3927\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.3463 - val_loss: 14.4824\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3262 - val_loss: 14.5409\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.4135 - val_loss: 15.7216\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.2671 - val_loss: 14.6162\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.1840 - val_loss: 14.3058\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.2499 - val_loss: 14.3557\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.1258 - val_loss: 14.4141\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.1156 - val_loss: 14.3718\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 14.0558 - val_loss: 14.2205\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 14.0691 - val_loss: 14.2976\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 14.0546 - val_loss: 14.2391\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 13.9592 - val_loss: 14.3255\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 14.1436 - val_loss: 14.1588\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 13.8597 - val_loss: 14.4103\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8960 - val_loss: 13.8765\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8360 - val_loss: 14.1429\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8513 - val_loss: 14.0760\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8246 - val_loss: 14.3554\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.8017 - val_loss: 13.9227\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.7571 - val_loss: 14.4043\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 37.1976 - val_loss: 27.6048\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 24.5758 - val_loss: 21.9287\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 21.0255 - val_loss: 19.9251\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.2963 - val_loss: 18.4842\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 18.2808 - val_loss: 17.3935\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 17.5344 - val_loss: 17.6679\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.8531 - val_loss: 16.4266\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.4878 - val_loss: 16.1899\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.9499 - val_loss: 15.4298\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.6951 - val_loss: 15.5988\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.3025 - val_loss: 15.8704\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.2607 - val_loss: 15.5781\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.0339 - val_loss: 14.5739\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.8255 - val_loss: 14.5590\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4592 - val_loss: 14.2874\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3271 - val_loss: 14.1855\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.2090 - val_loss: 14.8267\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1327 - val_loss: 14.0450\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.0653 - val_loss: 14.4123\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8715 - val_loss: 13.7746\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.7118 - val_loss: 13.9936\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.6636 - val_loss: 13.3317\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.4865 - val_loss: 14.9877\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.3971 - val_loss: 13.3344\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3521 - val_loss: 13.3607\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.2410 - val_loss: 13.5988\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2129 - val_loss: 13.7755\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 42.3059 - val_loss: 29.7917\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 25.8187 - val_loss: 22.0941\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 21.3083 - val_loss: 19.4946\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.1659 - val_loss: 19.9768\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.1236 - val_loss: 19.3017\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.2316 - val_loss: 16.7673\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.5532 - val_loss: 15.5762\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.8304 - val_loss: 14.8100\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.2645 - val_loss: 16.3925\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.0061 - val_loss: 14.8725\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.4546 - val_loss: 14.7974\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.1773 - val_loss: 13.4826\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.9512 - val_loss: 14.0677\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.6137 - val_loss: 13.0118\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 1s 338us/step - loss: 13.2671 - val_loss: 13.2928\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.0944 - val_loss: 12.7810\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 12.6840 - val_loss: 12.9093\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 12.5625 - val_loss: 12.0409\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 12.3956 - val_loss: 11.9236\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 12.1500 - val_loss: 11.7845\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 12.0145 - val_loss: 11.4885\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 11.8296 - val_loss: 11.7746\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.6770 - val_loss: 11.7362\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.5320 - val_loss: 11.4848\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.3717 - val_loss: 12.0263\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2463 - val_loss: 11.0821\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.1807 - val_loss: 12.6609\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1666 - val_loss: 12.2669\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.0496 - val_loss: 10.7125\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.8454 - val_loss: 11.5206\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.8511 - val_loss: 10.9614\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.7090 - val_loss: 10.5400\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.6618 - val_loss: 10.4851\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 10.6866 - val_loss: 11.5158\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.6095 - val_loss: 10.5008\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4667 - val_loss: 10.5285\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.3984 - val_loss: 10.2189\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.3929 - val_loss: 10.1377\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.2841 - val_loss: 10.1869\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 10.3350 - val_loss: 10.0045\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.2087 - val_loss: 9.9933\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.1918 - val_loss: 9.8207\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9836 - val_loss: 10.1458\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1184 - val_loss: 10.3133\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0825 - val_loss: 10.4025\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1591 - val_loss: 9.8576\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.8969 - val_loss: 10.1462\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 34.8040 - val_loss: 23.2757\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 21.6092 - val_loss: 19.9806\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.2661 - val_loss: 18.3095\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.9357 - val_loss: 17.4294\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.8370 - val_loss: 16.5398\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.1210 - val_loss: 15.4906\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.4404 - val_loss: 16.0071\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.8170 - val_loss: 14.3390\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.2627 - val_loss: 14.0204\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.8316 - val_loss: 14.7587\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 13.5046 - val_loss: 13.0868\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.1318 - val_loss: 13.1122\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 12.8204 - val_loss: 12.6856\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 470us/step - loss: 12.6978 - val_loss: 12.3258\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 12.2174 - val_loss: 12.5187\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.3625 - val_loss: 12.0738\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 12.0606 - val_loss: 12.0710\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7347 - val_loss: 11.8173\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5111 - val_loss: 13.5553\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.5116 - val_loss: 11.4294\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.3534 - val_loss: 11.5349\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1195 - val_loss: 11.3499\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.0257 - val_loss: 11.0626\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.9204 - val_loss: 12.5542\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7405 - val_loss: 10.6933\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7134 - val_loss: 11.1975\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6174 - val_loss: 10.8003\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4631 - val_loss: 11.7224\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6148 - val_loss: 10.7870\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3042 - val_loss: 10.1662\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.2715 - val_loss: 10.2054\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1280 - val_loss: 10.2247\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1126 - val_loss: 10.8362\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1588 - val_loss: 10.7998\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0195 - val_loss: 9.8352\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.8144 - val_loss: 10.1407\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.9462 - val_loss: 9.7411\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.6964 - val_loss: 9.6919\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.7436 - val_loss: 10.3714\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.6841 - val_loss: 9.7065\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.6427 - val_loss: 9.7338\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.6460 - val_loss: 9.7988\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.4730 - val_loss: 9.8174\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 39.1961 - val_loss: 29.6353\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 26.6799 - val_loss: 22.7035\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 21.4295 - val_loss: 20.0083\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.8091 - val_loss: 21.1556\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.9964 - val_loss: 17.4687\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 17.0908 - val_loss: 17.1996\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 16.0857 - val_loss: 15.8323\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 15.2246 - val_loss: 14.9434\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.7831 - val_loss: 14.3343\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.3417 - val_loss: 13.9863\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.7801 - val_loss: 13.4965\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.5362 - val_loss: 13.2178\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.2770 - val_loss: 13.1528\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.1644 - val_loss: 12.8045\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.7003 - val_loss: 12.5095\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.5820 - val_loss: 12.6891\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.3724 - val_loss: 12.1110\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.2623 - val_loss: 12.2240\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.9785 - val_loss: 12.8093\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8947 - val_loss: 11.7167\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.7624 - val_loss: 11.7249\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5709 - val_loss: 11.8353\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.4661 - val_loss: 11.6192\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 11.2498 - val_loss: 11.2085\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 11.3133 - val_loss: 11.4462\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 11.1083 - val_loss: 11.4078\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 11.0059 - val_loss: 11.0484\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.1042 - val_loss: 10.8481\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 10.8788 - val_loss: 10.8684\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 10.7611 - val_loss: 10.8451\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 567us/step - loss: 10.6241 - val_loss: 10.7460\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.7048 - val_loss: 10.6050\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.4788 - val_loss: 10.9712\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.3788 - val_loss: 10.3757\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.3568 - val_loss: 10.6108\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3599 - val_loss: 10.8736\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 10.3476 - val_loss: 11.3960\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.2233 - val_loss: 10.2618\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.2348 - val_loss: 10.3428\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0845 - val_loss: 10.0864\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0896 - val_loss: 10.0718\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.0092 - val_loss: 10.1112\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.9749 - val_loss: 10.2437\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.0207 - val_loss: 10.0132\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.9564 - val_loss: 10.4453\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.9024 - val_loss: 9.9777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.7700 - val_loss: 9.8182\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.7634 - val_loss: 9.9152\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.8978 - val_loss: 9.8470\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.6679 - val_loss: 10.2313\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.6711 - val_loss: 10.2988\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.7033 - val_loss: 9.9778\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 38.3201 - val_loss: 29.9761\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 24.8951 - val_loss: 22.2044\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.9736 - val_loss: 20.7546\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.5853 - val_loss: 20.1354\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 19.4119 - val_loss: 19.1761\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.5632 - val_loss: 18.0839\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.7926 - val_loss: 17.5476\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.2534 - val_loss: 17.0743\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.7781 - val_loss: 16.5520\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.4286 - val_loss: 16.2698\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.2263 - val_loss: 16.0117\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.5758 - val_loss: 16.0570\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.3998 - val_loss: 15.4563\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.1251 - val_loss: 14.9288\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 14.9364 - val_loss: 14.5585\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 14.8149 - val_loss: 14.4604\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 14.5079 - val_loss: 14.1968\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 14.0840 - val_loss: 14.0442\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 13.9439 - val_loss: 15.0019\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.8835 - val_loss: 14.2026\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 13.6160 - val_loss: 13.7558\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.5303 - val_loss: 14.2262\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.2920 - val_loss: 13.0876\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1161 - val_loss: 12.9650\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.0720 - val_loss: 13.0342\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.7714 - val_loss: 13.4263\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.7180 - val_loss: 12.7150\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.5599 - val_loss: 12.6619\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4892 - val_loss: 12.9770\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2692 - val_loss: 13.1862\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.2528 - val_loss: 12.6830\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.1566 - val_loss: 12.1429\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.9834 - val_loss: 12.1376\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.9472 - val_loss: 12.0963\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7974 - val_loss: 12.0325\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7217 - val_loss: 12.1227\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7863 - val_loss: 11.8665\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.6575 - val_loss: 11.7694\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5385 - val_loss: 11.8049\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.4518 - val_loss: 11.5628\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.4097 - val_loss: 12.4439\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3832 - val_loss: 11.5128\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3382 - val_loss: 11.5291\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.2474 - val_loss: 11.5562\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.1939 - val_loss: 12.0227\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1013 - val_loss: 11.2944\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0887 - val_loss: 11.1852\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.0465 - val_loss: 11.1825\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0735 - val_loss: 11.6853\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.8939 - val_loss: 11.8429\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.9418 - val_loss: 11.4247\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8293 - val_loss: 11.0364\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7876 - val_loss: 11.0762\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.8552 - val_loss: 11.0172\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8354 - val_loss: 11.1322\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6617 - val_loss: 10.9670\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.6824 - val_loss: 10.8282\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5641 - val_loss: 11.1038\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.5241 - val_loss: 11.0254\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6392 - val_loss: 10.8038\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.6668 - val_loss: 10.7227\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5205 - val_loss: 11.0632\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.4386 - val_loss: 10.6082\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3908 - val_loss: 11.0170\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3369 - val_loss: 10.7373\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.4958 - val_loss: 10.6370\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4517 - val_loss: 10.5703\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3315 - val_loss: 10.5752\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3238 - val_loss: 10.5747\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.2490 - val_loss: 10.5493\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.2431 - val_loss: 10.5606\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.2279 - val_loss: 10.4544\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.2340 - val_loss: 10.6407\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.1564 - val_loss: 10.6372\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.1944 - val_loss: 10.4709\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 10.0930 - val_loss: 11.0014\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 10.1740 - val_loss: 10.4421\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 10.1060 - val_loss: 10.7023\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.2477 - val_loss: 10.3444\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.0433 - val_loss: 10.5003\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 10.0860 - val_loss: 10.5048\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.9840 - val_loss: 10.4154\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.0057 - val_loss: 10.4729\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.0215 - val_loss: 10.2618\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9593 - val_loss: 10.5142\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9263 - val_loss: 10.4322\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9475 - val_loss: 10.3609\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.8982 - val_loss: 10.3225\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.8905 - val_loss: 10.3356\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 33.8576 - val_loss: 25.3673\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 23.3323 - val_loss: 20.9763\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.9692 - val_loss: 18.9931\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 19.0477 - val_loss: 18.1138\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 17.7793 - val_loss: 18.2609\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.9641 - val_loss: 16.1701\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.1850 - val_loss: 16.9523\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.6472 - val_loss: 15.1304\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.1541 - val_loss: 15.3887\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.7399 - val_loss: 15.2144\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.3017 - val_loss: 15.1279\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.7942 - val_loss: 13.4492\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6025 - val_loss: 13.3050\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.2155 - val_loss: 13.2730\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8024 - val_loss: 12.4380\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5929 - val_loss: 13.0794\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.4402 - val_loss: 12.0140\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1666 - val_loss: 11.8088\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.0479 - val_loss: 11.7355\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8325 - val_loss: 11.5398\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6472 - val_loss: 11.5671\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5088 - val_loss: 11.9428\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.4234 - val_loss: 11.4893\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3920 - val_loss: 11.2434\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0681 - val_loss: 11.3047\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.8997 - val_loss: 11.3000\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8933 - val_loss: 10.8570\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.8292 - val_loss: 10.8973\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.7613 - val_loss: 10.4388\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.6266 - val_loss: 10.8101\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.5515 - val_loss: 10.5178\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.3944 - val_loss: 10.3515\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 10.4618 - val_loss: 10.2883\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.3834 - val_loss: 10.2269\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3528 - val_loss: 10.2959\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.2415 - val_loss: 11.1350\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.0945 - val_loss: 10.8663\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0983 - val_loss: 9.9812\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.9566 - val_loss: 10.0409\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.9988 - val_loss: 9.8596\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.8932 - val_loss: 10.2583\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.9007 - val_loss: 9.7364\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.8561 - val_loss: 9.7421\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.8195 - val_loss: 9.8775\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.7948 - val_loss: 9.6987\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.6339 - val_loss: 10.0869\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.6653 - val_loss: 10.6057\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.5826 - val_loss: 9.7071\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.7137 - val_loss: 9.6438\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.5013 - val_loss: 9.6485\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.5802 - val_loss: 9.6657\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.4260 - val_loss: 9.5292\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.4719 - val_loss: 9.6211\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.4624 - val_loss: 9.4667\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.2824 - val_loss: 9.2734\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.3350 - val_loss: 9.5707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.3889 - val_loss: 9.3833\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.3332 - val_loss: 9.3716\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.1938 - val_loss: 9.3642\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.1929 - val_loss: 9.5964\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 40.7887 - val_loss: 28.5049\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 26.7685 - val_loss: 25.4881\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 23.7073 - val_loss: 23.5209\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 22.2920 - val_loss: 21.1091\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.9747 - val_loss: 21.8228\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 20.1149 - val_loss: 19.3055\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.5593 - val_loss: 19.0817\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.0143 - val_loss: 18.9057\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.2878 - val_loss: 18.6895\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.7909 - val_loss: 18.0082\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 17.4872 - val_loss: 17.2312\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 17.3306 - val_loss: 16.7790\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.7821 - val_loss: 17.0718\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.6453 - val_loss: 16.4383\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.3422 - val_loss: 16.4621\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 16.0754 - val_loss: 15.9462\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.9693 - val_loss: 15.5946\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.7406 - val_loss: 15.6089\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.6297 - val_loss: 15.4922\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.6204 - val_loss: 15.4585\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.4158 - val_loss: 15.1651\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.4169 - val_loss: 15.1203\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.0658 - val_loss: 15.1352\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.0487 - val_loss: 15.5278\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 14.9565 - val_loss: 14.7440\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 14.7798 - val_loss: 14.5898\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 14.9182 - val_loss: 14.6699\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 14.6035 - val_loss: 14.6445\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 14.5620 - val_loss: 14.6637\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 14.4799 - val_loss: 14.3787\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 14.4517 - val_loss: 14.6826\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.3932 - val_loss: 15.7430\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.4014 - val_loss: 14.6479\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1657 - val_loss: 14.2527\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.1070 - val_loss: 14.4764\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1391 - val_loss: 14.1023\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.0300 - val_loss: 13.9192\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 13.9589 - val_loss: 14.8108\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.9518 - val_loss: 14.0936\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8211 - val_loss: 13.9043\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.7415 - val_loss: 14.2878\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 13.6665 - val_loss: 14.4099\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 13.7448 - val_loss: 13.7599\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.6621 - val_loss: 13.6294\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.5171 - val_loss: 14.3150\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.5836 - val_loss: 14.0170\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 13.4478 - val_loss: 13.5405\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 13.4652 - val_loss: 13.6168\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 13.3623 - val_loss: 13.5664\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 13.3394 - val_loss: 13.4924\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.1927 - val_loss: 13.6157\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.3826 - val_loss: 13.4735\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.1589 - val_loss: 13.2343\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.1312 - val_loss: 13.2279\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.0700 - val_loss: 13.3616\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.1702 - val_loss: 13.2288\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9800 - val_loss: 13.2721\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9799 - val_loss: 13.7776\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.0136 - val_loss: 12.9980\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.8078 - val_loss: 12.9952\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.8803 - val_loss: 13.2211\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.8842 - val_loss: 13.0554\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.7318 - val_loss: 13.0462\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.8004 - val_loss: 13.1371\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.7501 - val_loss: 12.9560\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.6402 - val_loss: 12.9004\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.6003 - val_loss: 12.8535\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.6113 - val_loss: 12.9133\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 12.6050 - val_loss: 13.0253\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 12.6665 - val_loss: 12.9918\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 12.5018 - val_loss: 13.0527\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 471us/step - loss: 12.4810 - val_loss: 12.8617\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 39.2163 - val_loss: 29.9496\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 27.3396 - val_loss: 25.7513\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 22.7708 - val_loss: 20.9163\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.6543 - val_loss: 19.1994\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 19.3084 - val_loss: 18.0016\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.1808 - val_loss: 17.0777\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.2321 - val_loss: 17.2835\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 16.2972 - val_loss: 15.7400\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.7647 - val_loss: 16.0969\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.1125 - val_loss: 14.8098\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.8185 - val_loss: 14.3352\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.3177 - val_loss: 14.3592\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.9802 - val_loss: 14.3421\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.7579 - val_loss: 13.4317\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.5191 - val_loss: 13.3331\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2718 - val_loss: 13.1136\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.0679 - val_loss: 13.2113\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7691 - val_loss: 12.7915\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.6339 - val_loss: 12.7648\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.4562 - val_loss: 12.3164\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.2240 - val_loss: 12.3791\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.0907 - val_loss: 12.2306\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.0005 - val_loss: 11.9884\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.8229 - val_loss: 11.6777\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.7965 - val_loss: 11.7146\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5807 - val_loss: 12.0135\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.5966 - val_loss: 11.4185\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3587 - val_loss: 11.4601\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2828 - val_loss: 11.7587\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2165 - val_loss: 11.2949\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.0883 - val_loss: 11.3146\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0132 - val_loss: 11.5360\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0137 - val_loss: 10.9711\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8944 - val_loss: 11.2341\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.9689 - val_loss: 11.2583\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.8173 - val_loss: 11.2494\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.7138 - val_loss: 10.7804\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.6023 - val_loss: 11.0256\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.4941 - val_loss: 10.7805\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.6229 - val_loss: 10.7001\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.5088 - val_loss: 10.8592\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.4203 - val_loss: 10.4757\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3609 - val_loss: 10.5957\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3601 - val_loss: 10.9593\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3732 - val_loss: 10.3647\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.2071 - val_loss: 10.5116\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.2340 - val_loss: 10.3565\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1559 - val_loss: 10.3551\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1815 - val_loss: 10.5343\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1205 - val_loss: 10.5100\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1122 - val_loss: 10.2273\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0146 - val_loss: 10.4271\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.9856 - val_loss: 10.2350\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0721 - val_loss: 10.1847\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 9.8800 - val_loss: 10.0922\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 9.9274 - val_loss: 10.1853\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 9.9103 - val_loss: 10.1006\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 9.8719 - val_loss: 10.5120\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 9.8401 - val_loss: 10.1792\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 9.7981 - val_loss: 9.9540\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 9.8027 - val_loss: 10.0774\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.7061 - val_loss: 9.8926\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.6974 - val_loss: 9.8719\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 9.7105 - val_loss: 10.2986\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.7127 - val_loss: 10.0697\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.6337 - val_loss: 10.0095\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 9.5960 - val_loss: 10.1034\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.5945 - val_loss: 10.0690\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 38.7487 - val_loss: 24.9853\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 22.4042 - val_loss: 20.5196\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 18.9950 - val_loss: 18.3142\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 17.3895 - val_loss: 16.7794\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 16.3223 - val_loss: 15.6196\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.4453 - val_loss: 16.4505\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 458us/step - loss: 15.0598 - val_loss: 14.7262\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 14.5491 - val_loss: 14.5943\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.1785 - val_loss: 14.0863\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 13.7986 - val_loss: 14.4092\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.5749 - val_loss: 13.4835\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.3751 - val_loss: 13.9080\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.2744 - val_loss: 12.9090\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9360 - val_loss: 12.6963\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.6351 - val_loss: 13.7945\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7284 - val_loss: 12.6761\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3622 - val_loss: 12.5097\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3426 - val_loss: 12.2875\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1618 - val_loss: 11.9900\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1517 - val_loss: 11.9751\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.9149 - val_loss: 11.8220\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8857 - val_loss: 12.1666\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.6636 - val_loss: 11.7156\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.5240 - val_loss: 11.8077\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6097 - val_loss: 11.4756\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4938 - val_loss: 11.7271\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.3230 - val_loss: 11.9746\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 11.2421 - val_loss: 11.1836\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.2167 - val_loss: 12.5475\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.1956 - val_loss: 11.1042\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.1669 - val_loss: 11.1179\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 11.1226 - val_loss: 10.9850\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.0228 - val_loss: 10.8491\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 10.8720 - val_loss: 11.0964\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.8535 - val_loss: 12.2172\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.7849 - val_loss: 11.0829\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.8708 - val_loss: 11.2472\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.7249 - val_loss: 10.8002\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.7421 - val_loss: 10.7748\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.5527 - val_loss: 10.7877\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.6691 - val_loss: 10.8143\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.6148 - val_loss: 10.9394\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5835 - val_loss: 10.9749\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.6918 - val_loss: 10.3429\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3772 - val_loss: 10.8054\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.3880 - val_loss: 10.4764\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.3809 - val_loss: 10.5267\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4211 - val_loss: 10.3673\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.2463 - val_loss: 10.3041\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3448 - val_loss: 10.5884\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.1787 - val_loss: 10.2689\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.2782 - val_loss: 10.4190\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.1565 - val_loss: 10.2299\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1467 - val_loss: 10.3963\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1514 - val_loss: 10.3779\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.1150 - val_loss: 10.5832\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.9913 - val_loss: 10.5530\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.1075 - val_loss: 10.0960\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.0272 - val_loss: 10.1499\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.9492 - val_loss: 9.9970\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.9808 - val_loss: 10.1047\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.9329 - val_loss: 10.1431\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.9164 - val_loss: 10.0427\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.8461 - val_loss: 10.0244\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.9426 - val_loss: 11.6886\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 37.0027 - val_loss: 29.5824\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 28.0242 - val_loss: 27.3659\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 25.4027 - val_loss: 23.8840\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 23.5009 - val_loss: 24.4861\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 22.7583 - val_loss: 22.3451\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 21.6629 - val_loss: 22.9703\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 20.8602 - val_loss: 20.6339\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 20.4588 - val_loss: 19.9350\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.7733 - val_loss: 19.6022\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.7507 - val_loss: 19.3634\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.1074 - val_loss: 19.5202\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.7297 - val_loss: 17.9729\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.4008 - val_loss: 17.8881\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.0775 - val_loss: 17.4492\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.7636 - val_loss: 17.4218\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.5327 - val_loss: 17.4957\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.2423 - val_loss: 17.3390\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.1993 - val_loss: 18.4832\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 384us/step - loss: 16.9941 - val_loss: 16.6291\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 16.9133 - val_loss: 18.4843\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 16.6344 - val_loss: 16.2475\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 16.3898 - val_loss: 16.1417\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 16.1861 - val_loss: 15.9009\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 16.1351 - val_loss: 16.3635\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 16.0655 - val_loss: 16.1214\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 560us/step - loss: 15.8110 - val_loss: 15.8938\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.9777 - val_loss: 15.5031\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 15.6929 - val_loss: 17.2133\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 3s 654us/step - loss: 15.4981 - val_loss: 16.0112\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 3s 656us/step - loss: 15.4681 - val_loss: 15.3836\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 3s 637us/step - loss: 15.4167 - val_loss: 17.2289\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.3754 - val_loss: 15.1820\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.1485 - val_loss: 15.7478\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.1486 - val_loss: 14.8682\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.1593 - val_loss: 14.8778\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.8817 - val_loss: 15.0140\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.9301 - val_loss: 14.8347\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8388 - val_loss: 14.7823\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.8016 - val_loss: 14.7934\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.7230 - val_loss: 14.5258\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.6197 - val_loss: 15.0847\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.6324 - val_loss: 16.0390\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4903 - val_loss: 15.0659\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.5848 - val_loss: 15.0409\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.5143 - val_loss: 14.3114\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.3958 - val_loss: 14.5191\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.2816 - val_loss: 14.4482\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2868 - val_loss: 14.6054\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2782 - val_loss: 14.2072\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.1237 - val_loss: 14.2894\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.2517 - val_loss: 14.3366\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.1826 - val_loss: 14.0877\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.0631 - val_loss: 14.1459\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.0763 - val_loss: 14.0622\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.9965 - val_loss: 14.2351\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.0369 - val_loss: 13.9846\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8928 - val_loss: 14.1906\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.9765 - val_loss: 14.3602\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.8793 - val_loss: 14.2908\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.8074 - val_loss: 14.0350\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.8221 - val_loss: 13.9908\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 564us/step - loss: 36.2260 - val_loss: 27.0104\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 23.2495 - val_loss: 21.0984\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 20.6009 - val_loss: 20.3257\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 18.8661 - val_loss: 18.5731\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 17.8741 - val_loss: 17.1958\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 17.3626 - val_loss: 19.0953\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 16.5384 - val_loss: 16.5634\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 16.1611 - val_loss: 15.9521\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 15.8175 - val_loss: 15.7235\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.3957 - val_loss: 15.0610\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 15.2635 - val_loss: 14.9696\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 15.2069 - val_loss: 16.2859\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.9007 - val_loss: 14.9263\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 14.6407 - val_loss: 14.3976\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.4860 - val_loss: 15.1787\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.2670 - val_loss: 14.0710\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.2156 - val_loss: 14.5835\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.9725 - val_loss: 14.8411\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.9469 - val_loss: 13.9130\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.7714 - val_loss: 14.8024\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 13.4843 - val_loss: 13.4477\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.5159 - val_loss: 14.1821\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 13.2719 - val_loss: 13.1176\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.3372 - val_loss: 13.1589\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.2445 - val_loss: 12.9682\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.1545 - val_loss: 12.9774\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 12.8977 - val_loss: 13.0608\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 12.8551 - val_loss: 12.7259\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.7727 - val_loss: 13.1339\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.7563 - val_loss: 12.7366\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.6937 - val_loss: 12.3434\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.4701 - val_loss: 13.1464\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4043 - val_loss: 12.3936\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.3505 - val_loss: 12.5723\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.2267 - val_loss: 12.0968\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.1256 - val_loss: 12.2308\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.0783 - val_loss: 12.2136\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.0550 - val_loss: 11.9018\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1718 - val_loss: 12.6707\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.0343 - val_loss: 11.8813\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.9111 - val_loss: 12.3545\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.7746 - val_loss: 11.5409\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.7322 - val_loss: 11.8499\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.7019 - val_loss: 11.7902\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7025 - val_loss: 11.7880\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.5566 - val_loss: 12.2099\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.5869 - val_loss: 11.6987\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 39.6031 - val_loss: 28.2135\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 26.6329 - val_loss: 24.7210\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 22.9241 - val_loss: 20.7490\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 20.4657 - val_loss: 19.2007\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 18.9704 - val_loss: 21.5131\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 18.0614 - val_loss: 17.1491\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 17.2999 - val_loss: 17.1533\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 16.6130 - val_loss: 15.5557\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 16.0790 - val_loss: 15.3619\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 15.7252 - val_loss: 15.0462\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 15.3942 - val_loss: 14.9339\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.1178 - val_loss: 15.0886\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.8195 - val_loss: 14.1109\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2222 - val_loss: 14.8005\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.0974 - val_loss: 15.5906\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.9508 - val_loss: 15.4152\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.7396 - val_loss: 13.1516\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.5818 - val_loss: 13.0921\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.3626 - val_loss: 12.8904\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.1808 - val_loss: 13.1485\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.0657 - val_loss: 12.6305\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.0563 - val_loss: 12.9951\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8145 - val_loss: 13.1426\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.6318 - val_loss: 12.5618\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.4965 - val_loss: 12.3207\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.4393 - val_loss: 12.2149\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2966 - val_loss: 11.9939\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.3807 - val_loss: 11.9237\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.0297 - val_loss: 11.8480\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.0229 - val_loss: 12.0532\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.9415 - val_loss: 12.1660\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.9106 - val_loss: 12.0066\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.7404 - val_loss: 11.5480\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.7009 - val_loss: 11.3991\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5816 - val_loss: 11.4475\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5360 - val_loss: 11.2573\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.4677 - val_loss: 11.5969\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4544 - val_loss: 11.2468\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3536 - val_loss: 11.2081\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.3179 - val_loss: 10.9941\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5176 - val_loss: 10.9349\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0442 - val_loss: 11.0007\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.0139 - val_loss: 11.0321\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0579 - val_loss: 11.1656\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0981 - val_loss: 11.7337\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.0122 - val_loss: 11.1636\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 36.6468 - val_loss: 27.4224\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 23.1695 - val_loss: 22.7717\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 20.0134 - val_loss: 18.9656\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 18.6873 - val_loss: 21.8101\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 17.8607 - val_loss: 17.1953\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 17.0432 - val_loss: 16.7950\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 16.6670 - val_loss: 16.6456\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.0554 - val_loss: 15.7328\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7916 - val_loss: 15.4879\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.3127 - val_loss: 15.7179\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.1641 - val_loss: 15.2795\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.8884 - val_loss: 15.4306\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.5860 - val_loss: 14.9763\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.3148 - val_loss: 14.3815\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.3324 - val_loss: 14.2428\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.8914 - val_loss: 14.6514\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8130 - val_loss: 13.9503\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.7261 - val_loss: 14.1990\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3881 - val_loss: 14.0297\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2248 - val_loss: 13.3458\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.0802 - val_loss: 13.2090\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.9569 - val_loss: 13.5217\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.7714 - val_loss: 12.9504\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.6540 - val_loss: 13.1645\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.5222 - val_loss: 12.4426\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.5018 - val_loss: 12.3781\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.4367 - val_loss: 12.4787\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2567 - val_loss: 12.4687\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.0907 - val_loss: 12.6698\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1136 - val_loss: 12.3969\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1503 - val_loss: 12.2203\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8715 - val_loss: 11.8908\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7859 - val_loss: 12.8804\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8209 - val_loss: 11.7381\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6935 - val_loss: 11.8731\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6124 - val_loss: 11.5324\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4568 - val_loss: 11.6151\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6569 - val_loss: 12.4498\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5126 - val_loss: 11.5692\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.3914 - val_loss: 11.9006\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3113 - val_loss: 11.4087\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3595 - val_loss: 11.6692\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1613 - val_loss: 11.9936\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.1986 - val_loss: 11.6048\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3129 - val_loss: 11.6096\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.9967 - val_loss: 11.3971\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.9869 - val_loss: 11.0736\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9561 - val_loss: 10.8827\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.9388 - val_loss: 11.2101\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.8632 - val_loss: 10.9244\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.7812 - val_loss: 10.9642\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.7904 - val_loss: 10.8453\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8711 - val_loss: 10.9002\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.7550 - val_loss: 10.6455\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.6386 - val_loss: 10.9121\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6567 - val_loss: 11.3283\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5511 - val_loss: 10.8567\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5498 - val_loss: 10.7136\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5056 - val_loss: 10.9532\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 568us/step - loss: 37.9140 - val_loss: 31.2968\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 26.4941 - val_loss: 25.6295\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 23.2111 - val_loss: 22.4309\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 20.9808 - val_loss: 19.5076\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 19.4981 - val_loss: 18.5787\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 574us/step - loss: 18.3083 - val_loss: 17.9267\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.5781 - val_loss: 17.4181\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.9017 - val_loss: 17.3895\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.9556 - val_loss: 16.0882\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.1378 - val_loss: 17.6120\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.7393 - val_loss: 15.2406\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 15.4104 - val_loss: 15.2750\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.9501 - val_loss: 14.9136\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8078 - val_loss: 14.3486\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.5372 - val_loss: 13.9833\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.3370 - val_loss: 13.9240\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.1978 - val_loss: 14.4048\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.9964 - val_loss: 13.6069\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.6542 - val_loss: 13.2768\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.4690 - val_loss: 14.2746\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.5878 - val_loss: 13.5850\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.0202 - val_loss: 13.2087\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.0384 - val_loss: 13.3059\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9063 - val_loss: 12.4975\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.7254 - val_loss: 12.7000\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.5618 - val_loss: 12.6690\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.4066 - val_loss: 12.7326\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.3173 - val_loss: 12.4179\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.4367 - val_loss: 12.0582\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1465 - val_loss: 11.8600\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.9947 - val_loss: 12.0139\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.9615 - val_loss: 13.0930\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9579 - val_loss: 12.5587\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.7902 - val_loss: 11.7572\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.7605 - val_loss: 12.1972\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.6350 - val_loss: 11.8289\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5622 - val_loss: 11.5863\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.6211 - val_loss: 11.6916\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.4812 - val_loss: 11.3912\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3476 - val_loss: 11.4111\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4168 - val_loss: 11.4584\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.2003 - val_loss: 11.2833\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.1836 - val_loss: 11.5123\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1446 - val_loss: 11.5968\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.1641 - val_loss: 11.1405\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 11.0514 - val_loss: 11.5975\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 11.1526 - val_loss: 11.4805\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.9770 - val_loss: 11.5161\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.9567 - val_loss: 10.9254\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.8813 - val_loss: 11.4989\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.8280 - val_loss: 11.4100\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.7683 - val_loss: 10.9072\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8559 - val_loss: 10.9306\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5973 - val_loss: 10.7762\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6682 - val_loss: 10.8020\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7825 - val_loss: 10.9024\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.7645 - val_loss: 10.5859\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5071 - val_loss: 10.7411\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.4630 - val_loss: 10.9515\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.4578 - val_loss: 10.6956\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3720 - val_loss: 10.4949\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4666 - val_loss: 10.7061\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3666 - val_loss: 10.3313\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3037 - val_loss: 10.3251\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.2599 - val_loss: 10.6539\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.2433 - val_loss: 10.8863\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.2247 - val_loss: 10.2843\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.2805 - val_loss: 10.3177\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1317 - val_loss: 10.2600\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1468 - val_loss: 10.2838\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.0738 - val_loss: 10.1997\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0802 - val_loss: 10.4249\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0005 - val_loss: 10.4095\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1156 - val_loss: 11.6939\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9780 - val_loss: 10.2473\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9720 - val_loss: 10.2353\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 39.5388 - val_loss: 29.8466\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 26.1606 - val_loss: 23.9003\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 22.8749 - val_loss: 22.2521\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 21.2155 - val_loss: 20.2790\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.0515 - val_loss: 21.4340\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.3870 - val_loss: 18.8192\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.7087 - val_loss: 18.4421\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.9948 - val_loss: 17.5622\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.7542 - val_loss: 17.4018\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.4951 - val_loss: 17.7429\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.1209 - val_loss: 17.2356\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.7241 - val_loss: 16.6366\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.5599 - val_loss: 17.1292\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.2756 - val_loss: 17.5004\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.2631 - val_loss: 15.9333\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.7959 - val_loss: 15.7304\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.8259 - val_loss: 15.7071\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.6161 - val_loss: 16.1009\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.1866 - val_loss: 15.1340\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.0863 - val_loss: 15.1462\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.2137 - val_loss: 14.8256\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7959 - val_loss: 14.7220\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 577us/step - loss: 14.5782 - val_loss: 14.6021\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.5664 - val_loss: 14.9130\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 406us/step - loss: 14.4562 - val_loss: 14.5347\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 1s 329us/step - loss: 14.3740 - val_loss: 14.9304\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.1803 - val_loss: 14.7038\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 485us/step - loss: 14.1824 - val_loss: 14.2033\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 13.9244 - val_loss: 14.8065\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 14.0518 - val_loss: 13.9603\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 13.7856 - val_loss: 13.8541\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 13.6629 - val_loss: 13.7982\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 13.5815 - val_loss: 13.6022\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.4400 - val_loss: 13.7144\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.4827 - val_loss: 13.7715\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.3930 - val_loss: 13.4445\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.4211 - val_loss: 13.7726\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.1617 - val_loss: 13.4030\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.2111 - val_loss: 13.9076\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1364 - val_loss: 13.8569\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.0275 - val_loss: 13.4487\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 12.9194 - val_loss: 13.0191\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.9301 - val_loss: 13.4768\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8415 - val_loss: 13.1014\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8377 - val_loss: 13.1059\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.7464 - val_loss: 13.0005\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7951 - val_loss: 13.0462\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.6802 - val_loss: 14.5528\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.6462 - val_loss: 12.7010\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8431 - val_loss: 13.8966\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.5186 - val_loss: 13.1428\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.5065 - val_loss: 13.1307\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.4290 - val_loss: 12.7895\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.3858 - val_loss: 12.8648\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 35.4017 - val_loss: 28.5648\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 25.5363 - val_loss: 25.2657\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 22.4091 - val_loss: 22.2829\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 20.5161 - val_loss: 21.4503\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 19.4639 - val_loss: 18.5323\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.3647 - val_loss: 17.6008\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.5524 - val_loss: 17.0881\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.1822 - val_loss: 16.7036\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.7164 - val_loss: 16.8423\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 16.1299 - val_loss: 18.4769\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.7586 - val_loss: 15.9793\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.3897 - val_loss: 15.2961\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.2092 - val_loss: 15.9488\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8311 - val_loss: 14.6569\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.4969 - val_loss: 14.1887\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 14.2745 - val_loss: 13.9995\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.1010 - val_loss: 15.4975\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.8677 - val_loss: 13.9448\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.6430 - val_loss: 13.3532\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 13.4586 - val_loss: 13.1686\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 13.2216 - val_loss: 13.8712\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.1055 - val_loss: 13.0127\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.1025 - val_loss: 13.0322\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.9080 - val_loss: 13.4402\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.5327 - val_loss: 12.4981\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6631 - val_loss: 12.2579\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.3644 - val_loss: 12.0157\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.3704 - val_loss: 12.8439\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.2108 - val_loss: 12.2774\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.1586 - val_loss: 11.8307\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.0763 - val_loss: 12.0875\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.9254 - val_loss: 12.1286\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9481 - val_loss: 11.6417\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.7978 - val_loss: 12.6694\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6735 - val_loss: 11.6644\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5117 - val_loss: 11.3828\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4384 - val_loss: 11.7678\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3937 - val_loss: 11.5366\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.4172 - val_loss: 11.3586\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2300 - val_loss: 12.2614\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1505 - val_loss: 11.0605\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.1322 - val_loss: 11.8865\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.9529 - val_loss: 11.6437\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.9699 - val_loss: 11.1588\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.8973 - val_loss: 10.8152\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.9223 - val_loss: 11.0061\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7855 - val_loss: 11.4042\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.7256 - val_loss: 10.8085\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6546 - val_loss: 11.2748\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.5997 - val_loss: 11.1045\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.6152 - val_loss: 11.4581\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.5775 - val_loss: 10.4717\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5277 - val_loss: 10.8296\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5426 - val_loss: 10.7122\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5518 - val_loss: 10.6437\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5168 - val_loss: 10.9461\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.3519 - val_loss: 10.5967\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 41.1752 - val_loss: 28.7571\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 27.3334 - val_loss: 26.6045\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 25.0590 - val_loss: 23.7017\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 23.6521 - val_loss: 22.6688\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 22.7000 - val_loss: 22.5036\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 21.8207 - val_loss: 21.4155\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.6933 - val_loss: 21.5589\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 20.9450 - val_loss: 20.6058\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 20.2701 - val_loss: 19.7698\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 19.7043 - val_loss: 19.6980\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.1713 - val_loss: 18.5638\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.7112 - val_loss: 18.5779\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.3393 - val_loss: 17.9273\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 18.0929 - val_loss: 21.8720\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.8319 - val_loss: 17.5859\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 17.4320 - val_loss: 18.8002\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 17.0487 - val_loss: 17.2948\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 16.8847 - val_loss: 16.9372\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 16.5156 - val_loss: 16.4041\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 16.4509 - val_loss: 16.2723\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 16.0167 - val_loss: 16.1985\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.9323 - val_loss: 15.7273\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.6980 - val_loss: 15.4905\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7064 - val_loss: 15.1863\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.4577 - val_loss: 15.4045\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.1453 - val_loss: 16.2932\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.3523 - val_loss: 14.8671\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.9270 - val_loss: 16.8892\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 15.1009 - val_loss: 15.0804\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.7493 - val_loss: 15.3229\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.7856 - val_loss: 14.6331\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.5154 - val_loss: 14.3780\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.3880 - val_loss: 14.5287\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.3868 - val_loss: 14.2639\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.3560 - val_loss: 14.2436\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.1423 - val_loss: 14.8861\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.1607 - val_loss: 14.1779\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 14.3375 - val_loss: 14.6397\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.8650 - val_loss: 15.0115\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.0247 - val_loss: 13.7227\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.7441 - val_loss: 13.5897\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.7547 - val_loss: 14.5710\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.6944 - val_loss: 13.6661\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.6311 - val_loss: 13.5307\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.5165 - val_loss: 13.9021\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.6181 - val_loss: 13.8932\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4661 - val_loss: 14.0897\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.5130 - val_loss: 14.0882\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.4301 - val_loss: 15.1562\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 567us/step - loss: 40.6630 - val_loss: 30.6748\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 28.5159 - val_loss: 25.2185\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 23.8077 - val_loss: 21.6973\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.6076 - val_loss: 20.3029\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 19.8161 - val_loss: 18.7668\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.0919 - val_loss: 18.3339\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.0145 - val_loss: 17.5132\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 17.5045 - val_loss: 17.2614\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 16.9246 - val_loss: 16.5769\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 16.6062 - val_loss: 16.0723\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 16.1557 - val_loss: 15.5925\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 15.7172 - val_loss: 15.5954\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 15.5900 - val_loss: 16.6408\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 15.3936 - val_loss: 14.9696\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8032 - val_loss: 15.3255\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.8203 - val_loss: 14.4046\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.7052 - val_loss: 14.5384\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3169 - val_loss: 14.0183\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.0502 - val_loss: 14.0901\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.0847 - val_loss: 15.8096\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.0213 - val_loss: 14.5333\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.7367 - val_loss: 14.0559\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.6038 - val_loss: 13.4386\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.4505 - val_loss: 14.1178\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.4582 - val_loss: 13.4777\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.2705 - val_loss: 13.0715\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.1841 - val_loss: 13.0890\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.0783 - val_loss: 13.6219\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8311 - val_loss: 12.9420\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.9684 - val_loss: 13.5012\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7543 - val_loss: 12.9182\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.6601 - val_loss: 13.0304\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7081 - val_loss: 13.2282\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.5780 - val_loss: 12.8671\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.5536 - val_loss: 12.5373\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4744 - val_loss: 12.6079\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4664 - val_loss: 13.0837\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2565 - val_loss: 12.5940\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.2987 - val_loss: 12.8125\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1932 - val_loss: 12.1840\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.0613 - val_loss: 12.1112\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0038 - val_loss: 12.3744\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.0538 - val_loss: 12.1688\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.9591 - val_loss: 12.1732\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.9301 - val_loss: 12.0198\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.0017 - val_loss: 11.9681\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9930 - val_loss: 11.9490\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7022 - val_loss: 12.0167\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7235 - val_loss: 12.0546\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6503 - val_loss: 12.0122\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6100 - val_loss: 11.6176\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5390 - val_loss: 11.6429\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5089 - val_loss: 11.9737\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.5015 - val_loss: 11.8841\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.6264 - val_loss: 11.7957\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.5972 - val_loss: 11.4297\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.2677 - val_loss: 11.5713\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2799 - val_loss: 11.5975\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.3222 - val_loss: 11.5941\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2683 - val_loss: 11.4179\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1699 - val_loss: 11.6070\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1725 - val_loss: 11.4446\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.1821 - val_loss: 11.2757\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.0744 - val_loss: 11.4195\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 11.0655 - val_loss: 11.7879\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.0559 - val_loss: 11.6193\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 377us/step - loss: 11.0366 - val_loss: 11.7480\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 377us/step - loss: 10.9224 - val_loss: 11.3311\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 571us/step - loss: 37.0982 - val_loss: 25.5340\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 23.1633 - val_loss: 21.8011\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 20.1987 - val_loss: 19.7827\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 569us/step - loss: 18.8672 - val_loss: 19.0607\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.7755 - val_loss: 17.0771\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.7671 - val_loss: 16.6366\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.2041 - val_loss: 16.8797\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.4797 - val_loss: 15.7866\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.9026 - val_loss: 14.6344\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.4083 - val_loss: 15.0197\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 14.0778 - val_loss: 14.6183\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.7714 - val_loss: 13.4798\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.4813 - val_loss: 13.2080\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.3671 - val_loss: 13.2315\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.9476 - val_loss: 13.6742\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.8334 - val_loss: 12.5536\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.3959 - val_loss: 12.2036\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.3566 - val_loss: 12.0242\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.1860 - val_loss: 13.2785\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.0933 - val_loss: 12.4625\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.8689 - val_loss: 12.1735\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.8950 - val_loss: 11.8246\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.7652 - val_loss: 11.5581\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.4982 - val_loss: 11.5857\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6397 - val_loss: 11.3438\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.5355 - val_loss: 11.4315\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3070 - val_loss: 11.3229\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2160 - val_loss: 11.3487\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.2612 - val_loss: 11.2270\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1456 - val_loss: 11.3405\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0345 - val_loss: 10.9809\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0882 - val_loss: 11.1668\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.9690 - val_loss: 10.7383\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7997 - val_loss: 10.9803\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9089 - val_loss: 10.8291\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6465 - val_loss: 10.5736\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6500 - val_loss: 10.5235\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6946 - val_loss: 10.5955\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.5793 - val_loss: 10.7898\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5351 - val_loss: 10.7975\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5256 - val_loss: 10.4322\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.4980 - val_loss: 10.3716\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.4202 - val_loss: 10.4546\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.3480 - val_loss: 10.4550\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.3963 - val_loss: 10.8713\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.3627 - val_loss: 10.1580\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.3428 - val_loss: 10.7809\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.1040 - val_loss: 10.1347\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.1402 - val_loss: 10.5826\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0447 - val_loss: 10.0464\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1058 - val_loss: 10.3039\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.9968 - val_loss: 9.9529\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0626 - val_loss: 10.2881\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9969 - val_loss: 9.9799\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9951 - val_loss: 10.2810\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9194 - val_loss: 10.5330\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 9.9275 - val_loss: 9.9931\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 37.0365 - val_loss: 31.1256\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 27.8595 - val_loss: 27.8769\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 25.3000 - val_loss: 24.0454\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 23.6283 - val_loss: 22.6118\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 22.6001 - val_loss: 21.8835\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 21.6369 - val_loss: 21.3575\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 20.9490 - val_loss: 20.7106\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.3965 - val_loss: 19.8591\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.8865 - val_loss: 19.3587\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.6012 - val_loss: 19.0902\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.8726 - val_loss: 19.2173\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.4934 - val_loss: 18.1601\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.2064 - val_loss: 18.4702\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.7941 - val_loss: 17.3558\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.5174 - val_loss: 18.2653\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.3414 - val_loss: 16.8382\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.0613 - val_loss: 16.9356\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.7589 - val_loss: 16.6453\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.6752 - val_loss: 16.1841\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.3296 - val_loss: 16.1047\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.2721 - val_loss: 16.0946\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.2531 - val_loss: 16.4540\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.0699 - val_loss: 16.2445\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.8464 - val_loss: 15.7008\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.7655 - val_loss: 15.9324\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.6685 - val_loss: 16.0568\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.6824 - val_loss: 15.7113\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.4768 - val_loss: 16.4381\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.4258 - val_loss: 15.3804\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.4947 - val_loss: 15.4267\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.2680 - val_loss: 15.0639\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.2459 - val_loss: 15.3660\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.1665 - val_loss: 15.2842\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.0716 - val_loss: 15.0509\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.9807 - val_loss: 14.9893\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.9576 - val_loss: 15.1956\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.8827 - val_loss: 14.7491\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.8452 - val_loss: 14.9461\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.7711 - val_loss: 14.9125\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.7543 - val_loss: 14.6909\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.8503 - val_loss: 14.7226\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.6298 - val_loss: 14.8426\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 464us/step - loss: 14.5587 - val_loss: 14.7404\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 14.5697 - val_loss: 14.5883\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 14.5659 - val_loss: 14.7846\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 14.4380 - val_loss: 14.4855\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 14.4419 - val_loss: 14.4334\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 14.4379 - val_loss: 15.1377\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 568us/step - loss: 14.4075 - val_loss: 14.5926\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3545 - val_loss: 14.8027\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.3437 - val_loss: 14.6443\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 14.3190 - val_loss: 14.5471\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 35.1584 - val_loss: 26.1304\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 24.0964 - val_loss: 21.9163\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.3202 - val_loss: 21.0103\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 20.0415 - val_loss: 21.2441\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.3391 - val_loss: 18.6360\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 18.3818 - val_loss: 19.2109\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 17.7959 - val_loss: 17.1955\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 17.2524 - val_loss: 16.5479\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 16.6493 - val_loss: 16.3587\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 16.4277 - val_loss: 16.0735\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 15.8840 - val_loss: 15.7404\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.4516 - val_loss: 14.9611\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.3122 - val_loss: 14.9005\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.7298 - val_loss: 14.6746\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.8888 - val_loss: 14.4668\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.3978 - val_loss: 15.0566\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.4390 - val_loss: 14.2922\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.0922 - val_loss: 14.0601\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.1297 - val_loss: 13.9264\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8615 - val_loss: 13.6368\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.6767 - val_loss: 13.7557\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4641 - val_loss: 13.2314\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.6156 - val_loss: 13.7145\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.3614 - val_loss: 13.1797\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3421 - val_loss: 13.8349\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.2125 - val_loss: 13.6563\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.1951 - val_loss: 12.8943\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.9294 - val_loss: 12.8833\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.9331 - val_loss: 12.6022\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.7464 - val_loss: 12.4679\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.6761 - val_loss: 12.4283\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7258 - val_loss: 13.3595\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.6414 - val_loss: 15.1139\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 12.4743 - val_loss: 12.3740\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 12.4623 - val_loss: 12.3791\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.3149 - val_loss: 12.3332\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 12.3125 - val_loss: 12.1814\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 12.3173 - val_loss: 12.4700\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.2140 - val_loss: 11.9847\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.2815 - val_loss: 12.0954\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0550 - val_loss: 12.1818\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0877 - val_loss: 11.8401\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0295 - val_loss: 11.9714\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9837 - val_loss: 12.1592\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.9497 - val_loss: 11.9706\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.0173 - val_loss: 11.9501\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8386 - val_loss: 12.6685\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 38.3629 - val_loss: 29.2356\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 27.2895 - val_loss: 23.0060\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 22.4240 - val_loss: 21.5385\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 19.8943 - val_loss: 19.1052\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 19.0714 - val_loss: 18.1297\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.3135 - val_loss: 18.3265\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 16.4782 - val_loss: 15.5334\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.7344 - val_loss: 15.1421\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.0606 - val_loss: 14.9976\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.6404 - val_loss: 14.8364\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.1662 - val_loss: 13.8048\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.8269 - val_loss: 14.0316\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.6040 - val_loss: 13.4907\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3214 - val_loss: 13.2986\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.0763 - val_loss: 14.5872\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.7696 - val_loss: 13.2650\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6878 - val_loss: 12.8272\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.5458 - val_loss: 12.5437\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.2793 - val_loss: 12.2400\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 12.2013 - val_loss: 12.0507\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.0453 - val_loss: 13.1862\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8515 - val_loss: 11.8791\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6815 - val_loss: 11.7292\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 11.5587 - val_loss: 11.5236\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 11.5151 - val_loss: 11.3902\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4104 - val_loss: 11.4062\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.2224 - val_loss: 11.4282\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1065 - val_loss: 11.1594\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0792 - val_loss: 11.1252\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.0019 - val_loss: 11.0181\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 11.0401 - val_loss: 11.0042\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.7648 - val_loss: 10.8594\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.7554 - val_loss: 11.0174\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.6857 - val_loss: 10.7699\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.6030 - val_loss: 10.9368\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.5426 - val_loss: 11.1667\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5605 - val_loss: 10.9058\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5184 - val_loss: 10.6663\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.4762 - val_loss: 10.4679\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.3214 - val_loss: 10.5777\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3096 - val_loss: 10.8685\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.3443 - val_loss: 10.4780\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 1s 328us/step - loss: 10.2729 - val_loss: 10.4996\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 420us/step - loss: 10.1547 - val_loss: 10.3593\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 10.1729 - val_loss: 10.8398\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 10.1318 - val_loss: 10.4621\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.0062 - val_loss: 10.2064\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.0844 - val_loss: 10.2508\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 10.0128 - val_loss: 10.3637\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 9.9756 - val_loss: 10.1209\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.9437 - val_loss: 10.2441\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.9445 - val_loss: 9.9675\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.9132 - val_loss: 10.0467\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.8259 - val_loss: 10.0819\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 9.8418 - val_loss: 10.0640\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.8023 - val_loss: 10.0793\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.7239 - val_loss: 10.4080\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 35.3614 - val_loss: 23.6687\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 21.0641 - val_loss: 19.2921\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.1474 - val_loss: 16.6290\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.5976 - val_loss: 15.3955\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.4072 - val_loss: 15.3048\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.6483 - val_loss: 14.1814\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.9665 - val_loss: 14.0764\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.4401 - val_loss: 13.1396\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9604 - val_loss: 14.3147\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.6114 - val_loss: 12.3078\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.4715 - val_loss: 12.6032\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.0645 - val_loss: 11.5546\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.7866 - val_loss: 11.6164\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5316 - val_loss: 11.2268\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6242 - val_loss: 12.6610\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1532 - val_loss: 10.7118\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0160 - val_loss: 12.0208\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7889 - val_loss: 11.7701\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.6814 - val_loss: 10.5382\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7064 - val_loss: 10.4563\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.4596 - val_loss: 10.6278\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3114 - val_loss: 10.2632\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3002 - val_loss: 9.9850\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1867 - val_loss: 11.2205\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 10.0350 - val_loss: 10.0043\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.7532 - val_loss: 9.7274\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.8276 - val_loss: 9.4338\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.8503 - val_loss: 9.3740\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7052 - val_loss: 9.7950\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 9.5605 - val_loss: 10.2389\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 9.8715 - val_loss: 11.1069\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 9.4745 - val_loss: 9.6213\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 9.2733 - val_loss: 9.1300\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 9.4076 - val_loss: 9.1796\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 9.2056 - val_loss: 8.9281\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.2470 - val_loss: 9.0755\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.2014 - val_loss: 9.0522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.2313 - val_loss: 9.0906\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.2335 - val_loss: 8.9750\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.0954 - val_loss: 8.9027\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 8.9381 - val_loss: 9.0058\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 8.9768 - val_loss: 8.6433\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 8.9611 - val_loss: 8.9690\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 8.9376 - val_loss: 9.0417\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 8.7828 - val_loss: 8.5842\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 8.7584 - val_loss: 8.4519\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 8.9767 - val_loss: 8.4339\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 8.7168 - val_loss: 8.8123\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 8.6604 - val_loss: 9.1017\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 8.6637 - val_loss: 8.6169\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 8.6504 - val_loss: 8.6550\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 8.6611 - val_loss: 9.0984\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 38.2436 - val_loss: 28.2191\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 26.1577 - val_loss: 23.3330\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 21.8442 - val_loss: 19.7994\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 19.1054 - val_loss: 18.0780\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.8828 - val_loss: 17.7507\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.8550 - val_loss: 16.8736\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.0289 - val_loss: 18.1381\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.3478 - val_loss: 15.2858\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.8070 - val_loss: 15.4052\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.3895 - val_loss: 13.9165\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.9979 - val_loss: 13.7945\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.6192 - val_loss: 13.3755\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3430 - val_loss: 13.4078\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.0941 - val_loss: 12.9271\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.9312 - val_loss: 13.4113\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.7155 - val_loss: 12.4450\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6363 - val_loss: 12.5027\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.3042 - val_loss: 12.2355\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.2683 - val_loss: 12.0630\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.0347 - val_loss: 12.3066\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.9902 - val_loss: 11.9659\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8199 - val_loss: 11.7317\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8108 - val_loss: 11.5604\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5894 - val_loss: 11.6063\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5970 - val_loss: 12.6372\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.4552 - val_loss: 11.4239\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.3782 - val_loss: 11.6789\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2790 - val_loss: 11.9608\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.1257 - val_loss: 11.1592\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.0353 - val_loss: 11.2089\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.9474 - val_loss: 11.0101\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.8961 - val_loss: 11.7310\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.8631 - val_loss: 12.0097\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.7554 - val_loss: 10.9981\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.6486 - val_loss: 10.6081\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 10.5323 - val_loss: 10.4929\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 10.5410 - val_loss: 10.6524\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.4801 - val_loss: 11.0239\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 10.3969 - val_loss: 10.5292\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 10.2894 - val_loss: 10.5872\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 10.2744 - val_loss: 10.2234\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 10.1762 - val_loss: 10.3294\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.1267 - val_loss: 10.4906\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.1457 - val_loss: 10.1230\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0130 - val_loss: 10.1049\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.9516 - val_loss: 10.0707\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9455 - val_loss: 9.9366\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.0420 - val_loss: 10.0553\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.8638 - val_loss: 10.1713\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.8234 - val_loss: 9.9776\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7832 - val_loss: 9.8985\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.6973 - val_loss: 9.9638\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.6964 - val_loss: 10.0630\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.5994 - val_loss: 10.0050\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.5780 - val_loss: 9.6697\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.5126 - val_loss: 9.8734\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.5420 - val_loss: 9.6475\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.5079 - val_loss: 9.8186\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.5181 - val_loss: 9.7150\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.3961 - val_loss: 9.6515\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.4054 - val_loss: 9.9327\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.3836 - val_loss: 9.8525\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 38.0666 - val_loss: 25.5911\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 24.5960 - val_loss: 25.1971\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 21.9320 - val_loss: 20.8132\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 20.5470 - val_loss: 20.2444\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.1506 - val_loss: 18.2555\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.3917 - val_loss: 17.6001\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.7839 - val_loss: 16.8936\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.9134 - val_loss: 16.7364\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.5597 - val_loss: 15.8614\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.1009 - val_loss: 16.1330\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.8249 - val_loss: 15.4961\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.3337 - val_loss: 16.6116\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.1950 - val_loss: 15.1772\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.9512 - val_loss: 14.5853\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.6168 - val_loss: 14.5870\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 14.4478 - val_loss: 14.0061\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 14.3455 - val_loss: 14.0418\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 14.0497 - val_loss: 14.1596\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 13.9842 - val_loss: 14.7660\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.9077 - val_loss: 14.1392\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 13.6494 - val_loss: 13.3869\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.4824 - val_loss: 14.0561\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.2910 - val_loss: 13.4680\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.2527 - val_loss: 13.0466\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.0521 - val_loss: 12.9283\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9444 - val_loss: 12.9464\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8174 - val_loss: 12.6936\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.8251 - val_loss: 12.5764\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.6357 - val_loss: 12.4913\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.6400 - val_loss: 12.3246\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.5615 - val_loss: 12.2779\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.3738 - val_loss: 12.2363\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1917 - val_loss: 12.0658\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.2883 - val_loss: 11.9523\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.0724 - val_loss: 12.1051\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9745 - val_loss: 12.1921\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8588 - val_loss: 11.8229\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.9564 - val_loss: 11.5683\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8517 - val_loss: 11.7365\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7094 - val_loss: 11.8636\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.7059 - val_loss: 11.8595\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6203 - val_loss: 11.5782\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.6027 - val_loss: 11.6685\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 34.3008 - val_loss: 26.3325\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 22.5561 - val_loss: 20.1158\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 19.4854 - val_loss: 20.1992\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 17.7186 - val_loss: 17.2868\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 16.6238 - val_loss: 16.0979\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 16.0570 - val_loss: 15.4261\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 15.1385 - val_loss: 14.8939\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.8327 - val_loss: 15.4093\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.5768 - val_loss: 14.9844\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 13.7215 - val_loss: 14.0815\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 13.4312 - val_loss: 13.3858\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 13.0245 - val_loss: 13.2681\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 12.8008 - val_loss: 12.6187\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 12.6866 - val_loss: 12.8976\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 12.2658 - val_loss: 12.9740\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 12.1117 - val_loss: 11.9033\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 11.8213 - val_loss: 11.6888\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.7502 - val_loss: 11.9692\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.4742 - val_loss: 11.4329\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 11.3574 - val_loss: 11.2540\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 11.2830 - val_loss: 11.8632\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 11.1583 - val_loss: 10.9113\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.8955 - val_loss: 11.1237\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 10.7049 - val_loss: 10.6748\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 10.6669 - val_loss: 10.7756\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.6044 - val_loss: 10.6782\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 433us/step - loss: 10.5532 - val_loss: 10.5414\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 10.4506 - val_loss: 10.4663\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.3774 - val_loss: 11.1833\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.2629 - val_loss: 10.2519\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.1800 - val_loss: 10.4737\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.0648 - val_loss: 10.1979\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 493us/step - loss: 10.0807 - val_loss: 10.1371\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 571us/step - loss: 9.9684 - val_loss: 10.7778\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 9.9306 - val_loss: 10.1849\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.8688 - val_loss: 10.1372\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 9.8563 - val_loss: 9.9881\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 9.6749 - val_loss: 9.9099\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 9.8734 - val_loss: 9.9400\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.6241 - val_loss: 9.9664\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 9.6176 - val_loss: 10.0657\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 9.5564 - val_loss: 9.8925\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 9.4948 - val_loss: 9.9401\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 9.5087 - val_loss: 9.6099\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 9.4931 - val_loss: 9.5164\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 9.3988 - val_loss: 9.6666\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 9.3811 - val_loss: 9.6721\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 9.2056 - val_loss: 10.0312\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 9.2827 - val_loss: 9.3711\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 9.2440 - val_loss: 9.4903\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.2329 - val_loss: 9.5815\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 9.1929 - val_loss: 9.2655\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 9.1977 - val_loss: 9.4673\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 9.1299 - val_loss: 9.4460\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 9.1589 - val_loss: 9.2777\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 9.0564 - val_loss: 9.1393\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.0341 - val_loss: 9.1955\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 9.0276 - val_loss: 9.2114\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.1380 - val_loss: 9.3062\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 8.9280 - val_loss: 9.0300\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 8.9410 - val_loss: 9.6290\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 8.9591 - val_loss: 9.1676\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 8.9530 - val_loss: 10.3012\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 8.9170 - val_loss: 9.2261\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 8.9302 - val_loss: 9.1859\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 41.2697 - val_loss: 30.9341\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 27.9461 - val_loss: 26.8763\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 25.1009 - val_loss: 23.3835\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 22.8783 - val_loss: 21.9208\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 21.8021 - val_loss: 22.1176\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 20.8997 - val_loss: 20.8330\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 20.0993 - val_loss: 19.7099\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 19.4715 - val_loss: 18.9379\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 18.8882 - val_loss: 19.5711\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 18.5071 - val_loss: 18.0600\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 18.0008 - val_loss: 17.7417\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 17.6613 - val_loss: 18.8948\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 17.3093 - val_loss: 16.5511\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.9736 - val_loss: 16.5996\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.5644 - val_loss: 16.2542\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.3720 - val_loss: 17.2870\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 16.2057 - val_loss: 16.8257\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.9183 - val_loss: 15.5004\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.7247 - val_loss: 15.9590\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 15.4095 - val_loss: 16.5356\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.2929 - val_loss: 15.6696\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 15.2047 - val_loss: 15.1230\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.8401 - val_loss: 15.3050\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.8008 - val_loss: 14.6058\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.6538 - val_loss: 14.6111\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.6135 - val_loss: 14.2482\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.2779 - val_loss: 14.2167\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.3315 - val_loss: 14.2994\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0803 - val_loss: 14.2976\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.9613 - val_loss: 14.0938\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8495 - val_loss: 13.9408\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.7496 - val_loss: 13.9447\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 13.6587 - val_loss: 13.7207\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.6241 - val_loss: 13.8502\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.4664 - val_loss: 13.5718\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.5017 - val_loss: 13.6599\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.2512 - val_loss: 13.8654\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.2177 - val_loss: 13.3916\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.1937 - val_loss: 13.5443\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.1528 - val_loss: 13.0310\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.0205 - val_loss: 13.4501\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.8687 - val_loss: 13.0125\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 476us/step - loss: 12.8980 - val_loss: 13.1376\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.7700 - val_loss: 12.7265\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.7269 - val_loss: 12.9722\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7380 - val_loss: 12.8578\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.5606 - val_loss: 13.0180\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.5559 - val_loss: 12.5865\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.5455 - val_loss: 12.5312\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4660 - val_loss: 12.7047\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.4939 - val_loss: 12.8024\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.3071 - val_loss: 13.5563\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.5114 - val_loss: 12.3616\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.2778 - val_loss: 12.6056\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.2182 - val_loss: 12.4970\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.1246 - val_loss: 12.3800\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.0792 - val_loss: 12.2513\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1029 - val_loss: 12.4797\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.1488 - val_loss: 12.1765\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.9849 - val_loss: 12.2507\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 370us/step - loss: 12.0099 - val_loss: 12.1911\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 409us/step - loss: 12.0247 - val_loss: 12.6236\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 11.8942 - val_loss: 12.1835\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 11.8889 - val_loss: 12.1474\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 11.7897 - val_loss: 12.4922\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 11.8765 - val_loss: 12.0771\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 11.7457 - val_loss: 12.0299\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 570us/step - loss: 11.6933 - val_loss: 12.4404\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6922 - val_loss: 12.0320\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7026 - val_loss: 12.2923\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.6385 - val_loss: 12.0534\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 11.6713 - val_loss: 12.4839\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 40.5023 - val_loss: 30.7914\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 26.6219 - val_loss: 23.2113\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 22.7911 - val_loss: 20.6531\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 20.3500 - val_loss: 20.7092\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 19.1058 - val_loss: 18.1917\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.9027 - val_loss: 17.7696\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.2355 - val_loss: 17.7207\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 16.4343 - val_loss: 16.0266\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.0569 - val_loss: 15.5282\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 15.5914 - val_loss: 15.3155\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.0263 - val_loss: 14.6129\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 14.8040 - val_loss: 14.6158\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.4803 - val_loss: 14.0187\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.2903 - val_loss: 14.5546\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.8828 - val_loss: 14.0206\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.6504 - val_loss: 13.3288\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.5188 - val_loss: 13.4863\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.3175 - val_loss: 13.0770\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.0921 - val_loss: 12.8658\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.8992 - val_loss: 14.9689\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7663 - val_loss: 13.1945\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4797 - val_loss: 12.6119\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.4151 - val_loss: 12.4452\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.2330 - val_loss: 12.3764\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.1922 - val_loss: 12.0404\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.0529 - val_loss: 11.9930\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.9137 - val_loss: 11.9569\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.7660 - val_loss: 12.8566\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.8312 - val_loss: 12.1531\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.5673 - val_loss: 11.5942\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 11.5034 - val_loss: 12.1184\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.6102 - val_loss: 11.4502\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.4139 - val_loss: 11.6378\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 11.2586 - val_loss: 11.2495\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.2145 - val_loss: 11.6067\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 11.2417 - val_loss: 11.3266\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 11.1383 - val_loss: 11.6038\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.0622 - val_loss: 11.2531\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9941 - val_loss: 11.1379\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.9411 - val_loss: 11.0277\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9749 - val_loss: 11.1319\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.8518 - val_loss: 11.0270\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7019 - val_loss: 10.9708\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.8269 - val_loss: 10.8668\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.7612 - val_loss: 11.1700\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7132 - val_loss: 10.7820\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.6082 - val_loss: 10.7217\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5286 - val_loss: 11.2514\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.6184 - val_loss: 10.6985\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4399 - val_loss: 10.6847\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4127 - val_loss: 10.8048\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4494 - val_loss: 10.6383\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4239 - val_loss: 10.8019\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.3612 - val_loss: 10.4604\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.3256 - val_loss: 10.3944\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4000 - val_loss: 10.3905\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2681 - val_loss: 10.3144\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.1890 - val_loss: 10.5707\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.2738 - val_loss: 10.5522\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.1385 - val_loss: 10.4478\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.1597 - val_loss: 10.4462\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2833 - val_loss: 10.6585\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 38.1617 - val_loss: 28.0273\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 23.3710 - val_loss: 21.4803\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 20.7822 - val_loss: 19.3646\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.9921 - val_loss: 17.9908\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.8146 - val_loss: 17.1295\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.1139 - val_loss: 16.2818\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.4931 - val_loss: 15.8374\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.9900 - val_loss: 15.5965\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.4396 - val_loss: 14.9893\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.1044 - val_loss: 15.6346\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.7576 - val_loss: 13.9705\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3004 - val_loss: 14.0869\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.1094 - val_loss: 13.9046\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.9711 - val_loss: 14.0210\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.6330 - val_loss: 13.2847\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.6102 - val_loss: 13.2877\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2344 - val_loss: 13.0954\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1398 - val_loss: 12.8268\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.8422 - val_loss: 12.6228\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.8237 - val_loss: 12.4457\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6861 - val_loss: 12.7124\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.6251 - val_loss: 12.1228\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4647 - val_loss: 12.1014\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2265 - val_loss: 12.5616\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.2298 - val_loss: 12.4589\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 12.1000 - val_loss: 11.8825\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 12.0538 - val_loss: 12.1939\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 11.8904 - val_loss: 11.6902\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 11.7109 - val_loss: 11.9935\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.6508 - val_loss: 11.5110\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 11.4616 - val_loss: 11.6547\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 566us/step - loss: 11.4433 - val_loss: 11.1076\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.4683 - val_loss: 11.2269\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.2635 - val_loss: 11.1653\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3569 - val_loss: 11.1043\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1578 - val_loss: 10.7414\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.0946 - val_loss: 10.9155\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0365 - val_loss: 11.1277\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.0571 - val_loss: 11.1951\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.8655 - val_loss: 10.6113\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.8116 - val_loss: 10.7922\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.7493 - val_loss: 10.6083\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.6402 - val_loss: 10.5401\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6835 - val_loss: 10.4624\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.6463 - val_loss: 10.8369\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.5603 - val_loss: 10.5177\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.5364 - val_loss: 10.2843\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.5864 - val_loss: 10.2593\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.3679 - val_loss: 10.4659\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.8037 - val_loss: 10.5462\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.3055 - val_loss: 10.4071\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.3584 - val_loss: 10.0836\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.2484 - val_loss: 10.4746\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1728 - val_loss: 10.0650\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.1797 - val_loss: 10.1934\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1942 - val_loss: 9.9964\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1888 - val_loss: 10.2189\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0735 - val_loss: 10.0558\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0524 - val_loss: 9.9542\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.0255 - val_loss: 10.0589\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.0279 - val_loss: 9.9894\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9317 - val_loss: 10.7297\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9288 - val_loss: 9.8275\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9530 - val_loss: 9.9782\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.8616 - val_loss: 9.7044\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9479 - val_loss: 10.3541\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.8305 - val_loss: 9.8564\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.7532 - val_loss: 9.6935\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.7084 - val_loss: 9.8015\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.7260 - val_loss: 9.6405\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 9.7291 - val_loss: 10.0660\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 9.7348 - val_loss: 10.0278\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 9.6507 - val_loss: 9.9732\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 9.5834 - val_loss: 9.6855\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 9.5896 - val_loss: 9.5750\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 9.5448 - val_loss: 9.9094\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.5762 - val_loss: 9.6451\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.5684 - val_loss: 9.4908\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.5281 - val_loss: 9.3635\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4809 - val_loss: 10.0401\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.4981 - val_loss: 10.3068\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4040 - val_loss: 9.3875\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.4030 - val_loss: 9.5233\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.4166 - val_loss: 9.7317\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 38.0325 - val_loss: 29.8267\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 27.1838 - val_loss: 24.8655\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 24.4705 - val_loss: 22.9917\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 22.8153 - val_loss: 25.8507\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 21.6794 - val_loss: 21.1990\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 21.0346 - val_loss: 20.3935\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 20.6338 - val_loss: 20.8084\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.6557 - val_loss: 21.2142\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 19.3884 - val_loss: 18.7640\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.8829 - val_loss: 18.7300\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 18.5355 - val_loss: 18.5595\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.4064 - val_loss: 18.5169\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.8043 - val_loss: 17.7355\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 17.7389 - val_loss: 17.4848\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.3609 - val_loss: 19.7599\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.3727 - val_loss: 16.7582\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.7541 - val_loss: 16.4114\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.6269 - val_loss: 16.2211\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.4161 - val_loss: 16.2487\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.3422 - val_loss: 16.6339\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.2151 - val_loss: 18.6082\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.9506 - val_loss: 15.7595\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.8201 - val_loss: 15.8349\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.6077 - val_loss: 16.1074\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.4593 - val_loss: 15.2177\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.5104 - val_loss: 15.2149\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.2143 - val_loss: 15.0055\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.1683 - val_loss: 15.2114\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.0919 - val_loss: 15.1482\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.0945 - val_loss: 14.9363\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.9974 - val_loss: 14.7958\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.7925 - val_loss: 15.0073\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.6529 - val_loss: 15.3748\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.8040 - val_loss: 14.6769\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.5762 - val_loss: 14.6259\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.5549 - val_loss: 14.8320\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.5735 - val_loss: 14.4255\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.3396 - val_loss: 14.2660\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.2727 - val_loss: 14.6405\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3549 - val_loss: 14.1808\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.2039 - val_loss: 14.2787\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.3873 - val_loss: 14.2134\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.1098 - val_loss: 14.1225\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 14.0815 - val_loss: 14.0997\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 14.0015 - val_loss: 14.5643\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 14.0875 - val_loss: 13.8905\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 13.8596 - val_loss: 13.8692\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 13.9234 - val_loss: 14.0236\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 13.9411 - val_loss: 13.9725\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 3s 702us/step - loss: 13.7819 - val_loss: 14.0293\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8187 - val_loss: 13.7526\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.8081 - val_loss: 13.7947\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.7331 - val_loss: 13.7130\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.6295 - val_loss: 14.0571\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.6510 - val_loss: 13.7864\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.6129 - val_loss: 13.7735\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 13.7078 - val_loss: 13.6935\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 13.5097 - val_loss: 13.6095\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.4657 - val_loss: 13.5386\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5565 - val_loss: 13.7363\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.6443 - val_loss: 13.6664\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.4232 - val_loss: 13.6458\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.5110 - val_loss: 13.6349\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.2841 - val_loss: 13.6260\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 37.1508 - val_loss: 25.0561\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 22.5224 - val_loss: 22.6994\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 20.0599 - val_loss: 18.3714\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 18.3099 - val_loss: 17.6961\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 17.5538 - val_loss: 16.8107\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 16.7813 - val_loss: 17.2098\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.5088 - val_loss: 15.6434\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.1182 - val_loss: 15.7937\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 15.5350 - val_loss: 15.0578\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 15.4172 - val_loss: 14.7526\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 15.0193 - val_loss: 14.4451\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.7386 - val_loss: 14.4896\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 14.5598 - val_loss: 15.3800\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 14.5890 - val_loss: 14.7870\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.1694 - val_loss: 13.6630\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 13.8918 - val_loss: 13.5119\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.5961 - val_loss: 13.1552\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 13.4897 - val_loss: 13.9148\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.4020 - val_loss: 13.4525\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 13.3412 - val_loss: 13.0971\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.0458 - val_loss: 12.8131\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 13.0076 - val_loss: 12.8270\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 12.7018 - val_loss: 12.3670\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 12.7315 - val_loss: 12.8284\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 12.4254 - val_loss: 13.0579\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 12.3237 - val_loss: 12.3414\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 12.1596 - val_loss: 11.7585\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 12.0916 - val_loss: 12.2440\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 11.9291 - val_loss: 12.0547\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 11.8849 - val_loss: 11.8633\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.8774 - val_loss: 11.5183\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.6426 - val_loss: 12.0623\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.6170 - val_loss: 12.5695\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 11.5746 - val_loss: 11.2749\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 11.6933 - val_loss: 11.4114\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.3705 - val_loss: 11.3893\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 11.2487 - val_loss: 10.9683\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 11.1967 - val_loss: 11.2377\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 11.2522 - val_loss: 11.0532\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.1348 - val_loss: 10.9516\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 11.0611 - val_loss: 11.1598\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.0935 - val_loss: 11.5762\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.9590 - val_loss: 10.7493\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.0128 - val_loss: 10.7661\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 10.8499 - val_loss: 11.0835\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 10.7881 - val_loss: 10.5988\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.8017 - val_loss: 10.4833\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.7459 - val_loss: 10.4697\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.7727 - val_loss: 10.5970\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 10.6066 - val_loss: 10.8011\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 10.6209 - val_loss: 10.5190\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.5922 - val_loss: 10.5115\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 10.5189 - val_loss: 10.8741\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 38.8890 - val_loss: 28.8377\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 26.1204 - val_loss: 23.8664\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.9228 - val_loss: 20.2507\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 19.7887 - val_loss: 18.6015\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 18.5116 - val_loss: 18.4054\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.7851 - val_loss: 18.1340\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.9886 - val_loss: 18.6194\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.3829 - val_loss: 16.0541\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.9411 - val_loss: 16.3089\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 15.7475 - val_loss: 15.2889\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.0448 - val_loss: 15.9773\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.8481 - val_loss: 14.7164\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.3933 - val_loss: 16.2543\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.5579 - val_loss: 14.3385\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.9115 - val_loss: 13.7842\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.7462 - val_loss: 13.6057\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.5564 - val_loss: 13.3657\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.3179 - val_loss: 14.5036\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.1727 - val_loss: 14.1764\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.0553 - val_loss: 13.4137\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.7702 - val_loss: 12.9687\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.7426 - val_loss: 13.3689\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.5659 - val_loss: 12.9896\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 397us/step - loss: 12.4592 - val_loss: 12.6101\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 413us/step - loss: 12.3192 - val_loss: 12.5434\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 12.3074 - val_loss: 13.3244\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 12.2413 - val_loss: 12.2736\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 12.0808 - val_loss: 12.1003\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 12.0267 - val_loss: 12.2399\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 11.9973 - val_loss: 12.3325\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 11.8695 - val_loss: 11.9190\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.7889 - val_loss: 12.0583\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.7976 - val_loss: 11.7482\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.5701 - val_loss: 11.7630\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 11.5426 - val_loss: 11.5764\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.4975 - val_loss: 11.6389\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6037 - val_loss: 11.6151\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3275 - val_loss: 11.6173\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2720 - val_loss: 11.6363\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.2327 - val_loss: 11.8931\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 35.8159 - val_loss: 23.9494\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 22.7142 - val_loss: 20.5052\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 19.9200 - val_loss: 19.1198\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 18.3647 - val_loss: 17.3368\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.5426 - val_loss: 17.5381\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.7942 - val_loss: 16.0476\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 16.1164 - val_loss: 15.3064\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 15.6103 - val_loss: 15.2367\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.2044 - val_loss: 15.7692\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8137 - val_loss: 14.3480\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7914 - val_loss: 14.9372\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.5611 - val_loss: 14.0452\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.1308 - val_loss: 14.1716\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.2497 - val_loss: 13.5504\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.7367 - val_loss: 13.4454\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.6302 - val_loss: 13.5356\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.4126 - val_loss: 13.8584\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.2966 - val_loss: 13.1081\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.0173 - val_loss: 13.6036\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8299 - val_loss: 14.0542\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1272 - val_loss: 12.4378\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.4926 - val_loss: 12.3906\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3863 - val_loss: 12.3301\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3323 - val_loss: 12.1368\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.3064 - val_loss: 11.8229\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0542 - val_loss: 12.3871\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 11.9323 - val_loss: 12.1618\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.8562 - val_loss: 11.7667\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.7713 - val_loss: 11.5091\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.9472 - val_loss: 12.9695\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.5077 - val_loss: 11.3671\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 11.6880 - val_loss: 11.2289\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.3495 - val_loss: 11.1368\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.4497 - val_loss: 11.2415\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.2264 - val_loss: 11.4979\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3546 - val_loss: 11.2568\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1954 - val_loss: 11.4792\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.2550 - val_loss: 10.9225\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.9948 - val_loss: 10.8701\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.9573 - val_loss: 10.7979\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8930 - val_loss: 12.8224\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.9388 - val_loss: 10.9043\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.0412 - val_loss: 10.5404\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7128 - val_loss: 12.1011\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9281 - val_loss: 10.5133\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6322 - val_loss: 10.4753\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5975 - val_loss: 10.3839\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5756 - val_loss: 10.2695\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4701 - val_loss: 10.4809\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.5311 - val_loss: 10.4508\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5346 - val_loss: 10.2503\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.3547 - val_loss: 10.2404\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.3603 - val_loss: 10.6519\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.3183 - val_loss: 10.1479\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3843 - val_loss: 11.8405\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3689 - val_loss: 10.0939\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.1837 - val_loss: 11.1158\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.2899 - val_loss: 10.4251\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.0386 - val_loss: 10.2528\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.3238 - val_loss: 9.9236\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.9915 - val_loss: 9.9259\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.9858 - val_loss: 10.1334\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.2582 - val_loss: 9.9487\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.8379 - val_loss: 9.7586\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.8806 - val_loss: 10.1074\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.8843 - val_loss: 10.0555\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.8510 - val_loss: 9.7347\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.8003 - val_loss: 9.7966\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.8169 - val_loss: 9.7739\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.8584 - val_loss: 9.7168\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.6720 - val_loss: 9.6618\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.7591 - val_loss: 9.7363\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7035 - val_loss: 9.8954\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.6745 - val_loss: 9.6395\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.5336 - val_loss: 9.6044\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7023 - val_loss: 10.6053\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.5857 - val_loss: 9.5221\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.4670 - val_loss: 10.3133\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.8053 - val_loss: 10.0583\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4983 - val_loss: 9.6420\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.4366 - val_loss: 9.8929\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.4709 - val_loss: 9.4810\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.5145 - val_loss: 9.4768\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.3649 - val_loss: 9.3308\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.4170 - val_loss: 9.5306\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 413us/step - loss: 9.4005 - val_loss: 9.4188\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 9.2680 - val_loss: 9.3775\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 9.3948 - val_loss: 9.7680\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 9.3682 - val_loss: 9.4674\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 637us/step - loss: 38.0920 - val_loss: 30.5591\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 3s 641us/step - loss: 27.6284 - val_loss: 24.6925\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 3s 665us/step - loss: 23.1943 - val_loss: 23.6332\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 3s 652us/step - loss: 20.9574 - val_loss: 21.2232\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 3s 658us/step - loss: 19.6418 - val_loss: 18.7723\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 3s 663us/step - loss: 18.6491 - val_loss: 19.6509\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 17.5472 - val_loss: 17.8157\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 16.9097 - val_loss: 16.6785\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.2620 - val_loss: 17.0487\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.6731 - val_loss: 15.1280\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.1248 - val_loss: 15.0776\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8122 - val_loss: 14.4690\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.3627 - val_loss: 15.9409\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.0639 - val_loss: 15.0530\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.7223 - val_loss: 14.4310\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.5690 - val_loss: 13.2761\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2393 - val_loss: 13.4117\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9735 - val_loss: 12.9585\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8576 - val_loss: 12.9902\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.6422 - val_loss: 12.7338\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.4857 - val_loss: 12.6522\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.5092 - val_loss: 12.2423\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1419 - val_loss: 12.3455\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.1588 - val_loss: 12.1688\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.9699 - val_loss: 12.1101\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8098 - val_loss: 11.9803\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8556 - val_loss: 11.7002\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6402 - val_loss: 11.6126\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5284 - val_loss: 11.5233\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6643 - val_loss: 11.4402\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3837 - val_loss: 11.6192\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2800 - val_loss: 11.6799\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2505 - val_loss: 11.9067\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.1771 - val_loss: 11.3565\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 11.0628 - val_loss: 11.1577\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 11.0134 - val_loss: 11.0689\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.9469 - val_loss: 11.3308\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.9872 - val_loss: 11.0063\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.9143 - val_loss: 11.3290\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.7459 - val_loss: 11.0426\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.6607 - val_loss: 11.0198\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7564 - val_loss: 11.2076\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.6199 - val_loss: 10.7807\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5352 - val_loss: 11.3821\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.4872 - val_loss: 11.1928\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5147 - val_loss: 10.6096\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.6384 - val_loss: 10.6627\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4867 - val_loss: 10.7383\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.3135 - val_loss: 10.6295\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.2966 - val_loss: 10.8253\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3818 - val_loss: 10.4557\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.2428 - val_loss: 10.4529\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.2053 - val_loss: 10.4342\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.1300 - val_loss: 10.4045\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0993 - val_loss: 10.4312\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.2140 - val_loss: 10.7558\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.2292 - val_loss: 10.4110\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0376 - val_loss: 10.2661\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1113 - val_loss: 10.3884\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0890 - val_loss: 10.3580\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9807 - val_loss: 10.3156\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.9090 - val_loss: 10.3273\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 9.9494 - val_loss: 10.3985\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 37.6395 - val_loss: 28.3699\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 26.4000 - val_loss: 24.1588\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 23.3620 - val_loss: 22.9649\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 21.9741 - val_loss: 21.1543\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.7310 - val_loss: 20.8078\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.0915 - val_loss: 19.9307\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.3851 - val_loss: 19.0183\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 18.8796 - val_loss: 18.7955\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.3631 - val_loss: 18.4325\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.0919 - val_loss: 18.3537\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.6294 - val_loss: 17.5244\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.3232 - val_loss: 16.6419\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.9253 - val_loss: 17.4010\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.7904 - val_loss: 16.7182\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.4796 - val_loss: 16.2284\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.2103 - val_loss: 16.6731\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.0536 - val_loss: 15.8834\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.8186 - val_loss: 15.4175\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.5118 - val_loss: 15.1103\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.3194 - val_loss: 15.8756\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.0097 - val_loss: 15.2752\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.8754 - val_loss: 14.5288\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7875 - val_loss: 14.7987\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4916 - val_loss: 14.3542\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.4321 - val_loss: 14.1473\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.2530 - val_loss: 14.3342\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 396us/step - loss: 14.1347 - val_loss: 14.5474\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.0258 - val_loss: 13.8992\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 13.9553 - val_loss: 13.8836\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 13.8813 - val_loss: 13.7139\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 13.8211 - val_loss: 13.9485\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 13.5895 - val_loss: 13.8446\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 13.4684 - val_loss: 13.6696\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 564us/step - loss: 13.7557 - val_loss: 14.4043\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3449 - val_loss: 13.4192\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2707 - val_loss: 13.4475\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.2282 - val_loss: 13.4445\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.2910 - val_loss: 13.1845\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.0720 - val_loss: 13.7463\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.0820 - val_loss: 13.3526\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 13.1043 - val_loss: 13.3676\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.9519 - val_loss: 13.2776\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.8178 - val_loss: 13.0384\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.8516 - val_loss: 12.8094\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.8552 - val_loss: 12.6838\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.6782 - val_loss: 12.7360\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 12.5805 - val_loss: 12.5396\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.5588 - val_loss: 12.6712\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.5922 - val_loss: 13.0309\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.5757 - val_loss: 12.8233\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.4980 - val_loss: 12.7090\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.4143 - val_loss: 12.5070\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.3170 - val_loss: 12.8391\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.3815 - val_loss: 12.2179\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.3328 - val_loss: 12.4423\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.2717 - val_loss: 12.4347\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.2142 - val_loss: 12.2500\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1438 - val_loss: 12.3435\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.1218 - val_loss: 12.3535\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 34.1911 - val_loss: 26.9765\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 24.5986 - val_loss: 22.0539\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 21.0355 - val_loss: 24.2212\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 19.2868 - val_loss: 19.2910\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.0873 - val_loss: 17.5835\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.3879 - val_loss: 16.7516\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.9517 - val_loss: 16.7587\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.3175 - val_loss: 15.7041\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.9217 - val_loss: 15.8671\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.5637 - val_loss: 14.8917\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 15.0313 - val_loss: 15.6108\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.7361 - val_loss: 14.5459\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 14.5679 - val_loss: 14.5907\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 14.2685 - val_loss: 14.1453\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.0791 - val_loss: 13.7335\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.7873 - val_loss: 13.8184\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 13.6068 - val_loss: 13.5776\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.5301 - val_loss: 14.4070\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.1502 - val_loss: 13.0713\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.1767 - val_loss: 13.7008\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.7703 - val_loss: 13.1444\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5818 - val_loss: 12.5928\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6007 - val_loss: 13.0359\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.4095 - val_loss: 14.3312\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.3117 - val_loss: 12.7102\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.0580 - val_loss: 11.9515\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.9513 - val_loss: 13.6412\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0469 - val_loss: 11.9345\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6841 - val_loss: 11.6926\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.7253 - val_loss: 11.8783\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5377 - val_loss: 12.2208\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5352 - val_loss: 12.2002\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6510 - val_loss: 11.7554\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2822 - val_loss: 11.2596\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3167 - val_loss: 11.4626\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3792 - val_loss: 11.3090\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.0405 - val_loss: 10.9537\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.0311 - val_loss: 11.1274\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.0947 - val_loss: 10.8434\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.9434 - val_loss: 11.0369\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9497 - val_loss: 11.2216\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7736 - val_loss: 10.6464\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.7348 - val_loss: 11.6329\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.7280 - val_loss: 10.8556\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6890 - val_loss: 10.5709\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.7120 - val_loss: 10.9429\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5933 - val_loss: 10.7180\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5158 - val_loss: 10.5024\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.4935 - val_loss: 10.9712\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.4652 - val_loss: 10.6046\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3252 - val_loss: 10.7349\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3683 - val_loss: 11.0630\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.4931 - val_loss: 10.9792\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 42.2214 - val_loss: 30.5679\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 27.0907 - val_loss: 25.4727\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 24.3890 - val_loss: 23.6358\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 22.6990 - val_loss: 22.3833\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 21.6545 - val_loss: 20.3561\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 445us/step - loss: 20.3389 - val_loss: 19.4621\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 19.4415 - val_loss: 18.9227\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.8207 - val_loss: 18.0347\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 18.3158 - val_loss: 17.9742\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 17.8851 - val_loss: 17.0997\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.5178 - val_loss: 16.8294\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.0481 - val_loss: 16.6546\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 16.8543 - val_loss: 16.3349\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.6794 - val_loss: 16.6967\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 387us/step - loss: 16.4804 - val_loss: 16.0299\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 16.1500 - val_loss: 15.7004\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 15.9570 - val_loss: 15.3557\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 15.6923 - val_loss: 15.3813\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 15.5987 - val_loss: 14.9650\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 15.2725 - val_loss: 15.1218\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 15.2729 - val_loss: 15.2801\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 15.1833 - val_loss: 14.8249\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.9275 - val_loss: 14.6484\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 14.8101 - val_loss: 15.2157\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.6114 - val_loss: 14.4650\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.5863 - val_loss: 14.2196\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.4491 - val_loss: 14.4050\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.5448 - val_loss: 14.5437\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 416us/step - loss: 14.3299 - val_loss: 14.0464\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 14.0972 - val_loss: 13.9990\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.1182 - val_loss: 14.0245\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.0360 - val_loss: 14.2929\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8269 - val_loss: 13.7183\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.8325 - val_loss: 14.1069\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.8034 - val_loss: 13.4909\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.7319 - val_loss: 14.5080\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5996 - val_loss: 13.4614\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.5738 - val_loss: 13.5243\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.5261 - val_loss: 13.3643\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.4539 - val_loss: 13.3877\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.4662 - val_loss: 13.3057\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3422 - val_loss: 13.5990\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.3381 - val_loss: 13.2562\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2705 - val_loss: 13.9167\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.3115 - val_loss: 13.3887\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.1359 - val_loss: 13.1158\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.1975 - val_loss: 13.3019\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.0557 - val_loss: 13.2351\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.0840 - val_loss: 13.0403\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.9858 - val_loss: 12.9742\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.0430 - val_loss: 12.9168\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.8640 - val_loss: 13.0910\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8122 - val_loss: 12.9543\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.8908 - val_loss: 12.7557\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8890 - val_loss: 13.3833\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7760 - val_loss: 13.1087\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.6922 - val_loss: 12.6368\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.6718 - val_loss: 12.8080\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6777 - val_loss: 12.6225\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5806 - val_loss: 12.8068\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 12.5773 - val_loss: 12.6739\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 12.5837 - val_loss: 12.7626\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.5702 - val_loss: 12.7982\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 12.5460 - val_loss: 12.5619\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 12.5221 - val_loss: 12.6692\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 12.3677 - val_loss: 12.7855\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.4396 - val_loss: 12.6964\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5474 - val_loss: 12.5602\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.3607 - val_loss: 13.0060\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.3346 - val_loss: 12.5884\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 12.3962 - val_loss: 12.3157\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.2251 - val_loss: 12.3543\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.3228 - val_loss: 12.6255\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1971 - val_loss: 12.2839\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.2115 - val_loss: 12.1757\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.1534 - val_loss: 12.2851\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.2159 - val_loss: 12.5957\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1166 - val_loss: 12.2043\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0288 - val_loss: 12.3357\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.0927 - val_loss: 12.9462\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 535us/step - loss: 41.5516 - val_loss: 30.9479\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 26.8162 - val_loss: 27.9746\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 23.4221 - val_loss: 21.8224\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.4769 - val_loss: 20.6700\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 20.1074 - val_loss: 20.5586\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.9638 - val_loss: 19.4665\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 18.0203 - val_loss: 17.4609\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.4136 - val_loss: 18.5556\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.8581 - val_loss: 16.3158\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.2737 - val_loss: 16.3478\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.9438 - val_loss: 16.3690\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.6207 - val_loss: 15.4683\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.3584 - val_loss: 14.9863\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.9812 - val_loss: 15.2661\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.8615 - val_loss: 14.8405\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.5532 - val_loss: 14.3350\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.3896 - val_loss: 15.5274\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.1477 - val_loss: 14.1026\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.0137 - val_loss: 14.1040\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.7339 - val_loss: 13.6319\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.7190 - val_loss: 13.6225\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3959 - val_loss: 13.5698\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.2842 - val_loss: 13.5371\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.2583 - val_loss: 13.5368\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.9899 - val_loss: 13.2743\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.9332 - val_loss: 13.3604\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.0225 - val_loss: 13.8840\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7349 - val_loss: 12.7317\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.6186 - val_loss: 13.2927\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5310 - val_loss: 12.8712\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.4191 - val_loss: 12.4193\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4569 - val_loss: 12.6422\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.2770 - val_loss: 12.3042\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.2245 - val_loss: 12.3723\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.1696 - val_loss: 12.2443\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.0840 - val_loss: 12.7240\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 408us/step - loss: 11.9867 - val_loss: 12.1343\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 434us/step - loss: 11.8981 - val_loss: 12.2796\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 11.9570 - val_loss: 12.2708\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.7445 - val_loss: 12.1942\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 11.7284 - val_loss: 12.3636\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.7308 - val_loss: 12.2766\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 38.4051 - val_loss: 24.2085\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 22.4702 - val_loss: 19.9836\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 19.4418 - val_loss: 18.2283\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.5429 - val_loss: 18.7090\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.5780 - val_loss: 15.6624\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.7861 - val_loss: 15.1069\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 15.1813 - val_loss: 14.4332\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8661 - val_loss: 14.7318\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.4828 - val_loss: 14.3006\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.1708 - val_loss: 13.7715\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.6913 - val_loss: 13.4446\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.7169 - val_loss: 12.9714\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.2970 - val_loss: 14.4959\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.0708 - val_loss: 12.6736\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.8451 - val_loss: 12.6265\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.6293 - val_loss: 12.3901\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.4223 - val_loss: 12.4881\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.2604 - val_loss: 12.5978\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.0915 - val_loss: 12.0803\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.0411 - val_loss: 11.7387\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8602 - val_loss: 11.5166\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6994 - val_loss: 11.5150\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5984 - val_loss: 11.8897\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5419 - val_loss: 11.1125\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4293 - val_loss: 11.3822\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3748 - val_loss: 11.2247\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2576 - val_loss: 11.2026\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.1900 - val_loss: 10.9552\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1293 - val_loss: 10.9969\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.1223 - val_loss: 11.8863\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.9684 - val_loss: 10.7308\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.0076 - val_loss: 11.3715\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.8918 - val_loss: 11.3188\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8440 - val_loss: 10.6639\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.8529 - val_loss: 11.2600\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.8219 - val_loss: 10.4406\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.6899 - val_loss: 10.6666\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 10.7285 - val_loss: 10.4088\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.5567 - val_loss: 10.4014\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.6459 - val_loss: 10.3956\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.5855 - val_loss: 11.4386\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.5291 - val_loss: 10.6612\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 10.5646 - val_loss: 10.3102\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 10.3464 - val_loss: 10.3040\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3890 - val_loss: 10.2622\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.2622 - val_loss: 10.2000\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.2653 - val_loss: 11.1701\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.2288 - val_loss: 10.4389\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.3058 - val_loss: 11.0906\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.3555 - val_loss: 10.1287\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.1118 - val_loss: 9.9688\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0450 - val_loss: 10.0291\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.1475 - val_loss: 9.7784\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0812 - val_loss: 10.0404\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0221 - val_loss: 10.0201\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.9669 - val_loss: 10.3687\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.9919 - val_loss: 9.8139\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9067 - val_loss: 10.2820\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 37.3594 - val_loss: 29.1542\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 27.6776 - val_loss: 25.7727\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 24.9123 - val_loss: 23.4706\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 23.2720 - val_loss: 22.8015\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 22.1769 - val_loss: 21.6818\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.2001 - val_loss: 21.4588\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 20.6158 - val_loss: 19.8495\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 19.8644 - val_loss: 19.1631\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.5809 - val_loss: 18.8704\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 19.0968 - val_loss: 19.1050\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.5753 - val_loss: 18.3068\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.2394 - val_loss: 17.9679\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.9401 - val_loss: 17.4381\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.8163 - val_loss: 17.2027\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.3508 - val_loss: 16.9186\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.1691 - val_loss: 17.2093\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.1282 - val_loss: 16.8952\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.6864 - val_loss: 16.4096\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.6463 - val_loss: 16.3714\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.3025 - val_loss: 16.1003\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.2976 - val_loss: 16.9929\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 16.0285 - val_loss: 15.8942\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.9346 - val_loss: 16.8501\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.8651 - val_loss: 15.8550\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.6468 - val_loss: 15.4186\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.7259 - val_loss: 16.5133\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.5068 - val_loss: 15.5256\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.3651 - val_loss: 15.5781\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.2956 - val_loss: 15.2379\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.2361 - val_loss: 15.0189\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.1800 - val_loss: 14.8946\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.0319 - val_loss: 14.9401\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.9736 - val_loss: 14.8649\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.8661 - val_loss: 14.8444\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.8040 - val_loss: 15.2720\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.7643 - val_loss: 14.7286\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 416us/step - loss: 14.6674 - val_loss: 14.9411\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 14.7392 - val_loss: 14.7923\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 14.6836 - val_loss: 14.5969\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 14.6194 - val_loss: 14.5225\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 14.3747 - val_loss: 14.6742\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 14.4081 - val_loss: 14.5733\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 14.4167 - val_loss: 14.3948\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 14.3255 - val_loss: 14.4980\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.2565 - val_loss: 14.2237\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.3166 - val_loss: 14.3897\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.2210 - val_loss: 15.1549\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.2031 - val_loss: 14.5751\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.2646 - val_loss: 14.1843\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.1859 - val_loss: 14.2250\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.0511 - val_loss: 14.1220\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.0171 - val_loss: 14.1708\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.9813 - val_loss: 14.0802\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9291 - val_loss: 14.1238\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.9434 - val_loss: 13.9869\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.8543 - val_loss: 14.0035\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9857 - val_loss: 14.1243\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.9786 - val_loss: 14.0185\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 13.7913 - val_loss: 14.0590\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.7060 - val_loss: 13.8186\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.7781 - val_loss: 13.7267\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 13.8070 - val_loss: 14.2937\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.6259 - val_loss: 13.8388\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.5699 - val_loss: 13.7146\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.5821 - val_loss: 13.6828\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.6277 - val_loss: 14.0499\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.6131 - val_loss: 13.7773\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.5738 - val_loss: 13.9801\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.7211 - val_loss: 13.6677\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.4811 - val_loss: 14.1370\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.4749 - val_loss: 13.5478\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.4133 - val_loss: 13.6707\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.4994 - val_loss: 13.6560\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 13.4191 - val_loss: 13.7664\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.3832 - val_loss: 13.5496\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.5010 - val_loss: 13.9250\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 35.0937 - val_loss: 27.3852\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 24.6268 - val_loss: 23.1090\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 22.0906 - val_loss: 20.4863\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 20.1524 - val_loss: 20.1127\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 19.2396 - val_loss: 18.3099\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 18.3006 - val_loss: 17.3721\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 17.4987 - val_loss: 17.0686\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 16.9023 - val_loss: 17.2142\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 16.6255 - val_loss: 15.7505\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 16.2685 - val_loss: 15.8970\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.9708 - val_loss: 15.5378\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.4658 - val_loss: 15.5532\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.3268 - val_loss: 15.0233\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.9780 - val_loss: 14.8591\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7921 - val_loss: 14.6830\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.7166 - val_loss: 14.7523\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.3810 - val_loss: 13.9110\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2484 - val_loss: 14.5873\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2973 - val_loss: 13.8193\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.9433 - val_loss: 13.7504\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.0327 - val_loss: 15.4450\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.0548 - val_loss: 13.4779\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.6140 - val_loss: 13.3607\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.5662 - val_loss: 14.1736\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.5392 - val_loss: 13.1778\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.3628 - val_loss: 13.5518\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.3050 - val_loss: 13.2345\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.3180 - val_loss: 13.2613\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.2266 - val_loss: 13.0460\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.0520 - val_loss: 13.0275\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.0812 - val_loss: 13.3506\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9836 - val_loss: 13.1204\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.0271 - val_loss: 12.7390\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7856 - val_loss: 12.9218\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.9374 - val_loss: 12.8295\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7155 - val_loss: 12.4257\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.7227 - val_loss: 12.8581\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6674 - val_loss: 12.6536\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.6319 - val_loss: 12.9837\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.7767 - val_loss: 12.1985\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.4711 - val_loss: 12.3043\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4048 - val_loss: 12.4090\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.3744 - val_loss: 12.2164\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4107 - val_loss: 12.0573\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.3648 - val_loss: 12.3519\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.4682 - val_loss: 12.0727\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4572 - val_loss: 12.9508\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2034 - val_loss: 12.3514\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.1979 - val_loss: 12.0271\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.1003 - val_loss: 12.0402\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.1386 - val_loss: 12.5712\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1136 - val_loss: 12.5606\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.2067 - val_loss: 11.9573\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.9847 - val_loss: 12.2963\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.9976 - val_loss: 13.1767\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8789 - val_loss: 12.2472\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.9032 - val_loss: 11.8766\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7978 - val_loss: 11.9241\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 11.9140 - val_loss: 11.7504\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.7826 - val_loss: 12.1153\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.7943 - val_loss: 12.3705\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.9287 - val_loss: 11.7889\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.7631 - val_loss: 11.7953\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 11.7373 - val_loss: 11.6481\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 11.6711 - val_loss: 12.0708\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 11.6425 - val_loss: 11.6728\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 11.5938 - val_loss: 11.7124\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 11.5913 - val_loss: 11.5015\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 11.6187 - val_loss: 11.3977\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 11.5167 - val_loss: 11.5481\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.4675 - val_loss: 11.4766\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5368 - val_loss: 11.4294\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4643 - val_loss: 11.8786\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3950 - val_loss: 11.9505\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 40.8685 - val_loss: 30.3439\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 25.3776 - val_loss: 23.0507\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.1165 - val_loss: 19.5919\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 19.4206 - val_loss: 18.1519\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.9482 - val_loss: 18.3974\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 17.2148 - val_loss: 16.3586\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.2709 - val_loss: 16.0447\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.4865 - val_loss: 15.4099\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.0800 - val_loss: 14.6232\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.6354 - val_loss: 14.8937\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.1907 - val_loss: 14.1141\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.8236 - val_loss: 15.7215\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.7254 - val_loss: 13.4126\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.2758 - val_loss: 13.2214\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.0093 - val_loss: 12.9068\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.9408 - val_loss: 13.6093\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.9070 - val_loss: 12.6505\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.4965 - val_loss: 12.6169\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.3442 - val_loss: 12.5142\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.2277 - val_loss: 12.2526\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1294 - val_loss: 12.1950\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.0032 - val_loss: 12.3697\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.7985 - val_loss: 12.8702\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7589 - val_loss: 11.7725\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.5779 - val_loss: 11.5321\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4480 - val_loss: 13.1891\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3619 - val_loss: 11.5533\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.1867 - val_loss: 13.3261\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.2088 - val_loss: 11.2642\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.0751 - val_loss: 10.9180\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8590 - val_loss: 10.8321\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.7664 - val_loss: 10.8880\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.7328 - val_loss: 10.6843\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.5995 - val_loss: 10.9023\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.5974 - val_loss: 10.9660\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.4947 - val_loss: 11.0562\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.4076 - val_loss: 10.5396\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.2866 - val_loss: 11.1525\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3773 - val_loss: 11.5865\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1574 - val_loss: 10.2509\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1083 - val_loss: 10.2871\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0539 - val_loss: 10.2007\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.1046 - val_loss: 10.1932\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.9811 - val_loss: 10.2649\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 9.9941 - val_loss: 10.1174\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.8260 - val_loss: 10.1996\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7904 - val_loss: 9.8839\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.8254 - val_loss: 10.1347\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.8696 - val_loss: 10.1716\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9306 - val_loss: 9.9608\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.5963 - val_loss: 10.0191\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.5916 - val_loss: 9.8156\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.6513 - val_loss: 9.7604\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.5465 - val_loss: 9.7825\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.6203 - val_loss: 10.0787\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4913 - val_loss: 9.6844\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.4549 - val_loss: 9.9576\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.4619 - val_loss: 9.7296\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.4086 - val_loss: 9.7354\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4002 - val_loss: 9.6859\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.6960 - val_loss: 9.6295\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.3339 - val_loss: 9.4906\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.2313 - val_loss: 9.5414\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.2633 - val_loss: 9.4702\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.3122 - val_loss: 9.5432\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.2954 - val_loss: 9.4919\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.2260 - val_loss: 9.4801\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.1817 - val_loss: 9.9677\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.1562 - val_loss: 9.4857\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 35.4689 - val_loss: 24.2248\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 21.7964 - val_loss: 19.9616\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.0560 - val_loss: 19.0756\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.7825 - val_loss: 16.4862\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.5371 - val_loss: 15.9996\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.7617 - val_loss: 15.6292\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.2025 - val_loss: 15.1757\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.5881 - val_loss: 14.5158\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3473 - val_loss: 13.5827\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.7964 - val_loss: 14.8196\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.5582 - val_loss: 14.0475\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.1901 - val_loss: 13.5759\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.0227 - val_loss: 12.4206\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7466 - val_loss: 12.4977\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.4517 - val_loss: 12.7766\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.4741 - val_loss: 11.7889\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1943 - val_loss: 11.9551\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.9955 - val_loss: 11.8614\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 409us/step - loss: 11.8783 - val_loss: 11.5616\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.7541 - val_loss: 11.4411\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 11.6702 - val_loss: 12.0769\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 11.5008 - val_loss: 11.3951\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 11.7442 - val_loss: 11.3840\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 11.3098 - val_loss: 10.8362\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 11.2447 - val_loss: 11.7117\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 11.3254 - val_loss: 10.8156\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 10.9280 - val_loss: 11.5696\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.1854 - val_loss: 10.5511\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7485 - val_loss: 10.7433\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.8752 - val_loss: 14.1917\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.6979 - val_loss: 11.3873\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6450 - val_loss: 10.3363\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6246 - val_loss: 10.3247\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3061 - val_loss: 10.0381\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4123 - val_loss: 10.2187\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.6574 - val_loss: 11.3377\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 10.2967 - val_loss: 9.8835\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.2211 - val_loss: 9.9897\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.2127 - val_loss: 9.8467\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0529 - val_loss: 9.8038\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 10.0820 - val_loss: 10.2055\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.9606 - val_loss: 9.7309\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.9154 - val_loss: 9.7931\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.0142 - val_loss: 9.6421\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.7208 - val_loss: 9.8035\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.8203 - val_loss: 9.7482\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.7477 - val_loss: 9.3054\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.5845 - val_loss: 9.5626\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.5322 - val_loss: 9.8544\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.5346 - val_loss: 9.6526\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.4594 - val_loss: 9.2567\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.3903 - val_loss: 9.2872\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.3480 - val_loss: 9.4651\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.4368 - val_loss: 9.9721\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.2577 - val_loss: 12.0716\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.3339 - val_loss: 9.3395\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 38.2379 - val_loss: 27.4719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 24.9079 - val_loss: 22.2687\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 20.6997 - val_loss: 20.7411\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.7573 - val_loss: 17.6605\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.2912 - val_loss: 16.9439\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.0904 - val_loss: 15.8629\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 15.3552 - val_loss: 15.0883\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.5389 - val_loss: 14.3331\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 14.0374 - val_loss: 13.7821\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 13.6222 - val_loss: 14.0056\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 13.5236 - val_loss: 13.4080\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.0258 - val_loss: 13.1958\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.7001 - val_loss: 12.5284\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.5333 - val_loss: 12.9710\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.2690 - val_loss: 12.2116\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.3218 - val_loss: 12.0512\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8312 - val_loss: 11.8213\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8720 - val_loss: 12.0643\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4321 - val_loss: 11.4772\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.4272 - val_loss: 11.4415\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.2403 - val_loss: 11.1443\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0713 - val_loss: 11.7853\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9983 - val_loss: 10.9682\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.8551 - val_loss: 11.0556\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8760 - val_loss: 11.1932\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7504 - val_loss: 10.8915\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.5988 - val_loss: 10.8572\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.5868 - val_loss: 10.9230\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4049 - val_loss: 10.4935\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.3961 - val_loss: 10.5230\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.2832 - val_loss: 10.3930\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.3751 - val_loss: 10.4846\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.2445 - val_loss: 10.3057\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1467 - val_loss: 10.2059\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.0533 - val_loss: 10.3138\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.0431 - val_loss: 10.2399\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.9855 - val_loss: 10.1574\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.8943 - val_loss: 10.1080\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.9655 - val_loss: 10.1097\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.8428 - val_loss: 10.4230\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.7795 - val_loss: 9.9939\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 9.8139 - val_loss: 9.9118\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.6893 - val_loss: 10.0299\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.7062 - val_loss: 9.8212\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.6372 - val_loss: 10.5588\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.5344 - val_loss: 9.9308\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.5543 - val_loss: 9.7389\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.5015 - val_loss: 9.9072\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.5378 - val_loss: 10.6719\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.4351 - val_loss: 9.6783\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.3824 - val_loss: 9.9185\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.3958 - val_loss: 9.6293\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.4165 - val_loss: 9.5396\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.3051 - val_loss: 9.7292\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.3201 - val_loss: 9.4773\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.1940 - val_loss: 10.1689\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.3016 - val_loss: 9.6703\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.2750 - val_loss: 9.7673\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.1715 - val_loss: 9.4860\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.1955 - val_loss: 9.6470\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 38.3503 - val_loss: 27.8190\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 25.0402 - val_loss: 23.5596\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 415us/step - loss: 22.2251 - val_loss: 20.7528\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 431us/step - loss: 20.5270 - val_loss: 20.0994\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 19.4576 - val_loss: 19.0557\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 18.7691 - val_loss: 18.1908\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 18.0290 - val_loss: 18.2746\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 17.2941 - val_loss: 18.5961\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 16.7975 - val_loss: 16.1444\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 16.5700 - val_loss: 15.8701\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 16.0551 - val_loss: 17.9173\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.6812 - val_loss: 15.8858\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.3943 - val_loss: 15.7988\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.9617 - val_loss: 14.7155\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.9546 - val_loss: 14.7009\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.5299 - val_loss: 15.1310\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.3270 - val_loss: 14.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.0359 - val_loss: 13.9150\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 576us/step - loss: 13.8841 - val_loss: 14.4260\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.7306 - val_loss: 13.4876\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.6205 - val_loss: 13.2249\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.3792 - val_loss: 13.2622\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3034 - val_loss: 13.0458\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9546 - val_loss: 12.7093\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.7834 - val_loss: 13.0062\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 12.7743 - val_loss: 12.6259\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 12.5933 - val_loss: 12.4432\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.5077 - val_loss: 12.3338\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.3961 - val_loss: 13.9118\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.4161 - val_loss: 12.1614\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.0731 - val_loss: 12.6262\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.1405 - val_loss: 11.8820\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.9710 - val_loss: 11.8309\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.8567 - val_loss: 11.7656\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8204 - val_loss: 11.6603\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6426 - val_loss: 11.8690\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.7220 - val_loss: 12.4089\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.6182 - val_loss: 11.4227\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.4572 - val_loss: 11.4141\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.4228 - val_loss: 11.3373\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3162 - val_loss: 11.4271\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.3027 - val_loss: 11.2753\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 11.3020 - val_loss: 11.5732\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1524 - val_loss: 11.2271\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1379 - val_loss: 11.0954\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0644 - val_loss: 11.0044\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0273 - val_loss: 11.0208\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9606 - val_loss: 11.1304\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.8712 - val_loss: 10.9127\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.9587 - val_loss: 10.7585\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 10.8213 - val_loss: 10.9004\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.7436 - val_loss: 10.8989\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.7226 - val_loss: 10.6378\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.7478 - val_loss: 11.1191\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.6515 - val_loss: 10.6393\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6561 - val_loss: 10.9251\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5696 - val_loss: 10.4847\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4953 - val_loss: 11.2024\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5161 - val_loss: 11.0199\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.4359 - val_loss: 10.7700\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.4156 - val_loss: 10.5033\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.4196 - val_loss: 10.8923\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 34.4678 - val_loss: 25.7202\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 23.1094 - val_loss: 20.9044\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 19.4917 - val_loss: 20.1932\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 18.1225 - val_loss: 18.9532\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.9992 - val_loss: 17.4433\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.3283 - val_loss: 15.7408\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.6824 - val_loss: 15.6321\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.2416 - val_loss: 16.8533\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.8148 - val_loss: 14.6037\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.4303 - val_loss: 14.4256\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.0233 - val_loss: 15.1309\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6051 - val_loss: 13.4678\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 13.5403 - val_loss: 13.4843\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.2855 - val_loss: 13.8429\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.8267 - val_loss: 12.8375\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.5410 - val_loss: 12.6591\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.5143 - val_loss: 13.5360\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.1196 - val_loss: 12.1992\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.0255 - val_loss: 12.1743\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.7611 - val_loss: 11.4283\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.6728 - val_loss: 11.7692\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.3992 - val_loss: 11.2770\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.2509 - val_loss: 11.2825\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.1150 - val_loss: 12.1231\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.0891 - val_loss: 11.2462\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9023 - val_loss: 10.7865\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.8165 - val_loss: 10.6689\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.7618 - val_loss: 10.6612\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.6305 - val_loss: 10.9559\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.5235 - val_loss: 10.5370\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.3973 - val_loss: 10.6191\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.3317 - val_loss: 10.3961\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.3056 - val_loss: 10.2825\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.3656 - val_loss: 10.8947\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1481 - val_loss: 11.5132\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.1357 - val_loss: 11.0349\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0069 - val_loss: 10.2480\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0511 - val_loss: 10.2624\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.8584 - val_loss: 9.9994\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.9018 - val_loss: 9.9094\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.8112 - val_loss: 10.5651\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 9.7043 - val_loss: 9.9333\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.7611 - val_loss: 9.9284\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 9.8101 - val_loss: 9.7366\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 9.7054 - val_loss: 9.8568\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 9.5942 - val_loss: 9.8067\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 9.5262 - val_loss: 9.6341\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 9.5043 - val_loss: 10.2145\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 9.5012 - val_loss: 9.5374\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 9.4662 - val_loss: 9.7324\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.3447 - val_loss: 9.6935\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.4010 - val_loss: 9.5367\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 9.2868 - val_loss: 9.8213\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.3609 - val_loss: 9.9450\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.2502 - val_loss: 9.8581\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.2952 - val_loss: 10.2499\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 9.2249 - val_loss: 9.3493\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.1089 - val_loss: 9.3757\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.2481 - val_loss: 9.3262\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 9.1383 - val_loss: 9.3776\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.0490 - val_loss: 9.2685\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.0918 - val_loss: 9.6175\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.0997 - val_loss: 9.2499\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 8.9661 - val_loss: 9.1874\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 9.0469 - val_loss: 9.3039\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 8.9074 - val_loss: 9.0308\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 8.9140 - val_loss: 9.1197\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 8.9576 - val_loss: 9.2618\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 8.8918 - val_loss: 9.0784\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 8.8802 - val_loss: 9.4060\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 8.8032 - val_loss: 9.0698\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 41.0691 - val_loss: 29.4593\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 27.2203 - val_loss: 26.0754\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 24.0862 - val_loss: 24.1877\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 22.4967 - val_loss: 21.2038\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 21.3344 - val_loss: 21.0802\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.3676 - val_loss: 20.4418\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.6551 - val_loss: 19.3882\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.9448 - val_loss: 18.6051\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.5763 - val_loss: 18.4406\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.0346 - val_loss: 19.4966\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.5950 - val_loss: 17.5716\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.3025 - val_loss: 16.9530\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.9611 - val_loss: 16.6833\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 16.6912 - val_loss: 16.4086\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 16.4515 - val_loss: 16.5227\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 16.1797 - val_loss: 16.2408\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 16.2718 - val_loss: 15.9038\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 15.8173 - val_loss: 15.6092\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 15.6475 - val_loss: 15.7031\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 15.5661 - val_loss: 15.4474\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.4681 - val_loss: 15.3469\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.3274 - val_loss: 15.0109\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.0813 - val_loss: 14.9628\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.0762 - val_loss: 14.9522\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.0738 - val_loss: 14.7200\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.8418 - val_loss: 15.2273\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8292 - val_loss: 14.5466\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.7116 - val_loss: 14.7957\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.6996 - val_loss: 14.4092\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.5996 - val_loss: 14.5989\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 14.5632 - val_loss: 14.2840\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.2237 - val_loss: 14.3393\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2734 - val_loss: 14.2586\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.2154 - val_loss: 13.9860\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.0865 - val_loss: 13.9510\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.0251 - val_loss: 14.0822\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.0225 - val_loss: 14.1090\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.9200 - val_loss: 14.2247\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.8980 - val_loss: 13.8577\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.8585 - val_loss: 13.7865\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.7518 - val_loss: 13.9581\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.6486 - val_loss: 13.8956\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.7418 - val_loss: 13.5371\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.5886 - val_loss: 13.6033\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.5166 - val_loss: 13.6220\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.4801 - val_loss: 13.9659\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.5033 - val_loss: 14.1680\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.3479 - val_loss: 13.7204\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 41.4350 - val_loss: 29.2172\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 25.9050 - val_loss: 23.9797\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 22.2260 - val_loss: 23.5655\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 20.3059 - val_loss: 18.8458\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.7223 - val_loss: 17.4839\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.9486 - val_loss: 17.3540\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.8920 - val_loss: 17.3723\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 16.1941 - val_loss: 16.0354\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.5661 - val_loss: 15.7621\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.1611 - val_loss: 15.6305\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.7390 - val_loss: 14.4994\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.3701 - val_loss: 14.2376\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.0112 - val_loss: 14.6364\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8381 - val_loss: 14.1519\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.5380 - val_loss: 13.6435\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.3559 - val_loss: 13.7650\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.1603 - val_loss: 13.0400\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.0053 - val_loss: 13.1782\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.8596 - val_loss: 12.7243\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.7244 - val_loss: 12.6805\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.4270 - val_loss: 13.4250\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.3494 - val_loss: 12.4191\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 397us/step - loss: 12.1996 - val_loss: 12.2601\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.9754 - val_loss: 11.9954\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 12.0006 - val_loss: 13.1710\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 11.7632 - val_loss: 12.0357\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 476us/step - loss: 11.6687 - val_loss: 11.7327\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 11.6316 - val_loss: 11.5460\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 11.5434 - val_loss: 11.4851\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 11.3816 - val_loss: 11.5460\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3103 - val_loss: 11.3357\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2932 - val_loss: 11.2746\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3336 - val_loss: 11.3496\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.0362 - val_loss: 11.1762\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0124 - val_loss: 11.0792\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.9102 - val_loss: 11.0881\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.9608 - val_loss: 11.0896\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.9925 - val_loss: 11.0548\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.7100 - val_loss: 11.7695\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7734 - val_loss: 10.8101\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7143 - val_loss: 10.8082\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5894 - val_loss: 10.9253\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.8004 - val_loss: 11.0500\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 10.4938 - val_loss: 10.8476\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4255 - val_loss: 10.7204\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.4760 - val_loss: 10.8202\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.3352 - val_loss: 10.5748\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.3721 - val_loss: 10.4178\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.3395 - val_loss: 10.6636\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3008 - val_loss: 10.4959\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.2737 - val_loss: 10.5129\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.2311 - val_loss: 10.4368\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.1056 - val_loss: 10.4271\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 37.5376 - val_loss: 24.1415\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 22.0382 - val_loss: 19.8334\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 19.3318 - val_loss: 19.2793\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 17.9925 - val_loss: 18.3789\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 17.2136 - val_loss: 16.4506\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 16.3764 - val_loss: 15.6766\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.8646 - val_loss: 14.9884\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.3015 - val_loss: 15.0507\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.8734 - val_loss: 14.5501\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.8083 - val_loss: 14.5530\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2564 - val_loss: 13.9664\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.0684 - val_loss: 15.3522\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 13.8195 - val_loss: 13.4638\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 13.4947 - val_loss: 13.2102\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 13.1823 - val_loss: 13.0522\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.9961 - val_loss: 13.2407\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 13.0416 - val_loss: 12.9036\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.6616 - val_loss: 12.8480\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4568 - val_loss: 12.0717\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.4852 - val_loss: 12.0756\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.3159 - val_loss: 12.5678\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 12.1048 - val_loss: 12.2714\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.9469 - val_loss: 11.9342\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.8974 - val_loss: 11.6618\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.8889 - val_loss: 11.7986\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.7197 - val_loss: 11.8765\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.6445 - val_loss: 11.5871\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.5891 - val_loss: 11.5372\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.5509 - val_loss: 11.4632\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.5838 - val_loss: 11.2797\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.4602 - val_loss: 12.0102\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.3443 - val_loss: 11.0970\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.4424 - val_loss: 11.2946\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.2096 - val_loss: 11.5403\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.1878 - val_loss: 11.0779\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.1450 - val_loss: 11.5934\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.0566 - val_loss: 11.0803\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.0750 - val_loss: 10.7832\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.9891 - val_loss: 12.0095\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.9783 - val_loss: 11.0334\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.8558 - val_loss: 10.7547\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.8469 - val_loss: 11.0413\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.9081 - val_loss: 11.0931\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.7512 - val_loss: 10.4925\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.7479 - val_loss: 10.5991\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.6918 - val_loss: 10.6889\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.6616 - val_loss: 10.5921\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.6058 - val_loss: 10.4438\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.5566 - val_loss: 10.5114\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.4890 - val_loss: 10.6901\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 10.6053 - val_loss: 10.6940\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.4327 - val_loss: 10.3900\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.4222 - val_loss: 10.3476\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.3844 - val_loss: 10.5706\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4326 - val_loss: 10.5421\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.3287 - val_loss: 10.4941\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.3134 - val_loss: 10.2417\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.2601 - val_loss: 10.3476\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.2043 - val_loss: 10.3254\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.2189 - val_loss: 10.3364\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.1662 - val_loss: 10.1924\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1345 - val_loss: 10.2152\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.1519 - val_loss: 10.3097\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.0898 - val_loss: 10.0883\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.0620 - val_loss: 10.3744\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.0440 - val_loss: 10.3462\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 9.9960 - val_loss: 11.1721\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.0671 - val_loss: 10.2588\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 10.0646 - val_loss: 10.0493\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 9.9291 - val_loss: 9.8849\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.9715 - val_loss: 10.1500\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 9.9829 - val_loss: 10.0718\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 9.8202 - val_loss: 10.2991\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 490us/step - loss: 9.8568 - val_loss: 10.2330\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 9.8125 - val_loss: 9.7770\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 9.8154 - val_loss: 10.0316\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 9.7788 - val_loss: 10.3229\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.7526 - val_loss: 9.8300\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.7700 - val_loss: 9.7638\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.7685 - val_loss: 10.2442\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.7658 - val_loss: 9.7195\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.6311 - val_loss: 10.0921\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.6909 - val_loss: 9.6755\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 9.6754 - val_loss: 9.6060\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 9.6435 - val_loss: 9.8979\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.6364 - val_loss: 9.6646\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.6777 - val_loss: 9.6413\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 9.6251 - val_loss: 9.8145\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 9.5300 - val_loss: 9.8078\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 37.6810 - val_loss: 30.1944\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 28.6279 - val_loss: 28.8082\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 25.6225 - val_loss: 24.5936\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 23.6915 - val_loss: 23.6491\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 22.1812 - val_loss: 22.2976\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 21.2522 - val_loss: 22.2432\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.7745 - val_loss: 22.1157\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.9745 - val_loss: 19.4300\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 19.3633 - val_loss: 19.6135\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.0756 - val_loss: 18.4006\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.4242 - val_loss: 18.1857\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 18.0861 - val_loss: 18.1550\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.8579 - val_loss: 18.1348\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.6085 - val_loss: 17.0968\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.1323 - val_loss: 17.1242\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.0204 - val_loss: 16.9357\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.7393 - val_loss: 16.4998\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.4399 - val_loss: 16.6396\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.2938 - val_loss: 16.3452\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.0792 - val_loss: 16.0488\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.1165 - val_loss: 15.7980\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 15.8004 - val_loss: 16.7137\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 15.7462 - val_loss: 15.6749\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 15.6519 - val_loss: 16.0465\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 15.4499 - val_loss: 15.3009\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 15.4318 - val_loss: 15.3111\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 15.4019 - val_loss: 15.4087\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 15.2021 - val_loss: 15.1489\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 15.0389 - val_loss: 16.4490\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.0843 - val_loss: 15.3404\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.9996 - val_loss: 15.3667\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.9242 - val_loss: 14.9689\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.7872 - val_loss: 14.8222\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.7732 - val_loss: 14.6434\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.6331 - val_loss: 15.0066\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.6700 - val_loss: 14.6547\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.6491 - val_loss: 14.6373\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.5414 - val_loss: 14.7145\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.4662 - val_loss: 14.8290\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.4097 - val_loss: 14.6712\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4114 - val_loss: 14.6160\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.3141 - val_loss: 14.6329\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.2477 - val_loss: 14.3979\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.2443 - val_loss: 14.2032\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.1866 - val_loss: 14.2576\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.1905 - val_loss: 14.3040\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.1441 - val_loss: 14.4467\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0444 - val_loss: 14.0992\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.0183 - val_loss: 14.2953\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.9885 - val_loss: 14.1254\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.9968 - val_loss: 13.9068\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8391 - val_loss: 14.2481\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9032 - val_loss: 14.0498\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.8212 - val_loss: 14.0298\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 13.8327 - val_loss: 14.0037\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.8094 - val_loss: 14.0466\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 36.8622 - val_loss: 25.8311\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 23.9172 - val_loss: 21.5404\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 21.1357 - val_loss: 20.0345\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 19.8265 - val_loss: 18.2568\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.5514 - val_loss: 17.6830\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.6235 - val_loss: 17.0355\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.2177 - val_loss: 17.0817\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 16.6310 - val_loss: 16.8753\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.3666 - val_loss: 15.7783\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.7705 - val_loss: 15.0994\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.3812 - val_loss: 15.7305\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.1535 - val_loss: 15.1201\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 15.0166 - val_loss: 16.0903\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.9781 - val_loss: 14.8035\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.7198 - val_loss: 14.2892\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.4147 - val_loss: 15.1507\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.3491 - val_loss: 14.1174\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.0133 - val_loss: 14.3849\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 13.9971 - val_loss: 13.6098\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.8693 - val_loss: 13.1991\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.6043 - val_loss: 14.7975\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.5702 - val_loss: 13.0629\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.3243 - val_loss: 14.1355\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 13.3605 - val_loss: 12.9495\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 13.2547 - val_loss: 12.7782\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 13.1775 - val_loss: 12.5842\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 12.9103 - val_loss: 13.4783\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 12.9916 - val_loss: 12.8614\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 12.7859 - val_loss: 12.5448\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 562us/step - loss: 12.6583 - val_loss: 12.4551\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.6235 - val_loss: 12.3434\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.4879 - val_loss: 12.3693\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.4009 - val_loss: 12.0420\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 12.3418 - val_loss: 13.4069\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.2723 - val_loss: 12.4873\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.1199 - val_loss: 11.7696\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2134 - val_loss: 13.2179\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.0512 - val_loss: 11.9989\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0266 - val_loss: 11.5691\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8950 - val_loss: 11.7333\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.8378 - val_loss: 11.4461\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.7123 - val_loss: 11.8921\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.7079 - val_loss: 11.7203\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6960 - val_loss: 11.2218\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.6053 - val_loss: 11.9823\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.5334 - val_loss: 11.3656\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.4997 - val_loss: 11.4580\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.3884 - val_loss: 11.1346\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.4411 - val_loss: 11.2238\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.3135 - val_loss: 11.0182\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3062 - val_loss: 11.0615\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3565 - val_loss: 11.0245\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1896 - val_loss: 10.8617\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1636 - val_loss: 10.9531\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1435 - val_loss: 11.1161\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3272 - val_loss: 11.2604\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0927 - val_loss: 10.9739\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.9474 - val_loss: 10.9529\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 40.5660 - val_loss: 29.6923\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 26.6322 - val_loss: 24.4815\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 22.5047 - val_loss: 21.0799\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 20.5416 - val_loss: 20.0785\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 19.1467 - val_loss: 18.5042\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.3212 - val_loss: 20.2331\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.6235 - val_loss: 19.6545\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 17.0708 - val_loss: 16.7101\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 16.3695 - val_loss: 15.9290\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 16.1669 - val_loss: 17.4402\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 15.8251 - val_loss: 15.8537\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 15.5048 - val_loss: 15.5494\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 15.2044 - val_loss: 14.9117\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 14.8130 - val_loss: 14.7179\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.6537 - val_loss: 14.9453\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.6430 - val_loss: 14.9280\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.1344 - val_loss: 13.9841\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.9636 - val_loss: 14.3453\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.6423 - val_loss: 13.5993\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.7355 - val_loss: 13.4147\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.6485 - val_loss: 13.3086\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.3097 - val_loss: 13.7733\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.1740 - val_loss: 13.4544\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.1266 - val_loss: 13.1102\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.1799 - val_loss: 14.8120\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.8502 - val_loss: 13.3361\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.7633 - val_loss: 12.7957\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.6504 - val_loss: 12.6554\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6184 - val_loss: 12.8088\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 12.4194 - val_loss: 12.8799\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5182 - val_loss: 12.5280\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.2913 - val_loss: 13.1156\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.2172 - val_loss: 14.9315\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 12.0806 - val_loss: 12.3289\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.9835 - val_loss: 12.0299\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.8981 - val_loss: 13.6854\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.0159 - val_loss: 11.9618\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.7201 - val_loss: 11.8356\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7503 - val_loss: 12.3476\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.6952 - val_loss: 11.7047\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.5484 - val_loss: 11.8575\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.5643 - val_loss: 11.9553\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4988 - val_loss: 11.4921\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3577 - val_loss: 11.7562\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.3714 - val_loss: 11.9044\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2559 - val_loss: 11.3614\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.4659 - val_loss: 11.9440\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 11.1243 - val_loss: 11.2198\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.1063 - val_loss: 11.2594\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.0788 - val_loss: 11.3360\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0519 - val_loss: 11.1625\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0328 - val_loss: 11.3483\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.9995 - val_loss: 12.0338\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8664 - val_loss: 11.5445\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0876 - val_loss: 11.2984\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.8284 - val_loss: 11.0120\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.8091 - val_loss: 11.1016\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.7476 - val_loss: 10.9488\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.7130 - val_loss: 13.2947\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8730 - val_loss: 11.0135\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.7133 - val_loss: 11.0922\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5580 - val_loss: 10.9580\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5069 - val_loss: 10.8402\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5717 - val_loss: 10.7888\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.5505 - val_loss: 11.0886\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.5662 - val_loss: 10.7925\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.4830 - val_loss: 10.8276\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 408us/step - loss: 10.4126 - val_loss: 10.7280\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6143 - val_loss: 10.5881\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.3488 - val_loss: 11.0775\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 10.4125 - val_loss: 11.1424\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 10.3287 - val_loss: 10.6586\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 10.2976 - val_loss: 10.5549\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 10.3577 - val_loss: 10.8057\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 570us/step - loss: 10.3124 - val_loss: 10.4609\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1894 - val_loss: 10.7103\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.2459 - val_loss: 10.4964\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.2002 - val_loss: 10.5466\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.2256 - val_loss: 10.6846\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.1435 - val_loss: 10.5027\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 37.9937 - val_loss: 27.0365\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 24.2199 - val_loss: 22.1603\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 20.9331 - val_loss: 19.2834\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 19.2475 - val_loss: 19.0411\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 18.4647 - val_loss: 17.4715\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 17.7692 - val_loss: 17.0271\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.1426 - val_loss: 16.8447\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 16.6716 - val_loss: 16.3085\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 16.3566 - val_loss: 15.8266\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.6523 - val_loss: 16.0744\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 15.5180 - val_loss: 15.4477\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 15.3594 - val_loss: 15.5214\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 15.1531 - val_loss: 14.6944\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.7306 - val_loss: 14.7307\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.4853 - val_loss: 14.1239\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.3412 - val_loss: 13.8731\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.1062 - val_loss: 13.7031\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.0628 - val_loss: 13.8667\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.7673 - val_loss: 13.6804\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8064 - val_loss: 15.2305\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3750 - val_loss: 13.0644\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3299 - val_loss: 12.8361\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1364 - val_loss: 13.3237\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.0828 - val_loss: 13.0588\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.8969 - val_loss: 12.5332\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.8490 - val_loss: 12.9170\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7937 - val_loss: 12.9961\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.5631 - val_loss: 12.3340\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.7281 - val_loss: 12.2869\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.4860 - val_loss: 12.4028\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.3424 - val_loss: 12.1463\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 12.1756 - val_loss: 12.0350\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 12.2080 - val_loss: 11.9292\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.1030 - val_loss: 12.1682\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.0437 - val_loss: 11.7834\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 11.9778 - val_loss: 12.4465\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 11.8816 - val_loss: 12.0185\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.8899 - val_loss: 11.8630\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7851 - val_loss: 11.5027\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.6790 - val_loss: 11.9791\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6411 - val_loss: 11.4525\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5487 - val_loss: 12.2579\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6296 - val_loss: 11.8017\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.8061 - val_loss: 12.4286\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5518 - val_loss: 11.2698\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.2709 - val_loss: 11.3757\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.3626 - val_loss: 11.4693\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.3671 - val_loss: 11.4630\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.2751 - val_loss: 11.1044\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1824 - val_loss: 11.4323\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.1564 - val_loss: 11.2214\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.2275 - val_loss: 11.0415\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.0392 - val_loss: 11.1693\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1261 - val_loss: 11.6214\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1057 - val_loss: 10.9370\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0477 - val_loss: 11.2975\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.9563 - val_loss: 11.3195\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.0448 - val_loss: 10.9220\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8584 - val_loss: 11.0202\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8884 - val_loss: 10.6134\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9672 - val_loss: 10.9313\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.8779 - val_loss: 10.8448\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.7079 - val_loss: 10.7308\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.8038 - val_loss: 10.8205\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.9257 - val_loss: 10.6558\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 38.2852 - val_loss: 33.8087\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 26.9634 - val_loss: 24.3891\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 23.2323 - val_loss: 22.3033\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 21.1696 - val_loss: 19.6986\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.4816 - val_loss: 18.1619\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.2609 - val_loss: 17.5000\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.6789 - val_loss: 16.9621\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 16.7718 - val_loss: 16.9415\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 16.3350 - val_loss: 15.4949\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.6342 - val_loss: 15.1394\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.1705 - val_loss: 14.9892\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.9249 - val_loss: 14.9225\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.6168 - val_loss: 15.8629\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.2792 - val_loss: 13.8485\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8622 - val_loss: 14.1471\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.8429 - val_loss: 13.3758\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.4030 - val_loss: 13.5388\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3167 - val_loss: 13.0087\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.9699 - val_loss: 12.8037\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9889 - val_loss: 12.9033\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.6802 - val_loss: 13.8725\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6304 - val_loss: 12.5612\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 398us/step - loss: 12.4075 - val_loss: 12.3241\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.3559 - val_loss: 12.5633\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 12.1455 - val_loss: 12.2995\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 12.0971 - val_loss: 12.1627\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 11.9464 - val_loss: 12.2404\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 11.9715 - val_loss: 11.8640\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 11.6552 - val_loss: 11.8546\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 568us/step - loss: 11.8082 - val_loss: 11.8866\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.4902 - val_loss: 11.7822\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6939 - val_loss: 13.5137\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3897 - val_loss: 11.6294\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.3669 - val_loss: 11.3333\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1573 - val_loss: 11.9786\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1545 - val_loss: 11.3050\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.0987 - val_loss: 11.4759\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.0431 - val_loss: 11.1548\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.9933 - val_loss: 11.0075\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.9350 - val_loss: 11.0202\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.8309 - val_loss: 10.9859\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.8904 - val_loss: 10.9800\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.7387 - val_loss: 11.1134\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.6914 - val_loss: 10.8739\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.5958 - val_loss: 10.7464\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5221 - val_loss: 10.5346\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.3974 - val_loss: 10.7648\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.4187 - val_loss: 10.6181\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.4167 - val_loss: 10.5223\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.3194 - val_loss: 11.1183\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3151 - val_loss: 11.0874\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.2200 - val_loss: 10.4810\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.1465 - val_loss: 10.4666\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.2419 - val_loss: 10.6429\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.0347 - val_loss: 10.2595\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.0032 - val_loss: 10.4554\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9828 - val_loss: 10.2855\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.9660 - val_loss: 10.4484\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9551 - val_loss: 10.2873\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.8715 - val_loss: 10.1327\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.8385 - val_loss: 10.4148\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.8496 - val_loss: 10.1306\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.9103 - val_loss: 10.2613\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.7825 - val_loss: 10.3674\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.7785 - val_loss: 10.7094\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.6898 - val_loss: 9.9367\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.6464 - val_loss: 9.8645\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.6328 - val_loss: 10.1522\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 9.6675 - val_loss: 10.2760\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 9.6087 - val_loss: 9.8655\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.5367 - val_loss: 10.1037\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 9.6990 - val_loss: 9.8352\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 9.5049 - val_loss: 10.0307\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 9.5480 - val_loss: 9.8530\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.4534 - val_loss: 9.7918\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.5447 - val_loss: 9.7134\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.3377 - val_loss: 9.7458\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4071 - val_loss: 9.6681\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.4770 - val_loss: 9.7069\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.3525 - val_loss: 9.7009\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.3874 - val_loss: 9.8015\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.3492 - val_loss: 9.8397\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.3516 - val_loss: 9.6313\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.2377 - val_loss: 9.7547\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.2328 - val_loss: 10.0852\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.2381 - val_loss: 9.6862\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.2629 - val_loss: 9.5121\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.1721 - val_loss: 9.6400\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.1600 - val_loss: 10.1917\n",
      "Epoch 90/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.3472 - val_loss: 9.7471\n",
      "Epoch 91/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.1109 - val_loss: 9.7102\n",
      "Epoch 92/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.3007 - val_loss: 9.4791\n",
      "Epoch 93/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.0333 - val_loss: 9.8296\n",
      "Epoch 94/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.0549 - val_loss: 9.7685\n",
      "Epoch 95/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.0505 - val_loss: 9.4739\n",
      "Epoch 96/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.0826 - val_loss: 9.5495\n",
      "Epoch 97/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.0417 - val_loss: 9.6811\n",
      "Epoch 98/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.0163 - val_loss: 9.5421\n",
      "Epoch 99/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.1513 - val_loss: 9.4955\n",
      "Epoch 100/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 8.9388 - val_loss: 9.5338\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 39.7160 - val_loss: 28.1105\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 26.9012 - val_loss: 24.3684\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 23.5440 - val_loss: 22.1928\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 21.5908 - val_loss: 21.3225\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 20.1649 - val_loss: 19.6165\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 19.2228 - val_loss: 18.5728\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 18.4317 - val_loss: 18.6081\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 18.1305 - val_loss: 18.4901\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.5768 - val_loss: 16.8499\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.3205 - val_loss: 16.5531\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.8089 - val_loss: 16.2994\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.4872 - val_loss: 17.9868\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.3347 - val_loss: 16.7318\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.1145 - val_loss: 15.7942\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 15.7934 - val_loss: 15.4891\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.4819 - val_loss: 16.0209\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 15.4719 - val_loss: 15.4919\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 15.0927 - val_loss: 14.6682\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 15.0198 - val_loss: 14.8297\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 14.8305 - val_loss: 15.0307\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.6371 - val_loss: 15.1743\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.4907 - val_loss: 14.3073\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.3992 - val_loss: 14.1926\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.2420 - val_loss: 13.8794\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 14.2137 - val_loss: 16.2652\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 384us/step - loss: 14.1220 - val_loss: 13.7778\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.9967 - val_loss: 13.7782\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 13.8541 - val_loss: 13.7805\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 13.7324 - val_loss: 13.5447\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 13.8189 - val_loss: 13.4621\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 13.6715 - val_loss: 13.5197\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 13.4484 - val_loss: 13.2919\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 13.5613 - val_loss: 13.4358\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3798 - val_loss: 13.3014\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 13.4086 - val_loss: 13.3419\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.3043 - val_loss: 13.6796\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 13.2773 - val_loss: 13.2437\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.1473 - val_loss: 13.2682\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 13.0354 - val_loss: 13.8879\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.0431 - val_loss: 13.8042\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9802 - val_loss: 13.2632\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.0935 - val_loss: 13.0222\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.7453 - val_loss: 13.3789\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.7787 - val_loss: 13.4485\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.6922 - val_loss: 12.6905\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.6698 - val_loss: 12.9687\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.5886 - val_loss: 12.6407\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.6048 - val_loss: 12.5348\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.4362 - val_loss: 12.4440\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.4278 - val_loss: 12.4924\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4689 - val_loss: 12.6630\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.3237 - val_loss: 12.9121\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.3407 - val_loss: 12.6288\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1918 - val_loss: 13.1085\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 36.0875 - val_loss: 28.9467\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 26.1884 - val_loss: 23.3958\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 22.8214 - val_loss: 21.7449\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 20.4725 - val_loss: 20.5013\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 19.2536 - val_loss: 18.9266\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.3179 - val_loss: 18.8503\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.3759 - val_loss: 17.1641\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.0305 - val_loss: 16.4182\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.6302 - val_loss: 16.1256\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.1813 - val_loss: 15.6970\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.6083 - val_loss: 15.4922\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.4056 - val_loss: 15.5133\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 14.7673 - val_loss: 14.5840\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.6231 - val_loss: 14.3200\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 14.3115 - val_loss: 13.9452\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.9583 - val_loss: 13.9565\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.8614 - val_loss: 14.1135\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 13.6066 - val_loss: 13.2932\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 13.3692 - val_loss: 13.0983\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 13.2082 - val_loss: 12.9568\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.0389 - val_loss: 12.8814\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.8078 - val_loss: 12.6681\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.7813 - val_loss: 13.1333\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.5821 - val_loss: 12.3912\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.3897 - val_loss: 12.5550\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.3830 - val_loss: 12.7577\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.2798 - val_loss: 12.2289\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.4178 - val_loss: 12.2560\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0205 - val_loss: 11.9059\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.9468 - val_loss: 12.0234\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.7216 - val_loss: 11.6531\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.8320 - val_loss: 11.9023\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6140 - val_loss: 12.6389\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7045 - val_loss: 11.4683\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.4629 - val_loss: 11.3366\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5103 - val_loss: 13.3470\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4339 - val_loss: 11.8945\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1988 - val_loss: 11.9446\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 11.2288 - val_loss: 11.3679\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.2544 - val_loss: 12.2639\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 40.3831 - val_loss: 31.6816\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 28.1269 - val_loss: 25.5257\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 25.3337 - val_loss: 23.7866\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 24.0520 - val_loss: 22.4754\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 22.4137 - val_loss: 21.2115\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 21.2612 - val_loss: 21.6481\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 20.5064 - val_loss: 19.9553\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 19.8917 - val_loss: 19.0715\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 19.0721 - val_loss: 18.1362\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 18.5668 - val_loss: 17.8549\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 17.9780 - val_loss: 17.6578\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.4505 - val_loss: 17.0762\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 17.1056 - val_loss: 16.7825\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.9108 - val_loss: 17.2011\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.5507 - val_loss: 17.0368\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.1166 - val_loss: 17.8130\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.9911 - val_loss: 15.8580\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.6923 - val_loss: 15.9680\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.6891 - val_loss: 15.5268\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.3495 - val_loss: 15.0606\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.1800 - val_loss: 14.7598\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8680 - val_loss: 16.5617\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8404 - val_loss: 14.4147\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.6914 - val_loss: 15.4335\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.6054 - val_loss: 15.2197\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.4876 - val_loss: 14.3600\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 14.5234 - val_loss: 13.9231\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.2605 - val_loss: 13.7548\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.0770 - val_loss: 13.8779\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.1297 - val_loss: 14.3791\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 435us/step - loss: 13.9436 - val_loss: 14.0182\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 435us/step - loss: 13.8215 - val_loss: 13.7178\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 13.7467 - val_loss: 14.0281\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 13.6621 - val_loss: 13.7534\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 13.5575 - val_loss: 13.7434\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 13.5116 - val_loss: 13.4003\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 13.4932 - val_loss: 13.7861\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 13.5064 - val_loss: 13.3195\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 13.3702 - val_loss: 13.1325\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.2199 - val_loss: 13.0486\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.1653 - val_loss: 13.0916\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 13.1509 - val_loss: 13.0153\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.1152 - val_loss: 13.2700\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.0741 - val_loss: 12.9092\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.0933 - val_loss: 13.4198\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.9115 - val_loss: 12.9706\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8905 - val_loss: 12.7945\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.7817 - val_loss: 12.6458\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.6980 - val_loss: 13.4594\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.8337 - val_loss: 12.9670\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.7330 - val_loss: 13.2547\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.6407 - val_loss: 12.5664\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.7135 - val_loss: 12.4490\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.4776 - val_loss: 12.6378\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.5474 - val_loss: 12.7115\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.5653 - val_loss: 13.5487\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.5634 - val_loss: 12.5472\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.4093 - val_loss: 12.4841\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 39.5282 - val_loss: 29.9939\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 28.1189 - val_loss: 25.2977\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 24.0847 - val_loss: 23.8883\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 21.8959 - val_loss: 29.2463\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.2567 - val_loss: 20.1787\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 19.0737 - val_loss: 17.9896\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.0149 - val_loss: 17.7587\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.2903 - val_loss: 16.8193\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.7207 - val_loss: 16.1076\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.1777 - val_loss: 17.5035\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.7885 - val_loss: 16.2535\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.3632 - val_loss: 15.7351\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.0904 - val_loss: 14.7786\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.7146 - val_loss: 15.4473\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.5881 - val_loss: 14.2740\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.1777 - val_loss: 14.4932\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 14.0998 - val_loss: 14.1310\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 13.8615 - val_loss: 13.7219\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 13.6786 - val_loss: 13.6749\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.5116 - val_loss: 13.3723\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 13.3214 - val_loss: 13.4502\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 13.3924 - val_loss: 13.1599\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.9904 - val_loss: 13.0045\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.0228 - val_loss: 12.9727\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.9367 - val_loss: 12.9787\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.7005 - val_loss: 13.4689\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.6435 - val_loss: 12.6419\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5224 - val_loss: 12.8366\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5096 - val_loss: 12.7005\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.3968 - val_loss: 12.6205\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.2606 - val_loss: 12.4241\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.1605 - val_loss: 12.3382\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.1807 - val_loss: 12.1341\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.9901 - val_loss: 12.3831\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.9099 - val_loss: 12.0378\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8936 - val_loss: 12.0515\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8341 - val_loss: 12.0197\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.8051 - val_loss: 11.7663\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.7017 - val_loss: 11.6738\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.8608 - val_loss: 11.9017\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.4967 - val_loss: 11.6455\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.4748 - val_loss: 11.5992\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4095 - val_loss: 11.7235\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.3600 - val_loss: 11.5876\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.3759 - val_loss: 11.4949\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.3088 - val_loss: 11.5811\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3773 - val_loss: 11.4484\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1422 - val_loss: 11.3978\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.1783 - val_loss: 11.4381\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.1173 - val_loss: 11.4302\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.1562 - val_loss: 11.6875\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.0163 - val_loss: 11.4602\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0345 - val_loss: 11.2102\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.1675 - val_loss: 11.2922\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.8414 - val_loss: 11.0564\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8258 - val_loss: 11.1518\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.8129 - val_loss: 11.0136\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7757 - val_loss: 11.2660\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.7564 - val_loss: 11.0286\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7638 - val_loss: 11.1447\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7382 - val_loss: 10.9302\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 10.6995 - val_loss: 11.0081\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6324 - val_loss: 10.9577\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.6456 - val_loss: 11.0393\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.5462 - val_loss: 10.8505\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6258 - val_loss: 10.8449\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5337 - val_loss: 10.9793\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.5533 - val_loss: 10.9730\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.4720 - val_loss: 10.8664\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4175 - val_loss: 10.8159\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4171 - val_loss: 10.8581\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.3322 - val_loss: 10.8201\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4846 - val_loss: 10.8698\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.4914 - val_loss: 11.5261\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 427us/step - loss: 10.3132 - val_loss: 10.6400\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.2846 - val_loss: 10.6586\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 10.3217 - val_loss: 10.6597\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 10.3143 - val_loss: 10.6380\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 10.3008 - val_loss: 10.7107\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 10.2009 - val_loss: 10.9335\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 10.1874 - val_loss: 10.6677\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.1783 - val_loss: 10.5703\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 10.2036 - val_loss: 11.0642\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.2012 - val_loss: 10.6858\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.1048 - val_loss: 10.5903\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.1219 - val_loss: 11.0064\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.0953 - val_loss: 10.5785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 36.7897 - val_loss: 25.7015\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 23.6822 - val_loss: 21.8986\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 21.0270 - val_loss: 20.5251\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 19.2532 - val_loss: 18.5240\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 17.9479 - val_loss: 17.3109\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 17.2288 - val_loss: 16.5802\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.3515 - val_loss: 15.5953\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.6846 - val_loss: 15.2427\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 15.1567 - val_loss: 15.5890\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.7725 - val_loss: 14.1299\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.3144 - val_loss: 14.4981\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9949 - val_loss: 13.3289\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.5836 - val_loss: 13.3547\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3110 - val_loss: 13.5685\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.0179 - val_loss: 13.0470\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 12.8737 - val_loss: 13.0946\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.7391 - val_loss: 12.7292\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.3991 - val_loss: 11.9175\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.3820 - val_loss: 14.4646\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.2296 - val_loss: 11.9807\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.8833 - val_loss: 11.5795\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.7970 - val_loss: 11.5315\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.7792 - val_loss: 11.7431\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.6357 - val_loss: 11.7341\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6049 - val_loss: 11.3477\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.3999 - val_loss: 11.2455\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3836 - val_loss: 11.7603\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2896 - val_loss: 11.7119\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.0949 - val_loss: 10.8941\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.1962 - val_loss: 11.0734\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.9297 - val_loss: 10.8782\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.9015 - val_loss: 11.4823\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.9251 - val_loss: 10.6135\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.8421 - val_loss: 11.1352\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8471 - val_loss: 10.5412\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.6417 - val_loss: 10.7164\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.6279 - val_loss: 10.5859\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6387 - val_loss: 10.3327\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.5957 - val_loss: 10.7872\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5111 - val_loss: 10.7919\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.4977 - val_loss: 10.5563\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.3703 - val_loss: 10.8238\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.5619 - val_loss: 10.5930\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 37.9171 - val_loss: 29.5097\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 27.7171 - val_loss: 25.7297\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 24.7451 - val_loss: 23.3088\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 23.2136 - val_loss: 23.4291\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 22.0130 - val_loss: 22.7190\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 21.2797 - val_loss: 21.0694\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 20.6810 - val_loss: 20.0532\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 20.2238 - val_loss: 19.5293\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.7280 - val_loss: 19.1183\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 19.3641 - val_loss: 18.9979\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.9725 - val_loss: 19.2398\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 18.8628 - val_loss: 18.3234\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 18.2403 - val_loss: 18.0701\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 17.9351 - val_loss: 17.8927\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.5677 - val_loss: 17.8352\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.3514 - val_loss: 17.1359\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.0851 - val_loss: 16.7373\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.8909 - val_loss: 16.5383\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 16.5840 - val_loss: 18.1784\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 16.4875 - val_loss: 16.6633\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 16.2326 - val_loss: 18.0417\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.2653 - val_loss: 16.1869\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.0147 - val_loss: 16.5001\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.0121 - val_loss: 15.8836\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.7487 - val_loss: 15.9704\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.7162 - val_loss: 15.6883\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.6110 - val_loss: 17.8241\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.5495 - val_loss: 16.0569\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.4600 - val_loss: 15.7855\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.3934 - val_loss: 15.7922\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.2866 - val_loss: 15.4284\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.2688 - val_loss: 15.7759\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.1874 - val_loss: 15.5555\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.2022 - val_loss: 15.1664\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.0725 - val_loss: 15.6978\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.0823 - val_loss: 15.0941\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.9465 - val_loss: 15.0851\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8680 - val_loss: 14.9966\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.8737 - val_loss: 15.1262\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.8565 - val_loss: 15.0242\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.7407 - val_loss: 14.7071\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.6836 - val_loss: 14.8092\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.7041 - val_loss: 14.9554\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.6558 - val_loss: 14.7019\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 410us/step - loss: 14.6577 - val_loss: 14.7488\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 14.5376 - val_loss: 14.6768\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 14.5151 - val_loss: 14.5077\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 14.5072 - val_loss: 14.8432\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 14.4288 - val_loss: 14.6431\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 14.5740 - val_loss: 14.6404\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 14.3488 - val_loss: 14.4680\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.3674 - val_loss: 14.3355\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 3s 665us/step - loss: 14.3009 - val_loss: 14.8234\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 3s 658us/step - loss: 14.2915 - val_loss: 14.2250\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 3s 652us/step - loss: 14.2668 - val_loss: 14.4804\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 3s 658us/step - loss: 14.2335 - val_loss: 14.4239\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 14.2185 - val_loss: 14.1332\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 14.1919 - val_loss: 14.2209\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.1176 - val_loss: 14.2788\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.0845 - val_loss: 14.0799\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 14.1678 - val_loss: 14.1370\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.0995 - val_loss: 14.8503\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.9810 - val_loss: 14.2444\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.0124 - val_loss: 14.3113\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.9944 - val_loss: 14.0065\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.9584 - val_loss: 14.1655\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.9609 - val_loss: 13.9973\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8518 - val_loss: 14.1821\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8830 - val_loss: 14.1017\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8294 - val_loss: 14.3589\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.8300 - val_loss: 13.9085\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.8658 - val_loss: 13.9779\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.7403 - val_loss: 14.0086\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.8649 - val_loss: 14.0714\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.7351 - val_loss: 13.8388\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6830 - val_loss: 13.9528\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.7072 - val_loss: 14.0417\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.6847 - val_loss: 14.0121\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.6237 - val_loss: 13.9915\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.6136 - val_loss: 13.8442\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 36.0268 - val_loss: 27.6559\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 25.0743 - val_loss: 22.6956\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 22.3207 - val_loss: 22.1302\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 20.5214 - val_loss: 20.5455\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 19.2016 - val_loss: 18.4267\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 18.5478 - val_loss: 17.2212\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 17.6936 - val_loss: 18.0460\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 17.1003 - val_loss: 17.3869\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.4331 - val_loss: 16.5432\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.9999 - val_loss: 16.8105\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 15.5997 - val_loss: 14.9190\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.2648 - val_loss: 15.0147\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.1126 - val_loss: 14.5811\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.8437 - val_loss: 14.1706\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.4199 - val_loss: 14.1561\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 14.5277 - val_loss: 14.5662\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.1927 - val_loss: 14.0504\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 14.1347 - val_loss: 13.4917\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.9854 - val_loss: 13.4710\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.6859 - val_loss: 13.2837\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.5705 - val_loss: 14.3965\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.4614 - val_loss: 13.0310\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2044 - val_loss: 13.2592\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.1762 - val_loss: 12.9351\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3605 - val_loss: 12.9005\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.9093 - val_loss: 13.8157\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.9120 - val_loss: 13.1290\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8367 - val_loss: 13.0462\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.6890 - val_loss: 12.8410\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.6452 - val_loss: 12.3237\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 474us/step - loss: 12.5739 - val_loss: 12.9315\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.5250 - val_loss: 12.1177\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4789 - val_loss: 12.6306\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2992 - val_loss: 12.3430\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.3776 - val_loss: 12.1134\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.3296 - val_loss: 12.4987\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.2205 - val_loss: 12.5231\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.2018 - val_loss: 12.0120\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0919 - val_loss: 12.0052\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.0819 - val_loss: 11.8754\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.0109 - val_loss: 12.0256\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.9593 - val_loss: 11.7485\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.8980 - val_loss: 11.8772\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.8539 - val_loss: 12.1396\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.8448 - val_loss: 12.0025\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.9626 - val_loss: 11.6266\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.6933 - val_loss: 11.7490\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6828 - val_loss: 11.6888\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.7083 - val_loss: 11.8353\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6360 - val_loss: 11.5337\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.6415 - val_loss: 11.5131\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5746 - val_loss: 11.7021\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6092 - val_loss: 11.6644\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5528 - val_loss: 11.7311\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.5005 - val_loss: 11.4376\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.4773 - val_loss: 11.5914\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4383 - val_loss: 11.6488\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4385 - val_loss: 11.5757\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.3668 - val_loss: 11.2969\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.3828 - val_loss: 11.5531\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 401us/step - loss: 11.3248 - val_loss: 11.3512\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 432us/step - loss: 11.3733 - val_loss: 11.4271\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 11.3133 - val_loss: 11.7151\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 11.2764 - val_loss: 11.1072\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 11.1900 - val_loss: 11.2846\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 11.2702 - val_loss: 11.2666\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.2461 - val_loss: 11.2874\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.1562 - val_loss: 11.2224\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.2226 - val_loss: 11.0448\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0873 - val_loss: 11.0751\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.1065 - val_loss: 11.2555\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.1007 - val_loss: 11.3156\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.0669 - val_loss: 11.0820\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0291 - val_loss: 11.6155\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 39.6608 - val_loss: 29.9800\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 23.6960 - val_loss: 20.8726\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 20.5668 - val_loss: 18.8284\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 18.8903 - val_loss: 17.9769\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 17.6857 - val_loss: 16.2806\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 16.7582 - val_loss: 15.5913\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.1234 - val_loss: 15.0531\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 15.1979 - val_loss: 15.4718\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 14.8867 - val_loss: 13.9948\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 14.1430 - val_loss: 13.5544\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.7550 - val_loss: 13.9711\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.5805 - val_loss: 13.0934\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.2491 - val_loss: 14.0217\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.8548 - val_loss: 12.4192\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5442 - val_loss: 12.3256\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.3923 - val_loss: 13.4691\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.3086 - val_loss: 12.0337\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 12.0195 - val_loss: 12.5089\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 12.0073 - val_loss: 12.2263\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.6602 - val_loss: 11.5656\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.6814 - val_loss: 11.2574\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.5032 - val_loss: 11.4392\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.4216 - val_loss: 11.4633\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.3662 - val_loss: 11.3462\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2147 - val_loss: 10.9962\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1083 - val_loss: 11.2367\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.1407 - val_loss: 11.0155\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.0036 - val_loss: 12.7399\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9190 - val_loss: 10.9273\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.8667 - val_loss: 10.7910\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 10.8345 - val_loss: 10.6164\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 10.7466 - val_loss: 10.7369\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 10.7084 - val_loss: 10.5312\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.6887 - val_loss: 10.8430\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 10.5873 - val_loss: 10.8523\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 10.5745 - val_loss: 12.7398\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.4735 - val_loss: 10.6080\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.6269 - val_loss: 10.3766\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.7932 - val_loss: 10.2426\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.2589 - val_loss: 10.1795\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.2967 - val_loss: 10.4010\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.2717 - val_loss: 10.2343\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.2305 - val_loss: 10.2103\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.1875 - val_loss: 10.4693\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.2669 - val_loss: 10.4373\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 34.0485 - val_loss: 23.2911\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 20.6774 - val_loss: 18.8695\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.1181 - val_loss: 16.8494\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 16.6633 - val_loss: 16.3940\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.8721 - val_loss: 15.0176\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.2735 - val_loss: 14.5567\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 14.5338 - val_loss: 13.8279\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.0945 - val_loss: 13.5905\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.6656 - val_loss: 13.4524\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 13.4106 - val_loss: 12.7749\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.0891 - val_loss: 13.5866\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9195 - val_loss: 12.5713\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.5821 - val_loss: 12.4668\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.4301 - val_loss: 12.2273\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.1795 - val_loss: 12.0273\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.0953 - val_loss: 11.5910\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8225 - val_loss: 11.7310\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.6734 - val_loss: 12.2487\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.5398 - val_loss: 11.1875\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.2755 - val_loss: 10.9001\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2598 - val_loss: 11.6514\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.0557 - val_loss: 10.9695\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.0115 - val_loss: 10.9610\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.7508 - val_loss: 10.5457\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 10.7655 - val_loss: 10.5035\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.5512 - val_loss: 11.3364\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.5858 - val_loss: 10.2920\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 10.2876 - val_loss: 10.3743\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.3980 - val_loss: 10.1346\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.4489 - val_loss: 10.1558\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.0609 - val_loss: 9.9214\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 10.1550 - val_loss: 9.7612\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.8429 - val_loss: 10.2757\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.9206 - val_loss: 9.6353\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 9.8146 - val_loss: 9.5705\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.7413 - val_loss: 9.6249\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.7457 - val_loss: 10.7150\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.5560 - val_loss: 9.3211\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.8030 - val_loss: 9.6709\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.4181 - val_loss: 10.1976\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.4483 - val_loss: 10.0401\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.4763 - val_loss: 10.4511\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 395us/step - loss: 9.4815 - val_loss: 10.0715\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 38.3923 - val_loss: 29.2529\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 26.0487 - val_loss: 22.5747\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 21.6263 - val_loss: 23.2726\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 19.1002 - val_loss: 19.0445\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 17.7579 - val_loss: 17.1398\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 16.5856 - val_loss: 17.3144\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 15.7143 - val_loss: 15.1230\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 15.1426 - val_loss: 15.9517\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 14.6762 - val_loss: 14.6131\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 14.3812 - val_loss: 14.8491\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 1s 355us/step - loss: 13.8275 - val_loss: 13.3224\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 1s 335us/step - loss: 13.4447 - val_loss: 13.6515\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 416us/step - loss: 13.3427 - val_loss: 13.6499\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 13.0579 - val_loss: 13.8187\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.0104 - val_loss: 12.6490\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 439us/step - loss: 12.7059 - val_loss: 12.5076\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.5542 - val_loss: 12.3870\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.3348 - val_loss: 13.2978\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.3633 - val_loss: 12.1195\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.1832 - val_loss: 12.2348\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.2333 - val_loss: 11.9117\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.7866 - val_loss: 11.6070\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.7285 - val_loss: 11.9011\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.6982 - val_loss: 11.5350\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.4871 - val_loss: 11.9699\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.4777 - val_loss: 11.5354\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.4245 - val_loss: 11.3355\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 11.1749 - val_loss: 11.0122\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.1078 - val_loss: 11.4888\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.0171 - val_loss: 11.4283\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.8958 - val_loss: 11.1870\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.8552 - val_loss: 10.7415\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 464us/step - loss: 10.8492 - val_loss: 10.7100\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 10.6631 - val_loss: 10.5782\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.6531 - val_loss: 10.4607\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.5204 - val_loss: 10.6156\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.4875 - val_loss: 10.2544\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 10.4358 - val_loss: 10.3266\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 10.2709 - val_loss: 10.3324\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.1995 - val_loss: 10.2375\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 10.3186 - val_loss: 10.4227\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 10.1456 - val_loss: 10.2886\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 10.2125 - val_loss: 10.1964\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.0913 - val_loss: 10.2619\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 10.0010 - val_loss: 9.9303\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 10.0369 - val_loss: 10.0284\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 9.8634 - val_loss: 9.9613\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 462us/step - loss: 9.9941 - val_loss: 10.1667\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 460us/step - loss: 9.8434 - val_loss: 9.8237\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 463us/step - loss: 9.8028 - val_loss: 9.8639\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.7543 - val_loss: 9.9370\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.7607 - val_loss: 9.8142\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 437us/step - loss: 9.7091 - val_loss: 9.9177\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 9.6495 - val_loss: 9.9790\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.5876 - val_loss: 9.6381\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.5547 - val_loss: 9.6431\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.5372 - val_loss: 9.6124\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.5364 - val_loss: 10.8899\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 9.4782 - val_loss: 10.0595\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.5062 - val_loss: 9.8673\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.4805 - val_loss: 9.8287\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.3340 - val_loss: 10.0726\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 38.1639 - val_loss: 26.6360\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 23.9526 - val_loss: 21.8422\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 20.8678 - val_loss: 19.6498\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.6638 - val_loss: 19.4824\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 18.7246 - val_loss: 18.7373\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.0089 - val_loss: 17.7147\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 17.4068 - val_loss: 18.1481\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.8993 - val_loss: 16.3016\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 16.4578 - val_loss: 15.9613\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.0481 - val_loss: 15.8220\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.9070 - val_loss: 15.3844\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 15.3509 - val_loss: 14.9759\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 15.0719 - val_loss: 15.4192\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.7667 - val_loss: 14.3753\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 14.5442 - val_loss: 14.5638\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.3849 - val_loss: 14.5658\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.0899 - val_loss: 13.9185\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 14.0820 - val_loss: 14.4273\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.8482 - val_loss: 14.4397\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.6901 - val_loss: 13.9659\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 13.3876 - val_loss: 13.5198\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 13.2907 - val_loss: 12.9824\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 13.2470 - val_loss: 13.0849\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.1179 - val_loss: 12.8990\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.0072 - val_loss: 12.7656\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.8725 - val_loss: 13.2879\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.7185 - val_loss: 12.7275\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.7112 - val_loss: 12.8448\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.5453 - val_loss: 12.6899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 12.4294 - val_loss: 14.7801\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.5104 - val_loss: 12.5929\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.2814 - val_loss: 14.1559\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.2527 - val_loss: 12.1691\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.1992 - val_loss: 12.4868\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.1047 - val_loss: 12.2404\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.1072 - val_loss: 12.1106\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.0148 - val_loss: 11.9675\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 11.8933 - val_loss: 12.3152\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 397us/step - loss: 11.8300 - val_loss: 12.4793\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 436us/step - loss: 11.7755 - val_loss: 11.9641\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 11.6799 - val_loss: 11.9437\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 11.7759 - val_loss: 11.7796\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 11.6968 - val_loss: 12.4104\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 11.5607 - val_loss: 11.6675\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 11.5106 - val_loss: 11.5469\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 11.4863 - val_loss: 11.5362\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.4242 - val_loss: 11.3093\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4367 - val_loss: 11.6685\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 11.2712 - val_loss: 12.0744\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.3323 - val_loss: 11.9922\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.2593 - val_loss: 11.9784\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.1307 - val_loss: 12.1798\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 35.0661 - val_loss: 24.5703\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 22.2304 - val_loss: 19.9713\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 19.7636 - val_loss: 18.3821\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.8537 - val_loss: 17.3920\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 16.6431 - val_loss: 16.6353\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 15.8910 - val_loss: 15.7489\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.1442 - val_loss: 15.0756\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.7243 - val_loss: 14.3306\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.1819 - val_loss: 14.0847\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.9715 - val_loss: 14.1484\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 13.5369 - val_loss: 14.6468\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.5904 - val_loss: 13.2105\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.9489 - val_loss: 12.7172\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 12.8852 - val_loss: 12.6238\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.6334 - val_loss: 12.6999\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 12.5622 - val_loss: 12.1740\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.2475 - val_loss: 12.5395\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 12.0128 - val_loss: 11.7657\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.9284 - val_loss: 11.8712\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 12.0481 - val_loss: 11.7028\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 11.6718 - val_loss: 11.6051\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.6686 - val_loss: 12.4645\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.4138 - val_loss: 11.4908\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 11.4295 - val_loss: 12.2177\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 11.0850 - val_loss: 11.0452\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 11.0688 - val_loss: 11.3822\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 10.9598 - val_loss: 11.1464\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8430 - val_loss: 10.8162\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 10.8314 - val_loss: 10.6972\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 10.6764 - val_loss: 10.9946\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.6179 - val_loss: 10.4692\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.4305 - val_loss: 10.4732\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.3516 - val_loss: 10.7266\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.3110 - val_loss: 10.1895\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.3193 - val_loss: 10.6611\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 10.2133 - val_loss: 11.7580\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.0756 - val_loss: 10.1443\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.9833 - val_loss: 9.9174\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.0450 - val_loss: 10.8508\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.7972 - val_loss: 9.9192\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.9660 - val_loss: 9.8244\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.8297 - val_loss: 9.8850\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.7802 - val_loss: 9.7770\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 9.6161 - val_loss: 9.8147\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.6434 - val_loss: 9.5367\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.5690 - val_loss: 10.0126\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.5321 - val_loss: 9.4831\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.6283 - val_loss: 9.5581\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.4846 - val_loss: 9.5414\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.3723 - val_loss: 10.3006\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 9.4435 - val_loss: 9.4946\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.2514 - val_loss: 9.4449\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.3140 - val_loss: 9.4132\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.3406 - val_loss: 9.4666\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.2105 - val_loss: 9.4315\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 9.1881 - val_loss: 9.1977\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 9.1779 - val_loss: 9.6269\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.1903 - val_loss: 9.1057\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 9.1348 - val_loss: 9.2408\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 9.0477 - val_loss: 10.1565\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 9.0736 - val_loss: 9.0997\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 9.0521 - val_loss: 9.3361\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 8.9993 - val_loss: 9.2661\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 9.0206 - val_loss: 9.0156\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 439us/step - loss: 8.8543 - val_loss: 9.0996\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 8.9181 - val_loss: 9.0178\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 8.9279 - val_loss: 9.2123\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 440us/step - loss: 8.8772 - val_loss: 9.2440\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 8.8932 - val_loss: 9.0312\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 42.0483 - val_loss: 30.3191\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 441us/step - loss: 27.8507 - val_loss: 25.6386\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 24.9392 - val_loss: 23.4522\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 23.1171 - val_loss: 23.7273\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 21.9411 - val_loss: 20.9984\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.5541 - val_loss: 21.2961\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 20.0555 - val_loss: 19.3724\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 19.2953 - val_loss: 19.9289\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 18.5017 - val_loss: 18.4075\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.4613 - val_loss: 17.5281\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.7640 - val_loss: 17.1410\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 17.4470 - val_loss: 16.7859\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 17.1507 - val_loss: 17.4852\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 16.7364 - val_loss: 16.1670\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.2114 - val_loss: 15.9664\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 16.1380 - val_loss: 16.4512\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 15.9171 - val_loss: 15.6803\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 411us/step - loss: 15.6846 - val_loss: 15.8671\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 15.3965 - val_loss: 14.9918\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 15.3410 - val_loss: 15.0304\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 15.1251 - val_loss: 14.8845\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 477us/step - loss: 14.8479 - val_loss: 14.9420\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 14.8523 - val_loss: 14.5440\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 14.6940 - val_loss: 14.4316\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 14.6379 - val_loss: 14.4316\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.3649 - val_loss: 14.6005\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.2678 - val_loss: 14.1060\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 14.1813 - val_loss: 15.1741\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.9936 - val_loss: 14.2573\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.9232 - val_loss: 13.7833\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 13.9667 - val_loss: 13.7616\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.7520 - val_loss: 13.4697\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 13.6744 - val_loss: 13.9288\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.5736 - val_loss: 14.0024\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.4846 - val_loss: 13.6603\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.2683 - val_loss: 13.2096\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.4126 - val_loss: 13.5391\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.2157 - val_loss: 13.1853\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 13.3062 - val_loss: 13.1200\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.1236 - val_loss: 13.1156\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.0547 - val_loss: 13.0186\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.0049 - val_loss: 13.3361\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.9169 - val_loss: 13.0085\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 12.8919 - val_loss: 12.7494\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.8397 - val_loss: 13.2970\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.7672 - val_loss: 12.7077\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.9640 - val_loss: 12.6803\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.6301 - val_loss: 13.3525\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.6500 - val_loss: 12.7443\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 12.5755 - val_loss: 12.4922\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.4654 - val_loss: 12.8928\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 12.5225 - val_loss: 13.0145\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.5493 - val_loss: 12.6506\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 12.3411 - val_loss: 12.8322\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.3752 - val_loss: 12.7737\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 42.0929 - val_loss: 29.5886\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 26.0299 - val_loss: 23.0576\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 21.8814 - val_loss: 20.4177\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 452us/step - loss: 20.3310 - val_loss: 20.1553\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 19.1952 - val_loss: 20.0241\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 459us/step - loss: 18.2982 - val_loss: 17.4042\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 17.4257 - val_loss: 16.9324\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 16.5567 - val_loss: 16.7320\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 16.0843 - val_loss: 15.4700\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 15.4614 - val_loss: 15.7349\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 15.3460 - val_loss: 14.9132\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 14.7706 - val_loss: 14.9102\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 14.3658 - val_loss: 14.3622\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.2611 - val_loss: 15.1236\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 14.0877 - val_loss: 13.8232\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.6651 - val_loss: 14.8312\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 13.6428 - val_loss: 13.5628\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 13.3165 - val_loss: 13.2270\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.1599 - val_loss: 13.2747\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.9135 - val_loss: 12.8643\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.8168 - val_loss: 12.7039\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.6276 - val_loss: 12.6959\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 12.4465 - val_loss: 12.6711\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.5333 - val_loss: 12.2568\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.2267 - val_loss: 12.3154\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 12.1159 - val_loss: 12.3463\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 12.0827 - val_loss: 12.1136\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.9773 - val_loss: 11.9845\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 11.9093 - val_loss: 11.9489\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 11.8086 - val_loss: 12.7007\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.6017 - val_loss: 11.6173\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.6416 - val_loss: 11.5453\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.5994 - val_loss: 11.6845\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.5373 - val_loss: 11.5275\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 11.3021 - val_loss: 11.5010\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 11.3757 - val_loss: 11.5160\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.3421 - val_loss: 11.2702\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 11.2407 - val_loss: 11.3695\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.1665 - val_loss: 11.3384\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 11.1281 - val_loss: 11.1645\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 11.0867 - val_loss: 11.2015\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.9608 - val_loss: 11.0647\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.9642 - val_loss: 11.3036\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.8989 - val_loss: 11.2185\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.9091 - val_loss: 11.0305\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 10.8119 - val_loss: 10.9450\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.9353 - val_loss: 10.8735\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.6637 - val_loss: 10.8796\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.6549 - val_loss: 10.7594\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.6741 - val_loss: 11.1003\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5905 - val_loss: 10.6627\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.6735 - val_loss: 10.9458\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5572 - val_loss: 10.5497\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.5310 - val_loss: 10.7541\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5203 - val_loss: 10.7411\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5578 - val_loss: 10.5492\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.4023 - val_loss: 10.6096\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.4162 - val_loss: 10.5249\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 478us/step - loss: 10.3660 - val_loss: 10.7343\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.3555 - val_loss: 11.1459\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 10.3508 - val_loss: 10.6502\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3413 - val_loss: 10.4973\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.2679 - val_loss: 10.6068\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 412us/step - loss: 10.3432 - val_loss: 10.5542\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 465us/step - loss: 10.2427 - val_loss: 10.4082\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 10.1281 - val_loss: 10.5185\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 10.2019 - val_loss: 10.2501\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 480us/step - loss: 10.1247 - val_loss: 10.6465\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 10.1549 - val_loss: 10.5314\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 10.1377 - val_loss: 10.7262\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 10.0212 - val_loss: 10.5192\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.0544 - val_loss: 10.4857\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 37.4569 - val_loss: 26.0138\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 438us/step - loss: 23.7343 - val_loss: 22.1753\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 19.5319 - val_loss: 18.3552\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.9481 - val_loss: 18.3441\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 17.0594 - val_loss: 16.6464\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 461us/step - loss: 16.5112 - val_loss: 15.8576\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 452us/step - loss: 15.7984 - val_loss: 15.1506\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 458us/step - loss: 15.3287 - val_loss: 14.7657\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 15.0993 - val_loss: 14.4441\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 14.6213 - val_loss: 14.3100\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 14.5018 - val_loss: 13.8115\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.9697 - val_loss: 14.1298\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 13.8517 - val_loss: 13.4584\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.6849 - val_loss: 13.6476\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 13.3531 - val_loss: 13.0306\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 13.2142 - val_loss: 13.0202\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 13.0904 - val_loss: 12.9939\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.8841 - val_loss: 12.9981\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.6942 - val_loss: 12.3722\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 12.6234 - val_loss: 12.9058\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 12.3906 - val_loss: 12.0956\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.1779 - val_loss: 12.5131\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 12.2611 - val_loss: 12.5796\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 12.1781 - val_loss: 12.3884\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 11.8910 - val_loss: 11.6977\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 11.7143 - val_loss: 11.7261\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.6739 - val_loss: 11.5214\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.5416 - val_loss: 11.3357\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.5100 - val_loss: 11.4050\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 11.3338 - val_loss: 11.4272\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 11.2529 - val_loss: 11.5147\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.1490 - val_loss: 11.3471\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 11.0960 - val_loss: 11.2805\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 11.0758 - val_loss: 11.1414\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 10.9735 - val_loss: 10.7371\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.8954 - val_loss: 11.1226\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.8424 - val_loss: 10.7569\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.9129 - val_loss: 10.7238\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 472us/step - loss: 10.6196 - val_loss: 10.6423\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 10.5683 - val_loss: 10.5573\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.5748 - val_loss: 10.7692\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 10.5215 - val_loss: 10.4986\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.4566 - val_loss: 11.2087\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 10.3570 - val_loss: 10.5665\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 10.3351 - val_loss: 10.3682\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 10.2189 - val_loss: 10.2944\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 10.2421 - val_loss: 10.2723\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 10.1668 - val_loss: 10.1691\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 457us/step - loss: 10.1562 - val_loss: 9.9510\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.0467 - val_loss: 10.1291\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 10.0056 - val_loss: 10.1546\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.9437 - val_loss: 10.2225\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 9.9229 - val_loss: 9.9803\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 455us/step - loss: 9.9308 - val_loss: 9.9365\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.8779 - val_loss: 10.0088\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 9.9474 - val_loss: 10.0614\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.7574 - val_loss: 9.9377\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.7972 - val_loss: 9.5710\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.6549 - val_loss: 9.6607\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.6102 - val_loss: 9.7924\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 9.5825 - val_loss: 9.5638\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.6075 - val_loss: 9.9609\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 9.6401 - val_loss: 9.7839\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 9.5240 - val_loss: 9.6703\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 9.4955 - val_loss: 9.5900\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 449us/step - loss: 9.5404 - val_loss: 9.6989\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 37.5469 - val_loss: 29.0343\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 27.6772 - val_loss: 25.6869\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 25.0711 - val_loss: 23.6730\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 23.4316 - val_loss: 22.6161\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 22.4260 - val_loss: 21.2852\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 21.2275 - val_loss: 20.6676\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 20.6205 - val_loss: 21.0562\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 19.9575 - val_loss: 19.3168\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 19.5238 - val_loss: 18.7163\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 444us/step - loss: 18.8706 - val_loss: 18.1369\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 18.5673 - val_loss: 18.1022\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 18.2592 - val_loss: 18.7291\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 450us/step - loss: 17.7957 - val_loss: 17.3819\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 448us/step - loss: 17.4880 - val_loss: 17.4618\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 17.3211 - val_loss: 17.0445\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 17.0861 - val_loss: 16.5055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.7970 - val_loss: 16.6176\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 446us/step - loss: 16.3420 - val_loss: 16.0220\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 16.3912 - val_loss: 16.0921\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 443us/step - loss: 16.1355 - val_loss: 15.9390\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 445us/step - loss: 15.9550 - val_loss: 16.2493\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 442us/step - loss: 15.7641 - val_loss: 16.1943\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.6866 - val_loss: 15.6417\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 403us/step - loss: 15.3845 - val_loss: 16.3995\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 447us/step - loss: 15.3705 - val_loss: 15.4661\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 593us/step - loss: 15.1581 - val_loss: 15.2834\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 3s 679us/step - loss: 15.1741 - val_loss: 14.8893\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 3s 637us/step - loss: 14.9169 - val_loss: 15.3005\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 3s 666us/step - loss: 14.8830 - val_loss: 14.9754\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 3s 668us/step - loss: 14.7849 - val_loss: 14.8272\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 3s 818us/step - loss: 14.8054 - val_loss: 15.6705\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 3s 634us/step - loss: 14.6303 - val_loss: 14.7248\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 14.5006 - val_loss: 14.4459\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 14.4407 - val_loss: 14.4155\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 14.4009 - val_loss: 14.5334\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 14.3783 - val_loss: 14.3972\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 14.3351 - val_loss: 14.4603\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 588us/step - loss: 14.1830 - val_loss: 14.0876\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 14.2368 - val_loss: 14.1141\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 14.0870 - val_loss: 14.0123\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 14.0537 - val_loss: 14.0053\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 14.0502 - val_loss: 14.0192\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.9673 - val_loss: 13.8796\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 13.9506 - val_loss: 14.0928\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 13.8693 - val_loss: 14.0004\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 13.8960 - val_loss: 14.5198\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 13.8587 - val_loss: 13.7766\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 13.7210 - val_loss: 14.2361\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.7222 - val_loss: 13.6518\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 13.8419 - val_loss: 14.4598\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 13.7398 - val_loss: 13.6516\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 13.6376 - val_loss: 13.5925\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 13.5430 - val_loss: 13.9440\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.5087 - val_loss: 13.6578\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 13.5223 - val_loss: 13.7237\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 13.4893 - val_loss: 13.4233\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.5860 - val_loss: 14.1350\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.4576 - val_loss: 13.7492\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 13.4658 - val_loss: 13.5685\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.3186 - val_loss: 13.4253\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 13.3297 - val_loss: 13.5079\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 626us/step - loss: 36.5196 - val_loss: 25.9622\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 24.6567 - val_loss: 21.7104\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 21.2153 - val_loss: 20.0550\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 19.5832 - val_loss: 18.7919\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 18.5730 - val_loss: 19.0794\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 17.8787 - val_loss: 18.1224\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 569us/step - loss: 17.1011 - val_loss: 16.5254\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 16.5910 - val_loss: 16.3585\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 573us/step - loss: 15.8433 - val_loss: 15.5926\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 567us/step - loss: 15.4178 - val_loss: 15.0447\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 15.0200 - val_loss: 16.1868\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 15.0596 - val_loss: 14.6596\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 14.6215 - val_loss: 14.0273\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 14.3319 - val_loss: 13.8521\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 14.1646 - val_loss: 13.5718\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 13.7886 - val_loss: 15.5166\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.8297 - val_loss: 13.4326\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 13.6345 - val_loss: 13.5715\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 13.4878 - val_loss: 13.9754\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 13.1592 - val_loss: 12.8622\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 12.9675 - val_loss: 12.7473\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 12.9144 - val_loss: 12.7850\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 12.7477 - val_loss: 12.7439\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 12.4938 - val_loss: 12.6708\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 12.5823 - val_loss: 12.4480\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 12.3716 - val_loss: 12.4501\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 581us/step - loss: 12.3039 - val_loss: 12.3644\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 560us/step - loss: 12.1213 - val_loss: 12.0600\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 12.0669 - val_loss: 12.2154\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 11.9216 - val_loss: 11.7802\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.9497 - val_loss: 12.0472\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.7864 - val_loss: 11.5215\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.6998 - val_loss: 11.7128\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.7419 - val_loss: 11.7313\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.5361 - val_loss: 11.3821\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.4736 - val_loss: 11.4029\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.3760 - val_loss: 11.4716\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.3251 - val_loss: 11.4944\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.3309 - val_loss: 11.4530\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.3251 - val_loss: 11.1571\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.1475 - val_loss: 11.0034\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.1417 - val_loss: 11.0586\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.0361 - val_loss: 10.9040\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.0330 - val_loss: 11.0298\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.9857 - val_loss: 10.9000\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.9146 - val_loss: 10.9565\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.9905 - val_loss: 11.1345\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8749 - val_loss: 10.8125\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8566 - val_loss: 11.6507\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.8106 - val_loss: 10.6373\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.7549 - val_loss: 10.6566\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.7373 - val_loss: 10.5210\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.6719 - val_loss: 10.6284\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.5630 - val_loss: 10.5584\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5962 - val_loss: 10.6908\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6095 - val_loss: 10.4694\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5226 - val_loss: 10.5458\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.5232 - val_loss: 10.6406\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.4649 - val_loss: 10.5036\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.4311 - val_loss: 10.3019\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.4302 - val_loss: 10.5583\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.3928 - val_loss: 10.2228\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.2963 - val_loss: 10.4719\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.4327 - val_loss: 10.1873\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 10.2320 - val_loss: 10.8161\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 10.2108 - val_loss: 10.4479\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 10.2663 - val_loss: 10.3142\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 10.2046 - val_loss: 10.2922\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 10.1258 - val_loss: 10.2106\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 590us/step - loss: 40.0223 - val_loss: 30.9410\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 27.8761 - val_loss: 24.0569\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 23.6431 - val_loss: 21.4207\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 20.9046 - val_loss: 19.8576\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 19.4270 - val_loss: 20.0665\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 18.4720 - val_loss: 17.4434\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 17.6016 - val_loss: 16.7583\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 16.8577 - val_loss: 16.1230\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.2217 - val_loss: 15.5529\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 15.7733 - val_loss: 16.5222\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 15.2139 - val_loss: 15.0376\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 14.8734 - val_loss: 15.6650\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.4902 - val_loss: 14.9814\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.2805 - val_loss: 13.7990\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.9573 - val_loss: 13.8035\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.9195 - val_loss: 13.3816\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.6601 - val_loss: 13.5384\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.4211 - val_loss: 12.9905\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.1245 - val_loss: 13.0576\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.9790 - val_loss: 12.8179\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.8947 - val_loss: 12.7097\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.7190 - val_loss: 12.5479\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.6262 - val_loss: 12.6978\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.4494 - val_loss: 12.9517\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.3919 - val_loss: 12.2599\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.3594 - val_loss: 12.2732\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.1529 - val_loss: 12.0500\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.0927 - val_loss: 12.0794\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9249 - val_loss: 11.8921\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.8899 - val_loss: 11.8656\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.8913 - val_loss: 14.2447\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.8187 - val_loss: 11.7622\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.8107 - val_loss: 11.6886\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.6376 - val_loss: 11.5471\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.4115 - val_loss: 11.4538\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 11.5326 - val_loss: 11.5286\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 522us/step - loss: 11.2882 - val_loss: 11.2154\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 11.3354 - val_loss: 11.6051\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 11.2018 - val_loss: 11.1805\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 11.3458 - val_loss: 11.1018\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 11.1372 - val_loss: 11.2649\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 11.1317 - val_loss: 11.8822\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 11.0224 - val_loss: 11.3138\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.9500 - val_loss: 11.2671\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.0004 - val_loss: 11.3083\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 588us/step - loss: 36.4293 - val_loss: 23.9261\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 22.0785 - val_loss: 21.3152\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 19.3977 - val_loss: 18.7173\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 18.0551 - val_loss: 17.8542\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 17.1857 - val_loss: 17.7743\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 16.7274 - val_loss: 16.3723\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 16.2999 - val_loss: 15.3909\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.5661 - val_loss: 15.2456\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.2198 - val_loss: 14.7308\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 15.0297 - val_loss: 14.3283\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.6641 - val_loss: 14.0767\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 14.4112 - val_loss: 14.2458\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.2297 - val_loss: 13.7769\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.8646 - val_loss: 13.4793\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.8643 - val_loss: 13.7404\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.4291 - val_loss: 13.3543\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.5173 - val_loss: 14.1275\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 13.2094 - val_loss: 12.8138\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.9038 - val_loss: 13.0956\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8909 - val_loss: 12.5791\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.6323 - val_loss: 12.4171\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.5721 - val_loss: 12.7776\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.4071 - val_loss: 12.1409\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.4203 - val_loss: 12.0763\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.1611 - val_loss: 12.6592\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.2439 - val_loss: 11.7924\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.0210 - val_loss: 12.0423\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.8784 - val_loss: 11.4728\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.7948 - val_loss: 11.4860\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.6647 - val_loss: 11.7374\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.4830 - val_loss: 11.6380\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.5350 - val_loss: 11.3766\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.4127 - val_loss: 11.4657\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.3575 - val_loss: 11.3439\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.4405 - val_loss: 11.0522\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.1265 - val_loss: 11.1666\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.0488 - val_loss: 11.3376\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.0601 - val_loss: 11.5769\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.8642 - val_loss: 10.9658\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.8946 - val_loss: 11.1905\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.8662 - val_loss: 10.5204\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.7941 - val_loss: 10.5327\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.8000 - val_loss: 10.9093\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.8467 - val_loss: 10.5374\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6205 - val_loss: 10.5863\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.5603 - val_loss: 10.4827\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.4437 - val_loss: 10.4216\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 10.4813 - val_loss: 10.4492\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 10.3445 - val_loss: 10.6172\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 10.4626 - val_loss: 10.2703\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 10.4249 - val_loss: 10.5198\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 10.3635 - val_loss: 10.5912\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 10.2517 - val_loss: 10.1517\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 584us/step - loss: 10.2730 - val_loss: 9.9975\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 3s 636us/step - loss: 10.1444 - val_loss: 10.2820\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 10.0103 - val_loss: 10.2257\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.1079 - val_loss: 10.0788\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.1046 - val_loss: 10.1558\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.0435 - val_loss: 10.1490\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 611us/step - loss: 38.2559 - val_loss: 28.0082\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 26.0949 - val_loss: 23.1062\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 569us/step - loss: 22.4007 - val_loss: 21.2550\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 3s 617us/step - loss: 20.4716 - val_loss: 19.6834\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 19.2709 - val_loss: 18.4688\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 18.1849 - val_loss: 18.1347\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 17.6706 - val_loss: 18.0653\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 516us/step - loss: 16.8054 - val_loss: 16.8007\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.2186 - val_loss: 16.7139\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.0066 - val_loss: 16.0473\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.3832 - val_loss: 15.2079\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 14.7850 - val_loss: 14.4183\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.5047 - val_loss: 14.2404\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.1406 - val_loss: 14.3431\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 13.9338 - val_loss: 13.9906\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 13.5927 - val_loss: 13.4590\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 13.5077 - val_loss: 13.7638\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 13.1589 - val_loss: 12.9629\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 13.0504 - val_loss: 13.2717\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.8296 - val_loss: 12.8119\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.6570 - val_loss: 13.1422\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 12.6378 - val_loss: 12.5834\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.4246 - val_loss: 12.4076\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.2822 - val_loss: 12.2516\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 12.1359 - val_loss: 12.2865\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 12.0072 - val_loss: 12.3480\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.9265 - val_loss: 12.0841\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.8610 - val_loss: 11.8489\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.6472 - val_loss: 11.6071\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.7254 - val_loss: 11.6622\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.5226 - val_loss: 11.7419\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.4530 - val_loss: 14.1423\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 11.3927 - val_loss: 11.3466\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 11.2495 - val_loss: 11.2993\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 11.1900 - val_loss: 11.5891\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 11.3260 - val_loss: 11.4268\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 11.0474 - val_loss: 11.2368\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 10.9119 - val_loss: 11.2365\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.0748 - val_loss: 11.0075\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.8438 - val_loss: 11.2256\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.8546 - val_loss: 10.9081\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.7302 - val_loss: 10.6780\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.7317 - val_loss: 10.8607\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.6034 - val_loss: 10.6566\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.5828 - val_loss: 10.7661\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.5225 - val_loss: 10.8765\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 10.6149 - val_loss: 10.5065\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.4022 - val_loss: 10.5595\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.3801 - val_loss: 10.4896\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.2792 - val_loss: 10.5447\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.3170 - val_loss: 10.4525\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.2860 - val_loss: 10.5306\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.1794 - val_loss: 10.3338\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.1366 - val_loss: 10.2664\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.1750 - val_loss: 10.6520\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.2816 - val_loss: 10.4672\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.1066 - val_loss: 10.2340\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.9486 - val_loss: 10.2245\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.9180 - val_loss: 10.4563\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.9653 - val_loss: 10.2874\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.9147 - val_loss: 10.1240\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.0137 - val_loss: 10.5797\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.8395 - val_loss: 10.2009\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.8346 - val_loss: 9.9866\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.8774 - val_loss: 10.1836\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.8198 - val_loss: 10.0601\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 9.7563 - val_loss: 10.0842\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 9.7248 - val_loss: 10.2226\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.7673 - val_loss: 10.2726\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 599us/step - loss: 38.9205 - val_loss: 29.6928\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 26.4590 - val_loss: 23.4497\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 22.8327 - val_loss: 21.7544\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 21.1909 - val_loss: 20.5916\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 19.9115 - val_loss: 19.3188\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 19.2480 - val_loss: 18.7211\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 18.5431 - val_loss: 18.1291\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 18.0019 - val_loss: 17.5597\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 17.6284 - val_loss: 17.3310\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 17.2705 - val_loss: 17.0325\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 16.9545 - val_loss: 16.8669\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 16.5800 - val_loss: 16.8280\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 16.2738 - val_loss: 16.2426\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 504us/step - loss: 16.1719 - val_loss: 16.5895\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.8056 - val_loss: 15.7189\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.5612 - val_loss: 15.5921\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.2567 - val_loss: 15.2218\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.2355 - val_loss: 16.2572\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 484us/step - loss: 15.1387 - val_loss: 15.0193\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.8403 - val_loss: 14.8234\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 14.6240 - val_loss: 14.5243\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 14.5868 - val_loss: 14.5978\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 14.4577 - val_loss: 14.6564\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 14.2744 - val_loss: 14.4381\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 14.1846 - val_loss: 14.4606\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 3s 644us/step - loss: 14.0084 - val_loss: 16.0811\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.1198 - val_loss: 14.0288\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.7605 - val_loss: 13.9714\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.7667 - val_loss: 13.8668\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 13.6075 - val_loss: 13.8433\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 13.5855 - val_loss: 13.6547\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.4076 - val_loss: 13.4642\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.3429 - val_loss: 13.4626\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.3045 - val_loss: 14.4300\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.2437 - val_loss: 13.3132\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.0853 - val_loss: 13.1847\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.0819 - val_loss: 13.4156\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.9996 - val_loss: 13.1298\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.8992 - val_loss: 13.0936\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 12.7828 - val_loss: 14.2145\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.7863 - val_loss: 13.8899\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 12.7124 - val_loss: 13.4756\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.6778 - val_loss: 12.9730\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.5846 - val_loss: 13.3098\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.5562 - val_loss: 12.7608\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.4655 - val_loss: 12.6834\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.4470 - val_loss: 13.2126\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.3371 - val_loss: 12.6283\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.4572 - val_loss: 13.5137\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.3436 - val_loss: 12.5647\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 12.1922 - val_loss: 12.5070\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.1206 - val_loss: 12.5332\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.0730 - val_loss: 12.5475\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.1258 - val_loss: 14.4245\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.0441 - val_loss: 13.0608\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.9870 - val_loss: 12.7268\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 591us/step - loss: 35.1669 - val_loss: 28.5012\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 23.7864 - val_loss: 21.8850\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 20.5561 - val_loss: 19.3819\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 19.1741 - val_loss: 18.2466\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 18.1708 - val_loss: 18.5582\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 17.3235 - val_loss: 18.8094\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 16.8440 - val_loss: 16.4667\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 16.4094 - val_loss: 16.0330\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 15.9786 - val_loss: 15.6245\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 15.4800 - val_loss: 16.9297\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 15.2291 - val_loss: 14.9155\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.7460 - val_loss: 14.4278\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.6327 - val_loss: 14.4668\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.5344 - val_loss: 14.2564\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.1483 - val_loss: 13.7604\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.8152 - val_loss: 13.4843\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.6315 - val_loss: 14.0478\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.5497 - val_loss: 13.1514\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.1964 - val_loss: 13.5209\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.0013 - val_loss: 12.8927\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.9597 - val_loss: 12.8312\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.7240 - val_loss: 13.5558\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.5918 - val_loss: 12.4848\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.5044 - val_loss: 13.3984\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.3407 - val_loss: 12.9623\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.2257 - val_loss: 12.6670\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.2374 - val_loss: 12.2158\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.9489 - val_loss: 11.7945\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.7133 - val_loss: 11.7067\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.8433 - val_loss: 13.3472\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.5740 - val_loss: 11.5836\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.5499 - val_loss: 11.5561\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.4348 - val_loss: 11.4889\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.2963 - val_loss: 11.2805\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.2645 - val_loss: 11.3070\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.2610 - val_loss: 11.9190\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.2348 - val_loss: 11.2233\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 11.0243 - val_loss: 11.1739\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 11.1026 - val_loss: 11.2592\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 10.9801 - val_loss: 11.1585\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.8852 - val_loss: 11.0606\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 10.7766 - val_loss: 10.9012\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.8322 - val_loss: 10.7956\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.8006 - val_loss: 10.9011\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.7375 - val_loss: 10.9576\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.6621 - val_loss: 11.0038\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.6602 - val_loss: 10.6182\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 10.6441 - val_loss: 10.7231\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.4324 - val_loss: 10.7645\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.4931 - val_loss: 10.6961\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.4601 - val_loss: 10.6551\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.3977 - val_loss: 10.8540\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 589us/step - loss: 40.7069 - val_loss: 29.4632\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 27.7898 - val_loss: 26.2264\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 25.0120 - val_loss: 24.0608\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 23.5037 - val_loss: 23.9866\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 22.2359 - val_loss: 25.6285\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 21.5365 - val_loss: 20.6925\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 20.7483 - val_loss: 19.8816\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 20.0182 - val_loss: 19.3760\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 492us/step - loss: 19.3093 - val_loss: 18.7956\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 18.9387 - val_loss: 18.4466\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 18.2416 - val_loss: 18.0227\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 17.9170 - val_loss: 17.5871\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 17.7016 - val_loss: 17.0753\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 17.4243 - val_loss: 16.9550\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 17.0498 - val_loss: 16.9821\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 3s 599us/step - loss: 16.8289 - val_loss: 16.5271\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 570us/step - loss: 16.5861 - val_loss: 16.1798\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.3330 - val_loss: 16.6215\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 16.0307 - val_loss: 15.8076\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.7390 - val_loss: 15.4812\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.8012 - val_loss: 16.0966\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.4935 - val_loss: 16.2787\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 15.3297 - val_loss: 15.1135\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.2493 - val_loss: 16.3084\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.2421 - val_loss: 15.1318\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.9901 - val_loss: 14.7532\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.8835 - val_loss: 15.0613\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 14.7742 - val_loss: 14.6731\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 14.7167 - val_loss: 14.7245\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.6778 - val_loss: 14.5073\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 14.4409 - val_loss: 15.0228\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.3758 - val_loss: 14.4269\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.4005 - val_loss: 14.2681\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.1844 - val_loss: 14.0137\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.1304 - val_loss: 14.1316\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.0736 - val_loss: 13.8811\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.0259 - val_loss: 14.4862\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.0053 - val_loss: 13.9049\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.9774 - val_loss: 13.7446\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.6660 - val_loss: 13.8256\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.7791 - val_loss: 13.7436\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.6570 - val_loss: 13.7665\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.6461 - val_loss: 13.5361\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.5580 - val_loss: 13.5700\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.4548 - val_loss: 13.5643\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.4381 - val_loss: 14.0846\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.4162 - val_loss: 13.6575\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.5442 - val_loss: 13.5874\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 603us/step - loss: 41.3889 - val_loss: 32.9270\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 30.3218 - val_loss: 27.4387\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 25.5588 - val_loss: 23.8975\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 22.4354 - val_loss: 22.4445\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 20.2988 - val_loss: 18.9449\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 18.8321 - val_loss: 17.9527\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 17.8662 - val_loss: 18.1894\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 529us/step - loss: 17.1223 - val_loss: 17.4973\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 16.6194 - val_loss: 16.2322\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 16.2542 - val_loss: 15.8811\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.8282 - val_loss: 15.7140\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.4581 - val_loss: 18.2682\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 15.2996 - val_loss: 15.5108\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 14.8974 - val_loss: 14.6624\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.6215 - val_loss: 14.6143\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.4259 - val_loss: 14.4915\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.1123 - val_loss: 14.1329\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.0620 - val_loss: 13.8387\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.8282 - val_loss: 13.7992\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.5269 - val_loss: 13.6532\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.3830 - val_loss: 14.0835\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 13.2092 - val_loss: 13.5164\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.1101 - val_loss: 13.0565\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.0465 - val_loss: 12.8970\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.8490 - val_loss: 13.2328\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.7786 - val_loss: 12.6539\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.6673 - val_loss: 12.5769\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.4088 - val_loss: 12.4970\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.5477 - val_loss: 12.5401\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.2786 - val_loss: 12.3261\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.2087 - val_loss: 12.3891\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.1353 - val_loss: 12.6095\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.0182 - val_loss: 12.3390\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.9966 - val_loss: 12.1528\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 11.9049 - val_loss: 12.0754\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.7931 - val_loss: 12.0270\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.7405 - val_loss: 11.8566\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.9373 - val_loss: 12.1227\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.6407 - val_loss: 12.1646\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.5572 - val_loss: 11.6451\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.5607 - val_loss: 11.8819\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.4562 - val_loss: 11.6060\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.4600 - val_loss: 11.6468\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.3569 - val_loss: 11.5177\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.3588 - val_loss: 11.4808\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.3269 - val_loss: 11.5239\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.2783 - val_loss: 11.8175\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.2095 - val_loss: 12.2135\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.1734 - val_loss: 11.6085\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.2986 - val_loss: 11.5767\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 631us/step - loss: 37.7490 - val_loss: 25.2746\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 22.3528 - val_loss: 19.8856\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 18.8583 - val_loss: 17.6602\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.2873 - val_loss: 17.1681\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.1291 - val_loss: 15.4058\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.4207 - val_loss: 15.9022\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.7662 - val_loss: 14.2161\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.5003 - val_loss: 14.3273\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.7878 - val_loss: 13.4824\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 13.4414 - val_loss: 13.1240\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 13.2353 - val_loss: 12.9657\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 13.0275 - val_loss: 12.9508\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 12.6457 - val_loss: 12.7810\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 12.5776 - val_loss: 13.1096\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 12.2775 - val_loss: 13.2402\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 3s 648us/step - loss: 12.1060 - val_loss: 12.4256\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.0177 - val_loss: 11.9765\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.9803 - val_loss: 12.6448\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.7731 - val_loss: 11.9814\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.6824 - val_loss: 11.8985\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.5793 - val_loss: 12.8503\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.2816 - val_loss: 11.1733\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 11.1832 - val_loss: 11.1573\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 11.1805 - val_loss: 11.2840\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.1461 - val_loss: 11.0123\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 10.9700 - val_loss: 11.0230\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.9068 - val_loss: 11.0476\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 10.8474 - val_loss: 10.8311\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 10.8299 - val_loss: 10.8759\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 10.7062 - val_loss: 10.7166\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.6505 - val_loss: 10.6531\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 10.6118 - val_loss: 10.8363\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.6317 - val_loss: 10.5561\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.5103 - val_loss: 10.6865\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.4062 - val_loss: 10.5618\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.4233 - val_loss: 10.9897\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.3512 - val_loss: 11.9619\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.3815 - val_loss: 10.3962\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.1912 - val_loss: 10.5278\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.2068 - val_loss: 10.4238\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.2860 - val_loss: 10.3848\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.1218 - val_loss: 10.2215\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.1388 - val_loss: 10.2314\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.0103 - val_loss: 10.1192\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.0053 - val_loss: 10.0277\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.0003 - val_loss: 10.1144\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.0149 - val_loss: 10.3114\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.0163 - val_loss: 10.0380\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.8359 - val_loss: 9.9367\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.9539 - val_loss: 10.0272\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.8931 - val_loss: 10.4537\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.7973 - val_loss: 9.8899\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 9.7991 - val_loss: 10.0950\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 9.8208 - val_loss: 9.9529\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 575us/step - loss: 9.7749 - val_loss: 9.7038\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 9.6170 - val_loss: 10.0382\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 9.6741 - val_loss: 9.6572\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 9.6985 - val_loss: 9.8516\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 9.6029 - val_loss: 10.1803\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.6264 - val_loss: 10.0771\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.6584 - val_loss: 9.9271\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.5611 - val_loss: 10.1207\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 600us/step - loss: 37.5120 - val_loss: 29.1481\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 27.1203 - val_loss: 25.0060\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 24.9888 - val_loss: 24.2699\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 23.1951 - val_loss: 22.6793\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 22.0243 - val_loss: 21.7189\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 21.1515 - val_loss: 20.0893\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 20.1425 - val_loss: 19.8183\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 19.8052 - val_loss: 20.0726\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 19.1224 - val_loss: 18.4026\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 18.7666 - val_loss: 17.9988\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 18.2511 - val_loss: 17.7599\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.8679 - val_loss: 17.3582\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.5905 - val_loss: 18.1798\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.3366 - val_loss: 17.0398\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.9940 - val_loss: 16.6811\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.8988 - val_loss: 16.7641\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.6403 - val_loss: 16.6190\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.5090 - val_loss: 16.7041\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.3130 - val_loss: 15.9675\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.1462 - val_loss: 15.8424\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.1096 - val_loss: 16.0101\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.9404 - val_loss: 15.7268\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 15.6784 - val_loss: 15.7214\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.7033 - val_loss: 15.4689\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.5227 - val_loss: 15.4601\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.4195 - val_loss: 15.5229\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.3434 - val_loss: 15.1803\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.2969 - val_loss: 16.2878\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.3115 - val_loss: 15.1733\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.0432 - val_loss: 15.0329\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.1143 - val_loss: 15.2654\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.9733 - val_loss: 14.9123\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.9675 - val_loss: 15.1416\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.8758 - val_loss: 14.8210\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.9008 - val_loss: 14.6800\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.7986 - val_loss: 14.6289\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.7887 - val_loss: 14.9826\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.6567 - val_loss: 15.6876\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.6041 - val_loss: 14.5440\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.5489 - val_loss: 14.6741\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.5428 - val_loss: 14.4836\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 14.4481 - val_loss: 14.4139\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.4213 - val_loss: 14.4575\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.3543 - val_loss: 14.5248\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.3277 - val_loss: 14.3101\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 14.3255 - val_loss: 14.2281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 1s 335us/step - loss: 14.3238 - val_loss: 14.2965\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 493us/step - loss: 14.1973 - val_loss: 14.4026\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 14.2711 - val_loss: 14.3010\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 14.1408 - val_loss: 14.0735\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 14.0805 - val_loss: 14.0512\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 14.1140 - val_loss: 14.0353\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 14.0128 - val_loss: 14.1362\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 3s 641us/step - loss: 13.9967 - val_loss: 14.0540\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.0596 - val_loss: 14.0386\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.9082 - val_loss: 14.1246\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 13.9270 - val_loss: 14.0804\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 595us/step - loss: 36.3683 - val_loss: 27.3150\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 24.3280 - val_loss: 22.2348\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 21.1812 - val_loss: 19.7849\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 19.4148 - val_loss: 18.8948\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 18.3553 - val_loss: 17.9904\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 17.4770 - val_loss: 17.5233\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.8543 - val_loss: 17.3225\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 16.4791 - val_loss: 15.9889\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.8881 - val_loss: 15.7094\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.4413 - val_loss: 15.1480\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.2285 - val_loss: 14.9755\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.0648 - val_loss: 14.6784\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.7406 - val_loss: 15.7227\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.6238 - val_loss: 14.3984\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 14.2740 - val_loss: 14.1067\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 14.3750 - val_loss: 13.8737\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 14.1922 - val_loss: 13.9819\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.9179 - val_loss: 13.8834\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.8045 - val_loss: 13.7116\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 13.7275 - val_loss: 14.6494\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.7192 - val_loss: 13.8278\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.5379 - val_loss: 13.8276\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 13.3973 - val_loss: 14.0378\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.3888 - val_loss: 13.0284\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.2566 - val_loss: 14.0746\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.0411 - val_loss: 14.1377\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.1340 - val_loss: 12.8802\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.0410 - val_loss: 13.4335\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.0970 - val_loss: 13.2018\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.9878 - val_loss: 12.9515\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.7963 - val_loss: 12.7955\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.7606 - val_loss: 13.0816\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 12.6954 - val_loss: 12.8960\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 12.7535 - val_loss: 12.3765\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 12.5830 - val_loss: 12.4262\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 12.4307 - val_loss: 12.3080\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 12.5409 - val_loss: 13.3214\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 12.7896 - val_loss: 13.6129\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 12.4796 - val_loss: 12.8432\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.3978 - val_loss: 12.5565\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 12.3000 - val_loss: 12.1085\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 12.2922 - val_loss: 12.1221\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 12.1329 - val_loss: 12.5515\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.2516 - val_loss: 12.5050\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.1200 - val_loss: 12.1389\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.1606 - val_loss: 12.1962\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 597us/step - loss: 40.1604 - val_loss: 27.9010\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 25.6024 - val_loss: 22.9717\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 21.6469 - val_loss: 19.1627\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 19.6693 - val_loss: 18.5279\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.2140 - val_loss: 16.9993\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.9425 - val_loss: 15.8019\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.1207 - val_loss: 16.7679\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.4738 - val_loss: 15.2837\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.5998 - val_loss: 14.2526\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.2678 - val_loss: 14.3834\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.8408 - val_loss: 14.0849\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.5868 - val_loss: 12.9806\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.0866 - val_loss: 13.4636\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.9235 - val_loss: 12.5421\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.6018 - val_loss: 12.7828\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.3438 - val_loss: 12.5399\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.1032 - val_loss: 11.7817\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9451 - val_loss: 11.5730\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.8390 - val_loss: 11.8986\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.5547 - val_loss: 11.3314\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.4078 - val_loss: 11.6964\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.3135 - val_loss: 11.4830\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.1335 - val_loss: 11.0381\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 11.1190 - val_loss: 10.8548\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.0397 - val_loss: 10.7396\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.7735 - val_loss: 10.6740\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.8535 - val_loss: 10.9669\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.6694 - val_loss: 10.5574\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.7418 - val_loss: 11.2224\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.5796 - val_loss: 10.4016\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6426 - val_loss: 11.1435\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.3939 - val_loss: 10.3280\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.3751 - val_loss: 10.3392\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.3789 - val_loss: 10.2615\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.2123 - val_loss: 10.3647\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.1979 - val_loss: 10.2894\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.2454 - val_loss: 10.0308\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 10.1234 - val_loss: 9.9700\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.0498 - val_loss: 9.9769\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 9.9873 - val_loss: 10.1562\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 10.0139 - val_loss: 10.0395\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 494us/step - loss: 9.9389 - val_loss: 9.8539\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 10.2275 - val_loss: 9.7751\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.8233 - val_loss: 9.7161\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 9.7486 - val_loss: 9.7550\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 9.8492 - val_loss: 9.8422\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 9.7085 - val_loss: 9.6488\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 9.7470 - val_loss: 9.7771\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 581us/step - loss: 9.6347 - val_loss: 9.6338\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 3s 657us/step - loss: 9.7346 - val_loss: 9.8790\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.5665 - val_loss: 9.6921\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.5468 - val_loss: 10.4485\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 9.5567 - val_loss: 9.4422\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 9.5737 - val_loss: 9.6340\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.4516 - val_loss: 9.5328\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 9.4777 - val_loss: 9.5564\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 9.5025 - val_loss: 9.4106\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.4127 - val_loss: 9.4627\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.3670 - val_loss: 9.3419\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.3205 - val_loss: 9.3564\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.3303 - val_loss: 9.2463\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.3226 - val_loss: 9.6820\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.3390 - val_loss: 9.7217\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.2458 - val_loss: 9.3016\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.2464 - val_loss: 9.2700\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.1830 - val_loss: 9.1605\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.2421 - val_loss: 9.4394\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.2944 - val_loss: 9.7375\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.1044 - val_loss: 9.2081\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.1019 - val_loss: 9.2179\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.1059 - val_loss: 9.2402\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 603us/step - loss: 36.1425 - val_loss: 22.6172\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 20.8721 - val_loss: 18.6218\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 18.2180 - val_loss: 17.9552\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.7407 - val_loss: 15.7481\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.9468 - val_loss: 15.6618\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 15.2859 - val_loss: 14.8360\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.7300 - val_loss: 14.8823\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.2176 - val_loss: 13.7400\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.9203 - val_loss: 13.4286\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.6098 - val_loss: 12.9838\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.2367 - val_loss: 12.6990\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 13.1296 - val_loss: 13.9127\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.9524 - val_loss: 12.9781\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 12.7909 - val_loss: 12.6673\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 12.4110 - val_loss: 11.9642\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 12.1994 - val_loss: 12.0257\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 12.0604 - val_loss: 12.0430\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 12.0314 - val_loss: 11.5970\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 11.9784 - val_loss: 11.8108\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 11.7428 - val_loss: 11.3549\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.3953 - val_loss: 11.1389\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.4766 - val_loss: 11.1817\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.3461 - val_loss: 10.8987\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 499us/step - loss: 11.0640 - val_loss: 10.9031\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.0876 - val_loss: 10.8918\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.1932 - val_loss: 11.4821\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.7664 - val_loss: 11.0079\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.7769 - val_loss: 11.4255\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.6526 - val_loss: 10.4030\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.5973 - val_loss: 10.2725\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.4352 - val_loss: 10.0326\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.3850 - val_loss: 10.9624\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.2156 - val_loss: 9.9316\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.0774 - val_loss: 10.1621\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.1123 - val_loss: 9.8895\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 9.9662 - val_loss: 9.7356\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.0228 - val_loss: 9.9108\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.7918 - val_loss: 9.4910\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.8221 - val_loss: 9.5000\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.7318 - val_loss: 9.5340\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.7348 - val_loss: 10.2272\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.6304 - val_loss: 9.3243\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.5587 - val_loss: 9.9597\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.5851 - val_loss: 9.1548\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.5102 - val_loss: 10.3244\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.3528 - val_loss: 9.3865\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.3513 - val_loss: 9.4694\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.3136 - val_loss: 9.9025\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.2892 - val_loss: 9.7895\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 595us/step - loss: 36.6277 - val_loss: 27.6611\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 25.3328 - val_loss: 26.8541\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 22.2384 - val_loss: 21.6045\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 20.2642 - val_loss: 20.1701\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 18.7715 - val_loss: 18.0262\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 17.8533 - val_loss: 17.3310\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.9875 - val_loss: 16.4100\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.2045 - val_loss: 15.5213\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.5963 - val_loss: 14.9700\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.9717 - val_loss: 15.5056\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.8673 - val_loss: 14.1304\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.1605 - val_loss: 15.3641\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.9178 - val_loss: 13.9783\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.5147 - val_loss: 13.1137\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.2131 - val_loss: 12.9651\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.1068 - val_loss: 12.7273\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.0262 - val_loss: 12.6320\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.7226 - val_loss: 12.7701\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.4249 - val_loss: 12.4103\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.2968 - val_loss: 12.3855\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.2646 - val_loss: 12.0230\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.9744 - val_loss: 11.8556\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 11.9725 - val_loss: 11.8246\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 11.7380 - val_loss: 11.6933\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 11.6728 - val_loss: 11.5629\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 11.5513 - val_loss: 11.4045\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 11.3886 - val_loss: 12.0354\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 3s 601us/step - loss: 11.3123 - val_loss: 11.0718\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 573us/step - loss: 11.1838 - val_loss: 11.2047\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.1055 - val_loss: 11.2642\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.0273 - val_loss: 10.8683\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.9089 - val_loss: 11.4684\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.9377 - val_loss: 10.8642\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.7510 - val_loss: 11.1158\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 3s 631us/step - loss: 10.6950 - val_loss: 10.8721\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.6044 - val_loss: 10.6522\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.6759 - val_loss: 10.9116\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.4781 - val_loss: 10.5247\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 10.4142 - val_loss: 10.3638\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.3774 - val_loss: 10.4062\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 10.3477 - val_loss: 10.3823\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 10.1887 - val_loss: 10.3111\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.1835 - val_loss: 10.1116\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.1655 - val_loss: 10.0699\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.9978 - val_loss: 10.2367\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 10.1119 - val_loss: 10.2049\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.9241 - val_loss: 10.0790\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 9.9754 - val_loss: 9.9293\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.8273 - val_loss: 10.6650\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.8252 - val_loss: 9.8031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.8942 - val_loss: 10.1856\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.7943 - val_loss: 9.9451\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.7785 - val_loss: 9.9962\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 9.7279 - val_loss: 9.7061\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.6654 - val_loss: 9.9956\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.5999 - val_loss: 9.5616\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.5591 - val_loss: 10.0605\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.5285 - val_loss: 9.7972\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.4545 - val_loss: 9.7393\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.4953 - val_loss: 9.6561\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 9.4018 - val_loss: 9.5768\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 599us/step - loss: 39.0503 - val_loss: 25.6593\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 23.8803 - val_loss: 21.8112\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 21.0868 - val_loss: 19.8882\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 19.5545 - val_loss: 18.8822\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 18.6891 - val_loss: 17.9532\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 17.8918 - val_loss: 17.4720\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 17.2872 - val_loss: 16.7245\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 16.7535 - val_loss: 16.4160\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 16.3737 - val_loss: 16.3974\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.1006 - val_loss: 15.9193\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.6988 - val_loss: 15.7127\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.6430 - val_loss: 15.8793\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.1910 - val_loss: 16.0374\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.8819 - val_loss: 14.9707\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 14.7375 - val_loss: 14.5569\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.5342 - val_loss: 15.7795\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.3970 - val_loss: 14.3784\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.1533 - val_loss: 14.0434\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.8992 - val_loss: 13.8342\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.7752 - val_loss: 13.7591\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.4811 - val_loss: 13.4804\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.5298 - val_loss: 13.8788\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.3510 - val_loss: 13.3255\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.1500 - val_loss: 13.4824\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.0474 - val_loss: 12.9842\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 12.9012 - val_loss: 13.5227\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 12.7383 - val_loss: 13.3242\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.6708 - val_loss: 12.6751\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.5794 - val_loss: 12.9598\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.4339 - val_loss: 12.7924\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.3245 - val_loss: 12.6765\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.2501 - val_loss: 12.3289\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.1583 - val_loss: 12.3392\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.0049 - val_loss: 12.8990\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.9738 - val_loss: 12.1799\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9121 - val_loss: 12.1105\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.9666 - val_loss: 12.1195\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.8403 - val_loss: 12.4830\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.7307 - val_loss: 11.7583\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.6207 - val_loss: 12.3012\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.6799 - val_loss: 11.8896\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.5607 - val_loss: 11.7202\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.5619 - val_loss: 12.5079\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.5521 - val_loss: 11.6740\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.4216 - val_loss: 11.9246\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.3978 - val_loss: 11.9649\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.2863 - val_loss: 11.7165\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.3072 - val_loss: 11.7289\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.1819 - val_loss: 11.3597\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.2827 - val_loss: 11.4905\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.1503 - val_loss: 11.8901\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.0624 - val_loss: 11.3190\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.0883 - val_loss: 12.0092\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.0569 - val_loss: 11.2753\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.9383 - val_loss: 11.2201\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.0107 - val_loss: 11.2280\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.9031 - val_loss: 11.1182\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.9181 - val_loss: 11.1412\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.8566 - val_loss: 11.2707\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.8508 - val_loss: 11.1439\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.8344 - val_loss: 10.9997\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 471us/step - loss: 10.7237 - val_loss: 11.2449\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 10.7293 - val_loss: 11.0196\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 10.7831 - val_loss: 10.9016\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 548us/step - loss: 10.7012 - val_loss: 10.8774\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 10.6361 - val_loss: 10.9352\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 10.6379 - val_loss: 11.2233\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 10.5934 - val_loss: 10.9277\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 3s 633us/step - loss: 10.5261 - val_loss: 10.9009\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6254 - val_loss: 11.1399\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 579us/step - loss: 35.0997 - val_loss: 25.8879\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 23.3059 - val_loss: 21.8767\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 19.9769 - val_loss: 19.0466\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 18.2248 - val_loss: 17.0720\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 17.0220 - val_loss: 16.5033\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 16.4161 - val_loss: 16.9675\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 15.7257 - val_loss: 15.3412\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.1669 - val_loss: 14.9266\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 14.7488 - val_loss: 14.0777\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.4426 - val_loss: 14.6783\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.0454 - val_loss: 13.3966\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.5068 - val_loss: 13.4743\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.1029 - val_loss: 12.6022\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.9671 - val_loss: 12.4038\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.5386 - val_loss: 12.3080\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.5359 - val_loss: 12.2936\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.1892 - val_loss: 11.9987\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.0728 - val_loss: 12.4449\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.7534 - val_loss: 11.9071\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.6356 - val_loss: 12.6410\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.4513 - val_loss: 10.9898\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.4033 - val_loss: 11.1618\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.2413 - val_loss: 10.9071\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.1712 - val_loss: 10.8456\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.9992 - val_loss: 10.8754\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.9117 - val_loss: 12.1680\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8219 - val_loss: 10.7421\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6939 - val_loss: 10.7207\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.5139 - val_loss: 10.8393\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.5049 - val_loss: 10.6168\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.4342 - val_loss: 10.9684\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.3258 - val_loss: 10.4842\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.2416 - val_loss: 10.1679\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 10.2178 - val_loss: 10.9726\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 10.1567 - val_loss: 10.1744\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 10.0050 - val_loss: 10.0018\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 9.9392 - val_loss: 9.8361\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 9.9689 - val_loss: 10.4941\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 9.8761 - val_loss: 9.9888\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 9.7811 - val_loss: 9.8453\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.7793 - val_loss: 9.8817\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.7451 - val_loss: 9.6889\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.5984 - val_loss: 9.5293\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.6205 - val_loss: 10.1967\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.6503 - val_loss: 10.1087\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.5323 - val_loss: 9.5070\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.4790 - val_loss: 9.7139\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.4341 - val_loss: 9.4645\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.3269 - val_loss: 9.5618\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.3571 - val_loss: 10.4468\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.2843 - val_loss: 9.4513\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.3297 - val_loss: 9.7367\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.2027 - val_loss: 9.3528\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.2102 - val_loss: 9.6351\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.1963 - val_loss: 9.1454\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.1452 - val_loss: 9.6474\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.1997 - val_loss: 9.2444\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.0782 - val_loss: 9.3619\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.0668 - val_loss: 9.3502\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.0215 - val_loss: 9.0013\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 8.9958 - val_loss: 9.2045\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 8.9498 - val_loss: 9.4014\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 8.9146 - val_loss: 9.1555\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 8.9521 - val_loss: 9.2061\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 8.9568 - val_loss: 9.0647\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 621us/step - loss: 40.4976 - val_loss: 29.5068\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 28.0444 - val_loss: 25.2662\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 24.4185 - val_loss: 22.7897\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 22.4128 - val_loss: 21.7030\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 514us/step - loss: 21.3443 - val_loss: 20.7136\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 20.4078 - val_loss: 20.1726\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 19.7905 - val_loss: 19.0479\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 18.9133 - val_loss: 19.1317\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 18.5199 - val_loss: 17.9719\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.0048 - val_loss: 18.5388\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 17.9379 - val_loss: 18.2878\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.4132 - val_loss: 17.1092\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 17.0404 - val_loss: 17.1219\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.9425 - val_loss: 16.5912\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.6052 - val_loss: 16.8451\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.5026 - val_loss: 16.1408\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.3715 - val_loss: 16.6906\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.0001 - val_loss: 18.6234\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 16.0888 - val_loss: 16.1249\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.7140 - val_loss: 15.8913\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.7648 - val_loss: 15.3614\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.2754 - val_loss: 15.3872\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.2513 - val_loss: 15.2903\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.1809 - val_loss: 15.2576\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.0045 - val_loss: 14.9493\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 14.8577 - val_loss: 14.9771\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 14.8134 - val_loss: 14.6788\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 14.7641 - val_loss: 14.5975\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 14.7457 - val_loss: 15.5376\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 14.4783 - val_loss: 14.4028\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 3s 616us/step - loss: 14.4839 - val_loss: 14.6604\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 574us/step - loss: 14.3983 - val_loss: 14.7446\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 14.3119 - val_loss: 14.3504\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.2678 - val_loss: 14.5119\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.0945 - val_loss: 14.6240\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.1369 - val_loss: 14.1067\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.0914 - val_loss: 14.6690\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 13.9256 - val_loss: 13.9778\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.8482 - val_loss: 14.0556\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.9422 - val_loss: 14.1079\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 13.8687 - val_loss: 13.8431\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.6244 - val_loss: 13.8704\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 13.7679 - val_loss: 14.5399\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 13.5848 - val_loss: 13.6855\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.5708 - val_loss: 13.6459\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 13.4676 - val_loss: 13.7517\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 3s 652us/step - loss: 13.4140 - val_loss: 13.9791\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 13.4011 - val_loss: 13.7186\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.3781 - val_loss: 13.5529\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.2857 - val_loss: 13.6053\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 564us/step - loss: 13.2774 - val_loss: 13.9311\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 13.2614 - val_loss: 13.8195\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.2663 - val_loss: 13.4905\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 13.0861 - val_loss: 13.2251\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.0955 - val_loss: 13.2769\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.0572 - val_loss: 13.3701\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.0130 - val_loss: 13.2855\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.9837 - val_loss: 13.2709\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.9108 - val_loss: 13.1386\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.9400 - val_loss: 13.7660\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.8928 - val_loss: 13.0864\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.8592 - val_loss: 13.3814\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.7652 - val_loss: 13.1000\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.7288 - val_loss: 13.0471\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.6852 - val_loss: 13.6577\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.6951 - val_loss: 13.1225\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.6765 - val_loss: 12.9941\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.6558 - val_loss: 13.5469\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 12.5927 - val_loss: 12.9885\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 12.5568 - val_loss: 12.8486\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 12.5141 - val_loss: 13.4208\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 12.5653 - val_loss: 13.0000\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 12.4942 - val_loss: 12.7937\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 12.4541 - val_loss: 12.7626\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 12.4005 - val_loss: 12.7537\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 12.3864 - val_loss: 12.8925\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.3734 - val_loss: 12.7039\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 12.4063 - val_loss: 12.6973\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.3387 - val_loss: 12.6972\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 12.2590 - val_loss: 12.7286\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.2663 - val_loss: 12.9419\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.2141 - val_loss: 12.5222\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.2165 - val_loss: 12.6815\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.1789 - val_loss: 12.8280\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.1567 - val_loss: 12.7295\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.1898 - val_loss: 12.7414\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.1074 - val_loss: 12.5171\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.0782 - val_loss: 12.4783\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.1205 - val_loss: 12.5502\n",
      "Epoch 90/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.0960 - val_loss: 12.5967\n",
      "Epoch 91/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.0301 - val_loss: 12.5024\n",
      "Epoch 92/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.0354 - val_loss: 12.4931\n",
      "Epoch 93/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.9440 - val_loss: 12.5189\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 605us/step - loss: 39.3862 - val_loss: 28.2443\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 25.9463 - val_loss: 25.0623\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 22.3373 - val_loss: 22.0008\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 20.3423 - val_loss: 19.1414\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 19.1828 - val_loss: 18.6971\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 18.1612 - val_loss: 18.3055\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.1165 - val_loss: 16.2649\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.2649 - val_loss: 16.2657\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.5882 - val_loss: 15.2752\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.9260 - val_loss: 14.8671\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 14.5632 - val_loss: 14.2570\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 14.1257 - val_loss: 15.0118\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.8124 - val_loss: 13.6235\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.6353 - val_loss: 14.0963\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.4473 - val_loss: 13.3745\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.1281 - val_loss: 13.2577\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.8694 - val_loss: 13.1041\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.7326 - val_loss: 12.6835\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.6190 - val_loss: 12.6458\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.3852 - val_loss: 12.4899\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.2223 - val_loss: 12.1772\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.0818 - val_loss: 12.1316\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.9807 - val_loss: 12.0964\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.8085 - val_loss: 12.1191\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.7388 - val_loss: 12.1367\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.5389 - val_loss: 11.6728\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.5581 - val_loss: 11.5649\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.4230 - val_loss: 11.7345\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.2915 - val_loss: 11.2824\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.3494 - val_loss: 11.3035\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 11.1266 - val_loss: 11.4395\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 11.0730 - val_loss: 11.1153\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 10.9921 - val_loss: 11.2900\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 560us/step - loss: 11.0340 - val_loss: 11.2607\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 10.9550 - val_loss: 11.0478\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 10.9237 - val_loss: 11.3994\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 585us/step - loss: 10.7985 - val_loss: 11.3907\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 3s 606us/step - loss: 10.8238 - val_loss: 10.9451\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.7042 - val_loss: 10.8440\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.6160 - val_loss: 10.9512\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.6185 - val_loss: 11.1445\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6664 - val_loss: 11.0938\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.4606 - val_loss: 10.8820\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 10.4145 - val_loss: 10.8823\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 608us/step - loss: 38.2820 - val_loss: 25.4627\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 23.0386 - val_loss: 20.5800\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 19.6153 - val_loss: 18.0799\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 17.9174 - val_loss: 16.9438\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 16.8902 - val_loss: 16.5088\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 16.0200 - val_loss: 15.6700\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 15.5033 - val_loss: 15.2516\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 15.1618 - val_loss: 14.6616\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 14.5950 - val_loss: 14.6171\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 14.3127 - val_loss: 14.1781\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 14.0557 - val_loss: 13.6422\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.6810 - val_loss: 13.3388\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.4360 - val_loss: 13.7120\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.0830 - val_loss: 13.0277\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.0653 - val_loss: 13.2356\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.9618 - val_loss: 13.2930\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.8328 - val_loss: 13.3660\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.5792 - val_loss: 12.9727\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 543us/step - loss: 12.3644 - val_loss: 12.4042\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.3859 - val_loss: 12.6235\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.1591 - val_loss: 12.0815\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.0765 - val_loss: 13.1521\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.9324 - val_loss: 12.1118\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.9393 - val_loss: 11.9442\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.7310 - val_loss: 11.7033\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.6700 - val_loss: 12.1090\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.6419 - val_loss: 11.6004\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 11.5442 - val_loss: 11.4711\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 11.4582 - val_loss: 11.3420\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 11.5093 - val_loss: 11.2881\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 11.3852 - val_loss: 11.2977\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 11.2541 - val_loss: 11.6012\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 11.1629 - val_loss: 11.5622\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 11.1331 - val_loss: 11.3533\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.1595 - val_loss: 11.1407\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.9898 - val_loss: 11.3002\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.0103 - val_loss: 11.0544\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.0019 - val_loss: 10.9070\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.8299 - val_loss: 10.8308\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.9061 - val_loss: 11.8132\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.7927 - val_loss: 10.7225\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.8107 - val_loss: 10.7898\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.7339 - val_loss: 10.6031\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6697 - val_loss: 10.5479\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.6096 - val_loss: 10.7626\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.6404 - val_loss: 10.6415\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.6077 - val_loss: 10.8804\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.5046 - val_loss: 10.7302\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.4330 - val_loss: 10.5510\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 602us/step - loss: 36.5613 - val_loss: 28.7914\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 26.8235 - val_loss: 26.2683\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 24.3188 - val_loss: 22.8360\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 22.8272 - val_loss: 22.6337\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 21.7509 - val_loss: 20.8535\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 20.8949 - val_loss: 20.7517\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 20.2409 - val_loss: 20.9742\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 19.8102 - val_loss: 19.2355\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 19.4452 - val_loss: 18.6698\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 18.8424 - val_loss: 18.6824\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 18.5960 - val_loss: 18.8437\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 18.3863 - val_loss: 17.9499\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 17.8374 - val_loss: 17.3426\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 17.6176 - val_loss: 17.1726\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 17.5891 - val_loss: 16.8238\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 17.2794 - val_loss: 16.6704\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 17.0809 - val_loss: 16.6068\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.8341 - val_loss: 16.6297\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 16.5026 - val_loss: 16.0086\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 16.3053 - val_loss: 15.9285\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.2205 - val_loss: 16.5028\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 16.0824 - val_loss: 15.9967\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 15.8791 - val_loss: 15.7086\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.8733 - val_loss: 15.8734\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 15.6851 - val_loss: 15.2656\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.5257 - val_loss: 15.1751\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.4006 - val_loss: 15.5291\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.2827 - val_loss: 15.1432\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.2429 - val_loss: 15.1438\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.1862 - val_loss: 14.8560\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.0032 - val_loss: 15.0539\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.9088 - val_loss: 14.6376\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.8583 - val_loss: 14.6553\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.9224 - val_loss: 14.8076\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.7279 - val_loss: 14.6723\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 14.6374 - val_loss: 14.6732\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 14.6172 - val_loss: 14.6938\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 637us/step - loss: 36.1864 - val_loss: 24.4706\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 589us/step - loss: 23.8958 - val_loss: 22.9154\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 584us/step - loss: 21.3122 - val_loss: 19.8858\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 19.7623 - val_loss: 18.6169\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.5995 - val_loss: 17.7219\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 17.9174 - val_loss: 16.9815\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.9006 - val_loss: 16.7836\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 497us/step - loss: 16.5410 - val_loss: 15.9974\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.1416 - val_loss: 15.6374\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.8145 - val_loss: 15.2741\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 15.2257 - val_loss: 14.8391\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 15.0953 - val_loss: 15.1019\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.8170 - val_loss: 14.5791\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.7841 - val_loss: 15.2695\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.4798 - val_loss: 14.4576\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.3662 - val_loss: 14.0505\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.1235 - val_loss: 14.5475\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.9459 - val_loss: 13.8325\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.9849 - val_loss: 14.1290\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 13.7134 - val_loss: 13.3333\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.5870 - val_loss: 13.2581\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.5664 - val_loss: 13.0440\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.4154 - val_loss: 13.4333\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.4286 - val_loss: 13.0666\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.3515 - val_loss: 12.9310\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 13.1181 - val_loss: 13.2942\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8704 - val_loss: 13.2942\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.8371 - val_loss: 12.7301\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.9886 - val_loss: 12.4957\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.6536 - val_loss: 12.6630\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.5760 - val_loss: 12.2962\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.4683 - val_loss: 12.2558\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.4910 - val_loss: 12.2679\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.3743 - val_loss: 12.6530\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.1924 - val_loss: 12.5560\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.3299 - val_loss: 12.4092\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.0868 - val_loss: 12.1037\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 12.0885 - val_loss: 12.1385\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.8825 - val_loss: 11.8764\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 11.8625 - val_loss: 11.7776\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 11.8808 - val_loss: 11.6656\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 11.8176 - val_loss: 11.5342\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 11.7189 - val_loss: 11.6843\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 11.6607 - val_loss: 11.4593\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.6392 - val_loss: 11.7720\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.6159 - val_loss: 11.5434\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.4795 - val_loss: 11.3918\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.4702 - val_loss: 11.5813\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.3954 - val_loss: 11.5732\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.3767 - val_loss: 11.8872\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.4241 - val_loss: 11.4111\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.2416 - val_loss: 11.3428\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.2055 - val_loss: 11.1230\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.2352 - val_loss: 12.1137\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.1638 - val_loss: 11.0486\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.2496 - val_loss: 11.2603\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.9842 - val_loss: 11.0608\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.0052 - val_loss: 11.1665\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.9546 - val_loss: 10.8994\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.0023 - val_loss: 11.0817\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.9058 - val_loss: 11.1945\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.9204 - val_loss: 10.8217\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.9223 - val_loss: 11.2492\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.8078 - val_loss: 10.8873\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.8179 - val_loss: 10.8057\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.7147 - val_loss: 10.7647\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.9133 - val_loss: 10.7142\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8146 - val_loss: 10.7514\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6466 - val_loss: 10.8680\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.6847 - val_loss: 10.7681\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.6088 - val_loss: 10.7629\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.8206 - val_loss: 10.8239\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 607us/step - loss: 40.1817 - val_loss: 29.9641\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 27.1142 - val_loss: 23.6460\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 22.8203 - val_loss: 22.6630\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 20.9824 - val_loss: 19.3620\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 19.4340 - val_loss: 18.5616\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 18.4650 - val_loss: 17.6350\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 17.6803 - val_loss: 16.8533\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 17.1990 - val_loss: 16.7475\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 16.6685 - val_loss: 16.0738\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 16.1509 - val_loss: 16.8096\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 503us/step - loss: 15.6556 - val_loss: 15.5577\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.2502 - val_loss: 14.7879\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 15.0381 - val_loss: 14.8476\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 14.5196 - val_loss: 14.3679\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 14.3243 - val_loss: 14.1087\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 14.2161 - val_loss: 13.7893\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 14.0016 - val_loss: 14.2268\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 13.6256 - val_loss: 13.4786\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.5519 - val_loss: 13.0514\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.4740 - val_loss: 13.0432\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.0256 - val_loss: 12.9194\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.0005 - val_loss: 12.8649\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.7978 - val_loss: 12.7504\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.8044 - val_loss: 12.5679\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 12.6646 - val_loss: 12.6430\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 12.3960 - val_loss: 12.4399\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 12.3554 - val_loss: 12.1973\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 12.5867 - val_loss: 12.0906\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 12.0358 - val_loss: 12.1381\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 12.0000 - val_loss: 11.9544\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 3s 649us/step - loss: 11.9457 - val_loss: 12.0003\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.8948 - val_loss: 12.8702\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 11.7983 - val_loss: 11.7055\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 11.9033 - val_loss: 11.8660\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 11.6283 - val_loss: 11.4452\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.4738 - val_loss: 11.3535\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 11.5955 - val_loss: 11.3689\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 418us/step - loss: 11.4725 - val_loss: 11.6108\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 11.4104 - val_loss: 11.2442\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.2614 - val_loss: 11.9851\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.1992 - val_loss: 11.1669\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 11.1269 - val_loss: 11.2628\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2258 - val_loss: 11.0315\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 11.0630 - val_loss: 10.9946\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.9524 - val_loss: 11.2909\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.0539 - val_loss: 10.9950\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.1001 - val_loss: 11.0323\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.8513 - val_loss: 10.8800\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.8285 - val_loss: 10.9445\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.8301 - val_loss: 10.9376\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.7966 - val_loss: 11.4198\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.7386 - val_loss: 10.7923\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.6576 - val_loss: 10.8326\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.7360 - val_loss: 10.7116\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.6320 - val_loss: 11.0638\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5676 - val_loss: 10.9785\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5654 - val_loss: 11.3168\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6577 - val_loss: 10.6151\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.4608 - val_loss: 10.4872\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.4598 - val_loss: 10.7853\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.3724 - val_loss: 11.5213\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.3518 - val_loss: 10.8973\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.3565 - val_loss: 10.3321\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.3241 - val_loss: 10.4287\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.3550 - val_loss: 10.9942\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.2456 - val_loss: 10.1986\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.2201 - val_loss: 10.3079\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.2628 - val_loss: 10.3233\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.2272 - val_loss: 10.4995\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 10.1300 - val_loss: 10.1668\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 10.1093 - val_loss: 10.1616\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 10.1432 - val_loss: 10.2515\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 10.1111 - val_loss: 10.1676\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 583us/step - loss: 10.0853 - val_loss: 10.2073\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 9.9896 - val_loss: 10.2211\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 10.0625 - val_loss: 10.1091\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.0273 - val_loss: 10.0488\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.0322 - val_loss: 10.5020\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.9375 - val_loss: 10.0062\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.0963 - val_loss: 10.1421\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 9.8666 - val_loss: 10.3262\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.0457 - val_loss: 10.4060\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 9.9154 - val_loss: 10.0288\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 9.8939 - val_loss: 10.5514\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 606us/step - loss: 35.4228 - val_loss: 25.9389\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 510us/step - loss: 24.3521 - val_loss: 21.4457\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 20.8008 - val_loss: 19.0567\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 19.0201 - val_loss: 19.1403\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.3239 - val_loss: 17.1883\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 17.4241 - val_loss: 16.5447\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 16.9337 - val_loss: 16.1433\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.3162 - val_loss: 15.6132\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 15.8648 - val_loss: 15.2946\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 15.6330 - val_loss: 14.8233\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.1730 - val_loss: 15.5530\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.8433 - val_loss: 14.6569\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.8033 - val_loss: 14.2924\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.5126 - val_loss: 14.3484\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.2977 - val_loss: 14.3648\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.9226 - val_loss: 13.6580\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.9997 - val_loss: 13.4443\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.5472 - val_loss: 13.6081\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.5901 - val_loss: 13.4200\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.4093 - val_loss: 13.7173\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.9801 - val_loss: 13.4850\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.9665 - val_loss: 12.9968\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.7550 - val_loss: 12.6876\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.6651 - val_loss: 12.5012\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.5227 - val_loss: 12.2796\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.3822 - val_loss: 11.9600\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.3686 - val_loss: 13.1978\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.2410 - val_loss: 12.3640\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.0582 - val_loss: 12.5410\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.1182 - val_loss: 11.9001\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.8821 - val_loss: 11.7621\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 11.7880 - val_loss: 12.1598\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.7952 - val_loss: 11.8342\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.7403 - val_loss: 11.4226\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.5689 - val_loss: 11.3146\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.5736 - val_loss: 11.2042\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.5425 - val_loss: 11.3708\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2634 - val_loss: 11.2333\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.2099 - val_loss: 10.9796\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.2465 - val_loss: 11.9273\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 11.2405 - val_loss: 10.9156\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 11.1946 - val_loss: 12.2667\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 579us/step - loss: 11.0830 - val_loss: 11.8814\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 11.0562 - val_loss: 11.9865\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 10.9979 - val_loss: 12.5582\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 11.0126 - val_loss: 10.7498\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 10.8485 - val_loss: 11.3203\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 3s 645us/step - loss: 10.8526 - val_loss: 10.7614\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.8526 - val_loss: 11.3457\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.7460 - val_loss: 11.5804\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.7325 - val_loss: 11.0670\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 583us/step - loss: 37.9199 - val_loss: 29.2061\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 27.0124 - val_loss: 27.0092\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 23.3399 - val_loss: 22.0017\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 21.3394 - val_loss: 19.9031\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 19.8191 - val_loss: 19.0162\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 19.1798 - val_loss: 17.9711\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 18.1324 - val_loss: 17.5300\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 17.2722 - val_loss: 16.9684\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.9647 - val_loss: 16.2990\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 16.2579 - val_loss: 15.6474\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 15.7115 - val_loss: 15.6900\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 15.3413 - val_loss: 15.0124\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 15.3633 - val_loss: 15.4287\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.5905 - val_loss: 14.2458\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.5400 - val_loss: 14.2811\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.1835 - val_loss: 14.1914\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.0962 - val_loss: 13.8152\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.9141 - val_loss: 13.7286\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.5591 - val_loss: 13.4253\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.2427 - val_loss: 13.0868\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.1897 - val_loss: 13.1178\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.1138 - val_loss: 12.7134\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.9939 - val_loss: 12.8682\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.7738 - val_loss: 13.0068\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.7276 - val_loss: 12.4728\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.5475 - val_loss: 12.6648\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 12.4487 - val_loss: 12.3939\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.1684 - val_loss: 12.0928\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.1731 - val_loss: 12.5081\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 12.0585 - val_loss: 12.0152\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 11.9247 - val_loss: 11.9747\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.8527 - val_loss: 11.8951\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 11.9305 - val_loss: 11.7416\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 11.6764 - val_loss: 11.7184\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 11.5746 - val_loss: 11.4967\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 11.5007 - val_loss: 11.6174\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 11.4015 - val_loss: 13.1662\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.4146 - val_loss: 11.4236\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.3650 - val_loss: 11.7779\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.2047 - val_loss: 11.1253\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 11.2026 - val_loss: 11.5176\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.0884 - val_loss: 11.7089\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.0539 - val_loss: 11.2727\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.9936 - val_loss: 10.9747\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 10.9002 - val_loss: 11.0957\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.7745 - val_loss: 11.8039\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.9406 - val_loss: 10.8822\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.8338 - val_loss: 10.8177\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6689 - val_loss: 10.9897\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6673 - val_loss: 10.6506\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.6743 - val_loss: 10.5630\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.5316 - val_loss: 10.8418\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.4922 - val_loss: 10.8450\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.4685 - val_loss: 10.6526\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.3877 - val_loss: 10.6864\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.4108 - val_loss: 10.3658\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.3069 - val_loss: 10.7214\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.3787 - val_loss: 10.5996\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.2528 - val_loss: 10.9239\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.2739 - val_loss: 10.5552\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.1968 - val_loss: 10.7243\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 596us/step - loss: 39.9391 - val_loss: 29.1169\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 27.3666 - val_loss: 24.2623\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 23.3897 - val_loss: 23.6341\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 21.5775 - val_loss: 20.7630\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 20.4490 - val_loss: 20.0084\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 19.2005 - val_loss: 18.5164\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 18.7951 - val_loss: 18.1634\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.1186 - val_loss: 17.6516\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 17.7427 - val_loss: 18.4727\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 17.2585 - val_loss: 18.8609\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 17.0453 - val_loss: 17.7757\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.6698 - val_loss: 16.1751\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.1862 - val_loss: 15.9783\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.0452 - val_loss: 17.1764\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.9276 - val_loss: 15.9421\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.5036 - val_loss: 16.4200\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.3592 - val_loss: 15.4219\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.1249 - val_loss: 14.9507\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.0716 - val_loss: 15.0735\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.7464 - val_loss: 14.7066\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.5960 - val_loss: 14.3349\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.5166 - val_loss: 14.5665\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.3425 - val_loss: 14.2454\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.3795 - val_loss: 14.2879\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.0604 - val_loss: 14.2831\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.9973 - val_loss: 14.2761\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.0470 - val_loss: 14.0780\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 13.7967 - val_loss: 14.2963\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.8459 - val_loss: 13.7424\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 13.6418 - val_loss: 13.8364\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 13.6726 - val_loss: 13.7464\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 13.5416 - val_loss: 13.8771\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 13.4724 - val_loss: 13.4034\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 13.5058 - val_loss: 13.5149\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 3s 647us/step - loss: 13.3398 - val_loss: 13.4896\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 13.2290 - val_loss: 13.4039\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 3s 785us/step - loss: 13.1275 - val_loss: 13.2582\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 3s 759us/step - loss: 13.1142 - val_loss: 13.4750\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 3s 771us/step - loss: 13.1302 - val_loss: 13.1007\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 552us/step - loss: 13.1924 - val_loss: 13.6128\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.0761 - val_loss: 13.1313\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8992 - val_loss: 13.2883\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.8273 - val_loss: 12.9578\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.9059 - val_loss: 13.0177\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.7333 - val_loss: 13.1315\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.6639 - val_loss: 13.0714\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.7480 - val_loss: 12.7097\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.5710 - val_loss: 13.3918\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.5716 - val_loss: 12.9678\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.5381 - val_loss: 12.5298\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.5074 - val_loss: 13.1948\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.3409 - val_loss: 12.4650\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.4500 - val_loss: 12.4784\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.3630 - val_loss: 13.0559\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.2284 - val_loss: 12.7732\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.2923 - val_loss: 12.8644\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.1986 - val_loss: 12.5128\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 600us/step - loss: 35.0316 - val_loss: 32.7093\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 25.5890 - val_loss: 23.0474\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 22.4266 - val_loss: 20.7114\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 20.2737 - val_loss: 20.2434\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 18.9761 - val_loss: 17.9673\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.2754 - val_loss: 17.4712\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.4453 - val_loss: 16.5060\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 16.7159 - val_loss: 19.5728\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 16.4269 - val_loss: 16.3586\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 15.8817 - val_loss: 15.4560\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 15.5206 - val_loss: 14.9244\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 15.4174 - val_loss: 15.4116\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 14.9866 - val_loss: 14.7747\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 14.5998 - val_loss: 14.5432\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.4208 - val_loss: 15.8537\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.0303 - val_loss: 14.1737\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.9748 - val_loss: 13.7633\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.6426 - val_loss: 14.4651\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.6711 - val_loss: 14.4648\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.4286 - val_loss: 13.1591\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.2132 - val_loss: 13.0013\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.0228 - val_loss: 13.5611\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.9490 - val_loss: 13.4579\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.7805 - val_loss: 12.7927\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.6987 - val_loss: 13.4800\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.6982 - val_loss: 12.3223\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.4493 - val_loss: 12.2407\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.2945 - val_loss: 12.1631\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.1784 - val_loss: 12.2082\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.1507 - val_loss: 12.0503\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 12.0737 - val_loss: 11.9851\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 12.0409 - val_loss: 12.0539\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.8509 - val_loss: 11.6837\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.7986 - val_loss: 12.1309\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.6989 - val_loss: 11.6952\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.5759 - val_loss: 11.7746\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.6284 - val_loss: 11.6734\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.4285 - val_loss: 11.8919\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.4720 - val_loss: 11.3233\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.2876 - val_loss: 12.1179\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.3438 - val_loss: 12.9001\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.2137 - val_loss: 11.1408\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.1876 - val_loss: 12.0716\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.2115 - val_loss: 12.7458\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.0523 - val_loss: 11.0173\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.0505 - val_loss: 11.3615\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.9203 - val_loss: 11.0842\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.9130 - val_loss: 11.0091\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.7746 - val_loss: 11.3740\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.8106 - val_loss: 10.8977\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.7686 - val_loss: 10.8333\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.7029 - val_loss: 11.0588\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.8012 - val_loss: 10.7991\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.6424 - val_loss: 10.5441\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.5071 - val_loss: 10.8204\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 10.5540 - val_loss: 10.6976\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.5105 - val_loss: 10.5687\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.3961 - val_loss: 10.9913\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.4300 - val_loss: 10.7254\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 593us/step - loss: 40.9447 - val_loss: 33.2308\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 27.8368 - val_loss: 28.2353\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 25.0405 - val_loss: 23.7510\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 23.3418 - val_loss: 23.5499\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 21.9432 - val_loss: 21.2419\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 21.3252 - val_loss: 20.2007\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 20.1457 - val_loss: 19.6991\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 19.4422 - val_loss: 19.2833\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 18.9757 - val_loss: 19.6821\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 18.6244 - val_loss: 17.7902\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 18.0806 - val_loss: 17.8703\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 3s 650us/step - loss: 17.5685 - val_loss: 17.5625\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 17.1691 - val_loss: 16.8973\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 17.1286 - val_loss: 16.4250\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 16.7180 - val_loss: 16.3051\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 16.4594 - val_loss: 16.6347\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 16.3329 - val_loss: 16.0373\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.0462 - val_loss: 15.6704\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.7728 - val_loss: 16.9708\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 15.4752 - val_loss: 15.3912\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.5813 - val_loss: 15.4572\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.2164 - val_loss: 15.0567\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.0768 - val_loss: 14.8686\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 14.8696 - val_loss: 15.4061\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 14.7388 - val_loss: 14.8561\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 14.8599 - val_loss: 14.8853\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.5609 - val_loss: 14.4834\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 14.4781 - val_loss: 14.1566\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 14.4185 - val_loss: 14.8677\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.2612 - val_loss: 16.6114\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.2678 - val_loss: 14.7426\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.0257 - val_loss: 13.8386\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.8906 - val_loss: 13.9505\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.7202 - val_loss: 13.7971\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.8471 - val_loss: 13.7187\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.7092 - val_loss: 14.6631\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.7202 - val_loss: 14.1141\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.5889 - val_loss: 13.4321\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.4051 - val_loss: 13.5500\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.4620 - val_loss: 13.5796\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.5119 - val_loss: 13.5746\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.2767 - val_loss: 13.3729\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.1992 - val_loss: 13.2469\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.2664 - val_loss: 13.2171\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.3404 - val_loss: 13.3356\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.2425 - val_loss: 14.5241\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.1337 - val_loss: 13.4798\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.0772 - val_loss: 13.7849\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.0437 - val_loss: 13.3895\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 642us/step - loss: 39.0327 - val_loss: 29.9041\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 27.0321 - val_loss: 24.6633\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 23.1845 - val_loss: 21.4634\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 21.1274 - val_loss: 20.8080\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 19.4611 - val_loss: 18.4696\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 18.1652 - val_loss: 18.2968\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 17.4123 - val_loss: 16.8556\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 16.6369 - val_loss: 16.2363\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.2841 - val_loss: 15.9211\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.8420 - val_loss: 17.0563\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.6947 - val_loss: 15.2377\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.1872 - val_loss: 14.9937\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.9464 - val_loss: 14.9756\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.6447 - val_loss: 14.6319\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.3918 - val_loss: 14.1875\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.2998 - val_loss: 14.1702\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.0623 - val_loss: 13.8068\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.7796 - val_loss: 13.9488\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.5304 - val_loss: 13.5442\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.4153 - val_loss: 14.5550\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.2516 - val_loss: 13.2298\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.2092 - val_loss: 13.8296\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.0833 - val_loss: 13.2074\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.9191 - val_loss: 12.9276\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 498us/step - loss: 12.7934 - val_loss: 12.8264\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 12.6757 - val_loss: 12.5846\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 12.6160 - val_loss: 12.6563\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 12.4275 - val_loss: 12.5833\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.3906 - val_loss: 12.4871\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.2983 - val_loss: 12.3845\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.1895 - val_loss: 12.4538\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.1448 - val_loss: 12.3020\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.2278 - val_loss: 12.1271\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.9860 - val_loss: 12.0343\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.1327 - val_loss: 12.0410\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.8453 - val_loss: 12.2458\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.8905 - val_loss: 12.0900\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.6652 - val_loss: 11.8514\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.6968 - val_loss: 11.8045\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.5783 - val_loss: 11.8838\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.5819 - val_loss: 11.7615\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.4612 - val_loss: 11.7677\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.4563 - val_loss: 11.7945\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.4762 - val_loss: 11.6255\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.3800 - val_loss: 11.5826\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.3214 - val_loss: 11.8037\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.2170 - val_loss: 11.6456\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.2357 - val_loss: 11.4096\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.1433 - val_loss: 11.6256\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.1340 - val_loss: 11.3315\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.0998 - val_loss: 11.2616\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.0227 - val_loss: 11.2010\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.9975 - val_loss: 11.1582\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.9272 - val_loss: 11.1975\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.9265 - val_loss: 11.1813\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8956 - val_loss: 11.1835\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.8507 - val_loss: 11.7343\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 10.8323 - val_loss: 11.4351\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 633us/step - loss: 37.8567 - val_loss: 26.1886\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 24.2511 - val_loss: 25.2861\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 3s 654us/step - loss: 21.2980 - val_loss: 20.0863\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 19.4033 - val_loss: 19.1427\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.2159 - val_loss: 17.6100\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 17.2504 - val_loss: 18.1503\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 16.8380 - val_loss: 17.1195\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 16.0368 - val_loss: 15.7283\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 15.5163 - val_loss: 15.3288\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 15.3339 - val_loss: 14.9141\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.7054 - val_loss: 14.7501\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 14.3552 - val_loss: 14.0346\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.0868 - val_loss: 13.6117\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.6266 - val_loss: 13.4314\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.1861 - val_loss: 13.2307\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.9646 - val_loss: 12.6821\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.7971 - val_loss: 12.6555\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.5099 - val_loss: 12.1530\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.3002 - val_loss: 12.0550\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.1329 - val_loss: 12.0095\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 12.0919 - val_loss: 11.8624\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 11.9906 - val_loss: 11.6377\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.7372 - val_loss: 12.0142\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 11.7856 - val_loss: 11.7419\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 11.6183 - val_loss: 11.4582\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.4697 - val_loss: 11.7276\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.4815 - val_loss: 12.6925\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.4129 - val_loss: 11.2307\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2322 - val_loss: 11.0170\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.0889 - val_loss: 11.5190\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.0907 - val_loss: 11.3077\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.9952 - val_loss: 10.9874\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.9032 - val_loss: 10.8567\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.8712 - val_loss: 11.0957\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.8266 - val_loss: 10.8291\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.7134 - val_loss: 11.8286\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.7118 - val_loss: 10.6671\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.7491 - val_loss: 10.6562\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.4840 - val_loss: 10.8748\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.5416 - val_loss: 10.9342\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 10.4930 - val_loss: 10.5676\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.3933 - val_loss: 10.4282\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 10.4490 - val_loss: 10.4133\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 10.5646 - val_loss: 10.5384\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 10.2837 - val_loss: 10.6489\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 10.1161 - val_loss: 10.3430\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 10.2076 - val_loss: 10.3727\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.2275 - val_loss: 10.6650\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.0647 - val_loss: 10.3726\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.3184 - val_loss: 10.0274\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.0773 - val_loss: 10.0368\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.0060 - val_loss: 10.0959\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.1516 - val_loss: 10.4365\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.9205 - val_loss: 10.5946\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.8119 - val_loss: 9.9632\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.8758 - val_loss: 9.9202\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.0377 - val_loss: 9.9262\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 9.8290 - val_loss: 11.2340\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.7476 - val_loss: 9.7921\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.8093 - val_loss: 9.8081\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.8198 - val_loss: 9.8211\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.8086 - val_loss: 9.9987\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.6428 - val_loss: 9.6872\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.7411 - val_loss: 10.2647\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.9079 - val_loss: 9.7221\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.5726 - val_loss: 10.0109\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.5519 - val_loss: 10.2994\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.6460 - val_loss: 9.7075\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 594us/step - loss: 36.4716 - val_loss: 28.9877\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 26.9198 - val_loss: 25.9484\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 24.3694 - val_loss: 22.9797\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 23.2512 - val_loss: 22.3244\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 22.0916 - val_loss: 21.0886\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 21.2815 - val_loss: 21.0471\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 20.5253 - val_loss: 19.6607\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 19.8918 - val_loss: 19.6720\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 19.2475 - val_loss: 18.8961\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 18.8878 - val_loss: 18.1488\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 18.4890 - val_loss: 19.5108\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 18.3142 - val_loss: 17.7431\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 17.7347 - val_loss: 17.5518\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 17.5202 - val_loss: 17.2861\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 17.1212 - val_loss: 17.3060\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.0813 - val_loss: 16.4404\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.6857 - val_loss: 16.7288\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 16.5113 - val_loss: 16.5511\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.3972 - val_loss: 16.5756\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 16.2492 - val_loss: 15.9760\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.0333 - val_loss: 16.3083\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.9850 - val_loss: 16.4896\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.9375 - val_loss: 15.6447\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.7779 - val_loss: 16.1998\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.7154 - val_loss: 15.5917\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.4966 - val_loss: 15.4863\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.4614 - val_loss: 15.4541\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.3902 - val_loss: 15.4595\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.3019 - val_loss: 15.2262\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 15.2244 - val_loss: 15.2252\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 15.2044 - val_loss: 15.2207\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 15.1317 - val_loss: 15.2215\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 15.0479 - val_loss: 15.0214\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 590us/step - loss: 15.0435 - val_loss: 14.9255\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 3s 615us/step - loss: 14.9476 - val_loss: 15.8021\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 3s 645us/step - loss: 14.9261 - val_loss: 14.9100\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.8622 - val_loss: 15.0617\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.8415 - val_loss: 15.0817\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 14.7705 - val_loss: 14.8994\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.6982 - val_loss: 14.6637\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.7449 - val_loss: 14.6123\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 14.7548 - val_loss: 14.8005\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.6067 - val_loss: 15.3248\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 14.5483 - val_loss: 14.5016\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 14.5214 - val_loss: 14.5703\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.5772 - val_loss: 14.8395\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 14.4822 - val_loss: 14.7588\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 14.3621 - val_loss: 14.6783\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 14.5144 - val_loss: 14.4895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.3289 - val_loss: 14.3422\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 14.2591 - val_loss: 14.4609\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.3256 - val_loss: 14.2714\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.2272 - val_loss: 15.3106\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.3114 - val_loss: 14.1920\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.1623 - val_loss: 14.2215\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 14.1251 - val_loss: 14.1965\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.1207 - val_loss: 14.4416\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.1254 - val_loss: 15.0354\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 14.1281 - val_loss: 14.1904\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.0655 - val_loss: 14.3388\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 14.2622 - val_loss: 14.1892\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.9482 - val_loss: 14.1737\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 487us/step - loss: 13.9636 - val_loss: 14.4855\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 14.0936 - val_loss: 14.0592\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.8659 - val_loss: 14.2134\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.9125 - val_loss: 14.2387\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 13.8812 - val_loss: 13.8925\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.8748 - val_loss: 13.9821\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.9713 - val_loss: 14.0934\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.8724 - val_loss: 13.8664\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 3s 640us/step - loss: 13.9341 - val_loss: 14.0303\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 13.7881 - val_loss: 14.1317\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.7375 - val_loss: 14.1195\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 13.7170 - val_loss: 14.0185\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.7502 - val_loss: 14.3535\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 629us/step - loss: 36.7273 - val_loss: 25.1366\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 24.4000 - val_loss: 23.5118\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 22.1205 - val_loss: 21.1803\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 20.5761 - val_loss: 20.5278\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 19.3996 - val_loss: 21.0985\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 18.8751 - val_loss: 18.5743\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 18.2121 - val_loss: 17.7271\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 17.4297 - val_loss: 17.0546\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.2613 - val_loss: 16.9672\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.5028 - val_loss: 16.0267\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 16.2481 - val_loss: 16.0124\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.0163 - val_loss: 15.8583\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 15.7008 - val_loss: 15.8927\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.2245 - val_loss: 14.5133\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.9983 - val_loss: 14.6008\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.6762 - val_loss: 15.2027\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.5098 - val_loss: 14.1171\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.3171 - val_loss: 14.1410\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.1618 - val_loss: 13.8438\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.1172 - val_loss: 14.3895\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.7296 - val_loss: 13.9056\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.7776 - val_loss: 13.3490\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.5516 - val_loss: 13.4560\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.3345 - val_loss: 13.5537\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.2929 - val_loss: 12.9585\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.3149 - val_loss: 15.6775\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.1830 - val_loss: 13.5096\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.1409 - val_loss: 13.0830\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.9653 - val_loss: 12.9315\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.9084 - val_loss: 12.5895\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.8438 - val_loss: 12.6022\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.7767 - val_loss: 13.0905\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.6925 - val_loss: 13.1561\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.7331 - val_loss: 14.2452\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.6753 - val_loss: 12.1817\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.4805 - val_loss: 12.4957\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.4600 - val_loss: 12.9353\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.3521 - val_loss: 12.1476\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.3003 - val_loss: 12.4157\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.2990 - val_loss: 12.4801\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 12.2690 - val_loss: 12.1035\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 12.1596 - val_loss: 12.0067\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.0989 - val_loss: 11.9149\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.1509 - val_loss: 12.1703\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.0876 - val_loss: 12.4863\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.9936 - val_loss: 12.0107\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.9855 - val_loss: 11.8424\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9657 - val_loss: 12.0653\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 11.9024 - val_loss: 11.8226\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.8902 - val_loss: 12.9951\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.9455 - val_loss: 11.7552\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.7873 - val_loss: 12.2943\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.7895 - val_loss: 12.0880\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 485us/step - loss: 11.8306 - val_loss: 11.7905\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 380us/step - loss: 11.8023 - val_loss: 12.5314\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.6886 - val_loss: 11.9141\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 633us/step - loss: 37.2819 - val_loss: 27.2218\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 24.8301 - val_loss: 23.1324\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 3s 639us/step - loss: 21.3881 - val_loss: 19.8835\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 19.5202 - val_loss: 18.7231\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 18.3127 - val_loss: 18.3743\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 493us/step - loss: 17.1605 - val_loss: 17.1518\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 16.4224 - val_loss: 16.9402\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 15.5569 - val_loss: 15.2810\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 491us/step - loss: 14.9497 - val_loss: 15.6661\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.4180 - val_loss: 14.5000\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 492us/step - loss: 14.0127 - val_loss: 13.7086\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.2814 - val_loss: 13.4913\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.1598 - val_loss: 13.6920\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.7438 - val_loss: 13.2701\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.6679 - val_loss: 14.1954\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.4238 - val_loss: 13.1090\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.1352 - val_loss: 12.2749\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.9524 - val_loss: 12.2661\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.7781 - val_loss: 12.1259\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.6986 - val_loss: 11.7928\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.5507 - val_loss: 11.6227\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.3823 - val_loss: 11.4367\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.3693 - val_loss: 11.6083\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.1614 - val_loss: 11.3160\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.1390 - val_loss: 11.4694\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.0303 - val_loss: 11.1214\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.8804 - val_loss: 11.1185\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.0089 - val_loss: 10.8972\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.6637 - val_loss: 11.1139\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.7150 - val_loss: 11.1321\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.6030 - val_loss: 11.0747\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.6156 - val_loss: 10.8666\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.5591 - val_loss: 10.6047\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.4197 - val_loss: 11.6452\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.3813 - val_loss: 11.0999\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.3817 - val_loss: 10.5363\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.2343 - val_loss: 10.6445\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.3252 - val_loss: 10.3198\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 10.1096 - val_loss: 10.4325\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.1238 - val_loss: 10.9199\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 10.1507 - val_loss: 10.4406\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 10.0893 - val_loss: 10.2309\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 10.0026 - val_loss: 10.0885\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 9.9998 - val_loss: 10.2485\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 9.9667 - val_loss: 10.5848\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 9.8803 - val_loss: 10.0981\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 9.8701 - val_loss: 10.3651\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.8675 - val_loss: 9.9921\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.7897 - val_loss: 9.9420\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 9.7160 - val_loss: 10.9354\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.7427 - val_loss: 10.2063\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.6938 - val_loss: 9.9994\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.6649 - val_loss: 9.9076\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.6473 - val_loss: 9.9923\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.6020 - val_loss: 9.9333\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.5805 - val_loss: 10.4374\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.5443 - val_loss: 10.3307\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.5554 - val_loss: 10.2669\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 605us/step - loss: 35.0585 - val_loss: 22.7643\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 21.0257 - val_loss: 20.8832\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 18.4094 - val_loss: 17.9150\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 17.0345 - val_loss: 15.7904\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 15.8460 - val_loss: 16.2941\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.8563 - val_loss: 14.3786\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.5122 - val_loss: 13.7296\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.8120 - val_loss: 13.2244\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.6000 - val_loss: 13.5559\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.0163 - val_loss: 12.7005\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 499us/step - loss: 12.6368 - val_loss: 12.3542\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.4438 - val_loss: 12.9421\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.3185 - val_loss: 11.9659\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 11.8913 - val_loss: 11.9165\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.8766 - val_loss: 11.8467\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.6638 - val_loss: 11.6881\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.5736 - val_loss: 11.5260\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.3492 - val_loss: 10.9563\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.2402 - val_loss: 11.0156\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.9352 - val_loss: 10.8848\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.9405 - val_loss: 10.5355\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.8577 - val_loss: 10.4643\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6411 - val_loss: 10.3755\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.5299 - val_loss: 10.7409\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.4211 - val_loss: 10.3058\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.3972 - val_loss: 10.3592\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.3876 - val_loss: 10.4451\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.1789 - val_loss: 10.6725\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.1456 - val_loss: 9.9275\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.9333 - val_loss: 10.6109\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.8927 - val_loss: 10.0491\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 9.8986 - val_loss: 10.3254\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.9825 - val_loss: 9.8528\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 9.6463 - val_loss: 9.7234\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.5485 - val_loss: 9.4161\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 9.6999 - val_loss: 11.6282\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 9.8573 - val_loss: 9.2605\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.4201 - val_loss: 10.2370\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.5149 - val_loss: 9.6157\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.2585 - val_loss: 9.2375\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 9.2516 - val_loss: 9.1054\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 9.2855 - val_loss: 9.6709\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 9.1923 - val_loss: 9.0591\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 9.4055 - val_loss: 9.1027\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 9.1432 - val_loss: 9.0866\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 8.9381 - val_loss: 8.8343\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 3s 640us/step - loss: 9.0089 - val_loss: 8.8585\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.0114 - val_loss: 8.9691\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 8.9715 - val_loss: 9.6907\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 8.9241 - val_loss: 8.8709\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 8.8536 - val_loss: 8.7636\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 8.7792 - val_loss: 9.1042\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 452us/step - loss: 8.7457 - val_loss: 8.7791\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 481us/step - loss: 8.7295 - val_loss: 8.8802\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 8.7477 - val_loss: 8.6136\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 8.7019 - val_loss: 9.2961\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 8.5729 - val_loss: 8.4704\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 8.7033 - val_loss: 8.9326\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 8.5880 - val_loss: 9.8196\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 8.5574 - val_loss: 8.6598\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 8.4655 - val_loss: 8.5605\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 8.5546 - val_loss: 8.4788\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 607us/step - loss: 36.0552 - val_loss: 25.4155\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 23.4736 - val_loss: 22.9920\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 20.6855 - val_loss: 19.7877\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 19.0441 - val_loss: 18.0212\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 17.5234 - val_loss: 16.4778\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.4509 - val_loss: 15.4811\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.7754 - val_loss: 17.5430\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 15.2455 - val_loss: 15.5946\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 14.4771 - val_loss: 14.1393\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.0525 - val_loss: 13.6827\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.6744 - val_loss: 13.6612\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.2487 - val_loss: 13.2941\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.1256 - val_loss: 12.8453\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.7120 - val_loss: 12.9444\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.6850 - val_loss: 12.4334\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.3577 - val_loss: 12.1090\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.2497 - val_loss: 12.1776\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.2027 - val_loss: 12.2089\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.8523 - val_loss: 12.0330\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 11.7733 - val_loss: 11.6877\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 11.5780 - val_loss: 11.4787\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 11.5185 - val_loss: 11.3796\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 11.3110 - val_loss: 11.5792\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 591us/step - loss: 11.3068 - val_loss: 11.2970\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 541us/step - loss: 11.1535 - val_loss: 11.9535\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 11.0349 - val_loss: 11.2771\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 10.9320 - val_loss: 11.1746\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.9505 - val_loss: 10.8755\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 10.7500 - val_loss: 10.6650\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 10.6615 - val_loss: 10.6450\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.6375 - val_loss: 10.6644\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 493us/step - loss: 10.5092 - val_loss: 10.4864\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 10.3947 - val_loss: 10.3440\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.5208 - val_loss: 10.8178\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.2771 - val_loss: 10.6946\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.2745 - val_loss: 10.2470\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.2004 - val_loss: 10.2789\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 10.1948 - val_loss: 10.3402\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.1247 - val_loss: 10.5162\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.0647 - val_loss: 10.0269\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.9738 - val_loss: 10.0039\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.9763 - val_loss: 10.6447\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.8473 - val_loss: 9.9813\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.8045 - val_loss: 9.9346\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.7002 - val_loss: 9.9763\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.8416 - val_loss: 9.7263\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.7255 - val_loss: 9.7526\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.6190 - val_loss: 9.8253\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.6891 - val_loss: 10.1851\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.5731 - val_loss: 9.6753\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 9.4920 - val_loss: 9.8135\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.5392 - val_loss: 9.5121\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.4385 - val_loss: 10.1996\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 9.4572 - val_loss: 9.9719\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.4499 - val_loss: 9.8860\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.3787 - val_loss: 9.5981\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.3027 - val_loss: 9.5332\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 605us/step - loss: 39.0383 - val_loss: 26.0040\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 24.6730 - val_loss: 22.5799\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 21.3195 - val_loss: 20.2414\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 19.6401 - val_loss: 18.5931\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 18.4567 - val_loss: 18.0653\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 17.5873 - val_loss: 17.0213\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 17.1429 - val_loss: 16.7681\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 16.5588 - val_loss: 16.0551\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 16.1255 - val_loss: 15.6001\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 15.7463 - val_loss: 15.5375\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 15.3933 - val_loss: 15.7200\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 15.1298 - val_loss: 14.6920\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 14.7914 - val_loss: 14.4293\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 14.5223 - val_loss: 14.7531\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 14.2975 - val_loss: 14.1223\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 14.0853 - val_loss: 14.5014\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.7582 - val_loss: 13.7895\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.6267 - val_loss: 13.4076\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.4123 - val_loss: 13.1465\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 574us/step - loss: 13.2831 - val_loss: 12.8952\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 3s 600us/step - loss: 13.1008 - val_loss: 13.2940\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 573us/step - loss: 12.9220 - val_loss: 13.0250\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 12.8518 - val_loss: 12.8400\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 568us/step - loss: 12.7294 - val_loss: 12.4952\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 3s 604us/step - loss: 12.5367 - val_loss: 12.6901\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 578us/step - loss: 12.4407 - val_loss: 12.9266\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.4089 - val_loss: 12.2435\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.2345 - val_loss: 12.3835\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.1830 - val_loss: 12.7243\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.2133 - val_loss: 12.3343\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.0926 - val_loss: 12.0365\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 12.0150 - val_loss: 12.0673\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 11.9476 - val_loss: 12.0494\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 11.8330 - val_loss: 11.8718\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 11.7064 - val_loss: 11.7294\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 11.7420 - val_loss: 11.7191\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 11.6827 - val_loss: 12.1679\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.6505 - val_loss: 11.8136\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 11.4709 - val_loss: 11.5334\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 11.4484 - val_loss: 11.8424\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 11.4603 - val_loss: 11.4527\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 11.3703 - val_loss: 11.3903\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 11.3401 - val_loss: 11.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 11.3431 - val_loss: 11.3216\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 11.2111 - val_loss: 12.1123\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2350 - val_loss: 11.7577\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.1878 - val_loss: 11.3265\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.0827 - val_loss: 11.1199\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.9551 - val_loss: 11.3454\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.0825 - val_loss: 11.1637\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.9782 - val_loss: 11.0014\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.9329 - val_loss: 11.0270\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.9801 - val_loss: 11.4459\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.9215 - val_loss: 10.9980\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.8108 - val_loss: 11.0545\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.8480 - val_loss: 11.4926\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 10.7447 - val_loss: 10.8709\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.7769 - val_loss: 10.7384\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 10.7346 - val_loss: 11.0375\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.8069 - val_loss: 11.0190\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.6650 - val_loss: 11.0571\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 10.7651 - val_loss: 10.9007\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 10.5906 - val_loss: 10.7655\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 626us/step - loss: 35.1242 - val_loss: 26.2852\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 23.5487 - val_loss: 21.5966\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 19.9567 - val_loss: 21.1065\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 18.3897 - val_loss: 17.4026\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 17.2367 - val_loss: 17.0209\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 16.3997 - val_loss: 15.5881\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.6538 - val_loss: 16.2931\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.4878 - val_loss: 20.7642\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 15.0954 - val_loss: 14.5581\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 14.4799 - val_loss: 13.9931\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.1649 - val_loss: 13.5522\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.8366 - val_loss: 13.7401\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.5840 - val_loss: 14.0514\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.4563 - val_loss: 14.1658\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.9969 - val_loss: 13.0122\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.8193 - val_loss: 12.6309\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.5611 - val_loss: 12.5037\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.5383 - val_loss: 12.2299\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.2255 - val_loss: 12.1138\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.0722 - val_loss: 12.4388\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.9408 - val_loss: 12.5834\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.7313 - val_loss: 12.4418\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.5096 - val_loss: 11.1988\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.5463 - val_loss: 11.0925\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.3914 - val_loss: 13.9561\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.2153 - val_loss: 10.9561\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.0230 - val_loss: 10.8789\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.9282 - val_loss: 10.9001\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.8985 - val_loss: 10.8626\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.7154 - val_loss: 10.7804\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.6687 - val_loss: 10.6217\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.6135 - val_loss: 10.9333\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.5109 - val_loss: 11.1167\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.5626 - val_loss: 10.4301\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.3798 - val_loss: 11.0197\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.2958 - val_loss: 10.7343\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.1764 - val_loss: 10.3520\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.1538 - val_loss: 10.4298\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.1247 - val_loss: 10.6346\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.0507 - val_loss: 9.9653\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.0142 - val_loss: 10.2180\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.0091 - val_loss: 10.0401\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.8850 - val_loss: 9.8110\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.8376 - val_loss: 10.4255\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.8152 - val_loss: 9.7309\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 9.7888 - val_loss: 10.1215\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.9293 - val_loss: 9.6563\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.7129 - val_loss: 9.6115\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.5970 - val_loss: 10.0966\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.6313 - val_loss: 10.1794\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.5462 - val_loss: 9.7005\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.5306 - val_loss: 9.9083\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.5135 - val_loss: 9.6467\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 653us/step - loss: 41.6692 - val_loss: 29.5424\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 27.6448 - val_loss: 25.6786\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 541us/step - loss: 24.9627 - val_loss: 23.6674\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 23.4154 - val_loss: 22.1465\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 22.2752 - val_loss: 21.9025\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 3s 648us/step - loss: 20.8952 - val_loss: 20.0397\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 20.0376 - val_loss: 19.3654\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 19.3917 - val_loss: 19.6257\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 3s 749us/step - loss: 18.7813 - val_loss: 18.2260\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 3s 760us/step - loss: 18.2463 - val_loss: 18.3988\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 3s 718us/step - loss: 17.7595 - val_loss: 17.8749\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 17.4398 - val_loss: 17.7329\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 17.0207 - val_loss: 17.2669\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.6122 - val_loss: 16.7784\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.5523 - val_loss: 16.2991\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.1115 - val_loss: 16.4874\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.8730 - val_loss: 15.7238\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 15.6310 - val_loss: 15.6630\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 15.5669 - val_loss: 15.2403\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.0766 - val_loss: 14.9688\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.0065 - val_loss: 14.6486\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.0253 - val_loss: 15.4399\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.5708 - val_loss: 14.4051\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 14.3720 - val_loss: 14.4157\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.3783 - val_loss: 14.5566\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.2313 - val_loss: 14.3525\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.1527 - val_loss: 14.3628\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.9155 - val_loss: 13.8236\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.9570 - val_loss: 14.3502\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.8117 - val_loss: 13.6621\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.5286 - val_loss: 13.4031\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.5778 - val_loss: 14.0611\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.5310 - val_loss: 13.9071\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.2977 - val_loss: 15.1814\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.3676 - val_loss: 13.2669\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.2592 - val_loss: 13.6754\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.1288 - val_loss: 13.2267\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.1412 - val_loss: 13.0053\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.9251 - val_loss: 13.0800\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.1151 - val_loss: 13.2925\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 12.8459 - val_loss: 13.1130\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 12.8119 - val_loss: 13.0789\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 12.7579 - val_loss: 13.1274\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 608us/step - loss: 39.5350 - val_loss: 29.5103\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 25.4722 - val_loss: 23.1320\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 21.9400 - val_loss: 21.0385\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 20.1459 - val_loss: 19.0818\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 19.0213 - val_loss: 19.3348\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.8930 - val_loss: 17.1629\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 17.0802 - val_loss: 17.6035\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.4522 - val_loss: 15.9013\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.8683 - val_loss: 16.5324\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.6484 - val_loss: 15.3252\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.2195 - val_loss: 15.1759\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.9428 - val_loss: 14.8566\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.4289 - val_loss: 15.0507\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.2719 - val_loss: 14.5341\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 14.0564 - val_loss: 13.8279\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.7363 - val_loss: 13.6633\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 13.6351 - val_loss: 13.3445\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 13.4070 - val_loss: 13.3187\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.1344 - val_loss: 14.5008\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.1667 - val_loss: 14.3035\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.8631 - val_loss: 12.7693\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.8905 - val_loss: 12.8216\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.5223 - val_loss: 13.3431\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.4172 - val_loss: 12.7547\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.4657 - val_loss: 12.8974\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.2959 - val_loss: 13.4753\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.1416 - val_loss: 12.1679\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.0823 - val_loss: 12.0489\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.9257 - val_loss: 12.0569\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9631 - val_loss: 12.0868\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.7388 - val_loss: 11.8331\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.7370 - val_loss: 11.7916\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 11.6501 - val_loss: 12.8201\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.6639 - val_loss: 11.7476\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.4800 - val_loss: 11.7170\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.5245 - val_loss: 12.9983\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.3664 - val_loss: 11.7622\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.2559 - val_loss: 11.6654\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.2798 - val_loss: 11.3624\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.2628 - val_loss: 11.3174\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.0775 - val_loss: 11.3386\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.1571 - val_loss: 11.3182\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 11.0938 - val_loss: 11.1966\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.9977 - val_loss: 11.7316\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.9508 - val_loss: 11.1539\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.9910 - val_loss: 11.0774\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8905 - val_loss: 11.0340\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.8229 - val_loss: 11.0905\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.7959 - val_loss: 11.0368\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.7581 - val_loss: 11.2076\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.6740 - val_loss: 10.7957\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.6752 - val_loss: 10.9856\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 475us/step - loss: 10.5761 - val_loss: 10.8802\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.5381 - val_loss: 10.7439\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 10.5883 - val_loss: 10.7745\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 10.4906 - val_loss: 10.8198\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 10.4927 - val_loss: 10.6933\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 10.4199 - val_loss: 10.6974\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 10.3553 - val_loss: 10.6283\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 3s 648us/step - loss: 10.3869 - val_loss: 10.7734\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.3244 - val_loss: 10.7599\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.2309 - val_loss: 10.5931\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.2915 - val_loss: 10.6293\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.2648 - val_loss: 10.6802\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 10.1337 - val_loss: 10.6043\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.1610 - val_loss: 10.4394\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.1320 - val_loss: 10.4005\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.1331 - val_loss: 10.4139\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.1017 - val_loss: 10.4156\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.1246 - val_loss: 10.5096\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.9776 - val_loss: 10.2706\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.0758 - val_loss: 10.7444\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 9.9642 - val_loss: 10.2276\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 9.9070 - val_loss: 10.4466\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.8981 - val_loss: 10.1323\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.8872 - val_loss: 10.1386\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.8389 - val_loss: 10.1313\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.8460 - val_loss: 10.1529\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.9038 - val_loss: 10.1640\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.7539 - val_loss: 10.4551\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.7995 - val_loss: 10.5944\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.7665 - val_loss: 10.1225\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.6909 - val_loss: 9.9953\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.7662 - val_loss: 10.2402\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.7080 - val_loss: 10.3262\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.7271 - val_loss: 10.0771\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.6357 - val_loss: 9.9780\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.6683 - val_loss: 10.5729\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.6404 - val_loss: 10.3156\n",
      "Epoch 90/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.5723 - val_loss: 9.9547\n",
      "Epoch 91/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.5873 - val_loss: 9.9161\n",
      "Epoch 92/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.5529 - val_loss: 10.2289\n",
      "Epoch 93/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.5395 - val_loss: 9.9326\n",
      "Epoch 94/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.5789 - val_loss: 10.3353\n",
      "Epoch 95/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.5443 - val_loss: 10.2276\n",
      "Epoch 96/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 9.5321 - val_loss: 9.8579\n",
      "Epoch 97/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.4788 - val_loss: 9.9891\n",
      "Epoch 98/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 9.4646 - val_loss: 9.9853\n",
      "Epoch 99/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 9.4069 - val_loss: 10.0204\n",
      "Epoch 100/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 9.4438 - val_loss: 10.1326\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 639us/step - loss: 38.2818 - val_loss: 26.0950\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 23.8549 - val_loss: 21.4031\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 20.6479 - val_loss: 19.3495\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 18.8857 - val_loss: 19.1595\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 17.9378 - val_loss: 16.9347\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 16.8534 - val_loss: 16.3287\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 16.3283 - val_loss: 15.6163\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.7719 - val_loss: 15.3148\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 15.2589 - val_loss: 14.6706\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.0005 - val_loss: 15.7935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.4231 - val_loss: 14.5402\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.2301 - val_loss: 13.5245\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.7294 - val_loss: 13.4195\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.5828 - val_loss: 12.9595\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 13.6033 - val_loss: 13.5333\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.0656 - val_loss: 13.1628\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.8923 - val_loss: 13.0513\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.8926 - val_loss: 13.0469\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.5782 - val_loss: 12.5017\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 12.4883 - val_loss: 12.2101\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.2433 - val_loss: 12.0910\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.2150 - val_loss: 12.0211\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.0952 - val_loss: 12.4402\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.9485 - val_loss: 11.7875\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.9378 - val_loss: 11.8287\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.6816 - val_loss: 11.4881\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.6974 - val_loss: 11.4061\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.3770 - val_loss: 11.7986\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.5117 - val_loss: 11.3880\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.3152 - val_loss: 11.1560\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.2900 - val_loss: 11.2069\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2279 - val_loss: 10.9523\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.0987 - val_loss: 11.3038\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.9874 - val_loss: 10.9480\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.8694 - val_loss: 10.6938\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.1605 - val_loss: 10.8020\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.6991 - val_loss: 10.5066\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.7034 - val_loss: 10.7941\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6433 - val_loss: 10.6349\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.5613 - val_loss: 11.1810\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.5192 - val_loss: 10.4481\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.5330 - val_loss: 11.4030\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5084 - val_loss: 10.3892\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.3785 - val_loss: 11.0038\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.2305 - val_loss: 10.5088\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.3121 - val_loss: 10.6533\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.3172 - val_loss: 10.1438\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.1732 - val_loss: 10.1267\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.0908 - val_loss: 10.1355\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.0704 - val_loss: 10.0998\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.0517 - val_loss: 10.0529\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.1818 - val_loss: 10.2527\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.9905 - val_loss: 9.9440\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.9242 - val_loss: 9.8101\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 9.8469 - val_loss: 9.9488\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 9.8604 - val_loss: 9.9882\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 9.7996 - val_loss: 9.7538\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 9.7646 - val_loss: 9.9210\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 9.7842 - val_loss: 9.7077\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 9.7046 - val_loss: 10.1477\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 3s 662us/step - loss: 9.7089 - val_loss: 10.4953\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.6499 - val_loss: 9.8100\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.6195 - val_loss: 9.7774\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.5310 - val_loss: 9.5723\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.6093 - val_loss: 9.6239\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.4765 - val_loss: 9.8507\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.5464 - val_loss: 9.4316\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 9.4292 - val_loss: 9.3944\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 9.4869 - val_loss: 9.7556\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.4506 - val_loss: 9.3924\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.5100 - val_loss: 9.4706\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 9.3326 - val_loss: 9.3397\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 9.3288 - val_loss: 9.5004\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 9.3647 - val_loss: 9.4343\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 9.3176 - val_loss: 9.6250\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 9.3286 - val_loss: 9.5180\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 9.2540 - val_loss: 9.2330\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.2536 - val_loss: 9.5310\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.2198 - val_loss: 9.5458\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 9.2289 - val_loss: 9.6187\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 9.1603 - val_loss: 9.3650\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 9.2161 - val_loss: 9.3305\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 608us/step - loss: 37.4737 - val_loss: 28.8608\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 27.2573 - val_loss: 24.9204\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 24.9211 - val_loss: 23.5029\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 23.1338 - val_loss: 22.1572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 22.1183 - val_loss: 21.9326\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 21.1081 - val_loss: 20.8170\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 20.5354 - val_loss: 20.0475\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 20.1803 - val_loss: 19.7010\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 19.3573 - val_loss: 18.6792\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 18.8042 - val_loss: 19.4339\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 18.5242 - val_loss: 18.0225\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 18.1493 - val_loss: 18.3014\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 17.8368 - val_loss: 18.7535\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 17.5484 - val_loss: 17.0576\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 17.1647 - val_loss: 17.0670\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 16.9372 - val_loss: 16.7898\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 16.8130 - val_loss: 17.0116\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 16.6953 - val_loss: 16.3376\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 16.4329 - val_loss: 16.4751\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 16.1463 - val_loss: 15.8816\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.0561 - val_loss: 15.7954\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.8311 - val_loss: 15.7711\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.6543 - val_loss: 15.8475\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 15.6142 - val_loss: 15.7392\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.4240 - val_loss: 15.3376\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.2848 - val_loss: 15.0608\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.3675 - val_loss: 15.2422\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.9986 - val_loss: 15.1973\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.1474 - val_loss: 15.0649\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.9516 - val_loss: 15.5407\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 14.8765 - val_loss: 14.8098\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.6869 - val_loss: 14.6673\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.6054 - val_loss: 14.5044\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.5723 - val_loss: 14.5316\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.5625 - val_loss: 14.5668\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.4930 - val_loss: 14.4194\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.3777 - val_loss: 14.7330\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.3159 - val_loss: 16.2226\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.2609 - val_loss: 14.3927\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.2684 - val_loss: 14.5662\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.1178 - val_loss: 14.2623\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.1922 - val_loss: 14.1877\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.0709 - val_loss: 14.1823\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.9837 - val_loss: 13.9153\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.9930 - val_loss: 14.0704\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.8485 - val_loss: 14.2729\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.8684 - val_loss: 13.9036\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.8404 - val_loss: 14.0169\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.6963 - val_loss: 13.7521\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.7137 - val_loss: 13.9089\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.6964 - val_loss: 13.6953\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 13.6054 - val_loss: 13.8811\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.6348 - val_loss: 13.6934\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.6258 - val_loss: 13.5011\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.5056 - val_loss: 13.6497\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.5116 - val_loss: 13.6510\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.4664 - val_loss: 13.5804\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.4163 - val_loss: 13.7049\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.3708 - val_loss: 13.4769\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.4193 - val_loss: 13.7377\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.4153 - val_loss: 13.4640\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.2677 - val_loss: 13.3680\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.2310 - val_loss: 13.4095\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.3019 - val_loss: 13.3487\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 13.2358 - val_loss: 13.6771\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.2411 - val_loss: 13.2908\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.1606 - val_loss: 13.4118\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.0973 - val_loss: 13.3250\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.1351 - val_loss: 13.6939\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.1786 - val_loss: 13.7692\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.0598 - val_loss: 13.2930\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 648us/step - loss: 35.3249 - val_loss: 25.4434\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 23.7925 - val_loss: 21.9380\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 20.8471 - val_loss: 19.9022\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 19.4677 - val_loss: 18.8447\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 18.4817 - val_loss: 18.2253\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 3s 657us/step - loss: 17.7647 - val_loss: 17.0901\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 17.3619 - val_loss: 19.9542\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.8214 - val_loss: 16.5680\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 502us/step - loss: 16.4287 - val_loss: 15.8376\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 494us/step - loss: 16.0294 - val_loss: 15.6139\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 15.5346 - val_loss: 15.6690\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 15.3892 - val_loss: 14.9593\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.9126 - val_loss: 15.5505\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 14.8957 - val_loss: 16.7732\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.5787 - val_loss: 15.0315\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.5096 - val_loss: 15.2150\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.2336 - val_loss: 14.0151\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.0905 - val_loss: 13.7697\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.8098 - val_loss: 13.9572\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.5965 - val_loss: 14.0903\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.4134 - val_loss: 13.2348\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.3485 - val_loss: 13.4657\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.0684 - val_loss: 13.2095\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.1220 - val_loss: 12.8510\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.9793 - val_loss: 12.7955\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.8627 - val_loss: 12.5048\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 12.6526 - val_loss: 12.5296\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.4645 - val_loss: 12.4436\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.4302 - val_loss: 13.1734\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 12.3574 - val_loss: 12.1594\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.2048 - val_loss: 12.4784\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.1851 - val_loss: 12.0684\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 11.9671 - val_loss: 11.8540\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.9466 - val_loss: 12.3197\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.7342 - val_loss: 12.0575\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.7673 - val_loss: 12.1005\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.8380 - val_loss: 11.6664\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.5675 - val_loss: 11.5762\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.5185 - val_loss: 11.8177\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.4225 - val_loss: 11.7141\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.4278 - val_loss: 11.3533\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.2609 - val_loss: 11.8049\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.2916 - val_loss: 11.4378\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 11.1002 - val_loss: 11.6722\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.1747 - val_loss: 11.2838\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 10.9258 - val_loss: 11.5939\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 10.9815 - val_loss: 10.9913\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 10.9217 - val_loss: 11.9187\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 10.8916 - val_loss: 10.9274\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 10.8998 - val_loss: 11.1183\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.7376 - val_loss: 10.7379\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.7195 - val_loss: 10.6626\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.6367 - val_loss: 10.6211\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.5722 - val_loss: 11.0621\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5271 - val_loss: 10.6334\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.5422 - val_loss: 10.7661\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.4754 - val_loss: 10.4887\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.4708 - val_loss: 10.6365\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.3892 - val_loss: 10.5340\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.3469 - val_loss: 10.4952\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.3632 - val_loss: 10.9247\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.3049 - val_loss: 10.4798\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.2741 - val_loss: 10.6389\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.2451 - val_loss: 10.3355\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.1959 - val_loss: 10.3782\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.1824 - val_loss: 10.8287\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.0883 - val_loss: 10.4072\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.0853 - val_loss: 10.1033\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.0722 - val_loss: 10.2394\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.0482 - val_loss: 10.2865\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.9705 - val_loss: 10.2759\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.0332 - val_loss: 10.3947\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.9721 - val_loss: 10.1465\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 593us/step - loss: 37.2997 - val_loss: 27.7624\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 25.5747 - val_loss: 23.3934\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 21.8292 - val_loss: 23.3792\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 19.9471 - val_loss: 18.7626\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 18.6784 - val_loss: 18.0936\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 17.7336 - val_loss: 17.0416\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.8956 - val_loss: 16.8717\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.2488 - val_loss: 16.1881\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.9534 - val_loss: 15.7296\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 15.3704 - val_loss: 15.2511\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.1480 - val_loss: 15.4090\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 14.7972 - val_loss: 14.5854\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 14.3915 - val_loss: 14.1708\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 13.9960 - val_loss: 14.2954\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.9997 - val_loss: 14.5767\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 13.7333 - val_loss: 13.6248\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.5618 - val_loss: 14.2376\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 13.2967 - val_loss: 13.7228\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 13.2102 - val_loss: 13.2768\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 12.8742 - val_loss: 13.3066\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.7968 - val_loss: 13.1586\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.7810 - val_loss: 12.8396\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.5923 - val_loss: 12.5371\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.4552 - val_loss: 12.8424\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.5340 - val_loss: 12.6551\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.2170 - val_loss: 12.5429\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.2022 - val_loss: 12.7728\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 451us/step - loss: 12.2588 - val_loss: 12.5130\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 11.9564 - val_loss: 12.3414\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.9356 - val_loss: 11.9896\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 11.7583 - val_loss: 11.9281\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 11.7075 - val_loss: 11.9708\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 11.6121 - val_loss: 11.9165\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.6776 - val_loss: 12.1532\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 3s 638us/step - loss: 11.6063 - val_loss: 11.7409\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.4548 - val_loss: 12.4180\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 11.3659 - val_loss: 11.5564\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 494us/step - loss: 11.4058 - val_loss: 11.5534\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.2168 - val_loss: 11.7253\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 11.2384 - val_loss: 11.3900\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.2175 - val_loss: 11.4050\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.1787 - val_loss: 11.3568\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.9922 - val_loss: 11.4730\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.9974 - val_loss: 11.2681\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.9674 - val_loss: 11.7586\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.9800 - val_loss: 11.6577\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.8927 - val_loss: 11.1490\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.8470 - val_loss: 11.3319\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.7482 - val_loss: 11.0232\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 10.8098 - val_loss: 10.8979\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.6784 - val_loss: 10.8998\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.7019 - val_loss: 11.1573\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.7291 - val_loss: 10.7378\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 10.6113 - val_loss: 11.7427\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.5349 - val_loss: 10.9059\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.4861 - val_loss: 10.6897\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.5653 - val_loss: 10.7503\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.5195 - val_loss: 11.4701\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.3892 - val_loss: 10.5859\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.3755 - val_loss: 11.1463\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.5132 - val_loss: 11.3842\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.3364 - val_loss: 10.5983\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.1874 - val_loss: 10.5854\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.2925 - val_loss: 10.9334\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.2206 - val_loss: 10.5217\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.2719 - val_loss: 10.5132\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.1457 - val_loss: 10.6583\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.1599 - val_loss: 10.4726\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 10.1233 - val_loss: 10.5230\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 10.1614 - val_loss: 10.4053\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.2552 - val_loss: 10.8265\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.9449 - val_loss: 10.3167\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 10.0189 - val_loss: 10.3398\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 9.9941 - val_loss: 10.8634\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 10.0461 - val_loss: 10.2781\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 10.0158 - val_loss: 10.9956\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 9.9392 - val_loss: 10.4340\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 9.9198 - val_loss: 10.4719\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 9.9978 - val_loss: 10.2790\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.8812 - val_loss: 10.4648\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 601us/step - loss: 36.5772 - val_loss: 25.4152\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 23.1453 - val_loss: 20.5917\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 19.9796 - val_loss: 19.2678\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 18.6853 - val_loss: 17.6871\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 17.6853 - val_loss: 17.4080\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 506us/step - loss: 17.0761 - val_loss: 16.3334\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 3s 628us/step - loss: 16.4000 - val_loss: 15.7947\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 15.9450 - val_loss: 15.6311\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.6734 - val_loss: 15.3676\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 15.1135 - val_loss: 14.8198\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 14.9883 - val_loss: 14.4713\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.7522 - val_loss: 14.0481\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 14.4086 - val_loss: 14.3892\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 13.9947 - val_loss: 15.1920\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.8163 - val_loss: 13.5635\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.7293 - val_loss: 13.2692\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 13.5150 - val_loss: 13.3926\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 13.4053 - val_loss: 13.1327\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.4325 - val_loss: 12.7154\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.8418 - val_loss: 13.4656\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.7780 - val_loss: 13.5043\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.7487 - val_loss: 13.2818\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.8513 - val_loss: 12.6460\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.3328 - val_loss: 12.1517\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.2370 - val_loss: 12.4745\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.2814 - val_loss: 11.8684\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.4394 - val_loss: 12.1854\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.9568 - val_loss: 12.2599\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.9575 - val_loss: 11.6798\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.9098 - val_loss: 11.6997\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.8429 - val_loss: 11.7708\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.6700 - val_loss: 12.0227\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.6360 - val_loss: 11.9907\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.5211 - val_loss: 12.1416\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 584us/step - loss: 37.4792 - val_loss: 30.6069\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 27.1570 - val_loss: 24.1962\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 23.8179 - val_loss: 22.8493\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 21.5521 - val_loss: 20.4760\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 20.0527 - val_loss: 19.4308\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 18.7896 - val_loss: 18.0785\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 17.9944 - val_loss: 17.6751\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 17.3446 - val_loss: 17.2738\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 16.5336 - val_loss: 19.0105\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 16.3181 - val_loss: 15.8003\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.7540 - val_loss: 15.7685\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 15.5201 - val_loss: 15.7228\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 15.3730 - val_loss: 15.7939\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 14.8238 - val_loss: 14.7673\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 14.6818 - val_loss: 14.6117\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 14.3973 - val_loss: 14.4072\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 14.3189 - val_loss: 14.5169\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 13.9637 - val_loss: 13.8253\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 3s 623us/step - loss: 13.7570 - val_loss: 14.0849\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 13.5905 - val_loss: 13.3322\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 13.3070 - val_loss: 13.1291\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 13.2029 - val_loss: 13.0094\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.9506 - val_loss: 13.0650\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.0167 - val_loss: 12.9416\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.7296 - val_loss: 12.7480\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.5652 - val_loss: 13.4097\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.4853 - val_loss: 12.2423\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.3633 - val_loss: 12.3795\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.2490 - val_loss: 12.1561\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.1017 - val_loss: 12.1788\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.0294 - val_loss: 11.8398\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9039 - val_loss: 11.8739\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 11.8138 - val_loss: 12.0139\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.7929 - val_loss: 11.7205\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 11.5996 - val_loss: 11.6717\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.4861 - val_loss: 12.6939\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.5061 - val_loss: 11.5772\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.4936 - val_loss: 12.7840\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 11.3166 - val_loss: 11.3227\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2423 - val_loss: 12.1787\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2394 - val_loss: 11.2027\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.1635 - val_loss: 11.0685\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.1269 - val_loss: 11.2327\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.9950 - val_loss: 11.0367\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.9860 - val_loss: 11.2090\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.0660 - val_loss: 11.3390\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.9565 - val_loss: 11.7219\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 494us/step - loss: 10.8214 - val_loss: 10.8647\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 10.7758 - val_loss: 10.7292\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.7209 - val_loss: 10.8191\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.7184 - val_loss: 10.7681\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.5998 - val_loss: 10.8430\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.7717 - val_loss: 10.7125\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.6647 - val_loss: 10.7910\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.4933 - val_loss: 10.5229\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.5644 - val_loss: 10.7697\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.4089 - val_loss: 10.6818\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 10.4456 - val_loss: 10.7247\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 10.3713 - val_loss: 10.5062\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 10.3736 - val_loss: 10.5332\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 573us/step - loss: 10.3075 - val_loss: 10.5476\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 10.2783 - val_loss: 10.4287\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.2769 - val_loss: 10.2161\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.2095 - val_loss: 10.3192\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.2206 - val_loss: 10.2674\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.1768 - val_loss: 10.5360\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.2122 - val_loss: 10.9392\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.0366 - val_loss: 10.1319\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.2417 - val_loss: 10.1148\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.9622 - val_loss: 10.0676\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.0107 - val_loss: 10.1239\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.9627 - val_loss: 10.1641\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.9360 - val_loss: 9.9553\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.0756 - val_loss: 10.4319\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.8102 - val_loss: 10.0885\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.8132 - val_loss: 10.0064\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.8196 - val_loss: 10.0997\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.8223 - val_loss: 10.2700\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 600us/step - loss: 39.4650 - val_loss: 30.6135\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 26.1888 - val_loss: 23.3786\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 23.0590 - val_loss: 22.9306\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 22.0688 - val_loss: 20.7300\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 20.7012 - val_loss: 20.4951\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 19.9367 - val_loss: 19.0541\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 19.0681 - val_loss: 18.7309\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 18.7434 - val_loss: 18.0979\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.2279 - val_loss: 19.0121\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.7640 - val_loss: 17.9688\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.2740 - val_loss: 17.4039\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.8938 - val_loss: 16.4328\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.6494 - val_loss: 16.2538\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.2712 - val_loss: 15.8730\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.0565 - val_loss: 15.6521\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.9783 - val_loss: 15.5898\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.5781 - val_loss: 15.2173\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.4058 - val_loss: 15.6665\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 15.2829 - val_loss: 15.1754\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.0091 - val_loss: 15.2439\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 15.1333 - val_loss: 15.0715\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.7232 - val_loss: 14.4301\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.6052 - val_loss: 14.5028\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.3639 - val_loss: 14.5560\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.2816 - val_loss: 14.4236\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.3241 - val_loss: 14.1810\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.1451 - val_loss: 13.9764\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.9669 - val_loss: 13.9564\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.9402 - val_loss: 13.8301\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.7987 - val_loss: 13.6328\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.7102 - val_loss: 13.8246\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.6767 - val_loss: 13.8360\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.4250 - val_loss: 13.5357\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.4501 - val_loss: 13.7542\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 470us/step - loss: 13.4342 - val_loss: 13.9764\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 567us/step - loss: 13.3062 - val_loss: 13.8952\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 570us/step - loss: 13.3542 - val_loss: 13.1977\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 13.0645 - val_loss: 13.1318\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 13.2387 - val_loss: 13.7377\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 13.0143 - val_loss: 13.0556\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 12.9195 - val_loss: 13.2365\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 3s 662us/step - loss: 12.9318 - val_loss: 13.1214\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.9102 - val_loss: 12.8810\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.7287 - val_loss: 12.8096\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 12.7298 - val_loss: 12.8425\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 12.7050 - val_loss: 13.1438\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 12.5879 - val_loss: 12.6361\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.5517 - val_loss: 12.8200\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.6072 - val_loss: 13.5788\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.4875 - val_loss: 12.6621\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.3330 - val_loss: 12.5752\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.4723 - val_loss: 12.5528\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.2479 - val_loss: 12.6178\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.2999 - val_loss: 12.3179\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.2577 - val_loss: 12.3528\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.2473 - val_loss: 12.4119\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.1653 - val_loss: 12.3874\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.1749 - val_loss: 12.2434\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.1368 - val_loss: 12.2923\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.0056 - val_loss: 12.3547\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.0317 - val_loss: 12.0416\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.9658 - val_loss: 12.7834\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.9477 - val_loss: 12.1443\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.9128 - val_loss: 12.0678\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.8307 - val_loss: 12.0187\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 11.8184 - val_loss: 11.9635\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.8506 - val_loss: 12.0491\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.8048 - val_loss: 11.8871\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.7357 - val_loss: 12.8792\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.6968 - val_loss: 11.9577\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.8815 - val_loss: 12.2585\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.5769 - val_loss: 11.7386\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.6516 - val_loss: 11.8759\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.5882 - val_loss: 11.9473\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.5639 - val_loss: 12.0072\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.5444 - val_loss: 12.1044\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.5575 - val_loss: 11.7555\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 632us/step - loss: 36.0789 - val_loss: 29.8208\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 25.7588 - val_loss: 23.3673\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 22.0394 - val_loss: 20.3252\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 19.9975 - val_loss: 18.9753\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 18.9716 - val_loss: 20.2205\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 17.9463 - val_loss: 17.6285\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 17.8295 - val_loss: 17.6064\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 17.0109 - val_loss: 16.8041\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 16.4728 - val_loss: 16.1560\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.3126 - val_loss: 15.7295\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 15.7996 - val_loss: 15.7775\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 15.6557 - val_loss: 15.2619\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 15.3444 - val_loss: 15.6485\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.0706 - val_loss: 14.7599\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.8469 - val_loss: 15.0049\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.5711 - val_loss: 15.0571\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.3846 - val_loss: 13.8345\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.1165 - val_loss: 14.3193\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.9062 - val_loss: 14.2598\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.7667 - val_loss: 13.8456\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.6731 - val_loss: 13.3148\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.3328 - val_loss: 14.6492\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.3498 - val_loss: 15.2452\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.0391 - val_loss: 12.7305\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.9009 - val_loss: 13.9884\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.7460 - val_loss: 12.4410\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.7065 - val_loss: 12.6863\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.4421 - val_loss: 12.1365\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.4125 - val_loss: 12.4590\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.2692 - val_loss: 11.8704\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.0293 - val_loss: 12.0757\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.0431 - val_loss: 11.7489\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.8951 - val_loss: 12.1462\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.8198 - val_loss: 12.9546\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.6867 - val_loss: 11.6747\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.5996 - val_loss: 13.4832\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.5211 - val_loss: 11.4631\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.4377 - val_loss: 11.3169\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.4896 - val_loss: 12.8840\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.3107 - val_loss: 11.7156\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.2794 - val_loss: 11.5447\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.0915 - val_loss: 11.1101\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 11.1459 - val_loss: 11.3164\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.1011 - val_loss: 11.6424\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.9414 - val_loss: 10.9146\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.0155 - val_loss: 10.9074\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 10.9157 - val_loss: 10.7788\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.8163 - val_loss: 11.1494\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.9011 - val_loss: 10.8983\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6718 - val_loss: 10.8531\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6859 - val_loss: 10.7267\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.6259 - val_loss: 11.2574\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.6146 - val_loss: 10.5045\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.5365 - val_loss: 10.6066\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.4831 - val_loss: 11.0333\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.5090 - val_loss: 10.5911\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.4775 - val_loss: 10.6692\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.4757 - val_loss: 10.4034\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 468us/step - loss: 10.3250 - val_loss: 10.3860\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 10.4200 - val_loss: 10.5383\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 10.2954 - val_loss: 10.8836\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 10.2025 - val_loss: 10.2994\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 10.2503 - val_loss: 10.3500\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 10.1510 - val_loss: 10.1466\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 10.1108 - val_loss: 10.1810\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 3s 680us/step - loss: 10.2255 - val_loss: 10.3168\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 3s 784us/step - loss: 10.1037 - val_loss: 10.4042\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 3s 759us/step - loss: 10.0829 - val_loss: 10.0652\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 3s 765us/step - loss: 10.0948 - val_loss: 10.0835\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 3s 759us/step - loss: 9.9531 - val_loss: 10.1041\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 3s 664us/step - loss: 9.9482 - val_loss: 10.3188\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.9024 - val_loss: 10.0099\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 9.8797 - val_loss: 10.1646\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 9.9203 - val_loss: 9.9154\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 9.8430 - val_loss: 10.4141\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.8876 - val_loss: 10.1538\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.7957 - val_loss: 10.1995\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 9.7746 - val_loss: 10.3271\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.8278 - val_loss: 9.7548\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.7350 - val_loss: 9.8903\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.6926 - val_loss: 9.8675\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.7198 - val_loss: 9.7724\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.6166 - val_loss: 10.3053\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.6561 - val_loss: 9.9612\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 604us/step - loss: 40.4651 - val_loss: 29.0516\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 28.4549 - val_loss: 26.5006\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 25.6106 - val_loss: 24.5493\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 23.8224 - val_loss: 22.7319\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 22.5386 - val_loss: 22.0476\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 21.5952 - val_loss: 20.8305\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 20.7220 - val_loss: 20.4079\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 19.9705 - val_loss: 19.5077\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 19.5666 - val_loss: 18.8950\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 18.9778 - val_loss: 18.6692\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 18.6586 - val_loss: 18.3676\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 18.2302 - val_loss: 17.6332\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 17.8687 - val_loss: 17.9247\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 17.5952 - val_loss: 17.9291\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 17.3404 - val_loss: 17.0758\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 17.0082 - val_loss: 16.6680\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 16.7493 - val_loss: 17.1892\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 16.5213 - val_loss: 16.1780\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 16.2500 - val_loss: 16.1629\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.0857 - val_loss: 16.0361\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.8517 - val_loss: 15.8472\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 15.5298 - val_loss: 16.5496\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.4633 - val_loss: 15.6872\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.3973 - val_loss: 15.4642\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.1623 - val_loss: 15.3007\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.9403 - val_loss: 15.1577\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.9282 - val_loss: 15.0716\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.8387 - val_loss: 14.9188\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 14.6495 - val_loss: 14.6608\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.5829 - val_loss: 14.8767\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.4974 - val_loss: 14.5425\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 14.3931 - val_loss: 14.2530\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 14.3205 - val_loss: 14.2720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.1666 - val_loss: 14.5613\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 14.1934 - val_loss: 14.3465\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.9726 - val_loss: 14.3698\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 14.0273 - val_loss: 14.0398\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.9105 - val_loss: 14.2411\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.8808 - val_loss: 13.7913\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.7661 - val_loss: 14.2685\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.7255 - val_loss: 14.0494\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.6433 - val_loss: 13.7878\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.5628 - val_loss: 14.0111\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.5951 - val_loss: 13.5961\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 13.3794 - val_loss: 14.0176\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.3970 - val_loss: 13.3680\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.4345 - val_loss: 13.4540\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.2961 - val_loss: 13.5178\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.2798 - val_loss: 13.3106\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.2249 - val_loss: 13.4678\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.1610 - val_loss: 13.5810\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.1575 - val_loss: 13.4213\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.0590 - val_loss: 13.3232\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.0033 - val_loss: 13.1906\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.9918 - val_loss: 13.2166\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.9909 - val_loss: 13.1070\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.8611 - val_loss: 13.1478\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8646 - val_loss: 14.1307\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.9029 - val_loss: 12.9934\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8090 - val_loss: 13.2492\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.7296 - val_loss: 13.5168\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.6979 - val_loss: 13.3144\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.6650 - val_loss: 13.0321\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.7479 - val_loss: 12.8398\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.5741 - val_loss: 12.9612\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.6001 - val_loss: 12.8210\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.5101 - val_loss: 12.8897\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.5668 - val_loss: 12.8546\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.4928 - val_loss: 12.6957\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.4972 - val_loss: 12.6864\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 12.4238 - val_loss: 12.8549\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 12.4486 - val_loss: 12.8252\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 12.3692 - val_loss: 12.8323\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 12.4215 - val_loss: 12.8384\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 12.3114 - val_loss: 12.7279\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 598us/step - loss: 39.6161 - val_loss: 33.0027\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 26.9490 - val_loss: 24.2452\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 23.4419 - val_loss: 22.0762\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 21.3663 - val_loss: 20.4670\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 20.1464 - val_loss: 18.8458\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 18.9129 - val_loss: 18.7821\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 17.8854 - val_loss: 18.0089\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 17.5334 - val_loss: 17.0920\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 16.9213 - val_loss: 16.5616\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 16.3919 - val_loss: 16.2795\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 16.0726 - val_loss: 15.8933\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 15.6579 - val_loss: 15.9363\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 15.4162 - val_loss: 15.6194\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 15.2319 - val_loss: 15.4510\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 14.7701 - val_loss: 15.0815\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 14.7106 - val_loss: 14.5827\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 14.4387 - val_loss: 15.2773\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 14.3561 - val_loss: 14.8616\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 14.0072 - val_loss: 14.0251\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.8829 - val_loss: 14.0027\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.8165 - val_loss: 13.8024\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.4926 - val_loss: 13.7539\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.3449 - val_loss: 13.5038\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.2260 - val_loss: 13.9778\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.1520 - val_loss: 13.7671\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.0988 - val_loss: 13.3553\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.9672 - val_loss: 13.1576\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.7457 - val_loss: 13.1460\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.7224 - val_loss: 13.5289\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.6383 - val_loss: 13.3313\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.5291 - val_loss: 12.7292\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.4029 - val_loss: 12.8218\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.3441 - val_loss: 12.6436\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.2427 - val_loss: 12.3742\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.1330 - val_loss: 12.4006\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.0944 - val_loss: 12.2288\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 12.0506 - val_loss: 12.5267\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 11.9994 - val_loss: 12.3009\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 11.9457 - val_loss: 12.4772\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 11.7878 - val_loss: 12.1584\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 11.8826 - val_loss: 12.0719\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 11.9089 - val_loss: 12.5714\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.6791 - val_loss: 11.9599\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 11.6478 - val_loss: 12.1794\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.5216 - val_loss: 12.0283\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.6289 - val_loss: 12.1410\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.5904 - val_loss: 12.3316\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.4690 - val_loss: 12.1735\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 602us/step - loss: 38.3581 - val_loss: 25.5248\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 23.1166 - val_loss: 21.8627\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 19.8777 - val_loss: 18.2893\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.3266 - val_loss: 18.0904\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 17.0433 - val_loss: 17.0337\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.3381 - val_loss: 15.3612\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.6341 - val_loss: 15.1029\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.0688 - val_loss: 15.8636\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.5756 - val_loss: 14.1354\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.9439 - val_loss: 13.4876\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.7552 - val_loss: 13.8513\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.3409 - val_loss: 12.8741\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 13.2723 - val_loss: 14.1478\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.9086 - val_loss: 12.3885\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 12.7675 - val_loss: 12.4241\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 12.4250 - val_loss: 12.1033\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.4902 - val_loss: 11.9029\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.1860 - val_loss: 12.0237\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.9573 - val_loss: 12.0577\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 11.9547 - val_loss: 12.1004\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.9069 - val_loss: 11.5365\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.5513 - val_loss: 11.4022\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.4164 - val_loss: 11.7459\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 11.4420 - val_loss: 11.6550\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.2716 - val_loss: 11.0422\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.1430 - val_loss: 10.9663\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.2513 - val_loss: 10.8736\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.9849 - val_loss: 10.7374\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.9011 - val_loss: 11.1746\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.7757 - val_loss: 10.8698\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.8075 - val_loss: 10.5810\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.8716 - val_loss: 10.4666\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6617 - val_loss: 10.5346\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.5100 - val_loss: 10.2958\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.4856 - val_loss: 10.2787\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.4804 - val_loss: 10.5302\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.4464 - val_loss: 10.3573\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.3208 - val_loss: 10.9242\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.3852 - val_loss: 10.7297\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 10.3176 - val_loss: 10.0644\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.2204 - val_loss: 11.2203\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.2426 - val_loss: 10.5655\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.1631 - val_loss: 10.1167\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 482us/step - loss: 10.0332 - val_loss: 10.2101\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 10.1191 - val_loss: 10.1547\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 650us/step - loss: 36.5827 - val_loss: 29.0803\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 26.9316 - val_loss: 25.6627\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 3s 638us/step - loss: 24.2901 - val_loss: 26.1656\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 22.7229 - val_loss: 21.7643\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 21.3803 - val_loss: 21.8051\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 20.9477 - val_loss: 20.4124\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 20.1250 - val_loss: 21.1858\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 19.6466 - val_loss: 19.6593\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 19.2722 - val_loss: 21.5787\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 18.7930 - val_loss: 18.5444\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 18.1302 - val_loss: 17.8479\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 17.7722 - val_loss: 17.3437\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 17.5806 - val_loss: 17.0073\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 17.3867 - val_loss: 17.3368\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 16.9204 - val_loss: 17.0675\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.6145 - val_loss: 16.9789\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.4585 - val_loss: 16.4645\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 16.3351 - val_loss: 15.9332\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 16.1585 - val_loss: 15.9042\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 15.8905 - val_loss: 15.9051\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.7799 - val_loss: 15.8627\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.6963 - val_loss: 15.7485\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 3s 674us/step - loss: 15.6628 - val_loss: 15.7143\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 3s 683us/step - loss: 15.5177 - val_loss: 15.6098\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 3s 647us/step - loss: 15.4257 - val_loss: 15.7025\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 15.4201 - val_loss: 15.4172\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 3s 612us/step - loss: 15.1947 - val_loss: 15.1457\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 3s 601us/step - loss: 15.1376 - val_loss: 15.1846\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 3s 712us/step - loss: 15.1096 - val_loss: 15.4944\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 585us/step - loss: 14.9840 - val_loss: 15.1397\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 3s 608us/step - loss: 14.8990 - val_loss: 14.7023\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 575us/step - loss: 14.7525 - val_loss: 15.1339\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 14.7864 - val_loss: 15.1108\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 3s 641us/step - loss: 14.6441 - val_loss: 15.1481\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 3s 605us/step - loss: 14.6200 - val_loss: 14.8288\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 14.5590 - val_loss: 14.5425\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 14.5308 - val_loss: 14.5670\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 14.5646 - val_loss: 14.7418\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 14.4139 - val_loss: 14.8654\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 14.3601 - val_loss: 14.4373\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 581us/step - loss: 14.2948 - val_loss: 14.4205\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 586us/step - loss: 14.4722 - val_loss: 14.3299\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 574us/step - loss: 14.2254 - val_loss: 15.0547\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 560us/step - loss: 14.2408 - val_loss: 14.4711\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 560us/step - loss: 14.1524 - val_loss: 14.0045\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 562us/step - loss: 14.0474 - val_loss: 14.1862\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 14.1752 - val_loss: 14.2213\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 14.0893 - val_loss: 14.2105\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 13.9989 - val_loss: 14.2266\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 13.9471 - val_loss: 14.0859\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 623us/step - loss: 36.4944 - val_loss: 27.7810\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 569us/step - loss: 24.2176 - val_loss: 22.0870\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 21.4443 - val_loss: 20.1138\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 19.6334 - val_loss: 19.9689\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 18.8220 - val_loss: 18.0528\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 18.2596 - val_loss: 17.5749\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 17.4482 - val_loss: 17.1728\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 16.9855 - val_loss: 16.3494\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 16.4590 - val_loss: 16.2236\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 16.0750 - val_loss: 16.8828\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 15.6970 - val_loss: 15.7961\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 15.5266 - val_loss: 15.0502\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 15.0796 - val_loss: 16.0802\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 15.0409 - val_loss: 14.9210\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 14.8377 - val_loss: 16.3374\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 14.5702 - val_loss: 14.5109\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 14.2355 - val_loss: 14.2953\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 14.4455 - val_loss: 14.8051\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 13.9996 - val_loss: 14.1388\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 578us/step - loss: 13.9226 - val_loss: 13.9237\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 13.8512 - val_loss: 13.6171\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 13.7212 - val_loss: 13.7916\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 13.5660 - val_loss: 13.8779\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 13.6124 - val_loss: 13.5470\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 13.4013 - val_loss: 13.5550\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 13.2530 - val_loss: 13.6221\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 13.2798 - val_loss: 12.9236\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 13.0241 - val_loss: 13.3001\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 13.0982 - val_loss: 12.8803\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 13.0322 - val_loss: 13.3939\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 12.8429 - val_loss: 13.1342\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 12.8617 - val_loss: 12.7344\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 12.7688 - val_loss: 12.8791\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 12.6796 - val_loss: 14.1264\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 12.6574 - val_loss: 12.6483\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 12.6422 - val_loss: 12.7514\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 12.5164 - val_loss: 12.7128\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 12.5044 - val_loss: 12.4256\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 12.4804 - val_loss: 13.1961\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 12.4829 - val_loss: 12.6410\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.3465 - val_loss: 12.5023\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.2410 - val_loss: 12.5265\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.3308 - val_loss: 12.3777\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.2337 - val_loss: 12.5389\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.1889 - val_loss: 12.1045\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.0665 - val_loss: 12.5658\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 456us/step - loss: 12.0808 - val_loss: 12.5033\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 12.1734 - val_loss: 12.3415\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 12.0134 - val_loss: 12.2661\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 11.9820 - val_loss: 12.1109\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 730us/step - loss: 39.7403 - val_loss: 30.7290\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 26.0033 - val_loss: 23.7541\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 22.2883 - val_loss: 19.9789\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 497us/step - loss: 19.7983 - val_loss: 19.9481\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 18.1293 - val_loss: 17.4958\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 17.0199 - val_loss: 16.3558\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 15.8217 - val_loss: 15.7985\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 15.4505 - val_loss: 15.2234\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.8026 - val_loss: 15.5389\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.3636 - val_loss: 14.5977\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.1385 - val_loss: 14.1080\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.6787 - val_loss: 13.8063\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.6315 - val_loss: 13.8735\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.1600 - val_loss: 13.2779\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.0072 - val_loss: 12.9922\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.6902 - val_loss: 12.7628\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.5966 - val_loss: 12.6591\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.3781 - val_loss: 13.0236\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.2418 - val_loss: 12.2650\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.2231 - val_loss: 12.4014\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.9532 - val_loss: 12.0775\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 11.7304 - val_loss: 11.7446\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.6714 - val_loss: 11.9167\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.6172 - val_loss: 11.8179\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.5028 - val_loss: 11.5695\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.2572 - val_loss: 11.4088\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.1887 - val_loss: 11.4781\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.1408 - val_loss: 11.1511\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.0773 - val_loss: 11.6472\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.9562 - val_loss: 11.1588\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.9347 - val_loss: 10.9459\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.8041 - val_loss: 11.7100\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.5972 - val_loss: 10.9040\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.6635 - val_loss: 11.0401\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 10.4898 - val_loss: 10.6617\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.4198 - val_loss: 10.8205\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.5885 - val_loss: 10.6021\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.2284 - val_loss: 10.5306\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.1941 - val_loss: 10.4640\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 10.1721 - val_loss: 10.8304\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 10.0960 - val_loss: 10.4034\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 10.0742 - val_loss: 10.1559\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 10.0180 - val_loss: 10.0905\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 9.9371 - val_loss: 10.1321\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 9.9265 - val_loss: 10.1438\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.8521 - val_loss: 10.0269\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.7969 - val_loss: 10.0707\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.8213 - val_loss: 10.3423\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.7710 - val_loss: 10.5880\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 9.6864 - val_loss: 9.8782\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.7007 - val_loss: 9.9379\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.7085 - val_loss: 9.9440\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.5776 - val_loss: 9.8346\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.5710 - val_loss: 9.8817\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.5639 - val_loss: 9.7499\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.4768 - val_loss: 9.6577\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.4451 - val_loss: 9.8968\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.4732 - val_loss: 9.8145\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.3441 - val_loss: 9.7485\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.3789 - val_loss: 10.0273\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 9.3550 - val_loss: 9.8771\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 599us/step - loss: 36.5104 - val_loss: 26.6950\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 21.7348 - val_loss: 19.1964\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 18.4702 - val_loss: 19.8174\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 17.1322 - val_loss: 16.3437\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 549us/step - loss: 16.3016 - val_loss: 15.5939\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.4640 - val_loss: 14.7225\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.7489 - val_loss: 15.9872\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.4913 - val_loss: 15.1729\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 14.0292 - val_loss: 14.0423\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.7214 - val_loss: 13.2395\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.5346 - val_loss: 13.1163\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.4173 - val_loss: 14.4829\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8270 - val_loss: 12.7259\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 12.6835 - val_loss: 12.4600\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.5078 - val_loss: 12.0401\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.1694 - val_loss: 12.1797\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.0657 - val_loss: 13.2037\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.7624 - val_loss: 12.0927\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.8389 - val_loss: 11.3823\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.5571 - val_loss: 11.5652\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.3762 - val_loss: 11.4648\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.3542 - val_loss: 11.0394\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.1285 - val_loss: 11.2812\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.0608 - val_loss: 11.6740\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.8674 - val_loss: 11.0189\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.8692 - val_loss: 11.0610\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.8123 - val_loss: 11.1273\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.5814 - val_loss: 11.7494\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.7280 - val_loss: 10.4789\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.5396 - val_loss: 10.6304\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.2683 - val_loss: 10.2316\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.2871 - val_loss: 10.0485\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.0863 - val_loss: 10.6562\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 483us/step - loss: 10.0490 - val_loss: 9.9540\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.1016 - val_loss: 10.2979\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 562us/step - loss: 9.9024 - val_loss: 10.1009\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 9.7577 - val_loss: 10.0010\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 9.8383 - val_loss: 9.7728\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 9.8277 - val_loss: 9.6843\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 9.6441 - val_loss: 9.3734\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 3s 661us/step - loss: 9.4888 - val_loss: 9.6199\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.4668 - val_loss: 9.8961\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.4813 - val_loss: 9.2811\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.3082 - val_loss: 9.5159\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.3293 - val_loss: 9.1879\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 9.3036 - val_loss: 9.0164\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 9.1640 - val_loss: 9.2769\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 9.1565 - val_loss: 9.3617\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.1703 - val_loss: 9.1345\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.0852 - val_loss: 8.9774\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.0996 - val_loss: 9.3104\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 8.9024 - val_loss: 9.0901\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 8.9909 - val_loss: 9.2282\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 8.8888 - val_loss: 11.7500\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 9.0067 - val_loss: 9.3363\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 616us/step - loss: 37.2351 - val_loss: 28.7490\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 26.7576 - val_loss: 25.0088\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 22.4908 - val_loss: 20.2098\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 19.8666 - val_loss: 18.0158\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 18.3516 - val_loss: 17.4807\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.9949 - val_loss: 16.2711\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.1101 - val_loss: 15.2651\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.5346 - val_loss: 14.6901\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 14.8349 - val_loss: 15.3322\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.1498 - val_loss: 13.9314\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.9879 - val_loss: 13.6890\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 13.5795 - val_loss: 13.2410\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 13.2079 - val_loss: 13.1202\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.9750 - val_loss: 13.0361\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.7841 - val_loss: 12.6918\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.4933 - val_loss: 12.4988\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.3483 - val_loss: 12.3611\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.1722 - val_loss: 12.4245\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9250 - val_loss: 12.7298\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.8462 - val_loss: 11.7112\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.7038 - val_loss: 12.1687\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 11.5739 - val_loss: 11.4713\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 11.3870 - val_loss: 11.4356\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 11.4015 - val_loss: 11.8997\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 548us/step - loss: 11.2984 - val_loss: 11.4251\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 539us/step - loss: 11.1125 - val_loss: 10.9861\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 10.9686 - val_loss: 11.2201\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.8042 - val_loss: 10.7857\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.7205 - val_loss: 10.6383\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.6816 - val_loss: 10.5344\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.6247 - val_loss: 10.5624\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.5402 - val_loss: 10.6945\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.4031 - val_loss: 10.3091\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.3060 - val_loss: 10.6271\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.2257 - val_loss: 10.0785\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.2206 - val_loss: 10.2988\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.1207 - val_loss: 10.2215\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.0475 - val_loss: 10.0043\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.0004 - val_loss: 10.6618\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.3262 - val_loss: 10.7292\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 9.9199 - val_loss: 10.0003\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.7984 - val_loss: 9.8872\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.7626 - val_loss: 10.8998\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.7608 - val_loss: 9.7546\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 9.7537 - val_loss: 9.8172\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.6640 - val_loss: 10.0362\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.7048 - val_loss: 9.6648\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.7164 - val_loss: 9.9310\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.5978 - val_loss: 9.7176\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.5134 - val_loss: 9.5878\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.4881 - val_loss: 9.6478\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.5130 - val_loss: 9.6826\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.4398 - val_loss: 9.4005\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.3398 - val_loss: 9.4133\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.4423 - val_loss: 9.6134\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.3420 - val_loss: 9.3462\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.2524 - val_loss: 9.4410\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 9.3224 - val_loss: 9.5080\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.1802 - val_loss: 9.4975\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.2169 - val_loss: 9.2560\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 9.1685 - val_loss: 9.1955\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.1703 - val_loss: 9.5191\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.2066 - val_loss: 9.4242\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 9.1694 - val_loss: 9.8086\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.1435 - val_loss: 9.1184\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.1272 - val_loss: 9.3517\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 9.0201 - val_loss: 9.0926\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 9.0295 - val_loss: 9.1501\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 9.0257 - val_loss: 9.7619\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 8.9511 - val_loss: 9.1658\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 8.9178 - val_loss: 9.0246\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 8.9412 - val_loss: 9.1392\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.0243 - val_loss: 9.6201\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 8.8570 - val_loss: 9.0859\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 8.8389 - val_loss: 9.1460\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 8.8691 - val_loss: 9.5594\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 564us/step - loss: 38.3373 - val_loss: 26.5766\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 24.5354 - val_loss: 24.1954\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 22.0462 - val_loss: 20.7924\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 20.5238 - val_loss: 19.8167\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 19.4186 - val_loss: 18.8644\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 18.7681 - val_loss: 18.2490\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 18.0053 - val_loss: 17.4020\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 3s 635us/step - loss: 17.4562 - val_loss: 17.4326\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 546us/step - loss: 17.0160 - val_loss: 17.7797\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.5466 - val_loss: 17.6515\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.2452 - val_loss: 17.7123\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.9126 - val_loss: 15.5304\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.5133 - val_loss: 15.4324\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.3313 - val_loss: 15.1453\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 15.1507 - val_loss: 14.7733\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.7503 - val_loss: 15.0655\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.5545 - val_loss: 14.4580\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.4187 - val_loss: 14.3671\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 14.1577 - val_loss: 14.4743\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.9512 - val_loss: 13.7354\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.8450 - val_loss: 13.4833\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.6386 - val_loss: 13.5978\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 13.4553 - val_loss: 14.0205\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 13.3097 - val_loss: 13.3523\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 13.2702 - val_loss: 13.0261\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.0910 - val_loss: 13.5341\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.8553 - val_loss: 12.9504\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.7862 - val_loss: 13.1530\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.7775 - val_loss: 12.8045\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.6192 - val_loss: 12.4245\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.5213 - val_loss: 12.4563\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.4232 - val_loss: 12.2533\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.2312 - val_loss: 12.3018\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 12.1468 - val_loss: 12.1173\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 12.0535 - val_loss: 12.2105\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.9554 - val_loss: 12.2529\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.0064 - val_loss: 11.8674\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.8578 - val_loss: 11.8302\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.7403 - val_loss: 12.2774\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.6863 - val_loss: 11.6863\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.6132 - val_loss: 11.6820\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.4868 - val_loss: 11.5022\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.4616 - val_loss: 11.4833\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 11.4095 - val_loss: 11.6922\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.3530 - val_loss: 11.4598\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 11.3265 - val_loss: 11.3947\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 11.1872 - val_loss: 11.1997\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 11.2434 - val_loss: 11.3659\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 11.1470 - val_loss: 11.1975\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 11.1185 - val_loss: 11.7019\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.0090 - val_loss: 11.6275\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 11.0092 - val_loss: 11.3181\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.9571 - val_loss: 10.9695\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.8701 - val_loss: 11.0842\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.8697 - val_loss: 11.2755\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 3s 649us/step - loss: 10.7827 - val_loss: 11.0972\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 10.8907 - val_loss: 10.8738\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.6996 - val_loss: 10.8439\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.7439 - val_loss: 10.8494\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.6708 - val_loss: 10.8703\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.6838 - val_loss: 10.9220\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.5824 - val_loss: 10.6828\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.5624 - val_loss: 10.6461\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.5542 - val_loss: 10.6957\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.5430 - val_loss: 10.6385\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.4829 - val_loss: 10.6210\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.4717 - val_loss: 10.5953\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 10.3810 - val_loss: 10.7964\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.3856 - val_loss: 10.5276\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.3898 - val_loss: 10.7912\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.3623 - val_loss: 10.5957\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.3091 - val_loss: 10.8539\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.2500 - val_loss: 10.5984\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.2618 - val_loss: 10.5925\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 599us/step - loss: 35.4776 - val_loss: 26.9064\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 24.0223 - val_loss: 21.5507\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 20.3578 - val_loss: 21.1262\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 18.6909 - val_loss: 17.8368\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 17.6541 - val_loss: 17.0244\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 16.9176 - val_loss: 17.1917\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 16.2125 - val_loss: 15.8775\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.5282 - val_loss: 15.4515\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.3065 - val_loss: 15.1801\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.7517 - val_loss: 15.0565\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.5503 - val_loss: 14.5033\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.9774 - val_loss: 13.8481\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.9464 - val_loss: 13.9547\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.6309 - val_loss: 13.6119\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.4768 - val_loss: 12.9603\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.2902 - val_loss: 12.8358\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.8390 - val_loss: 12.5880\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.7484 - val_loss: 12.2474\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.6163 - val_loss: 12.5852\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.3708 - val_loss: 13.2298\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.3247 - val_loss: 12.2142\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 12.0797 - val_loss: 11.8038\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 11.8777 - val_loss: 11.5073\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.7135 - val_loss: 11.3686\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 11.5003 - val_loss: 11.4774\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.3611 - val_loss: 11.5055\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.3348 - val_loss: 10.9654\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 414us/step - loss: 11.1643 - val_loss: 10.9322\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 453us/step - loss: 10.9017 - val_loss: 12.3398\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 10.8515 - val_loss: 11.2633\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 10.7266 - val_loss: 11.0028\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 10.5737 - val_loss: 10.8138\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 10.6883 - val_loss: 10.8204\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 10.4452 - val_loss: 10.4987\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 582us/step - loss: 10.3239 - val_loss: 10.2029\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 581us/step - loss: 10.2953 - val_loss: 10.2466\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.3941 - val_loss: 10.0648\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.0377 - val_loss: 10.0540\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.1007 - val_loss: 9.9329\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.1684 - val_loss: 10.0039\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 496us/step - loss: 9.8943 - val_loss: 10.1308\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.9505 - val_loss: 9.8092\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.8907 - val_loss: 9.8260\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 9.7795 - val_loss: 10.2519\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.6799 - val_loss: 9.9272\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.7052 - val_loss: 9.9530\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.7085 - val_loss: 9.5854\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.6478 - val_loss: 9.7746\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.5733 - val_loss: 9.6819\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.4917 - val_loss: 9.7849\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 9.5333 - val_loss: 9.8880\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 9.4559 - val_loss: 10.2668\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 599us/step - loss: 40.5846 - val_loss: 29.3076\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 27.4698 - val_loss: 27.3737\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 24.0774 - val_loss: 23.0095\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 22.4761 - val_loss: 21.6478\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 21.0201 - val_loss: 21.4665\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 20.2309 - val_loss: 19.6203\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 19.3998 - val_loss: 18.6639\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 18.8839 - val_loss: 18.3423\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 18.1401 - val_loss: 17.6997\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 17.7551 - val_loss: 17.4505\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.3601 - val_loss: 17.2472\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.1091 - val_loss: 17.1096\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.6810 - val_loss: 16.5210\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.6572 - val_loss: 16.5761\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.1486 - val_loss: 16.0211\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.1667 - val_loss: 15.7116\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.6647 - val_loss: 15.5145\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 15.5309 - val_loss: 15.6992\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 15.4201 - val_loss: 15.4035\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 15.1556 - val_loss: 15.8762\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 15.0304 - val_loss: 15.2481\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 14.9052 - val_loss: 15.4827\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 589us/step - loss: 14.9448 - val_loss: 15.5785\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 14.7124 - val_loss: 15.1267\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.5589 - val_loss: 14.8803\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.4684 - val_loss: 14.6631\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.4171 - val_loss: 14.6332\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.2752 - val_loss: 14.4800\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.2548 - val_loss: 14.6402\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.1298 - val_loss: 14.1310\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.0549 - val_loss: 14.1241\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.9790 - val_loss: 14.2417\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.9003 - val_loss: 14.1793\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.8662 - val_loss: 13.9783\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.7746 - val_loss: 13.9177\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.7237 - val_loss: 13.8868\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.6923 - val_loss: 13.7738\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.5497 - val_loss: 13.8985\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 13.5287 - val_loss: 14.2082\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.5293 - val_loss: 13.9181\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.4380 - val_loss: 13.7844\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.3680 - val_loss: 15.1598\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 600us/step - loss: 41.0398 - val_loss: 31.3132\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 27.0632 - val_loss: 23.6296\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 22.7922 - val_loss: 21.3648\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 20.9255 - val_loss: 21.0120\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 19.1974 - val_loss: 18.2936\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 17.8908 - val_loss: 17.8303\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 16.7392 - val_loss: 16.9169\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 507us/step - loss: 16.0771 - val_loss: 15.9307\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 15.5633 - val_loss: 15.5770\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 15.2018 - val_loss: 15.6567\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 14.7392 - val_loss: 15.1837\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 14.4049 - val_loss: 14.2097\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.0478 - val_loss: 14.4404\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.0525 - val_loss: 14.2542\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.5685 - val_loss: 13.6197\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.4892 - val_loss: 14.2820\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.3861 - val_loss: 13.9324\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.1012 - val_loss: 13.1362\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.9059 - val_loss: 12.9087\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.7298 - val_loss: 12.6549\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.6599 - val_loss: 12.9847\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 12.6506 - val_loss: 12.8088\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.3057 - val_loss: 12.7079\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.2529 - val_loss: 13.8925\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.1297 - val_loss: 12.2773\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.0189 - val_loss: 12.1700\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.9909 - val_loss: 11.9815\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 11.7077 - val_loss: 11.9910\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.6516 - val_loss: 11.8498\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.5597 - val_loss: 11.7252\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.5561 - val_loss: 11.8158\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 469us/step - loss: 11.3713 - val_loss: 11.6503\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 11.4038 - val_loss: 11.5563\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.3789 - val_loss: 11.4818\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 576us/step - loss: 11.2797 - val_loss: 11.6119\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 11.1243 - val_loss: 11.3013\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.0532 - val_loss: 11.4184\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 11.0805 - val_loss: 11.4778\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 3s 642us/step - loss: 11.0372 - val_loss: 11.1632\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.9726 - val_loss: 10.9665\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.9065 - val_loss: 11.2713\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.7675 - val_loss: 11.1893\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.8090 - val_loss: 11.2473\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.7645 - val_loss: 11.0890\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.7459 - val_loss: 10.8815\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.5788 - val_loss: 10.9752\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.6086 - val_loss: 10.8197\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.5289 - val_loss: 10.8020\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.7027 - val_loss: 10.7368\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.4456 - val_loss: 11.0140\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.4753 - val_loss: 11.1459\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.4029 - val_loss: 10.7725\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.3807 - val_loss: 10.5768\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.3710 - val_loss: 10.6795\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.3912 - val_loss: 11.1232\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.3031 - val_loss: 11.5389\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 10.2781 - val_loss: 10.4312\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.2349 - val_loss: 10.5617\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.2383 - val_loss: 10.6498\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 10.1399 - val_loss: 10.6016\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.1292 - val_loss: 10.5198\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.1262 - val_loss: 10.3900\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.1455 - val_loss: 10.6084\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.0667 - val_loss: 10.5315\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.0923 - val_loss: 10.6373\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 9.9755 - val_loss: 10.6758\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.0719 - val_loss: 10.2440\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 9.9169 - val_loss: 10.3767\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 9.9780 - val_loss: 10.1929\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.1001 - val_loss: 10.3900\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 9.9237 - val_loss: 10.6742\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 9.9299 - val_loss: 10.2972\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 9.8677 - val_loss: 10.1177\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 9.8271 - val_loss: 10.3080\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.8408 - val_loss: 10.3999\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 9.7736 - val_loss: 10.8994\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 9.8498 - val_loss: 10.6750\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 9.8163 - val_loss: 10.1291\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 646us/step - loss: 38.8711 - val_loss: 25.1195\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 22.4393 - val_loss: 20.7415\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 19.6798 - val_loss: 19.0166\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 18.2671 - val_loss: 17.1926\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 508us/step - loss: 17.2942 - val_loss: 16.6004\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 16.6004 - val_loss: 16.2562\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 16.0738 - val_loss: 15.4175\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 15.6025 - val_loss: 15.6437\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 15.2972 - val_loss: 14.7052\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.8542 - val_loss: 14.5401\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 14.5366 - val_loss: 13.9061\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.2096 - val_loss: 13.7711\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.9687 - val_loss: 13.8239\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.6835 - val_loss: 13.1459\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.4821 - val_loss: 13.1627\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.3180 - val_loss: 13.0732\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.0634 - val_loss: 13.5502\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8937 - val_loss: 12.6681\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.7820 - val_loss: 12.6071\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.5471 - val_loss: 12.4029\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.4618 - val_loss: 13.1634\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.4018 - val_loss: 12.1101\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.2792 - val_loss: 12.0975\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.1998 - val_loss: 11.9748\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.1196 - val_loss: 11.9675\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.8160 - val_loss: 11.6043\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.8342 - val_loss: 11.7009\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.7561 - val_loss: 11.7250\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.8105 - val_loss: 11.5800\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.6437 - val_loss: 11.4375\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.6295 - val_loss: 11.2423\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.5339 - val_loss: 11.4224\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.4866 - val_loss: 11.1750\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.2997 - val_loss: 11.1955\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.3541 - val_loss: 11.0893\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.2334 - val_loss: 11.2533\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.3700 - val_loss: 11.7354\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.1263 - val_loss: 11.7709\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2014 - val_loss: 11.4422\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.1153 - val_loss: 10.7942\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.0960 - val_loss: 11.1388\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.0357 - val_loss: 11.1165\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.8567 - val_loss: 10.8545\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.9978 - val_loss: 10.8119\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 10.8168 - val_loss: 10.6901\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 10.8675 - val_loss: 10.5735\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 10.7159 - val_loss: 10.5288\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.7521 - val_loss: 10.5210\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.7154 - val_loss: 10.6462\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.6336 - val_loss: 10.7220\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.5443 - val_loss: 10.4261\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.6141 - val_loss: 10.5797\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.5652 - val_loss: 10.2978\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.5538 - val_loss: 10.4208\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 473us/step - loss: 10.5320 - val_loss: 10.4822\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 10.4858 - val_loss: 10.5317\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 10.4302 - val_loss: 10.6174\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 10.3813 - val_loss: 10.3557\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 692us/step - loss: 37.1677 - val_loss: 33.8340\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 580us/step - loss: 28.2263 - val_loss: 26.0199\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 3s 648us/step - loss: 25.7221 - val_loss: 25.7217\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 3s 779us/step - loss: 24.0703 - val_loss: 23.4005\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 3s 772us/step - loss: 22.6673 - val_loss: 22.0576\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 3s 734us/step - loss: 21.6764 - val_loss: 21.1768\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 20.9535 - val_loss: 21.8428\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 20.4933 - val_loss: 20.1530\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 20.0415 - val_loss: 19.5143\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 19.6226 - val_loss: 19.9370\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 19.0090 - val_loss: 18.7358\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 18.8620 - val_loss: 18.5292\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 18.3496 - val_loss: 18.0367\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 18.0995 - val_loss: 18.8221\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 17.6757 - val_loss: 17.6683\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 17.3347 - val_loss: 16.8354\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 17.2704 - val_loss: 17.9439\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 17.0322 - val_loss: 16.6899\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 16.7089 - val_loss: 17.4474\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 16.4637 - val_loss: 16.1263\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 16.3661 - val_loss: 16.5899\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 505us/step - loss: 16.0505 - val_loss: 16.9917\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.1940 - val_loss: 16.1901\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 15.7668 - val_loss: 15.5688\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.7171 - val_loss: 15.7736\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 15.5478 - val_loss: 15.3699\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.5355 - val_loss: 15.5333\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.3843 - val_loss: 16.2545\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 15.1655 - val_loss: 15.0597\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.1944 - val_loss: 15.0752\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.0672 - val_loss: 16.6326\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.9995 - val_loss: 15.0699\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.8761 - val_loss: 15.0561\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 14.8858 - val_loss: 15.3629\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 14.7016 - val_loss: 14.9168\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 14.7325 - val_loss: 14.6894\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 14.6188 - val_loss: 14.5514\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 14.5950 - val_loss: 15.2931\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 14.5387 - val_loss: 14.6420\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 14.4089 - val_loss: 14.7238\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 14.4629 - val_loss: 14.3459\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.3128 - val_loss: 14.6431\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.2877 - val_loss: 14.3309\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.2604 - val_loss: 14.3541\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.2331 - val_loss: 14.4226\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.2056 - val_loss: 14.5846\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.1235 - val_loss: 14.3617\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.1016 - val_loss: 14.1440\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 14.0124 - val_loss: 14.6331\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.0950 - val_loss: 14.3194\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.0171 - val_loss: 14.0580\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.9259 - val_loss: 14.2904\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.0176 - val_loss: 14.3155\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.8125 - val_loss: 13.9707\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.8833 - val_loss: 14.1466\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 13.8289 - val_loss: 13.8514\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.7839 - val_loss: 14.6880\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.7512 - val_loss: 13.9066\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.8169 - val_loss: 13.9667\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.6783 - val_loss: 13.9203\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.7253 - val_loss: 13.6906\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.6572 - val_loss: 13.8429\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.6441 - val_loss: 13.9883\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.5725 - val_loss: 13.7082\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.5623 - val_loss: 14.3155\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.5864 - val_loss: 13.6782\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.5002 - val_loss: 14.0877\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 13.5380 - val_loss: 13.8169\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.5154 - val_loss: 13.7585\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.5079 - val_loss: 13.6404\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.4957 - val_loss: 13.6574\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.3643 - val_loss: 13.6294\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.3050 - val_loss: 13.7435\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.4264 - val_loss: 13.9659\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.2966 - val_loss: 13.6420\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.3391 - val_loss: 13.5856\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.2656 - val_loss: 13.4424\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.2833 - val_loss: 13.5614\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.2408 - val_loss: 13.5870\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.2860 - val_loss: 13.4048\n",
      "Epoch 81/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.2308 - val_loss: 13.4125\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.2030 - val_loss: 13.4988\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 13.2236 - val_loss: 13.4448\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.1596 - val_loss: 13.5480\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.1206 - val_loss: 13.4396\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 603us/step - loss: 35.1095 - val_loss: 25.6719\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 23.5419 - val_loss: 22.1737\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 21.1562 - val_loss: 20.2724\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 489us/step - loss: 19.9176 - val_loss: 18.9915\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 18.9051 - val_loss: 18.2052\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 18.0911 - val_loss: 17.1820\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 563us/step - loss: 17.2345 - val_loss: 17.8146\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 16.8606 - val_loss: 16.9968\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 560us/step - loss: 16.2935 - val_loss: 15.8787\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 562us/step - loss: 15.8642 - val_loss: 15.8398\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 3s 635us/step - loss: 15.5950 - val_loss: 15.9758\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 535us/step - loss: 15.2414 - val_loss: 17.9475\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 15.3376 - val_loss: 15.9615\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 14.8145 - val_loss: 14.6684\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 14.6865 - val_loss: 14.6886\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 493us/step - loss: 14.4223 - val_loss: 14.3334\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 495us/step - loss: 14.2165 - val_loss: 15.4107\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.1468 - val_loss: 14.1925\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.1228 - val_loss: 13.7937\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.9056 - val_loss: 14.0259\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.8623 - val_loss: 13.9885\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 13.5955 - val_loss: 13.3799\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.5386 - val_loss: 13.1683\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.3368 - val_loss: 15.0709\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.2920 - val_loss: 13.5291\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.2358 - val_loss: 12.8968\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.1490 - val_loss: 12.8590\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.9262 - val_loss: 12.9004\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.8991 - val_loss: 12.8997\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.7154 - val_loss: 13.0663\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.7935 - val_loss: 13.3207\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 12.6665 - val_loss: 13.0310\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 590us/step - loss: 40.1564 - val_loss: 31.9150\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 27.5902 - val_loss: 26.9706\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 23.0104 - val_loss: 21.4018\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 20.9029 - val_loss: 19.9415\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 19.2904 - val_loss: 19.5678\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 18.4690 - val_loss: 18.5854\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 17.9108 - val_loss: 18.3987\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 17.2104 - val_loss: 17.0152\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.9491 - val_loss: 16.0459\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.2101 - val_loss: 16.3459\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 15.6830 - val_loss: 15.8707\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.4634 - val_loss: 15.3946\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.9062 - val_loss: 15.7431\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.6114 - val_loss: 14.4896\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 14.2529 - val_loss: 14.1987\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 14.1130 - val_loss: 13.9379\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.9048 - val_loss: 13.7993\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 543us/step - loss: 13.7055 - val_loss: 14.3070\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.3824 - val_loss: 13.6214\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 13.3173 - val_loss: 13.2696\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.9792 - val_loss: 13.5016\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.0270 - val_loss: 13.1772\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.0157 - val_loss: 13.1931\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.4607 - val_loss: 12.6234\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.4330 - val_loss: 12.7242\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.2851 - val_loss: 12.3436\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.4813 - val_loss: 12.1452\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.0083 - val_loss: 12.5978\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.9139 - val_loss: 12.0781\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.8672 - val_loss: 12.8301\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.9016 - val_loss: 12.5559\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.6699 - val_loss: 11.6891\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.7366 - val_loss: 11.5804\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.6475 - val_loss: 11.6502\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.3741 - val_loss: 11.7558\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.3425 - val_loss: 11.5405\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.2669 - val_loss: 11.5736\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.2176 - val_loss: 11.3488\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.3244 - val_loss: 11.6327\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.1903 - val_loss: 11.2557\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.0413 - val_loss: 11.4654\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 11.0164 - val_loss: 11.1802\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.9810 - val_loss: 11.0849\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 10.8821 - val_loss: 11.5673\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 10.8307 - val_loss: 11.2700\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.9042 - val_loss: 10.9757\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.7908 - val_loss: 10.9323\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.6805 - val_loss: 10.8431\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.6377 - val_loss: 10.8246\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.7327 - val_loss: 11.1388\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.6252 - val_loss: 10.8412\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.5310 - val_loss: 10.8583\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.4577 - val_loss: 10.7784\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.4559 - val_loss: 10.6817\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.4676 - val_loss: 10.6930\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 494us/step - loss: 10.3860 - val_loss: 10.6237\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.2933 - val_loss: 10.8831\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.3859 - val_loss: 10.5474\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.3618 - val_loss: 10.6412\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 10.2279 - val_loss: 10.5322\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.2818 - val_loss: 10.5851\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.2059 - val_loss: 10.6139\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.1741 - val_loss: 10.4954\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.0856 - val_loss: 10.5188\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.3254 - val_loss: 10.2957\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.0012 - val_loss: 10.3284\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.0125 - val_loss: 10.2415\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.0759 - val_loss: 10.3654\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.0051 - val_loss: 10.3631\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.0172 - val_loss: 10.4676\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 9.9030 - val_loss: 10.3574\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 499us/step - loss: 9.9228 - val_loss: 10.5366\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 646us/step - loss: 38.6637 - val_loss: 27.8033\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 25.1515 - val_loss: 23.0935\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 21.6142 - val_loss: 20.2952\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 19.5707 - val_loss: 18.4350\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 18.4500 - val_loss: 17.4677\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 3s 637us/step - loss: 17.6285 - val_loss: 16.8855\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 17.3243 - val_loss: 17.5067\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.4971 - val_loss: 16.3742\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 16.1807 - val_loss: 15.6152\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.9955 - val_loss: 15.5968\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.4605 - val_loss: 15.5666\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 15.3042 - val_loss: 15.1145\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.7921 - val_loss: 15.8332\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.6728 - val_loss: 14.2332\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 14.4306 - val_loss: 14.7399\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 14.1785 - val_loss: 13.9540\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 14.0733 - val_loss: 14.5868\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.8084 - val_loss: 13.8112\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.6605 - val_loss: 13.3600\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 13.6680 - val_loss: 13.5742\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 13.2627 - val_loss: 13.2592\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 13.1552 - val_loss: 12.8885\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.0154 - val_loss: 12.7237\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 12.9649 - val_loss: 12.7178\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 12.6961 - val_loss: 12.6141\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.5830 - val_loss: 12.4245\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.5628 - val_loss: 12.4034\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.4293 - val_loss: 12.3660\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.1159 - val_loss: 12.4161\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.2309 - val_loss: 12.0723\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.1410 - val_loss: 12.3486\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.1197 - val_loss: 11.8177\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.8604 - val_loss: 11.8434\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.9839 - val_loss: 11.6763\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.6660 - val_loss: 12.0885\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.6946 - val_loss: 11.4801\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.6477 - val_loss: 11.6257\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.5501 - val_loss: 11.5800\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.4586 - val_loss: 11.5271\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.3786 - val_loss: 11.7863\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.3362 - val_loss: 11.6176\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 638us/step - loss: 38.4583 - val_loss: 30.0315\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 27.3115 - val_loss: 24.2694\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 23.1992 - val_loss: 21.3245\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 21.1177 - val_loss: 19.8322\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 20.1333 - val_loss: 19.9518\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 18.8906 - val_loss: 21.5611\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 18.0081 - val_loss: 18.6207\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 17.1974 - val_loss: 17.6671\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 16.7085 - val_loss: 16.0646\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 16.3630 - val_loss: 15.5386\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 15.7642 - val_loss: 15.9533\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.4245 - val_loss: 15.6841\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 15.0975 - val_loss: 14.7657\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.8677 - val_loss: 14.1546\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.5367 - val_loss: 15.1101\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 14.2007 - val_loss: 13.8356\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 538us/step - loss: 13.9571 - val_loss: 15.7700\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.8876 - val_loss: 14.0255\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.5952 - val_loss: 13.4184\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 13.4103 - val_loss: 13.4582\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.1365 - val_loss: 12.8774\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 13.0964 - val_loss: 12.8722\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.8760 - val_loss: 12.6403\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.7728 - val_loss: 13.6370\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.6575 - val_loss: 12.4943\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.5136 - val_loss: 12.4149\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.3813 - val_loss: 12.2691\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.2500 - val_loss: 12.9165\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.0849 - val_loss: 12.0123\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.0615 - val_loss: 12.0492\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.9895 - val_loss: 12.7227\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.9849 - val_loss: 11.8405\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.7395 - val_loss: 11.8759\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.6193 - val_loss: 11.6051\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.5882 - val_loss: 12.1145\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 11.7404 - val_loss: 11.8158\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 11.3744 - val_loss: 11.2837\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.3732 - val_loss: 11.3548\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.4052 - val_loss: 11.7292\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.2940 - val_loss: 12.1771\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 11.2379 - val_loss: 11.3397\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 11.2470 - val_loss: 11.5497\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 601us/step - loss: 39.2451 - val_loss: 28.5999\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 26.6901 - val_loss: 25.3898\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 23.5185 - val_loss: 22.2950\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 21.5724 - val_loss: 21.3295\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 20.3131 - val_loss: 19.8253\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 19.6568 - val_loss: 21.9843\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 18.9017 - val_loss: 19.0639\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 18.4187 - val_loss: 18.0442\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 18.0043 - val_loss: 17.6257\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 17.5501 - val_loss: 17.0487\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.2388 - val_loss: 16.9808\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 17.0391 - val_loss: 16.8782\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.6551 - val_loss: 16.7313\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 488us/step - loss: 16.6556 - val_loss: 16.2268\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 16.1766 - val_loss: 16.4442\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 16.2967 - val_loss: 15.7889\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 560us/step - loss: 15.7932 - val_loss: 15.8951\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 15.7760 - val_loss: 15.5186\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 552us/step - loss: 15.3803 - val_loss: 15.7687\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 550us/step - loss: 15.2669 - val_loss: 15.1144\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 3s 625us/step - loss: 15.1677 - val_loss: 14.9685\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.9154 - val_loss: 15.9122\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.7819 - val_loss: 14.5071\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 14.5660 - val_loss: 14.6122\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.3874 - val_loss: 14.2717\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 14.2764 - val_loss: 14.2361\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 14.1144 - val_loss: 14.1021\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 13.9772 - val_loss: 14.1677\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 13.8573 - val_loss: 14.5838\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 13.7865 - val_loss: 13.9630\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 13.6634 - val_loss: 13.5756\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 13.6027 - val_loss: 13.5823\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 13.5947 - val_loss: 13.5500\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 13.4258 - val_loss: 13.4704\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 13.3296 - val_loss: 13.4171\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 13.3129 - val_loss: 13.3811\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 13.1846 - val_loss: 13.2436\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 13.3071 - val_loss: 13.3126\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 13.0892 - val_loss: 13.0346\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 12.8829 - val_loss: 13.1454\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.9344 - val_loss: 12.8691\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.8081 - val_loss: 12.9878\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 12.7648 - val_loss: 12.7819\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.7291 - val_loss: 12.6962\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.7176 - val_loss: 12.8889\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 12.6580 - val_loss: 12.7666\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 12.6830 - val_loss: 12.5391\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 12.5139 - val_loss: 12.7503\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.4707 - val_loss: 12.5257\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.5102 - val_loss: 13.4008\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.4582 - val_loss: 12.4668\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.2572 - val_loss: 12.8011\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.3499 - val_loss: 12.3609\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.2579 - val_loss: 12.2151\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.2835 - val_loss: 12.2285\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.2227 - val_loss: 12.2702\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.2043 - val_loss: 12.6481\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 535us/step - loss: 12.0754 - val_loss: 12.4580\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 12.0133 - val_loss: 12.1243\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 533us/step - loss: 12.0897 - val_loss: 12.1928\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 534us/step - loss: 11.9688 - val_loss: 12.0439\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.9187 - val_loss: 12.0470\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 11.9219 - val_loss: 12.0295\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 11.8447 - val_loss: 12.0935\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.8296 - val_loss: 12.0403\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.8099 - val_loss: 12.1914\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.8234 - val_loss: 11.8699\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.7631 - val_loss: 11.8776\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.7686 - val_loss: 12.0389\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 11.6685 - val_loss: 11.8156\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.6266 - val_loss: 12.0927\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.5291 - val_loss: 11.8664\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.7287 - val_loss: 13.4292\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.6168 - val_loss: 11.8904\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.4907 - val_loss: 11.9887\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 595us/step - loss: 36.0811 - val_loss: 30.4124\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 26.2070 - val_loss: 30.6214\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 22.3199 - val_loss: 20.6473\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 20.0338 - val_loss: 19.4664\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 18.5866 - val_loss: 18.5548\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 17.5940 - val_loss: 17.1247\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 17.2849 - val_loss: 16.9955\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.6683 - val_loss: 16.3814\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.0982 - val_loss: 15.7410\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 15.7385 - val_loss: 15.3031\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 15.1856 - val_loss: 15.6716\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.9764 - val_loss: 14.4146\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.6648 - val_loss: 14.3817\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.2781 - val_loss: 14.4028\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.0298 - val_loss: 14.5729\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.7089 - val_loss: 13.3189\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.8443 - val_loss: 13.4916\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.2688 - val_loss: 14.1302\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.1342 - val_loss: 13.0580\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.0006 - val_loss: 13.0530\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.7242 - val_loss: 12.9084\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.5312 - val_loss: 12.5104\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.4216 - val_loss: 12.2285\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 12.2740 - val_loss: 12.3381\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 12.2310 - val_loss: 12.2335\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.1749 - val_loss: 12.2713\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.8955 - val_loss: 11.7754\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.7863 - val_loss: 11.6259\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.8351 - val_loss: 11.6064\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.5456 - val_loss: 11.6923\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 11.5827 - val_loss: 12.9329\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.5592 - val_loss: 11.3299\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 11.2702 - val_loss: 11.4067\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 11.2420 - val_loss: 11.2934\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 11.2639 - val_loss: 11.5566\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.1105 - val_loss: 11.1271\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.0763 - val_loss: 11.3178\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.2272 - val_loss: 11.1708\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.9965 - val_loss: 10.8489\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 10.7961 - val_loss: 10.8612\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 10.9366 - val_loss: 10.7277\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 10.9648 - val_loss: 10.9291\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 556us/step - loss: 10.8503 - val_loss: 10.6619\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 558us/step - loss: 10.7113 - val_loss: 10.9068\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 10.7690 - val_loss: 10.5801\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 3s 652us/step - loss: 10.6249 - val_loss: 10.4469\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.4928 - val_loss: 11.2243\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.4825 - val_loss: 10.5849\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 10.6932 - val_loss: 10.9084\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 501us/step - loss: 10.3999 - val_loss: 10.4660\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 10.2969 - val_loss: 10.3627\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 466us/step - loss: 10.3813 - val_loss: 11.0704\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 479us/step - loss: 10.4058 - val_loss: 10.4416\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.2698 - val_loss: 10.8356\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 10.2568 - val_loss: 10.4690\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.2157 - val_loss: 10.5724\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 608us/step - loss: 41.2119 - val_loss: 29.6598\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 27.8287 - val_loss: 26.2414\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 25.3932 - val_loss: 25.0788\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 23.6514 - val_loss: 22.9886\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 22.3984 - val_loss: 22.2691\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 21.3696 - val_loss: 22.0256\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 20.6492 - val_loss: 20.0082\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 19.9052 - val_loss: 19.1676\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 19.2711 - val_loss: 19.4181\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 18.6962 - val_loss: 18.4647\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 18.3073 - val_loss: 18.1785\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 17.7764 - val_loss: 17.7096\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 17.3483 - val_loss: 17.1841\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 17.0212 - val_loss: 16.6884\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.8375 - val_loss: 17.0194\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 16.4381 - val_loss: 16.8178\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.3118 - val_loss: 16.7884\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 16.0609 - val_loss: 15.8548\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 15.5435 - val_loss: 16.4090\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 15.4162 - val_loss: 15.1798\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 15.1887 - val_loss: 15.6095\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 15.1401 - val_loss: 15.7229\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.8686 - val_loss: 14.7979\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.6744 - val_loss: 14.6410\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 537us/step - loss: 14.5426 - val_loss: 15.0360\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 14.4188 - val_loss: 14.4208\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 14.3149 - val_loss: 14.4608\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 540us/step - loss: 14.1529 - val_loss: 14.1091\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 14.0221 - val_loss: 14.2114\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 541us/step - loss: 14.0234 - val_loss: 14.0087\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 532us/step - loss: 13.8339 - val_loss: 13.9259\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.7742 - val_loss: 14.0296\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.7180 - val_loss: 13.8337\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.5854 - val_loss: 13.4653\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.5914 - val_loss: 13.6058\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.4848 - val_loss: 13.5648\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.4165 - val_loss: 13.6034\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.3871 - val_loss: 13.3870\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.2050 - val_loss: 13.3305\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.1929 - val_loss: 13.4320\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 13.1332 - val_loss: 13.7896\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 13.1582 - val_loss: 13.1136\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 13.0209 - val_loss: 13.3862\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.9871 - val_loss: 13.8247\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 13.0037 - val_loss: 13.3115\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.8363 - val_loss: 13.0378\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.8540 - val_loss: 13.1083\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.8208 - val_loss: 12.9225\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.7096 - val_loss: 13.2188\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.6718 - val_loss: 12.6360\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.6847 - val_loss: 12.7769\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.5761 - val_loss: 12.8487\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.5850 - val_loss: 12.6358\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 12.5845 - val_loss: 12.8346\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.4863 - val_loss: 12.9193\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.4440 - val_loss: 12.9845\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 12.3678 - val_loss: 12.6575\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.4485 - val_loss: 12.4701\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 12.3142 - val_loss: 12.3628\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 12.2739 - val_loss: 12.8497\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.3113 - val_loss: 12.4330\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.2739 - val_loss: 12.3808\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 12.2444 - val_loss: 12.4026\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 12.1453 - val_loss: 12.4375\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 611us/step - loss: 39.5767 - val_loss: 30.3897\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 28.1700 - val_loss: 25.3232\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 24.5845 - val_loss: 23.2332\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 22.5743 - val_loss: 21.8869\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 500us/step - loss: 20.9992 - val_loss: 21.0139\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 19.8954 - val_loss: 18.5779\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 498us/step - loss: 18.9637 - val_loss: 17.8711\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 18.0855 - val_loss: 18.1076\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 17.7095 - val_loss: 17.8564\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 16.8630 - val_loss: 19.5725\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 16.6189 - val_loss: 16.1168\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 16.1153 - val_loss: 16.3112\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.7774 - val_loss: 15.3986\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 15.5676 - val_loss: 15.1529\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.2110 - val_loss: 15.5576\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 15.0040 - val_loss: 15.2905\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 400us/step - loss: 14.6676 - val_loss: 15.4738\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 454us/step - loss: 14.7050 - val_loss: 14.5774\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 14.4188 - val_loss: 14.7806\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 14.1796 - val_loss: 13.9472\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 14.0163 - val_loss: 14.6727\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 13.8310 - val_loss: 13.6940\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 13.6762 - val_loss: 14.3403\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 594us/step - loss: 13.5482 - val_loss: 14.4279\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 572us/step - loss: 13.4038 - val_loss: 13.4361\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 13.2878 - val_loss: 14.2694\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 13.1050 - val_loss: 13.8860\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 13.1256 - val_loss: 13.0246\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 12.9875 - val_loss: 12.9498\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 12.9252 - val_loss: 12.8924\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 12.6254 - val_loss: 12.8901\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 12.7112 - val_loss: 13.4313\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.5048 - val_loss: 12.8884\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.5742 - val_loss: 13.6640\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.5486 - val_loss: 13.3109\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 12.3076 - val_loss: 12.5916\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 12.2273 - val_loss: 12.2905\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.1893 - val_loss: 12.2496\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 12.1611 - val_loss: 12.5784\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.0515 - val_loss: 12.5260\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.0360 - val_loss: 12.0854\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 11.9488 - val_loss: 12.2522\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.9285 - val_loss: 12.2396\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 11.7197 - val_loss: 12.5547\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 529us/step - loss: 11.6950 - val_loss: 12.0304\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.7113 - val_loss: 12.2712\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.6732 - val_loss: 11.7344\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 11.5959 - val_loss: 12.0884\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.5329 - val_loss: 11.6529\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 11.5570 - val_loss: 11.7612\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.5327 - val_loss: 11.9757\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 11.4736 - val_loss: 11.6086\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.3677 - val_loss: 11.5939\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.4589 - val_loss: 11.5794\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.2518 - val_loss: 11.6020\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 527us/step - loss: 11.2279 - val_loss: 11.6894\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.1909 - val_loss: 11.5970\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 11.2599 - val_loss: 11.5255\n",
      "Epoch 59/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 11.2312 - val_loss: 11.8867\n",
      "Epoch 60/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.0897 - val_loss: 11.9072\n",
      "Epoch 61/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.0861 - val_loss: 11.5814\n",
      "Epoch 62/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 11.0280 - val_loss: 11.4460\n",
      "Epoch 63/100\n",
      "4200/4200 [==============================] - 2s 544us/step - loss: 11.0453 - val_loss: 11.2892\n",
      "Epoch 64/100\n",
      "4200/4200 [==============================] - 2s 545us/step - loss: 10.9223 - val_loss: 11.7024\n",
      "Epoch 65/100\n",
      "4200/4200 [==============================] - 2s 592us/step - loss: 10.9110 - val_loss: 11.2459\n",
      "Epoch 66/100\n",
      "4200/4200 [==============================] - 2s 553us/step - loss: 10.8791 - val_loss: 11.2172\n",
      "Epoch 67/100\n",
      "4200/4200 [==============================] - 2s 547us/step - loss: 10.8612 - val_loss: 11.4405\n",
      "Epoch 68/100\n",
      "4200/4200 [==============================] - 2s 549us/step - loss: 10.8379 - val_loss: 11.5613\n",
      "Epoch 69/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.8523 - val_loss: 11.1741\n",
      "Epoch 70/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.7785 - val_loss: 11.2531\n",
      "Epoch 71/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.7617 - val_loss: 11.3309\n",
      "Epoch 72/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.7372 - val_loss: 11.1289\n",
      "Epoch 73/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.6653 - val_loss: 11.0906\n",
      "Epoch 74/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.7165 - val_loss: 11.0790\n",
      "Epoch 75/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 10.6652 - val_loss: 11.4100\n",
      "Epoch 76/100\n",
      "4200/4200 [==============================] - 2s 580us/step - loss: 10.6800 - val_loss: 11.2707\n",
      "Epoch 77/100\n",
      "4200/4200 [==============================] - 3s 605us/step - loss: 10.5803 - val_loss: 11.4395\n",
      "Epoch 78/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 10.6229 - val_loss: 10.8979\n",
      "Epoch 79/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 10.6134 - val_loss: 11.1067\n",
      "Epoch 80/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 10.5385 - val_loss: 10.9891\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.4876 - val_loss: 10.8937\n",
      "Epoch 82/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.5806 - val_loss: 11.1222\n",
      "Epoch 83/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.5185 - val_loss: 10.8701\n",
      "Epoch 84/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 10.3789 - val_loss: 11.3987\n",
      "Epoch 85/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.5780 - val_loss: 11.0045\n",
      "Epoch 86/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.6212 - val_loss: 11.0477\n",
      "Epoch 87/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.5552 - val_loss: 10.7195\n",
      "Epoch 88/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 10.2955 - val_loss: 11.2678\n",
      "Epoch 89/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.2964 - val_loss: 10.9014\n",
      "Epoch 90/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.2693 - val_loss: 10.8384\n",
      "Epoch 91/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.3023 - val_loss: 10.6845\n",
      "Epoch 92/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 10.2911 - val_loss: 10.9235\n",
      "Epoch 93/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 10.2778 - val_loss: 10.6867\n",
      "Epoch 94/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 10.2556 - val_loss: 10.9599\n",
      "Epoch 95/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.2627 - val_loss: 10.7573\n",
      "Epoch 96/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 10.2249 - val_loss: 11.0019\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 2s 592us/step - loss: 38.6683 - val_loss: 25.3250\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 23.9949 - val_loss: 22.7295\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 21.3992 - val_loss: 20.4867\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 19.7381 - val_loss: 18.9620\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 18.5810 - val_loss: 18.2709\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 17.9235 - val_loss: 16.8665\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 16.9854 - val_loss: 16.5428\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.3953 - val_loss: 15.6389\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 15.7885 - val_loss: 15.3580\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 15.2256 - val_loss: 14.9674\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.7915 - val_loss: 14.4598\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.3875 - val_loss: 14.0886\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 14.1847 - val_loss: 14.1207\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.8022 - val_loss: 13.3482\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 13.4268 - val_loss: 13.2757\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.2201 - val_loss: 13.0351\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.9868 - val_loss: 12.5892\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.8208 - val_loss: 12.8467\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 12.6676 - val_loss: 12.7982\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.4231 - val_loss: 12.5299\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 551us/step - loss: 12.3775 - val_loss: 12.0808\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 413us/step - loss: 12.1236 - val_loss: 11.7970\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 1s 300us/step - loss: 12.0183 - val_loss: 11.9767\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 486us/step - loss: 11.9715 - val_loss: 11.7553\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 11.7537 - val_loss: 11.8202\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 11.6130 - val_loss: 12.4201\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 554us/step - loss: 11.5839 - val_loss: 11.5971\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 11.6688 - val_loss: 11.8232\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 555us/step - loss: 11.4146 - val_loss: 12.2571\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 3s 666us/step - loss: 11.4462 - val_loss: 11.0554\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 11.2319 - val_loss: 11.0889\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 11.1391 - val_loss: 11.7141\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.1209 - val_loss: 10.9162\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 11.0984 - val_loss: 10.8288\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 10.9551 - val_loss: 10.8110\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 10.9037 - val_loss: 10.6265\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.8427 - val_loss: 11.2639\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 10.8492 - val_loss: 11.3482\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 10.8613 - val_loss: 10.6114\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 519us/step - loss: 10.6436 - val_loss: 10.5255\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.7059 - val_loss: 11.2588\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.6509 - val_loss: 10.4293\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.6406 - val_loss: 10.7753\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 10.6590 - val_loss: 10.8103\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 10.4360 - val_loss: 10.4730\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.4122 - val_loss: 10.5628\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.4240 - val_loss: 10.1562\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 10.3430 - val_loss: 10.5034\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 530us/step - loss: 10.3499 - val_loss: 10.1338\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 526us/step - loss: 10.3151 - val_loss: 10.3782\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 525us/step - loss: 10.2883 - val_loss: 10.5917\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 523us/step - loss: 10.2382 - val_loss: 10.3316\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 521us/step - loss: 10.1701 - val_loss: 10.1364\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 10.1295 - val_loss: 10.4492\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 605us/step - loss: 37.5801 - val_loss: 30.7452\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 27.7851 - val_loss: 26.0678\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 25.0689 - val_loss: 24.3455\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 23.5222 - val_loss: 22.9411\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 22.4347 - val_loss: 21.5564\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 506us/step - loss: 21.5779 - val_loss: 21.2013\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 20.7554 - val_loss: 20.5754\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 20.4486 - val_loss: 20.8817\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 19.9340 - val_loss: 19.3328\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 19.4587 - val_loss: 19.5219\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 524us/step - loss: 19.1110 - val_loss: 19.1811\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 18.8074 - val_loss: 18.3172\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 536us/step - loss: 18.4291 - val_loss: 20.2106\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 538us/step - loss: 18.2690 - val_loss: 18.6179\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 542us/step - loss: 17.9725 - val_loss: 19.9459\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 2s 539us/step - loss: 17.7866 - val_loss: 19.7250\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 17.5100 - val_loss: 17.0934\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 17.3031 - val_loss: 17.3671\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 528us/step - loss: 16.9958 - val_loss: 16.7565\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 531us/step - loss: 16.8260 - val_loss: 16.3951\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 16.6377 - val_loss: 16.5282\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 16.6205 - val_loss: 16.2359\n",
      "Epoch 23/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 16.4135 - val_loss: 16.8329\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 16.2512 - val_loss: 16.9776\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 16.1626 - val_loss: 16.0519\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 16.0208 - val_loss: 15.7783\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 15.9265 - val_loss: 15.7645\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 15.8642 - val_loss: 15.8283\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 503us/step - loss: 15.8249 - val_loss: 15.9387\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 500us/step - loss: 15.6884 - val_loss: 15.6731\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.6835 - val_loss: 16.2170\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 15.5169 - val_loss: 15.3876\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 15.4698 - val_loss: 15.3165\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 15.4244 - val_loss: 15.4316\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 501us/step - loss: 15.3254 - val_loss: 15.3432\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 502us/step - loss: 15.2423 - val_loss: 15.2377\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 504us/step - loss: 15.1845 - val_loss: 15.0803\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 15.0947 - val_loss: 15.1531\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 15.0710 - val_loss: 15.1889\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 15.0303 - val_loss: 14.9631\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 15.0690 - val_loss: 17.0860\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.9636 - val_loss: 14.9201\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 14.8433 - val_loss: 15.1343\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.8735 - val_loss: 14.8134\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.8048 - val_loss: 15.1077\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.7880 - val_loss: 14.6658\n",
      "Epoch 47/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.7485 - val_loss: 14.7495\n",
      "Epoch 48/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.7673 - val_loss: 14.7878\n",
      "Epoch 49/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 14.6708 - val_loss: 14.8888\n",
      "Epoch 50/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 14.6677 - val_loss: 14.6135\n",
      "Epoch 51/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.6177 - val_loss: 14.9450\n",
      "Epoch 52/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.5603 - val_loss: 14.6567\n",
      "Epoch 53/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 14.5713 - val_loss: 14.5540\n",
      "Epoch 54/100\n",
      "4200/4200 [==============================] - 2s 515us/step - loss: 14.5490 - val_loss: 14.8427\n",
      "Epoch 55/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 14.4620 - val_loss: 14.5926\n",
      "Epoch 56/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.4767 - val_loss: 14.6860\n",
      "Epoch 57/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.4512 - val_loss: 14.7312\n",
      "Epoch 58/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 14.4267 - val_loss: 14.6649\n",
      "Train on 4200 samples, validate on 1260 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 3s 600us/step - loss: 35.7082 - val_loss: 26.3835\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 24.6014 - val_loss: 24.4244\n",
      "Epoch 3/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 21.2741 - val_loss: 19.8592\n",
      "Epoch 4/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 19.6556 - val_loss: 18.8330\n",
      "Epoch 5/100\n",
      "4200/4200 [==============================] - 2s 522us/step - loss: 18.7643 - val_loss: 17.7444\n",
      "Epoch 6/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 17.8614 - val_loss: 17.1403\n",
      "Epoch 7/100\n",
      "4200/4200 [==============================] - 2s 518us/step - loss: 17.3982 - val_loss: 17.4166\n",
      "Epoch 8/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 16.7592 - val_loss: 18.0003\n",
      "Epoch 9/100\n",
      "4200/4200 [==============================] - 2s 467us/step - loss: 16.5219 - val_loss: 16.7022\n",
      "Epoch 10/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 15.9559 - val_loss: 15.9769\n",
      "Epoch 11/100\n",
      "4200/4200 [==============================] - 2s 557us/step - loss: 15.6588 - val_loss: 15.3776\n",
      "Epoch 12/100\n",
      "4200/4200 [==============================] - 2s 561us/step - loss: 15.5055 - val_loss: 15.1879\n",
      "Epoch 13/100\n",
      "4200/4200 [==============================] - 2s 565us/step - loss: 15.3341 - val_loss: 15.9143\n",
      "Epoch 14/100\n",
      "4200/4200 [==============================] - 2s 559us/step - loss: 14.9470 - val_loss: 14.6653\n",
      "Epoch 15/100\n",
      "4200/4200 [==============================] - 2s 584us/step - loss: 14.6858 - val_loss: 14.4362\n",
      "Epoch 16/100\n",
      "4200/4200 [==============================] - 3s 673us/step - loss: 14.4877 - val_loss: 14.6978\n",
      "Epoch 17/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 14.4364 - val_loss: 14.2496\n",
      "Epoch 18/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 14.1794 - val_loss: 13.8612\n",
      "Epoch 19/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 13.9442 - val_loss: 13.8955\n",
      "Epoch 20/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 13.9895 - val_loss: 14.6167\n",
      "Epoch 21/100\n",
      "4200/4200 [==============================] - 2s 520us/step - loss: 13.8664 - val_loss: 13.4847\n",
      "Epoch 22/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.5734 - val_loss: 13.5187\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 519us/step - loss: 13.4789 - val_loss: 13.2426\n",
      "Epoch 24/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 13.3836 - val_loss: 13.4739\n",
      "Epoch 25/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 13.2684 - val_loss: 13.5477\n",
      "Epoch 26/100\n",
      "4200/4200 [==============================] - 2s 512us/step - loss: 13.2733 - val_loss: 12.9920\n",
      "Epoch 27/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 13.3318 - val_loss: 13.1115\n",
      "Epoch 28/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 12.9494 - val_loss: 13.5777\n",
      "Epoch 29/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.9570 - val_loss: 13.3255\n",
      "Epoch 30/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.8278 - val_loss: 12.8770\n",
      "Epoch 31/100\n",
      "4200/4200 [==============================] - 2s 511us/step - loss: 12.7354 - val_loss: 13.5117\n",
      "Epoch 32/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.7129 - val_loss: 12.9616\n",
      "Epoch 33/100\n",
      "4200/4200 [==============================] - 2s 517us/step - loss: 12.6881 - val_loss: 12.7253\n",
      "Epoch 34/100\n",
      "4200/4200 [==============================] - 2s 516us/step - loss: 12.6413 - val_loss: 12.3495\n",
      "Epoch 35/100\n",
      "4200/4200 [==============================] - 2s 513us/step - loss: 12.5299 - val_loss: 12.7246\n",
      "Epoch 36/100\n",
      "4200/4200 [==============================] - 2s 514us/step - loss: 12.4367 - val_loss: 12.2786\n",
      "Epoch 37/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.4497 - val_loss: 13.6029\n",
      "Epoch 38/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.4500 - val_loss: 13.3440\n",
      "Epoch 39/100\n",
      "4200/4200 [==============================] - 2s 509us/step - loss: 12.2362 - val_loss: 12.4814\n",
      "Epoch 40/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.1887 - val_loss: 12.6912\n",
      "Epoch 41/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 12.1782 - val_loss: 12.0644\n",
      "Epoch 42/100\n",
      "4200/4200 [==============================] - 2s 505us/step - loss: 12.1050 - val_loss: 12.8904\n",
      "Epoch 43/100\n",
      "4200/4200 [==============================] - 2s 507us/step - loss: 12.0839 - val_loss: 12.3966\n",
      "Epoch 44/100\n",
      "4200/4200 [==============================] - 2s 506us/step - loss: 12.0978 - val_loss: 12.1033\n",
      "Epoch 45/100\n",
      "4200/4200 [==============================] - 2s 508us/step - loss: 11.9769 - val_loss: 12.4582\n",
      "Epoch 46/100\n",
      "4200/4200 [==============================] - 2s 510us/step - loss: 11.9243 - val_loss: 12.5382\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=1)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(0)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "tf.random.set_seed(0)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "degree=[0,90,180,270]\n",
    "values=[0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4]\n",
    "convo=[6]\n",
    "y2=Image.open(\"Lenna.png\").resize([28,28]).convert(\"L\")\n",
    "for goal in images:\n",
    "    #y2=Image.open(goal).resize([32,32])\n",
    "    data2=fashion_mnist.load_data()[0][0]\n",
    "    label2=fashion_mnist.load_data()[0][1]\n",
    "    #label2=label2.reshape(len(label2))\n",
    "    x_test=fashion_mnist.load_data()[1][0]\n",
    "    y_test=fashion_mnist.load_data()[1][1]\n",
    "    #y_test=y_test.reshape(len(y_test))\n",
    "    #data3=np.zeros([len(data2),32,32,3])\n",
    "    #for n in range(len(data2)):\n",
    "        #data3[n]=Image.fromarray(data2[n].astype(\"uint8\"))\n",
    "    #data2=data3\n",
    "    \n",
    "    outputs=[]\n",
    "    outputs4=[]\n",
    "    outputs5=[]\n",
    "    for c in range(len(convo)):\n",
    "        outputs2=[]\n",
    "        outputs3=[]\n",
    "        for e in range(5):\n",
    "            ensemble=[]\n",
    "            for rot in degree:\n",
    "                error_record=[]\n",
    "                clear_session()\n",
    "                unseen_score=np.zeros([10,9])\n",
    "                AUC_score=np.zeros(10)\n",
    "                for i in range(10):\n",
    "                    x_train=data2[label2==i]\n",
    "                    y_train=np.zeros([len(x_train),28,28,1])\n",
    "                    for n in range(len(x_train)):\n",
    "                        y_train[n]=np.array(y2.rotate(rot)).reshape(28,28,1)\n",
    "                    #x_train=x_train/255\n",
    "                    y_train=y_train\n",
    "                    #x_test=data2[label2!=i]\n",
    "                    #x_test=x_test/255\n",
    "                    x_test=x_test.reshape(len(x_test),28,28,1)\n",
    "                    y_label=np.zeros(len(y_test))\n",
    "                    y_label[y_test==i]=1\n",
    "                    #(x_train, train), (x_test, y_test) = mnist.load_data()\n",
    "                    image_height, image_width = 28, 28\n",
    "                    # \n",
    "                    if K.image_data_format() == 'channels_last':\n",
    "                        x_train = x_train.reshape(x_train.shape[0],\n",
    "                                                  image_height, image_width,1)\n",
    "                        #x_test = x_test.reshape(x_test.shape[0],image_height, image_width, 1)\n",
    "                        y_train = y_train.reshape(y_train.shape[0],\n",
    "                                                  28, 28,1)\n",
    "                        input_shape = (image_height, image_width,1)\n",
    "                    else:\n",
    "                        x_train = x_train.reshape(x_train.shape[0],\n",
    "                                                  1, image_height, image_width)\n",
    "                        x_test = x_test.reshape(x_test.shape[0],1, image_height, image_width)\n",
    "                        input_shape = (1, image_height, image_width)\n",
    "\n",
    "                    # Min-Max Normalization (0. ~ 1. )\n",
    "                    x_train = x_train.astype('float32')\n",
    "                    y_train = y_train.astype('float32')\n",
    "                    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.3, random_state=e)\n",
    "                    x_valid, x_valid2, y_valid, y_valid2 = train_test_split(x_valid, y_valid, test_size=0.3, random_state=e)\n",
    "                    #x_test = x_test.astype('float32')\n",
    "                    #x_train = (x_train - x_train.min()) / (x_train.max() - x_train.min())\n",
    "                    #x_test = (x_test - x_test.min()) / (x_test.max() - x_test.min())\n",
    "                    #  AutoEncoder  (Sequential API)\n",
    "                    model = models.Sequential()\n",
    "                    # 28 x 28 x 1\n",
    "                    model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',input_shape=input_shape))\n",
    "                    for n in range(convo[c]):\n",
    "                        model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\n",
    "                    model.add(layers.Conv2D(1, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "                    # 28 x 28 x 1\n",
    "                    model.compile(optimizer='adam',\n",
    "                                  loss='mean_absolute_error')\n",
    "                    # \n",
    "                    fit_callbacks = [\n",
    "                        callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=5,\n",
    "                                                mode='min')\n",
    "                    ]\n",
    "                    # \n",
    "                    model.fit(x_train, y_train,\n",
    "                              epochs=100,\n",
    "                              batch_size=16,\n",
    "                              shuffle=True,\n",
    "                              validation_data=(x_valid, y_valid),callbacks=fit_callbacks)\n",
    "                    result=model.predict(x_valid2)\n",
    "                    result2=model.predict(x_test)\n",
    "                    y_train=y_train.reshape(y_train.shape[0],784,1)\n",
    "                    result=result.reshape(result.shape[0],784,1)\n",
    "                    result2=result2.reshape(result2.shape[0],784,1)\n",
    "                    loss=np.zeros(len(result))\n",
    "                    for n in range(len(result)):\n",
    "                        loss[n]=mean_absolute_error(y_train[0],result[n])\n",
    "                    loss_outlier=np.zeros(len(result2))\n",
    "                    for n in range(len(result2)):\n",
    "                        loss_outlier[n]=mean_absolute_error(y_train[0],result2[n])\n",
    "                    error_record.append(loss_outlier)\n",
    "                    #y_one=np.ones(len(loss))\n",
    "                    #y_outlier=np.zeros(len(loss_outlier))\n",
    "                    #data=np.concatenate([loss,loss_outlier])\n",
    "                    #label=np.concatenate([y_one,y_outlier])\n",
    "                    #plt.scatter(data,label)\n",
    "                    #plt.hist([loss,loss_outlier],range=(0,0.3),stacked=False,bins=10)\n",
    "                    m=0\n",
    "                    AUC_score[i]=roc_auc_score(y_label,(-1)*loss_outlier)\n",
    "                    for p in values:\n",
    "                        y_pred=np.zeros(len(y_label))\n",
    "                        threshold=int(len(loss)*p)+1\n",
    "                        #print(loss[loss.argsort()[-threshold]])\n",
    "                        y_pred[loss_outlier<=loss[loss.argsort()[-threshold]]]=1\n",
    "                        #loss_outlier[loss_outlier>loss[loss.argsort()[-threshold]]\n",
    "                        unseen_score[i][m]=balanced_accuracy_score(y_label,y_pred)\n",
    "                        m+=1\n",
    "                #print(unseen_score)\n",
    "                #outputs.append(unseen_score)\n",
    "                outputs2.append(AUC_score)\n",
    "                outputs3.append(unseen_score)\n",
    "                ensemble.append(error_record)\n",
    "            outputs5.append(ensemble)\n",
    "            outputs.append(outputs2)\n",
    "            outputs4.append(outputs3)\n",
    "    #makefile(outputs,\"result_ocitn/cifar10_\"+str(goal)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "outputs6=[]\n",
    "for ensemble in outputs5:\n",
    "    CEtest2=None\n",
    "    value = 0\n",
    "    for scores in ensemble:\n",
    "        if type(CEtest2)==type(None):\n",
    "            CEtest2=np.array(scores)\n",
    "        else:\n",
    "            print(\"OK\")\n",
    "            CEtest2=CEtest2+np.array(scores)\n",
    "    AUC_ensemble=np.zeros(10)\n",
    "    for i in range(10):\n",
    "        y_label=np.zeros(len(y_test))\n",
    "        y_label[y_test==i]=1\n",
    "        AUC_ensemble[i]=roc_auc_score(y_label,(-1)*CEtest2[i])\n",
    "    outputs6.append(AUC_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95617938, 0.9917696 , 0.9388218 , 0.96634653, 0.94177902,\n",
       "       0.94717736, 0.86018656, 0.98987613, 0.98272144, 0.98813091])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(outputs6).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00068128, 0.00036138, 0.00132716, 0.00052171, 0.00358254,\n",
       "       0.00304269, 0.00073294, 0.00044329, 0.00076371, 0.00052   ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(outputs6).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_score2=[]\n",
    "for ensemble in outputs5:\n",
    "    AUC_score=[]\n",
    "    for scores in ensemble:\n",
    "        AUC=np.zeros(10)\n",
    "        for i in range(10):\n",
    "            y_label=np.zeros(len(y_test))\n",
    "            y_label[y_test==i]=1\n",
    "            AUC[i]=roc_auc_score(y_label,(-1)*scores[i])\n",
    "        AUC_score.append(AUC)\n",
    "    AUC_score2.append(AUC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9582054 , 0.99161504, 0.93407823, 0.96402192, 0.93795613,\n",
       "        0.95221437, 0.85736133, 0.98875478, 0.98240439, 0.98941911],\n",
       "       [0.94185028, 0.9880062 , 0.94026446, 0.9538541 , 0.94300873,\n",
       "        0.93387923, 0.85555176, 0.9889814 , 0.97308063, 0.98266378],\n",
       "       [0.95359729, 0.99103016, 0.93073933, 0.95895468, 0.93625312,\n",
       "        0.95485663, 0.85152419, 0.98780281, 0.96894348, 0.98701401],\n",
       "       [0.95596527, 0.99185729, 0.93376156, 0.96211399, 0.93819279,\n",
       "        0.93173519, 0.86272012, 0.98796513, 0.97571542, 0.98657862]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(AUC_score2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00155044, 0.00027467, 0.00389312, 0.00150637, 0.00299386,\n",
       "        0.00485335, 0.00179307, 0.00045113, 0.00153467, 0.00115301],\n",
       "       [0.00280302, 0.00045101, 0.00079447, 0.00345202, 0.00560862,\n",
       "        0.00257243, 0.00197692, 0.0006311 , 0.00285045, 0.00337683],\n",
       "       [0.00098214, 0.00058862, 0.00194046, 0.00419895, 0.00304209,\n",
       "        0.00263483, 0.00159805, 0.00040425, 0.0035037 , 0.00131025],\n",
       "       [0.00181084, 0.00055503, 0.00407824, 0.00285717, 0.00430927,\n",
       "        0.00361698, 0.00284274, 0.00058775, 0.00177915, 0.00105826]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(AUC_score2).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9562988733333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(outputs6).mean(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00068128, 0.00036138, 0.00132716, 0.00052171, 0.00358254,\n",
       "       0.00304269, 0.00073294, 0.00044329, 0.00076371, 0.00052   ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(outputs6).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs7=[]\n",
    "outputs7.append(np.array(AUC_score2).mean(axis=0))\n",
    "outputs7.append(np.array(AUC_score2).std(axis=0))\n",
    "outputs7.append(np.array(outputs6).mean(axis=0))\n",
    "outputs7.append(np.array(outputs6).std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.9582054 , 0.99161504, 0.93407823, 0.96402192, 0.93795613,\n",
       "         0.95221437, 0.85736133, 0.98875478, 0.98240439, 0.98941911],\n",
       "        [0.94185028, 0.9880062 , 0.94026446, 0.9538541 , 0.94300873,\n",
       "         0.93387923, 0.85555176, 0.9889814 , 0.97308063, 0.98266378],\n",
       "        [0.95359729, 0.99103016, 0.93073933, 0.95895468, 0.93625312,\n",
       "         0.95485663, 0.85152419, 0.98780281, 0.96894348, 0.98701401],\n",
       "        [0.95596527, 0.99185729, 0.93376156, 0.96211399, 0.93819279,\n",
       "         0.93173519, 0.86272012, 0.98796513, 0.97571542, 0.98657862]]),\n",
       " array([[0.00155044, 0.00027467, 0.00389312, 0.00150637, 0.00299386,\n",
       "         0.00485335, 0.00179307, 0.00045113, 0.00153467, 0.00115301],\n",
       "        [0.00280302, 0.00045101, 0.00079447, 0.00345202, 0.00560862,\n",
       "         0.00257243, 0.00197692, 0.0006311 , 0.00285045, 0.00337683],\n",
       "        [0.00098214, 0.00058862, 0.00194046, 0.00419895, 0.00304209,\n",
       "         0.00263483, 0.00159805, 0.00040425, 0.0035037 , 0.00131025],\n",
       "        [0.00181084, 0.00055503, 0.00407824, 0.00285717, 0.00430927,\n",
       "         0.00361698, 0.00284274, 0.00058775, 0.00177915, 0.00105826]]),\n",
       " array([0.95617938, 0.9917696 , 0.9388218 , 0.96634653, 0.94177902,\n",
       "        0.94717736, 0.86018656, 0.98987613, 0.98272144, 0.98813091]),\n",
       " array([0.00068128, 0.00036138, 0.00132716, 0.00052171, 0.00358254,\n",
       "        0.00304269, 0.00073294, 0.00044329, 0.00076371, 0.00052   ])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "makefile(outputs7,\"ITNensemble/fashionmnist.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
